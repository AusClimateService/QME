Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-10-02 09:24:23,100 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:34833'
2025-10-02 09:24:23,109 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:46859'
2025-10-02 09:24:23,112 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:33675'
2025-10-02 09:24:23,117 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:42029'
2025-10-02 09:24:23,121 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:41891'
2025-10-02 09:24:23,125 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:45523'
2025-10-02 09:24:23,129 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:45545'
2025-10-02 09:24:23,132 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:38449'
2025-10-02 09:24:23,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:42855'
2025-10-02 09:24:23,142 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:36619'
2025-10-02 09:24:23,145 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:33155'
2025-10-02 09:24:23,149 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:45135'
2025-10-02 09:24:23,154 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:43627'
2025-10-02 09:24:23,158 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:36375'
2025-10-02 09:24:23,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:43857'
2025-10-02 09:24:23,175 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:34179'
2025-10-02 09:24:23,179 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:42669'
2025-10-02 09:24:23,183 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:39965'
2025-10-02 09:24:23,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:34607'
2025-10-02 09:24:23,192 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:45935'
2025-10-02 09:24:23,250 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:35331'
2025-10-02 09:24:23,255 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:35381'
2025-10-02 09:24:23,259 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:38581'
2025-10-02 09:24:23,263 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:37859'
2025-10-02 09:24:23,267 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:33001'
2025-10-02 09:24:23,272 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:36897'
2025-10-02 09:24:23,277 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:41449'
2025-10-02 09:24:23,282 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:45047'
2025-10-02 09:24:23,287 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:37623'
2025-10-02 09:24:23,291 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:43923'
2025-10-02 09:24:23,295 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:33729'
2025-10-02 09:24:23,299 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:33775'
2025-10-02 09:24:23,304 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:40321'
2025-10-02 09:24:23,309 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:46531'
2025-10-02 09:24:23,314 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:36449'
2025-10-02 09:24:23,319 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:40703'
2025-10-02 09:24:23,323 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:40629'
2025-10-02 09:24:23,328 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:40477'
2025-10-02 09:24:23,332 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:34325'
2025-10-02 09:24:23,336 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:36389'
2025-10-02 09:24:23,340 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:43289'
2025-10-02 09:24:23,343 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:42087'
2025-10-02 09:24:23,346 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:42399'
2025-10-02 09:24:23,352 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:33161'
2025-10-02 09:24:23,358 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:39545'
2025-10-02 09:24:23,362 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:44175'
2025-10-02 09:24:23,365 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:36465'
2025-10-02 09:24:23,371 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:34725'
2025-10-02 09:24:23,375 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:33877'
2025-10-02 09:24:23,381 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:37947'
2025-10-02 09:24:23,386 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:42019'
2025-10-02 09:24:23,390 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.11:43501'
2025-10-02 09:24:24,352 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:37999
2025-10-02 09:24:24,352 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:40577
2025-10-02 09:24:24,352 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:34289
2025-10-02 09:24:24,352 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:36931
2025-10-02 09:24:24,352 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:37999
2025-10-02 09:24:24,352 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:40577
2025-10-02 09:24:24,352 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:34289
2025-10-02 09:24:24,352 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:36931
2025-10-02 09:24:24,352 - distributed.worker - INFO -          dashboard at:           10.6.83.11:40163
2025-10-02 09:24:24,352 - distributed.worker - INFO -          dashboard at:           10.6.83.11:33449
2025-10-02 09:24:24,352 - distributed.worker - INFO -          dashboard at:           10.6.83.11:41765
2025-10-02 09:24:24,352 - distributed.worker - INFO -          dashboard at:           10.6.83.11:41043
2025-10-02 09:24:24,352 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,352 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,352 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,352 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,352 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,352 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,352 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,352 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,352 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,352 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,352 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,352 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,352 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-b3clvi7o
2025-10-02 09:24:24,352 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-qi16mou8
2025-10-02 09:24:24,352 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-nbud8z5u
2025-10-02 09:24:24,352 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-zio8f17c
2025-10-02 09:24:24,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,352 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,364 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:40655
2025-10-02 09:24:24,364 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:40655
2025-10-02 09:24:24,364 - distributed.worker - INFO -          dashboard at:           10.6.83.11:44179
2025-10-02 09:24:24,364 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,364 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,364 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,364 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,364 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-8n20qhr3
2025-10-02 09:24:24,364 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,374 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:35847
2025-10-02 09:24:24,374 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:35847
2025-10-02 09:24:24,374 - distributed.worker - INFO -          dashboard at:           10.6.83.11:43189
2025-10-02 09:24:24,374 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,374 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,374 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,374 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,375 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-8q7ebfm0
2025-10-02 09:24:24,375 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,387 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:35525
2025-10-02 09:24:24,388 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:35525
2025-10-02 09:24:24,388 - distributed.worker - INFO -          dashboard at:           10.6.83.11:36083
2025-10-02 09:24:24,388 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,388 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,388 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,388 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,388 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-qhdv76ji
2025-10-02 09:24:24,388 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,391 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:42805
2025-10-02 09:24:24,392 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:42805
2025-10-02 09:24:24,392 - distributed.worker - INFO -          dashboard at:           10.6.83.11:41659
2025-10-02 09:24:24,392 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,392 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,392 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,392 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,392 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-92ba9vk6
2025-10-02 09:24:24,392 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,393 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:44731
2025-10-02 09:24:24,393 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:44731
2025-10-02 09:24:24,393 - distributed.worker - INFO -          dashboard at:           10.6.83.11:41893
2025-10-02 09:24:24,393 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,393 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,393 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,393 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,393 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-fu1mcgmj
2025-10-02 09:24:24,393 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,393 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,394 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,394 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,395 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,396 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,396 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,396 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,396 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,397 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,398 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,398 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,398 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:37169
2025-10-02 09:24:24,398 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:37169
2025-10-02 09:24:24,398 - distributed.worker - INFO -          dashboard at:           10.6.83.11:35415
2025-10-02 09:24:24,398 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,398 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,398 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,398 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,398 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-rsdyomfq
2025-10-02 09:24:24,398 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,398 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,399 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,400 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,400 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,400 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,401 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,401 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,401 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,402 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:41545
2025-10-02 09:24:24,402 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:41545
2025-10-02 09:24:24,402 - distributed.worker - INFO -          dashboard at:           10.6.83.11:38029
2025-10-02 09:24:24,402 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,402 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,402 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,402 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,402 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-bzktep9a
2025-10-02 09:24:24,402 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,403 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,405 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:38473
2025-10-02 09:24:24,405 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:38473
2025-10-02 09:24:24,405 - distributed.worker - INFO -          dashboard at:           10.6.83.11:41819
2025-10-02 09:24:24,405 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,405 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,406 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,406 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,406 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-wb0qg_49
2025-10-02 09:24:24,406 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,411 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:33405
2025-10-02 09:24:24,411 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:33405
2025-10-02 09:24:24,411 - distributed.worker - INFO -          dashboard at:           10.6.83.11:42777
2025-10-02 09:24:24,411 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,411 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,411 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,411 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,411 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-timr5uqw
2025-10-02 09:24:24,411 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,414 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:37927
2025-10-02 09:24:24,414 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:37927
2025-10-02 09:24:24,414 - distributed.worker - INFO -          dashboard at:           10.6.83.11:42865
2025-10-02 09:24:24,414 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,414 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,414 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,414 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,414 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-55kjv5ve
2025-10-02 09:24:24,414 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,417 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:38285
2025-10-02 09:24:24,417 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:38285
2025-10-02 09:24:24,417 - distributed.worker - INFO -          dashboard at:           10.6.83.11:40101
2025-10-02 09:24:24,417 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,417 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,417 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,417 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,417 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,417 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-afw5m34p
2025-10-02 09:24:24,417 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,417 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:42435
2025-10-02 09:24:24,418 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:42435
2025-10-02 09:24:24,418 - distributed.worker - INFO -          dashboard at:           10.6.83.11:44867
2025-10-02 09:24:24,418 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,418 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,418 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,418 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,418 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-1avfpqi3
2025-10-02 09:24:24,418 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,418 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,418 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,418 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,419 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,419 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,419 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,420 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,420 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,421 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,421 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:45153
2025-10-02 09:24:24,421 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,421 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:45153
2025-10-02 09:24:24,421 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,421 - distributed.worker - INFO -          dashboard at:           10.6.83.11:46783
2025-10-02 09:24:24,421 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,421 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,421 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,421 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,421 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-suuv9e4m
2025-10-02 09:24:24,421 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,422 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,422 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,422 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,422 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,424 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,424 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,424 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,425 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:38099
2025-10-02 09:24:24,425 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:38099
2025-10-02 09:24:24,425 - distributed.worker - INFO -          dashboard at:           10.6.83.11:44713
2025-10-02 09:24:24,425 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,425 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,425 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,425 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,425 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-pwuqsnz5
2025-10-02 09:24:24,425 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,425 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,425 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,426 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,426 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,428 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,428 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,429 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,429 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:39425
2025-10-02 09:24:24,429 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,429 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:39425
2025-10-02 09:24:24,430 - distributed.worker - INFO -          dashboard at:           10.6.83.11:35247
2025-10-02 09:24:24,430 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,430 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,430 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,430 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,430 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-xlw6n7un
2025-10-02 09:24:24,430 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,430 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,431 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,431 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,431 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,431 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,432 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,432 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,433 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,433 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,434 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,435 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,435 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,436 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,440 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,441 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,441 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,443 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,444 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,445 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,445 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:42329
2025-10-02 09:24:24,445 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,445 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:42329
2025-10-02 09:24:24,446 - distributed.worker - INFO -          dashboard at:           10.6.83.11:40905
2025-10-02 09:24:24,446 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,446 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,446 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,446 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,446 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-8ldpmxe5
2025-10-02 09:24:24,446 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,446 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,447 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,447 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,447 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,447 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:41469
2025-10-02 09:24:24,447 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:41469
2025-10-02 09:24:24,447 - distributed.worker - INFO -          dashboard at:           10.6.83.11:45277
2025-10-02 09:24:24,447 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,447 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,447 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,447 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,447 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-85isja0b
2025-10-02 09:24:24,447 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,448 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,448 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,448 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,449 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,450 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,452 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:35411
2025-10-02 09:24:24,452 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:35411
2025-10-02 09:24:24,452 - distributed.worker - INFO -          dashboard at:           10.6.83.11:44861
2025-10-02 09:24:24,452 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,452 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,452 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,452 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,452 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-n57vv6z4
2025-10-02 09:24:24,452 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,453 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:34153
2025-10-02 09:24:24,453 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:34153
2025-10-02 09:24:24,453 - distributed.worker - INFO -          dashboard at:           10.6.83.11:46681
2025-10-02 09:24:24,453 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,453 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,453 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,453 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,453 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-c08837g3
2025-10-02 09:24:24,453 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,465 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,466 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,466 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,467 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,468 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,468 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,468 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,469 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,472 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,474 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,474 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,474 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,475 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,475 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,475 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,477 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,492 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:38921
2025-10-02 09:24:24,492 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:38921
2025-10-02 09:24:24,492 - distributed.worker - INFO -          dashboard at:           10.6.83.11:45721
2025-10-02 09:24:24,492 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,492 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,492 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,492 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,492 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-iliyk4lt
2025-10-02 09:24:24,492 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,516 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,517 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,517 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,518 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,559 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:45817
2025-10-02 09:24:24,559 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:45817
2025-10-02 09:24:24,560 - distributed.worker - INFO -          dashboard at:           10.6.83.11:46633
2025-10-02 09:24:24,560 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,560 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,560 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,560 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,560 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-gfwx80et
2025-10-02 09:24:24,560 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,581 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,582 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,582 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,584 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,584 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:36629
2025-10-02 09:24:24,585 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:36629
2025-10-02 09:24:24,585 - distributed.worker - INFO -          dashboard at:           10.6.83.11:42099
2025-10-02 09:24:24,585 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,585 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,585 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,585 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-6v9z8sg2
2025-10-02 09:24:24,585 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,589 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:42467
2025-10-02 09:24:24,589 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:42467
2025-10-02 09:24:24,589 - distributed.worker - INFO -          dashboard at:           10.6.83.11:34765
2025-10-02 09:24:24,589 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,589 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,589 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,589 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,589 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-xerfz8dc
2025-10-02 09:24:24,589 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,609 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,610 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,611 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,612 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,613 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,614 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,614 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,615 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,797 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:35851
2025-10-02 09:24:24,797 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:35851
2025-10-02 09:24:24,797 - distributed.worker - INFO -          dashboard at:           10.6.83.11:34193
2025-10-02 09:24:24,797 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,797 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,797 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,797 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,797 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-dp878jjx
2025-10-02 09:24:24,797 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:36933
2025-10-02 09:24:24,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:36933
2025-10-02 09:24:24,801 - distributed.worker - INFO -          dashboard at:           10.6.83.11:42433
2025-10-02 09:24:24,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,801 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,801 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,801 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,801 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-rpnh99k6
2025-10-02 09:24:24,801 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,802 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:44969
2025-10-02 09:24:24,802 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:44969
2025-10-02 09:24:24,802 - distributed.worker - INFO -          dashboard at:           10.6.83.11:35711
2025-10-02 09:24:24,802 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,802 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,802 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,802 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,802 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-dq77y3jo
2025-10-02 09:24:24,802 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,802 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:45975
2025-10-02 09:24:24,802 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:45975
2025-10-02 09:24:24,802 - distributed.worker - INFO -          dashboard at:           10.6.83.11:44515
2025-10-02 09:24:24,802 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,802 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,802 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,802 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,802 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-loj2i4x3
2025-10-02 09:24:24,802 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,803 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:36777
2025-10-02 09:24:24,803 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:36777
2025-10-02 09:24:24,803 - distributed.worker - INFO -          dashboard at:           10.6.83.11:37799
2025-10-02 09:24:24,803 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,803 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,803 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,803 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,803 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-69dkguf7
2025-10-02 09:24:24,803 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,805 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:44535
2025-10-02 09:24:24,805 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:44535
2025-10-02 09:24:24,805 - distributed.worker - INFO -          dashboard at:           10.6.83.11:39547
2025-10-02 09:24:24,805 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,805 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,805 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,805 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,805 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-8xhjkb_t
2025-10-02 09:24:24,805 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,805 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:40097
2025-10-02 09:24:24,805 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:40097
2025-10-02 09:24:24,805 - distributed.worker - INFO -          dashboard at:           10.6.83.11:42915
2025-10-02 09:24:24,805 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,805 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,806 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,806 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,806 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-8ur717a9
2025-10-02 09:24:24,806 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,808 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:36177
2025-10-02 09:24:24,808 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:36177
2025-10-02 09:24:24,808 - distributed.worker - INFO -          dashboard at:           10.6.83.11:43575
2025-10-02 09:24:24,808 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,808 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,808 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,808 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,808 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-comey6uy
2025-10-02 09:24:24,808 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,810 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:45639
2025-10-02 09:24:24,810 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:45639
2025-10-02 09:24:24,810 - distributed.worker - INFO -          dashboard at:           10.6.83.11:40397
2025-10-02 09:24:24,811 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,811 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,811 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,811 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,811 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-2tgxcmng
2025-10-02 09:24:24,811 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,811 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:40913
2025-10-02 09:24:24,811 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:40913
2025-10-02 09:24:24,811 - distributed.worker - INFO -          dashboard at:           10.6.83.11:45637
2025-10-02 09:24:24,811 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,811 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,811 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,811 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,811 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-7cmzngbs
2025-10-02 09:24:24,811 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,813 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:37347
2025-10-02 09:24:24,813 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:39217
2025-10-02 09:24:24,813 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:37347
2025-10-02 09:24:24,813 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:39217
2025-10-02 09:24:24,813 - distributed.worker - INFO -          dashboard at:           10.6.83.11:37693
2025-10-02 09:24:24,813 - distributed.worker - INFO -          dashboard at:           10.6.83.11:34001
2025-10-02 09:24:24,813 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,813 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,813 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,813 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,813 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,813 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,813 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,813 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,813 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-pdedutr1
2025-10-02 09:24:24,813 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-9bc7eywb
2025-10-02 09:24:24,813 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,813 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,814 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:45645
2025-10-02 09:24:24,814 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:45645
2025-10-02 09:24:24,814 - distributed.worker - INFO -          dashboard at:           10.6.83.11:40539
2025-10-02 09:24:24,814 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,814 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,814 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,814 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,814 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,814 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-05x1v7k6
2025-10-02 09:24:24,814 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,814 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,814 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,815 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:32895
2025-10-02 09:24:24,815 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:32895
2025-10-02 09:24:24,815 - distributed.worker - INFO -          dashboard at:           10.6.83.11:34665
2025-10-02 09:24:24,815 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,815 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:33447
2025-10-02 09:24:24,815 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,815 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,815 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:33447
2025-10-02 09:24:24,815 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,815 - distributed.worker - INFO -          dashboard at:           10.6.83.11:44691
2025-10-02 09:24:24,815 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-_wguxav_
2025-10-02 09:24:24,815 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,815 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,815 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,815 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,815 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,815 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,815 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-t_lei6ep
2025-10-02 09:24:24,815 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,817 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:36265
2025-10-02 09:24:24,817 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:36265
2025-10-02 09:24:24,817 - distributed.worker - INFO -          dashboard at:           10.6.83.11:43839
2025-10-02 09:24:24,817 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,817 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,817 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,817 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,817 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-qr_8ane9
2025-10-02 09:24:24,817 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,818 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,819 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,819 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,819 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,823 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,824 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,824 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,824 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:45329
2025-10-02 09:24:24,824 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:43569
2025-10-02 09:24:24,824 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:45329
2025-10-02 09:24:24,824 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:43569
2025-10-02 09:24:24,824 - distributed.worker - INFO -          dashboard at:           10.6.83.11:45069
2025-10-02 09:24:24,824 - distributed.worker - INFO -          dashboard at:           10.6.83.11:42007
2025-10-02 09:24:24,824 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,824 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,824 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,824 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,824 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,825 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,825 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,825 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,825 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,825 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-peirdqu1
2025-10-02 09:24:24,825 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-v80eadj1
2025-10-02 09:24:24,825 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,825 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,825 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:37523
2025-10-02 09:24:24,825 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:37523
2025-10-02 09:24:24,825 - distributed.worker - INFO -          dashboard at:           10.6.83.11:35691
2025-10-02 09:24:24,825 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,825 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,825 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,825 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,825 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-9stn9xgs
2025-10-02 09:24:24,825 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,826 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,827 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,827 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,828 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,829 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:40239
2025-10-02 09:24:24,829 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:40239
2025-10-02 09:24:24,829 - distributed.worker - INFO -          dashboard at:           10.6.83.11:33679
2025-10-02 09:24:24,829 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,829 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,829 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,829 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,829 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-7uz_2b1w
2025-10-02 09:24:24,830 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,833 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:41279
2025-10-02 09:24:24,833 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:41279
2025-10-02 09:24:24,833 - distributed.worker - INFO -          dashboard at:           10.6.83.11:38643
2025-10-02 09:24:24,833 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,833 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,833 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,833 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,833 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-zs7gufk9
2025-10-02 09:24:24,833 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,833 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,834 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:34897
2025-10-02 09:24:24,834 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:34897
2025-10-02 09:24:24,834 - distributed.worker - INFO -          dashboard at:           10.6.83.11:46673
2025-10-02 09:24:24,834 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,834 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,834 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,834 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,834 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-x86qxy96
2025-10-02 09:24:24,834 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,834 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,835 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,835 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,836 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,836 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,837 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,837 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:44317
2025-10-02 09:24:24,837 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:44317
2025-10-02 09:24:24,837 - distributed.worker - INFO -          dashboard at:           10.6.83.11:33663
2025-10-02 09:24:24,837 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,837 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,837 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,837 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,837 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-ee8iaiid
2025-10-02 09:24:24,837 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,838 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,838 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,838 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,839 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,840 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,841 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,841 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,842 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,842 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,842 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,842 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,843 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,843 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,844 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,844 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,845 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,845 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:42179
2025-10-02 09:24:24,845 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:42179
2025-10-02 09:24:24,845 - distributed.worker - INFO -          dashboard at:           10.6.83.11:41167
2025-10-02 09:24:24,845 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,845 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,845 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,845 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,845 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,845 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-co56g0f9
2025-10-02 09:24:24,845 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,845 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,845 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,846 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,847 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,848 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,848 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,849 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,852 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,853 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,853 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,853 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.11:41657
2025-10-02 09:24:24,853 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.11:41657
2025-10-02 09:24:24,853 - distributed.worker - INFO -          dashboard at:           10.6.83.11:45155
2025-10-02 09:24:24,853 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,853 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,853 - distributed.worker - INFO -               Threads:                          2
2025-10-02 09:24:24,853 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-02 09:24:24,853 - distributed.worker - INFO -       Local Directory: /jobfs/151413012.gadi-pbs/dask-scratch-space/worker-cg631x36
2025-10-02 09:24:24,853 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,853 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,854 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,854 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,855 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,855 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,855 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,856 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,856 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,856 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,857 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,857 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,857 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,858 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,858 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,859 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,859 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,859 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,860 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,860 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,860 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,861 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,861 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,861 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,862 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,862 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,862 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,862 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,863 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,863 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,863 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,864 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,864 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,864 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,865 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,865 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,865 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,866 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,866 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,866 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,866 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,867 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,868 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,869 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,869 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,870 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:24,876 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-02 09:24:24,877 - distributed.worker - INFO -         Registered to:       tcp://10.6.83.1:8728
2025-10-02 09:24:24,877 - distributed.worker - INFO - -------------------------------------------------
2025-10-02 09:24:24,878 - distributed.core - INFO - Starting established connection to tcp://10.6.83.1:8728
2025-10-02 09:24:56,268 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,268 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,268 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,269 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,269 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,269 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,269 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,269 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,269 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,270 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,270 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,270 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,270 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,270 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,270 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,270 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,271 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,271 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,271 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,271 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,271 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,271 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,271 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,271 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,271 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,271 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,272 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,272 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,272 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,272 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,272 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,272 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,272 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,272 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,272 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,272 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,273 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,273 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,271 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,273 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,273 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,274 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,274 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,274 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,274 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,274 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,275 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,275 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,275 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,275 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,275 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,273 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,275 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,274 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,276 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,277 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,275 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,275 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,276 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,276 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,276 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,276 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,277 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,277 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,278 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,278 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,278 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 09:24:56,281 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,282 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,284 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,284 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,284 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,285 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,286 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,286 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,287 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,287 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,287 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,288 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,288 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,288 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,289 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,289 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:56,291 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-02 09:24:59,022 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,027 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,027 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,027 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,029 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 09:24:59,031 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,031 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,031 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,031 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,031 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,031 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,031 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,031 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,034 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,034 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-02 09:24:59,420 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,420 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,420 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,420 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,421 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,421 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,421 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,421 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,421 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,421 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,422 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,422 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,422 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,422 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,422 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,422 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,422 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,422 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,422 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,423 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,423 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,423 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,423 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,423 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,423 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,423 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,424 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,424 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,424 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,424 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,424 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,424 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,424 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,424 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,424 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,424 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,425 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,425 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,425 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,425 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,425 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,425 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,425 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,425 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,425 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,425 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,425 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,425 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,425 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,426 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,426 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,426 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,426 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,426 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,426 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,426 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,426 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,426 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,426 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,426 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,426 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,427 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,427 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,427 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,427 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,427 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,427 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,427 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,427 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 09:24:59,428 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,428 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,428 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,428 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,428 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,428 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,428 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,428 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,428 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,429 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,430 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,430 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,430 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,430 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,430 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,431 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-02 09:24:59,857 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,857 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,857 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,858 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,858 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,858 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,858 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,858 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,858 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,858 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,858 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,858 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,859 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,859 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,859 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,859 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,859 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,859 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,860 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,860 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,860 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,860 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,860 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,860 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,860 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,860 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,860 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,860 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,860 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,861 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,862 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,862 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,862 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,862 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,862 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,862 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,862 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,863 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,863 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,862 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,863 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,863 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,863 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,863 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,863 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,863 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,863 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,863 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,863 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,863 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,864 - distributed.worker - INFO - Starting Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 09:24:59,864 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,864 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,864 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,864 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,864 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,864 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,865 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,865 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,865 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,865 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,865 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,866 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,866 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,866 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,866 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,866 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,866 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,866 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,866 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,867 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,867 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,867 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:24:59,867 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-02 09:25:23,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,810 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 09:25:23,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-10-02 19:25:43,478 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,514 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:42329. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,480 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,514 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:35525. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,515 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:45639. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,515 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:42435. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,478 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,515 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:44731. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,478 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,515 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:37927. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,481 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,516 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:36931. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,516 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:40577. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,516 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:37347. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,480 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,479 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59116 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,516 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:34153. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,478 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59308 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,516 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:42467. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,517 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:45153. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,516 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:42805. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,481 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,517 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:45817. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,480 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,517 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:39217. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,479 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,518 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:33405. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,479 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59168 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,518 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:38473. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,478 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59296 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,518 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:35411. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,478 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59356 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,519 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:41469. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,478 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59326 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,478 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59294 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,482 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,497 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,520 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,517 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,518 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,520 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,520 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,520 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:42179. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,520 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:44969. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,520 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:38921. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,520 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:44317. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,520 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:40239. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,521 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:36265. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,520 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,523 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:35851. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,518 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59240 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,520 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,525 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:33447. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,525 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:36629. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,520 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59276 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,525 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59254 remote=tcp://10.6.83.1:8728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-02 19:25:43,531 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:36619'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,533 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:38449'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,533 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,534 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:37623'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,534 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,534 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,534 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:45545'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,534 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,534 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,534 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,534 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:34179'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,534 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,534 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,535 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:38581'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,535 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:33675'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,535 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,536 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,537 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,540 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:35331'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,540 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,540 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,540 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,540 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:34607'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,541 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,541 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:43923'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,541 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:43857'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,541 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,541 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,541 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:40629'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,541 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,541 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,541 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,541 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,542 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:33001'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,542 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,542 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:45523'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,542 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:41891'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,542 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,542 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:45935'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,543 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,544 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,544 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,544 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,544 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,544 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,544 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,544 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,544 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,545 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,545 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,545 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,545 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,546 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,546 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,547 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:35381'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,547 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:33155'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,548 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,548 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,548 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:36465'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,548 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:43289'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,548 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,548 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:46531'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,548 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,548 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:37859'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,548 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,549 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:33775'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,549 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:42087'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,549 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:44175'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,549 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:40703'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,549 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,550 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,551 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,551 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,551 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:43501'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,551 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,551 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,552 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,552 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,552 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,552 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,552 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,552 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,552 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,552 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,554 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,554 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,554 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,554 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,556 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,556 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,556 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,556 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,557 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,557 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,559 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,559 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,560 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,562 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,562 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,563 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,563 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,564 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:43,613 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,607 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,622 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:36933. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,624 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:36777. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,634 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:45329. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,653 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:36389'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,653 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,656 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:44535. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,664 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 11, 0, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,670 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,676 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,665 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,673 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,677 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:41279. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,681 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,682 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:45645. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,687 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,692 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,699 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,709 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:37999. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,711 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,711 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,705 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,719 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:38285. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,720 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:32895. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,722 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:40655. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,745 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,748 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:37169. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,751 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:36897'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,745 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,759 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:40321'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,762 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:35847. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,770 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 8, 11, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,775 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,781 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,783 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 15, 17, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,783 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:43627'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,786 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,777 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,791 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:45047'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,791 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,792 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:36375'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,794 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:38099. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,794 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 5, 15, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,797 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,800 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,802 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 13, 9, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,806 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,804 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,797 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,808 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,811 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,812 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:34289. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,813 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:41545. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,814 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,816 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,818 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:45135'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,819 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,819 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,820 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:42019'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,821 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,824 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,825 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,829 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,827 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,830 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,831 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 11, 14, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,835 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 6, 13, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,835 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,835 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:41657. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,837 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,836 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,840 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,840 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,843 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,839 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,844 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:34897. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,846 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,848 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,848 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:40913. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,849 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:34833'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,852 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,852 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:34725'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,853 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,857 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,855 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,858 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,860 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 14, 1, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,862 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,863 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:33161'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,863 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:46859'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,861 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:43,864 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:39425. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,866 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,869 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:40097. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,872 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,875 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 13, 16, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,877 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,883 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,884 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 16, 0, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,888 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,623 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59202 remote=tcp://10.6.83.1:8728>: Stream is closed
2025-10-02 19:25:43,902 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:43,903 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:41449'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,655 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.83.11:59130 remote=tcp://10.6.83.1:8728>: Stream is closed
2025-10-02 19:25:43,907 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:43,909 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:39965'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,913 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:43,918 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:43,919 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:42029'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,923 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:43,937 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:42855'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,942 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 1, 13, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,950 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:37947'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,951 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:42669'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:43,954 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 1, 21, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,967 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 2, 2, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:43,992 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 6, 17, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,045 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,050 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,055 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,061 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,066 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,080 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 1, 8, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,084 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:44,092 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:45975. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,102 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:44,111 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:36177. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,112 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,114 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:44,117 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,123 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,123 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:37523. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,128 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,133 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,150 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 4, 4, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,152 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 4, 3, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,162 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:40477'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,172 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,177 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,182 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,188 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,188 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,193 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,194 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,198 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,199 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,200 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:34325'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,204 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,204 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,210 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,210 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,215 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,220 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,231 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,236 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,242 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,247 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,247 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 11, 20, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,250 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,250 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 12, 6, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,252 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,255 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,261 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,266 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,266 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,269 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 3, 16, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,271 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,272 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,275 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,277 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,280 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,282 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,286 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,287 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,291 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,295 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,296 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,306 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,311 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,323 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,329 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,334 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,333 - distributed.core - INFO - Connection to tcp://10.6.83.1:8728 has been closed.
2025-10-02 19:25:44,339 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,342 - distributed.worker - INFO - Stopping worker at tcp://10.6.83.11:43569. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,197 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,477 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:36449'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,176 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,532 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:33877'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,626 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 6, 21, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,648 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:39545'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:44,668 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,673 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,679 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,684 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,689 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,706 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 0, 1, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,712 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,717 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,723 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,726 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 8, 3, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:44,728 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,733 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,339 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14cbc8a2b010>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,391 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14a034714050>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,400 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,825 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:44,830 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:44,836 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:44,841 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:44,846 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:44,491 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,749 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14a76c86b7d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,785 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14c0a895d9d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,760 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14c9d23acb90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:44,853 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14b19a5ac210>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:45,544 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,544 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,544 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,546 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,549 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,550 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,551 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,552 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,556 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,557 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,558 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,558 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,560 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,560 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,560 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,561 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,561 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,562 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,563 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,563 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,565 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,566 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,566 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:45,252 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ca0831cb90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:45,809 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:42399'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:45,848 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:38449'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,850 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:37623'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,852 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:38449' closed.
2025-10-02 19:25:45,853 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:37623' closed.
2025-10-02 19:25:45,855 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:33775'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,856 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:33775' closed.
2025-10-02 19:25:45,858 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:36619'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,859 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:36619' closed.
2025-10-02 19:25:45,902 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:43923'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,903 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:43923' closed.
2025-10-02 19:25:45,908 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:46531'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,908 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:46531' closed.
2025-10-02 19:25:45,974 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:41891'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,983 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:41891' closed.
2025-10-02 19:25:45,998 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:34179'. Reason: nanny-close-gracefully
2025-10-02 19:25:45,999 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:34179' closed.
2025-10-02 19:25:46,018 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:42087'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,022 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:42087' closed.
2025-10-02 19:25:46,124 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:45545'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,128 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:38581'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,129 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:45545' closed.
2025-10-02 19:25:46,130 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:38581' closed.
2025-10-02 19:25:46,136 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:43289'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,137 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:43289' closed.
2025-10-02 19:25:46,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:40629'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,143 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:40629' closed.
2025-10-02 19:25:46,162 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:33675'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,164 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:33675' closed.
2025-10-02 19:25:46,187 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:43501'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,188 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:43501' closed.
2025-10-02 19:25:46,190 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:36465'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,192 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:34607'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,193 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:36465' closed.
2025-10-02 19:25:46,193 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:34607' closed.
2025-10-02 19:25:46,204 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:43857'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,206 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:43857' closed.
2025-10-02 19:25:46,246 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:45523'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,247 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:45523' closed.
2025-10-02 19:25:46,261 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:33155'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,262 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:33155' closed.
2025-10-02 19:25:46,308 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:33001'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,309 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:33001' closed.
2025-10-02 19:25:46,312 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:45935'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,313 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:37859'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,314 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:45935' closed.
2025-10-02 19:25:46,314 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:37859' closed.
2025-10-02 19:25:46,352 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:40703'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,353 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:40703' closed.
2025-10-02 19:25:46,366 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:35381'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,367 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:35381' closed.
2025-10-02 19:25:46,390 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:44175'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,396 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:44175' closed.
2025-10-02 19:25:46,418 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:35331'. Reason: nanny-close-gracefully
2025-10-02 19:25:46,419 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:35331' closed.
2025-10-02 19:25:46,547 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-vectorize_count_dist-vectorize_count_dist_0-transpose-b96e810c809ee6f674372a61e71c6a58', 9, 3, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:46,857 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:46,862 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:46,868 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:46,870 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.83.11:33729'. Reason: worker-handle-scheduler-connection-broken
2025-10-02 19:25:46,873 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:46,878 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:47,569 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('getitem-open_dataset-tas-vectorize_count_dist-vectorize_count_dist_0-transpose-8ed21b9130c99dbf2e08f6c98849c361', 9, 19, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-10-02 19:25:47,305 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14bf35906550>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:47,852 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-02 19:25:47,858 - distributed.worker - INFO - Removing Worker plugin qme_utils.pyded5daa7-7007-47f6-ad27-3b0ac9da2b87
2025-10-02 19:25:47,863 - distributed.worker - INFO - Removing Worker plugin qme_vars.py562be83c-1ca7-4bdc-9337-bb154c7b8f74
2025-10-02 19:25:47,868 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb23b4f7a-3d99-4e2f-8599-9faead5e5cc0
2025-10-02 19:25:47,873 - distributed.worker - INFO - Removing Worker plugin qme_apply.py52c91d12-ae3f-4ab5-b0e4-d44fef9dc495
2025-10-02 19:25:48,051 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-02 19:25:50,204 - distributed.nanny - INFO - Worker closed
2025-10-02 19:25:52,209 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-02 19:25:52,672 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.83.11:42669'. Reason: nanny-close-gracefully
2025-10-02 19:25:52,674 - distributed.nanny - INFO - Nanny at 'tcp://10.6.83.11:42669' closed.
