Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-05 09:11:42,918 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:41989'
2025-09-05 09:11:42,927 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:34015'
2025-09-05 09:11:42,931 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:42685'
2025-09-05 09:11:42,935 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:46495'
2025-09-05 09:11:42,939 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:40443'
2025-09-05 09:11:42,945 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:35301'
2025-09-05 09:11:42,948 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:45271'
2025-09-05 09:11:42,952 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:41599'
2025-09-05 09:11:42,957 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:32769'
2025-09-05 09:11:42,963 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:45191'
2025-09-05 09:11:42,968 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:35237'
2025-09-05 09:11:42,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:44473'
2025-09-05 09:11:42,976 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:39651'
2025-09-05 09:11:42,981 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:38739'
2025-09-05 09:11:42,985 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:43621'
2025-09-05 09:11:42,989 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:34089'
2025-09-05 09:11:42,993 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:37629'
2025-09-05 09:11:42,997 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:39187'
2025-09-05 09:11:43,002 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:33029'
2025-09-05 09:11:43,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:41005'
2025-09-05 09:11:43,079 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:43395'
2025-09-05 09:11:43,083 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:37793'
2025-09-05 09:11:43,087 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:43305'
2025-09-05 09:11:43,092 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:43879'
2025-09-05 09:11:43,095 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:34647'
2025-09-05 09:11:43,102 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:44967'
2025-09-05 09:11:43,105 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:44099'
2025-09-05 09:11:43,110 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:38175'
2025-09-05 09:11:43,114 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:46341'
2025-09-05 09:11:43,118 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:37197'
2025-09-05 09:11:43,122 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:40661'
2025-09-05 09:11:43,127 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:36111'
2025-09-05 09:11:43,131 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:36517'
2025-09-05 09:11:43,135 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:34325'
2025-09-05 09:11:43,140 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:43579'
2025-09-05 09:11:43,144 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:33841'
2025-09-05 09:11:43,149 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:38685'
2025-09-05 09:11:43,154 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:36409'
2025-09-05 09:11:43,157 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:32867'
2025-09-05 09:11:43,162 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:45463'
2025-09-05 09:11:43,166 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:33529'
2025-09-05 09:11:43,170 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:45997'
2025-09-05 09:11:43,175 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:41107'
2025-09-05 09:11:43,180 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:34261'
2025-09-05 09:11:43,184 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:36899'
2025-09-05 09:11:43,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:34173'
2025-09-05 09:11:43,193 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:33449'
2025-09-05 09:11:43,197 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:37593'
2025-09-05 09:11:43,201 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:46133'
2025-09-05 09:11:43,205 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:44021'
2025-09-05 09:11:43,209 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:37019'
2025-09-05 09:11:43,213 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.56:38215'
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:44597
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:45197
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:39485
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:42399
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:46527
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:44375
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:36129
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:38157
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:36073
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:43389
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:40493
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:44739
2025-09-05 09:11:44,216 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:44597
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:44529
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:39505
2025-09-05 09:11:44,216 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:45197
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:37039
2025-09-05 09:11:44,216 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:39485
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:35663
2025-09-05 09:11:44,216 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:42399
2025-09-05 09:11:44,216 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:46527
2025-09-05 09:11:44,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:38183
2025-09-05 09:11:44,216 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:44375
2025-09-05 09:11:44,216 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:36129
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:38157
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:36073
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:43389
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:40493
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:44739
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:43289
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:44529
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:39505
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:41601
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:37039
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:36395
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:35663
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:38745
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:42333
2025-09-05 09:11:44,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:38183
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:45935
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:35061
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:36249
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:33939
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:36229
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:33287
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:46385
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:42325
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:33535
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:34065
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:43877
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO -          dashboard at:          10.6.101.56:35909
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-t19z1bgh
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-dlx9o321
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-5ur3xvtt
2025-09-05 09:11:44,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,217 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-0_grx0i1
2025-09-05 09:11:44,217 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-u2gqnr_z
2025-09-05 09:11:44,218 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-qtxg7_9n
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-u3_p_d9x
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-0pj4ed4a
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-admxnm84
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-h5as6t0v
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-bbjfxkmj
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-pjz4bqi_
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-7z3ezwcw
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-hkgpdexm
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-t894yq4n
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-hbmc65gu
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-h9cy0g1s
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,221 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:43335
2025-09-05 09:11:44,221 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:43335
2025-09-05 09:11:44,221 - distributed.worker - INFO -          dashboard at:          10.6.101.56:40973
2025-09-05 09:11:44,221 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,221 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,221 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,221 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,221 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-i513rdt8
2025-09-05 09:11:44,221 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,243 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,243 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,243 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,244 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,247 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,248 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,248 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,249 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,251 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,251 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,252 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,253 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,255 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,255 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,257 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,258 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,259 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,259 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,261 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,261 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,262 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,262 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,263 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,264 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,264 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,264 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,266 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,267 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,268 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,268 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,269 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,270 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,270 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,271 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,272 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,272 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,272 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,273 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,274 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,274 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,274 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,275 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,276 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,276 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,276 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,277 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,278 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,278 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,279 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,280 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,280 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,281 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,282 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,282 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,282 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,283 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,283 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,284 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,284 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,285 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,285 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,285 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,287 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,287 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,288 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,290 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,366 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:44851
2025-09-05 09:11:44,366 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:44851
2025-09-05 09:11:44,366 - distributed.worker - INFO -          dashboard at:          10.6.101.56:42397
2025-09-05 09:11:44,366 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,366 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,366 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,366 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,366 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-nyty8wez
2025-09-05 09:11:44,366 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,366 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:40221
2025-09-05 09:11:44,366 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:40221
2025-09-05 09:11:44,367 - distributed.worker - INFO -          dashboard at:          10.6.101.56:40045
2025-09-05 09:11:44,367 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,367 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,367 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,367 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,367 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-wosow92h
2025-09-05 09:11:44,367 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,391 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,392 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,394 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:42721
2025-09-05 09:11:44,394 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:42721
2025-09-05 09:11:44,394 - distributed.worker - INFO -          dashboard at:          10.6.101.56:42143
2025-09-05 09:11:44,394 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,394 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,394 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,394 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,394 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-dk4q2ts6
2025-09-05 09:11:44,394 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,394 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,397 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,399 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,399 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,400 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,418 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:44675
2025-09-05 09:11:44,418 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:44675
2025-09-05 09:11:44,418 - distributed.worker - INFO -          dashboard at:          10.6.101.56:41163
2025-09-05 09:11:44,418 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,418 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,418 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,418 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,418 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-4277ddhw
2025-09-05 09:11:44,418 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,421 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,422 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,422 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,423 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,434 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,434 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,434 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,435 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,461 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:35425
2025-09-05 09:11:44,461 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:35425
2025-09-05 09:11:44,461 - distributed.worker - INFO -          dashboard at:          10.6.101.56:35931
2025-09-05 09:11:44,461 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,461 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,461 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,461 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,461 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-q4de5nv7
2025-09-05 09:11:44,461 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,472 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:41839
2025-09-05 09:11:44,472 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:41839
2025-09-05 09:11:44,472 - distributed.worker - INFO -          dashboard at:          10.6.101.56:44759
2025-09-05 09:11:44,472 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,472 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,472 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,472 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,472 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-4epvio7d
2025-09-05 09:11:44,472 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,475 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,475 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,475 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,476 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,485 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:40555
2025-09-05 09:11:44,485 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:40555
2025-09-05 09:11:44,485 - distributed.worker - INFO -          dashboard at:          10.6.101.56:43441
2025-09-05 09:11:44,485 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,485 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,485 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,485 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,485 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8sp361q0
2025-09-05 09:11:44,485 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,499 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,500 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,500 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,502 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,508 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:38715
2025-09-05 09:11:44,509 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:38715
2025-09-05 09:11:44,509 - distributed.worker - INFO -          dashboard at:          10.6.101.56:40067
2025-09-05 09:11:44,509 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,509 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,509 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,509 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,509 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-b40lqjki
2025-09-05 09:11:44,509 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,513 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,514 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,514 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,516 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,530 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:33953
2025-09-05 09:11:44,530 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:33953
2025-09-05 09:11:44,530 - distributed.worker - INFO -          dashboard at:          10.6.101.56:44765
2025-09-05 09:11:44,531 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,531 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,531 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,531 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,531 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-2ixxgfuo
2025-09-05 09:11:44,531 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,538 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,539 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,540 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,552 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,552 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,553 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,554 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:35491
2025-09-05 09:11:44,555 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:35491
2025-09-05 09:11:44,555 - distributed.worker - INFO -          dashboard at:          10.6.101.56:46083
2025-09-05 09:11:44,555 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,555 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,555 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,555 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-96mx55ql
2025-09-05 09:11:44,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,559 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:40117
2025-09-05 09:11:44,559 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:40117
2025-09-05 09:11:44,559 - distributed.worker - INFO -          dashboard at:          10.6.101.56:37621
2025-09-05 09:11:44,559 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,559 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,559 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,559 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,559 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-x2bgpyyp
2025-09-05 09:11:44,559 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,577 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,578 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,578 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,579 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,584 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,585 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,585 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,586 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,604 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:45705
2025-09-05 09:11:44,604 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:45705
2025-09-05 09:11:44,604 - distributed.worker - INFO -          dashboard at:          10.6.101.56:41263
2025-09-05 09:11:44,604 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,604 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,604 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,604 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-effxrma9
2025-09-05 09:11:44,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,630 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,630 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,630 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,632 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,730 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:33963
2025-09-05 09:11:44,731 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:33963
2025-09-05 09:11:44,731 - distributed.worker - INFO -          dashboard at:          10.6.101.56:37797
2025-09-05 09:11:44,731 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,731 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,731 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,731 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,731 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-h91eywh4
2025-09-05 09:11:44,731 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,739 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:38881
2025-09-05 09:11:44,739 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:38881
2025-09-05 09:11:44,739 - distributed.worker - INFO -          dashboard at:          10.6.101.56:44139
2025-09-05 09:11:44,739 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,739 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,739 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,739 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ul3d74qj
2025-09-05 09:11:44,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,742 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:43707
2025-09-05 09:11:44,742 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:43707
2025-09-05 09:11:44,742 - distributed.worker - INFO -          dashboard at:          10.6.101.56:40297
2025-09-05 09:11:44,742 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,742 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,742 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,742 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ftgdljvh
2025-09-05 09:11:44,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,742 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:32793
2025-09-05 09:11:44,742 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:32793
2025-09-05 09:11:44,743 - distributed.worker - INFO -          dashboard at:          10.6.101.56:45057
2025-09-05 09:11:44,743 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,743 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,743 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,743 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-z398gwx9
2025-09-05 09:11:44,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,745 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:33059
2025-09-05 09:11:44,745 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:33059
2025-09-05 09:11:44,745 - distributed.worker - INFO -          dashboard at:          10.6.101.56:44561
2025-09-05 09:11:44,745 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,746 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,746 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,746 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-f1hy6rfm
2025-09-05 09:11:44,746 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,751 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:33177
2025-09-05 09:11:44,751 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:33177
2025-09-05 09:11:44,751 - distributed.worker - INFO -          dashboard at:          10.6.101.56:42699
2025-09-05 09:11:44,751 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,751 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,751 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,751 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,751 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-uduy8dsg
2025-09-05 09:11:44,751 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,752 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:40265
2025-09-05 09:11:44,752 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:40265
2025-09-05 09:11:44,752 - distributed.worker - INFO -          dashboard at:          10.6.101.56:37639
2025-09-05 09:11:44,752 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,752 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,752 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,752 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-tliohofh
2025-09-05 09:11:44,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,755 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:44183
2025-09-05 09:11:44,755 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:44183
2025-09-05 09:11:44,755 - distributed.worker - INFO -          dashboard at:          10.6.101.56:35093
2025-09-05 09:11:44,755 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,755 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,755 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,755 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-q_pn18c4
2025-09-05 09:11:44,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,756 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:39351
2025-09-05 09:11:44,756 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:39351
2025-09-05 09:11:44,756 - distributed.worker - INFO -          dashboard at:          10.6.101.56:40145
2025-09-05 09:11:44,756 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,756 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,756 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:43775
2025-09-05 09:11:44,756 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,756 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:43775
2025-09-05 09:11:44,756 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,756 - distributed.worker - INFO -          dashboard at:          10.6.101.56:33043
2025-09-05 09:11:44,756 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8lkt4g94
2025-09-05 09:11:44,756 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,756 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,756 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,756 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,756 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,756 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-wzuphing
2025-09-05 09:11:44,756 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,767 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:37573
2025-09-05 09:11:44,767 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:37573
2025-09-05 09:11:44,767 - distributed.worker - INFO -          dashboard at:          10.6.101.56:38627
2025-09-05 09:11:44,767 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,767 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,767 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,767 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-nhdzpxpl
2025-09-05 09:11:44,767 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:33251
2025-09-05 09:11:44,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,767 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:33251
2025-09-05 09:11:44,767 - distributed.worker - INFO -          dashboard at:          10.6.101.56:38511
2025-09-05 09:11:44,767 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,767 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,767 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,767 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-f2vt4s2f
2025-09-05 09:11:44,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,768 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:36391
2025-09-05 09:11:44,768 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:36391
2025-09-05 09:11:44,768 - distributed.worker - INFO -          dashboard at:          10.6.101.56:45821
2025-09-05 09:11:44,768 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,768 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,768 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,768 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,768 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-17gv9w_g
2025-09-05 09:11:44,768 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,771 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:40647
2025-09-05 09:11:44,771 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:40647
2025-09-05 09:11:44,771 - distributed.worker - INFO -          dashboard at:          10.6.101.56:42183
2025-09-05 09:11:44,771 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,771 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,771 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,771 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,771 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-6mrsgww7
2025-09-05 09:11:44,771 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,772 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:33523
2025-09-05 09:11:44,772 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:33523
2025-09-05 09:11:44,772 - distributed.worker - INFO -          dashboard at:          10.6.101.56:42831
2025-09-05 09:11:44,772 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,772 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,772 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,772 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,772 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-01yn2cc_
2025-09-05 09:11:44,772 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,773 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:33799
2025-09-05 09:11:44,773 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:33799
2025-09-05 09:11:44,773 - distributed.worker - INFO -          dashboard at:          10.6.101.56:33165
2025-09-05 09:11:44,773 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,773 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,773 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,773 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-bep2pbb5
2025-09-05 09:11:44,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,773 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:33389
2025-09-05 09:11:44,773 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:33389
2025-09-05 09:11:44,773 - distributed.worker - INFO -          dashboard at:          10.6.101.56:32939
2025-09-05 09:11:44,773 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,773 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,773 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,773 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-65n0site
2025-09-05 09:11:44,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,779 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:44833
2025-09-05 09:11:44,779 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:44833
2025-09-05 09:11:44,779 - distributed.worker - INFO -          dashboard at:          10.6.101.56:33045
2025-09-05 09:11:44,779 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,779 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,779 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,779 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-i5k5g0e8
2025-09-05 09:11:44,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,781 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:33289
2025-09-05 09:11:44,781 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:33289
2025-09-05 09:11:44,781 - distributed.worker - INFO -          dashboard at:          10.6.101.56:33585
2025-09-05 09:11:44,781 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,781 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,781 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,781 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,781 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-e3pjzx0b
2025-09-05 09:11:44,781 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,786 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:44513
2025-09-05 09:11:44,786 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:44513
2025-09-05 09:11:44,786 - distributed.worker - INFO -          dashboard at:          10.6.101.56:35783
2025-09-05 09:11:44,786 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,786 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,786 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,786 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,786 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-q6y8rbnw
2025-09-05 09:11:44,786 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,790 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:40229
2025-09-05 09:11:44,790 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:40229
2025-09-05 09:11:44,790 - distributed.worker - INFO -          dashboard at:          10.6.101.56:36609
2025-09-05 09:11:44,790 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,790 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,790 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,790 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,790 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-tnz8udod
2025-09-05 09:11:44,790 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,790 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,791 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,791 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,791 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,795 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,795 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,795 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,796 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,800 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,801 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,803 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,803 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,803 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,805 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,805 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,806 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.56:42087
2025-09-05 09:11:44,806 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.56:42087
2025-09-05 09:11:44,806 - distributed.worker - INFO -          dashboard at:          10.6.101.56:38687
2025-09-05 09:11:44,806 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,806 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,806 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,806 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,806 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-2o_r8csa
2025-09-05 09:11:44,806 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,806 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,806 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,807 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,807 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,808 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,808 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,809 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,809 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,810 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,810 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,811 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,812 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,812 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,812 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,813 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,813 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,813 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,814 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,815 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,815 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,815 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,816 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,817 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,817 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,817 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,817 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,818 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,818 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,819 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,820 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,821 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,822 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,822 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,824 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,824 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,825 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,826 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,827 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,828 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,829 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,829 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,829 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,830 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,830 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,831 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,831 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,832 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,832 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,832 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,832 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,833 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,834 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,834 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,835 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,835 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,835 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,837 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,837 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,838 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,838 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,840 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,841 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,841 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,842 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,859 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,860 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,860 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,862 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:12:06,675 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,676 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,676 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,676 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,676 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,676 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,676 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,677 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,677 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,677 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,677 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,677 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,677 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,678 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,677 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,678 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,678 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,678 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,678 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,678 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,678 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,678 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,678 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,678 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,678 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,679 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,679 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,679 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,679 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,679 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,679 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,679 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,679 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,679 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,679 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,679 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,680 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,680 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,680 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,680 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,680 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,680 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,680 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,681 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,681 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,681 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,681 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,681 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,681 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,682 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,680 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,683 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,683 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,683 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,683 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,683 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,682 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,684 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,684 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,682 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,682 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,684 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,684 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,683 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,682 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,685 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,685 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,683 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,684 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,685 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,690 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,690 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,691 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,695 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:09,477 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,477 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,477 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,477 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,477 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,479 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,479 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,479 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,479 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,479 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,479 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,479 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,481 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,482 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,482 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,482 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,482 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,482 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,482 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,480 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,482 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,482 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,482 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,479 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,482 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,483 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,483 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,483 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,483 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,484 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,484 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,484 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,482 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,484 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,484 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,484 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,484 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,483 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,482 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,481 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,483 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,485 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,486 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,486 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,483 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,486 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,482 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,486 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,486 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,487 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,487 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,484 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,487 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,488 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,488 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,488 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,488 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,488 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,489 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,489 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,860 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,861 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,861 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,861 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,861 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,861 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,861 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,861 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,861 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,861 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,862 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,862 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,862 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,862 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,862 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,862 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,862 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,862 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,863 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,863 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,863 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,863 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,863 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,863 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,863 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,863 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,863 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,864 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,864 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,864 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,864 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,864 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,864 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,864 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,864 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,864 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,864 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,865 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,865 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,865 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,865 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,865 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,865 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,865 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,865 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,865 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,865 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,865 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,865 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,865 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,865 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,865 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,865 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,866 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,866 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,866 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,866 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,866 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,866 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,866 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,866 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,867 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,868 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,868 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,868 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,868 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,868 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,868 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,868 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,868 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,869 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,869 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,869 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,869 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,869 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,869 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,869 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,869 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,869 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,870 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,870 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,870 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,870 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,871 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:10,319 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,319 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,319 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,319 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,319 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,319 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,319 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,320 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,320 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,320 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,320 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,320 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,320 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,320 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,321 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,321 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,321 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,321 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,321 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,321 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,321 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,321 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,321 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,322 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,321 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,322 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,322 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,323 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,323 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,323 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,323 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,323 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,323 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,323 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,323 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,323 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,323 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,323 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,323 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,323 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,323 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,323 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,323 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,323 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,324 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,324 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,324 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,324 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,324 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,324 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,324 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,324 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,324 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,324 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,324 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,324 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,325 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,325 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,325 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,325 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,325 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,326 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,325 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,325 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,325 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,325 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,325 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,325 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,325 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,326 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,326 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,326 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,326 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,326 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,327 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,327 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,327 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,327 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,327 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,327 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,327 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,327 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,328 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,328 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,328 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,328 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,328 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,328 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:16:17,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,442 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:00,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:04,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:04,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:06,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:10,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:10,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:10,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,779 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:28,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:29,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:32,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:33,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:33,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:33,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:33,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,330 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,824 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,824 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:40,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:41,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:41,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:44,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:51,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:55,108 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:55,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:57,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:57,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:59,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:59,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:59,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:59,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:59,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:59,684 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:01,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:05,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:09,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:09,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:10,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:11,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:11,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:12,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:12,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:12,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:14,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:14,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:18,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:32,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:39,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:39,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:42,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:42,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:42,936 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,142 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,142 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:52,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:54,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:06,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,207 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,947 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:15,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:16,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:16,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:16,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:17,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,467 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,146 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,447 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,903 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,223 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,947 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:52,316 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:52,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:52,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:54,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:55,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:56,107 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:56,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:56,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:56,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:03,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:03,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:03,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:06,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:10,865 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.101.37:45833
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
                ^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.56:54456 remote=tcp://10.6.101.37:45833>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:37573. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:36391. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:40229. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:40265. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:43707. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:33059. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:33799. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:33963. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:38881. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:43775. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:33289. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:33389. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:33177. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:39351. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:44833. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:39485. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:32793. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:33251. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:33523. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:44529. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:46527. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:37039. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:40493. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:42399. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:45197. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:44513. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:44375. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:33953. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:44597. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:44183. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:41839. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:44739. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:35425. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:43335. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:38715. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:40555. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:39505. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:40117. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:35663. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:44851. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:42721. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:35491. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:45705. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:44675. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,277 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:40221. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:42087. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:33841'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,290 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:38953, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,291 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 609, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,291 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,291 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,292 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,292 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,292 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,294 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:46133'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2179, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2155, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:44967'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:41107'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:36409'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:43579'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:37019'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:45997'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2289, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:38685'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 8048, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2278, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 814, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:37197'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4257, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.63:39903, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2188, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:40661'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6863, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:36517'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.67:40313, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:40675, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.47:37615, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:44021'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4256, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.66:44873, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:39805, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1115, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:37593'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.56:36129, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:33449'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2541, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:34089'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7566, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1051, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 816, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:32867'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.51:41353, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2656, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:38215'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.51:33881, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3354, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1257, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.56:43389, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:44473'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2831, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1780, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2538, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:34173'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.56:36129, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2456, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:38739'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1055, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1028, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1109, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 996, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6859, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2166, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:43621'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:36081, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:40443'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2135, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.43:33649, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:35301'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3060, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.66:40249, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2533, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:35237'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 988, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:45611, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:34015'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1680, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 8242, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:34261'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4198, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7473, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1679, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:34325'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2636, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1027, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1829, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,318 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:38175'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 756, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,319 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:44099'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.40:34127, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3507, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,319 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:41599'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1682, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4094, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:34647'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 930, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,320 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:41989'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:35731, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2459, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1633, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:33791, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:45463'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4912, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6862, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:40789, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,321 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1642, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,321 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.63:45509, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,321 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:36899'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,321 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2474, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,321 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4254, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,322 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6844, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,322 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:44061, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,322 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1408, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,322 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1461, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,323 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 974, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,322 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:42685'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,322 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1453, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,322 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.63:39963, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,323 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 8046, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,323 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.41:36685, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,323 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.54:45943, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,324 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:33029'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,325 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 806, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,325 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2168, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,326 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,326 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,326 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,327 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,327 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,327 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,327 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 8051, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.37:36981, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.61:43631, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:41005'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,332 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:32769'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,332 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:43879'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,332 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:43305'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5861, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:37629'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5844, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 795, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 815, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1708, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:36111'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1684, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,336 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3319, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4240, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,335 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:43395'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5364, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4217, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4784, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,338 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5099, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,338 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:37793'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,339 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:33529'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,339 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3579, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,340 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3273, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,340 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,340 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,340 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.37:34325, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,340 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1259, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3535, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1248, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,340 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,341 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3561, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,341 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,341 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,341 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,341 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,341 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,341 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,341 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:11,341 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,341 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,341 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,343 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,343 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3021, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,343 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1910, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,344 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,344 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,344 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,344 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,344 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,347 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:11,347 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,257 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,266 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,345 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,351 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,351 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,712 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:13,712 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:38183. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,715 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.56:38183 -> tcp://10.6.101.62:43683
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.56:38183 remote=tcp://10.6.101.62:33240>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-05 09:20:13,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:13,719 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.56:40668 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:13,748 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:39651'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,749 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3860, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:13,750 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:13,750 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:13,750 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:13,750 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:13,750 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:13,782 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,785 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,872 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:45997'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,874 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:45997' closed.
2025-09-05 09:20:13,876 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:41599'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,884 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:41599' closed.
2025-09-05 09:20:13,892 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:34325'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,894 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:34325' closed.
2025-09-05 09:20:13,995 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,996 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:14,892 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:14,896 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:15,263 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,272 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,672 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:37629'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,673 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:37629' closed.
2025-09-05 09:20:15,681 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:43579'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,682 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:43579' closed.
2025-09-05 09:20:15,786 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,790 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,975 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:15,977 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:40647. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:15,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:15,992 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.56:40904 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:15,997 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:46341'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:15,997 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:15,997 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:15,998 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:15,998 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:15,998 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:15,999 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,001 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,000 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x151200ed7fd0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:16,007 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,017 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:16,019 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:38157. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,019 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,023 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,023 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,029 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:16,035 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.56:40602 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:16,040 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:39187'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,041 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2986, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:16,041 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:16,041 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:16,041 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:16,041 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:16,041 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:16,044 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14fd3240fc10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:16,156 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,199 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:33529'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,201 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:33529' closed.
2025-09-05 09:20:16,319 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:34261'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,321 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:34261' closed.
2025-09-05 09:20:16,393 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:35301'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,393 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:35301' closed.
2025-09-05 09:20:16,396 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:44021'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,397 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:44021' closed.
2025-09-05 09:20:16,777 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,896 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,900 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:17,318 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:33029'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,319 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:43305'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,320 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:33029' closed.
2025-09-05 09:20:17,321 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:43305' closed.
2025-09-05 09:20:17,603 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,603 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,736 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,796 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,807 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:17,810 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:36073. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:17,811 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,815 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:17,827 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.56:40604 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:17,837 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:45271'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:17,837 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:17,838 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:17,838 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:17,838 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:17,838 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:17,840 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x151434b56d90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:17,847 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,939 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:17,942 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:43389. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:17,954 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:17,960 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.56:40610 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:17,965 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:45191'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:17,966 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:17,966 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:17,966 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:17,966 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:17,966 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:17,969 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1462bad22bd0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:17,975 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,010 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,023 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,027 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,027 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,041 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,042 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,042 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,046 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,046 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,046 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,160 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,412 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:38739'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,413 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:38739' closed.
2025-09-05 09:20:18,424 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:32769'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,425 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:32769' closed.
2025-09-05 09:20:18,431 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:46341'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,431 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:46341' closed.
2025-09-05 09:20:18,441 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:33841'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,442 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:33841' closed.
2025-09-05 09:20:18,445 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,522 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,522 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,524 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,537 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,537 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,541 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:44967'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,543 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:44967' closed.
2025-09-05 09:20:18,781 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,014 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,015 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,014 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:19,016 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.56:36129. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:19,028 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:19,034 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.56:40584 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:19,038 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.56:46495'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:19,039 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:19,039 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:19,039 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:19,039 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:19,039 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:19,041 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14a55e5ea850>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:19,047 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,152 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,166 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:36409'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,167 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:36409' closed.
2025-09-05 09:20:19,431 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,432 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,549 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,550 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,551 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,551 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,589 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,608 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,608 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,641 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,668 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,740 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,797 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,801 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,815 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,839 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,851 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,979 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,020 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:43395'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,021 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:43395' closed.
2025-09-05 09:20:20,045 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,046 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,046 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,050 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,050 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,051 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,072 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:32867'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,073 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:32867' closed.
2025-09-05 09:20:20,202 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:38175'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,204 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:38175' closed.
2025-09-05 09:20:20,214 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:41107'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,215 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:41107' closed.
2025-09-05 09:20:20,271 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:40443'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,272 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:40443' closed.
2025-09-05 09:20:20,348 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:34089'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,350 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:34089' closed.
2025-09-05 09:20:20,367 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:45271'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,368 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:45271' closed.
2025-09-05 09:20:20,380 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:45191'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,385 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:45191' closed.
2025-09-05 09:20:20,445 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:36111'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,448 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,448 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:36111' closed.
2025-09-05 09:20:20,475 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:37197'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,476 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:37197' closed.
2025-09-05 09:20:20,478 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:38215'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,479 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:38215' closed.
2025-09-05 09:20:20,483 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:44099'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,484 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:44099' closed.
2025-09-05 09:20:20,507 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:40661'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,509 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:42685'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,510 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:40661' closed.
2025-09-05 09:20:20,510 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:42685' closed.
2025-09-05 09:20:20,526 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,529 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,540 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,541 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,812 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:46133'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,813 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:46133' closed.
2025-09-05 09:20:20,894 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:39651'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,895 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:39651' closed.
2025-09-05 09:20:21,003 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:41005'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,004 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:41005' closed.
2025-09-05 09:20:21,006 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:37019'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,006 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:37019' closed.
2025-09-05 09:20:21,016 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:38685'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,017 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:37593'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,018 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:38685' closed.
2025-09-05 09:20:21,018 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,018 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:37593' closed.
2025-09-05 09:20:21,050 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,156 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,426 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:44473'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,427 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:44473' closed.
2025-09-05 09:20:21,435 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,483 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:46495'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,484 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:46495' closed.
2025-09-05 09:20:21,503 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:34015'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,504 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:34015' closed.
2025-09-05 09:20:21,553 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,554 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,555 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,556 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,594 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,647 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,672 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,696 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:41989'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,697 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:41989' closed.
2025-09-05 09:20:21,801 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,831 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:39187'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,832 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:39187' closed.
2025-09-05 09:20:21,843 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,884 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:36899'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,885 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:36899' closed.
2025-09-05 09:20:21,943 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:43879'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,943 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:43879' closed.
2025-09-05 09:20:21,947 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:43621'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,948 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:43621' closed.
2025-09-05 09:20:22,019 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:35237'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,020 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:35237' closed.
2025-09-05 09:20:22,040 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:34173'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,041 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:34173' closed.
2025-09-05 09:20:22,045 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:45463'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,045 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:45463' closed.
2025-09-05 09:20:22,140 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:33449'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,141 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:33449' closed.
2025-09-05 09:20:22,142 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:36517'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,142 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:36517' closed.
2025-09-05 09:20:22,193 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:37793'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,194 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:37793' closed.
2025-09-05 09:20:22,235 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.56:34647'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,236 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.56:34647' closed.
2025-09-05 09:20:22,238 - distributed.dask_worker - INFO - End worker
