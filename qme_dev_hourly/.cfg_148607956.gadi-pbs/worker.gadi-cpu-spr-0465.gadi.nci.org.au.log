Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:52:27,820 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41297'
2025-09-03 10:52:27,831 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:34047'
2025-09-03 10:52:27,837 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:45601'
2025-09-03 10:52:27,841 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:34105'
2025-09-03 10:52:27,846 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35243'
2025-09-03 10:52:27,885 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:36695'
2025-09-03 10:52:27,890 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35573'
2025-09-03 10:52:27,896 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:33823'
2025-09-03 10:52:27,900 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:44783'
2025-09-03 10:52:27,906 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41351'
2025-09-03 10:52:27,909 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:43291'
2025-09-03 10:52:27,913 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:42489'
2025-09-03 10:52:27,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:34741'
2025-09-03 10:52:27,921 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:39415'
2025-09-03 10:52:27,926 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:45297'
2025-09-03 10:52:27,931 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:33719'
2025-09-03 10:52:27,936 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:38091'
2025-09-03 10:52:27,945 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:32919'
2025-09-03 10:52:27,950 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:45423'
2025-09-03 10:52:27,955 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41813'
2025-09-03 10:52:27,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:33357'
2025-09-03 10:52:27,964 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:37209'
2025-09-03 10:52:27,969 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:45111'
2025-09-03 10:52:27,974 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:40075'
2025-09-03 10:52:27,978 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:40165'
2025-09-03 10:52:27,983 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:33285'
2025-09-03 10:52:27,988 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:44431'
2025-09-03 10:52:27,993 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:44963'
2025-09-03 10:52:27,998 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:37529'
2025-09-03 10:52:28,003 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:36131'
2025-09-03 10:52:28,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:33921'
2025-09-03 10:52:28,012 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46661'
2025-09-03 10:52:28,016 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46523'
2025-09-03 10:52:28,021 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35489'
2025-09-03 10:52:28,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46181'
2025-09-03 10:52:28,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:43359'
2025-09-03 10:52:28,033 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:45249'
2025-09-03 10:52:28,038 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46197'
2025-09-03 10:52:28,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41995'
2025-09-03 10:52:28,049 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35811'
2025-09-03 10:52:28,053 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46203'
2025-09-03 10:52:28,144 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35485'
2025-09-03 10:52:28,148 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:40723'
2025-09-03 10:52:28,152 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:43091'
2025-09-03 10:52:28,157 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46579'
2025-09-03 10:52:28,161 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:40143'
2025-09-03 10:52:28,166 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:34163'
2025-09-03 10:52:28,171 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35747'
2025-09-03 10:52:28,176 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:42925'
2025-09-03 10:52:28,179 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35537'
2025-09-03 10:52:28,183 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:42053'
2025-09-03 10:52:28,186 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:42173'
2025-09-03 10:52:28,192 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35027'
2025-09-03 10:52:28,197 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:42471'
2025-09-03 10:52:28,203 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:36335'
2025-09-03 10:52:28,206 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46811'
2025-09-03 10:52:28,211 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:43121'
2025-09-03 10:52:28,215 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:33011'
2025-09-03 10:52:28,218 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:39523'
2025-09-03 10:52:28,223 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:37997'
2025-09-03 10:52:28,227 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:45817'
2025-09-03 10:52:28,233 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:38037'
2025-09-03 10:52:28,239 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:43529'
2025-09-03 10:52:28,243 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:39743'
2025-09-03 10:52:28,247 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:36775'
2025-09-03 10:52:28,250 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:40357'
2025-09-03 10:52:28,256 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:37281'
2025-09-03 10:52:28,261 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:42519'
2025-09-03 10:52:28,264 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:43301'
2025-09-03 10:52:28,268 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41815'
2025-09-03 10:52:28,272 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:38509'
2025-09-03 10:52:28,276 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:43473'
2025-09-03 10:52:28,280 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41067'
2025-09-03 10:52:28,286 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:43689'
2025-09-03 10:52:28,289 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46807'
2025-09-03 10:52:28,294 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:44265'
2025-09-03 10:52:28,298 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46325'
2025-09-03 10:52:28,303 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:38741'
2025-09-03 10:52:28,321 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:39257'
2025-09-03 10:52:28,325 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41721'
2025-09-03 10:52:28,330 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41805'
2025-09-03 10:52:28,333 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:42151'
2025-09-03 10:52:28,338 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:37333'
2025-09-03 10:52:28,343 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:36683'
2025-09-03 10:52:28,348 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:46249'
2025-09-03 10:52:28,353 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:34989'
2025-09-03 10:52:28,357 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35309'
2025-09-03 10:52:28,361 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:34129'
2025-09-03 10:52:28,365 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:44469'
2025-09-03 10:52:28,369 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:40153'
2025-09-03 10:52:28,371 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:45745'
2025-09-03 10:52:28,374 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41621'
2025-09-03 10:52:28,379 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:33027'
2025-09-03 10:52:28,385 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:45185'
2025-09-03 10:52:28,390 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:34061'
2025-09-03 10:52:28,394 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:43933'
2025-09-03 10:52:28,399 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:42535'
2025-09-03 10:52:28,402 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:33519'
2025-09-03 10:52:28,407 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:40295'
2025-09-03 10:52:28,412 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:41003'
2025-09-03 10:52:28,416 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:37927'
2025-09-03 10:52:28,421 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:39107'
2025-09-03 10:52:28,431 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:35469'
2025-09-03 10:52:28,434 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.33:34247'
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:39559
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:35881
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:39559
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:35881
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:36721
2025-09-03 10:52:30,049 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:38549
2025-09-03 10:52:30,049 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43641
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43713
2025-09-03 10:52:30,049 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37093
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:46437
2025-09-03 10:52:30,049 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:36241
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:46779
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45677
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37453
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43641
2025-09-03 10:52:30,049 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:35895
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43713
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:33739
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37093
2025-09-03 10:52:30,049 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:46437
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:36241
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:46779
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45677
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37453
2025-09-03 10:52:30,049 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44787
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:35895
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44311
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:33739
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:37725
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-yoacfqb3
2025-09-03 10:52:30,049 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:44955
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:38065
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39313
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:43461
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:43643
2025-09-03 10:52:30,049 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:42293
2025-09-03 10:52:30,049 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:46791
2025-09-03 10:52:30,049 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,049 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,049 - distributed.worker - INFO -          dashboard at:          10.6.102.33:40437
2025-09-03 10:52:30,049 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,049 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:44955
2025-09-03 10:52:30,049 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,049 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,049 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,050 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7b3u5672
2025-09-03 10:52:30,050 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -          dashboard at:          10.6.102.33:43527
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2sa0vfxg
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-95x1fa4s
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-9xcdb7m0
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-klr7s04_
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ln1vzbjh
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-p0lnu5iv
2025-09-03 10:52:30,050 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-205hgo3g
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-xdrlouxu
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2h7uktrb
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-s4xr8cem
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,050 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-138ln6oj
2025-09-03 10:52:30,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,051 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:39189
2025-09-03 10:52:30,051 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:39189
2025-09-03 10:52:30,051 - distributed.worker - INFO -          dashboard at:          10.6.102.33:46429
2025-09-03 10:52:30,051 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,051 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,051 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,051 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ridhpmjd
2025-09-03 10:52:30,052 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,051 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:41745
2025-09-03 10:52:30,051 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:41267
2025-09-03 10:52:30,052 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:41745
2025-09-03 10:52:30,052 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:41267
2025-09-03 10:52:30,052 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44553
2025-09-03 10:52:30,052 - distributed.worker - INFO -          dashboard at:          10.6.102.33:43387
2025-09-03 10:52:30,052 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,052 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,052 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,052 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,052 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,052 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,052 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,052 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,052 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-9aqdr_0b
2025-09-03 10:52:30,052 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43739
2025-09-03 10:52:30,052 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kt5u3bdh
2025-09-03 10:52:30,052 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,052 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43739
2025-09-03 10:52:30,052 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,052 - distributed.worker - INFO -          dashboard at:          10.6.102.33:37425
2025-09-03 10:52:30,052 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,052 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,053 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,053 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,053 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-u9g4f_e8
2025-09-03 10:52:30,053 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,061 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:32963
2025-09-03 10:52:30,061 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:32963
2025-09-03 10:52:30,061 - distributed.worker - INFO -          dashboard at:          10.6.102.33:38755
2025-09-03 10:52:30,062 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,062 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,062 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,062 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,062 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-80uisrri
2025-09-03 10:52:30,062 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,219 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:33063
2025-09-03 10:52:30,219 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:33063
2025-09-03 10:52:30,219 - distributed.worker - INFO -          dashboard at:          10.6.102.33:40227
2025-09-03 10:52:30,219 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,219 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,219 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,219 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,219 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-0j3dcs5f
2025-09-03 10:52:30,219 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,283 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:36651
2025-09-03 10:52:30,284 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:36651
2025-09-03 10:52:30,284 - distributed.worker - INFO -          dashboard at:          10.6.102.33:40479
2025-09-03 10:52:30,284 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,284 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,284 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,284 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,284 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-elba5t0a
2025-09-03 10:52:30,284 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,312 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:39541
2025-09-03 10:52:30,312 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:39541
2025-09-03 10:52:30,313 - distributed.worker - INFO -          dashboard at:          10.6.102.33:33039
2025-09-03 10:52:30,313 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,313 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,313 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,313 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-p0gtmv3z
2025-09-03 10:52:30,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,384 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:44041
2025-09-03 10:52:30,384 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:44041
2025-09-03 10:52:30,384 - distributed.worker - INFO -          dashboard at:          10.6.102.33:43017
2025-09-03 10:52:30,384 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,384 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,384 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,384 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,384 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-k_v4tiyl
2025-09-03 10:52:30,385 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,446 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:36635
2025-09-03 10:52:30,446 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:36635
2025-09-03 10:52:30,446 - distributed.worker - INFO -          dashboard at:          10.6.102.33:37861
2025-09-03 10:52:30,446 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,446 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,446 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,446 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,446 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-jk2enrsn
2025-09-03 10:52:30,446 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,495 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:33929
2025-09-03 10:52:30,495 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:33929
2025-09-03 10:52:30,495 - distributed.worker - INFO -          dashboard at:          10.6.102.33:46861
2025-09-03 10:52:30,495 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,495 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,495 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,495 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,495 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-zwvxge3f
2025-09-03 10:52:30,495 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,547 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:33211
2025-09-03 10:52:30,547 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:33211
2025-09-03 10:52:30,547 - distributed.worker - INFO -          dashboard at:          10.6.102.33:45237
2025-09-03 10:52:30,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,548 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-31pk393r
2025-09-03 10:52:30,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,557 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:38643
2025-09-03 10:52:30,557 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:38643
2025-09-03 10:52:30,557 - distributed.worker - INFO -          dashboard at:          10.6.102.33:38231
2025-09-03 10:52:30,557 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,558 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,558 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,558 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,558 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-co3j9rda
2025-09-03 10:52:30,558 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,609 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45165
2025-09-03 10:52:30,609 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45165
2025-09-03 10:52:30,609 - distributed.worker - INFO -          dashboard at:          10.6.102.33:43081
2025-09-03 10:52:30,609 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,609 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,609 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,609 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,609 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-dgt85zw5
2025-09-03 10:52:30,609 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,618 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45109
2025-09-03 10:52:30,618 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45109
2025-09-03 10:52:30,618 - distributed.worker - INFO -          dashboard at:          10.6.102.33:34285
2025-09-03 10:52:30,618 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,618 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,618 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,618 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,618 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-rj2begvr
2025-09-03 10:52:30,618 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,637 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45707
2025-09-03 10:52:30,638 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45707
2025-09-03 10:52:30,638 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44219
2025-09-03 10:52:30,638 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,638 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,638 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,638 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,638 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-oksoi60d
2025-09-03 10:52:30,638 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,646 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45149
2025-09-03 10:52:30,646 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45149
2025-09-03 10:52:30,646 - distributed.worker - INFO -          dashboard at:          10.6.102.33:45643
2025-09-03 10:52:30,646 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,646 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,646 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,646 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,646 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7yxd5jd0
2025-09-03 10:52:30,646 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,650 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:33517
2025-09-03 10:52:30,650 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:33517
2025-09-03 10:52:30,650 - distributed.worker - INFO -          dashboard at:          10.6.102.33:46061
2025-09-03 10:52:30,650 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,650 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,650 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,650 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ogmhbzt6
2025-09-03 10:52:30,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,659 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45043
2025-09-03 10:52:30,659 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45043
2025-09-03 10:52:30,659 - distributed.worker - INFO -          dashboard at:          10.6.102.33:36135
2025-09-03 10:52:30,659 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,659 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,659 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,659 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-34l695e1
2025-09-03 10:52:30,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,663 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:36077
2025-09-03 10:52:30,663 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:36077
2025-09-03 10:52:30,663 - distributed.worker - INFO -          dashboard at:          10.6.102.33:35029
2025-09-03 10:52:30,663 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,663 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,663 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,663 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,663 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-y0po61zj
2025-09-03 10:52:30,663 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,666 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:40351
2025-09-03 10:52:30,666 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:40351
2025-09-03 10:52:30,666 - distributed.worker - INFO -          dashboard at:          10.6.102.33:33393
2025-09-03 10:52:30,666 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,666 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,666 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,666 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,666 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ucvgghw5
2025-09-03 10:52:30,666 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,679 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:41853
2025-09-03 10:52:30,679 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:41853
2025-09-03 10:52:30,679 - distributed.worker - INFO -          dashboard at:          10.6.102.33:40283
2025-09-03 10:52:30,679 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,679 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,679 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,679 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,679 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-flcxfgvt
2025-09-03 10:52:30,679 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,683 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:35603
2025-09-03 10:52:30,683 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:35603
2025-09-03 10:52:30,683 - distributed.worker - INFO -          dashboard at:          10.6.102.33:33431
2025-09-03 10:52:30,683 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,683 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,683 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,683 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,683 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-70zktny9
2025-09-03 10:52:30,683 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,688 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:40367
2025-09-03 10:52:30,688 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:40367
2025-09-03 10:52:30,688 - distributed.worker - INFO -          dashboard at:          10.6.102.33:34917
2025-09-03 10:52:30,688 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,688 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,688 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,688 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,688 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ssuvyrbf
2025-09-03 10:52:30,689 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,696 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:44239
2025-09-03 10:52:30,696 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:44239
2025-09-03 10:52:30,696 - distributed.worker - INFO -          dashboard at:          10.6.102.33:33691
2025-09-03 10:52:30,696 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,696 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,696 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,696 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,697 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-gj65r1av
2025-09-03 10:52:30,697 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,703 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:36767
2025-09-03 10:52:30,703 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:36767
2025-09-03 10:52:30,703 - distributed.worker - INFO -          dashboard at:          10.6.102.33:38617
2025-09-03 10:52:30,703 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,703 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,703 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,703 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,703 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-oj9hgdvl
2025-09-03 10:52:30,703 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,710 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:42507
2025-09-03 10:52:30,710 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:42507
2025-09-03 10:52:30,710 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39617
2025-09-03 10:52:30,710 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,710 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,710 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,710 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,710 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-es7mrohd
2025-09-03 10:52:30,710 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,868 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43349
2025-09-03 10:52:30,868 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43349
2025-09-03 10:52:30,868 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44043
2025-09-03 10:52:30,868 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,868 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,868 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,868 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,868 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-rww0b8dm
2025-09-03 10:52:30,868 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,926 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:42573
2025-09-03 10:52:30,926 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:42573
2025-09-03 10:52:30,926 - distributed.worker - INFO -          dashboard at:          10.6.102.33:35055
2025-09-03 10:52:30,926 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,926 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,926 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,926 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,926 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-1eyl91vr
2025-09-03 10:52:30,926 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,943 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43647
2025-09-03 10:52:30,943 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43647
2025-09-03 10:52:30,943 - distributed.worker - INFO -          dashboard at:          10.6.102.33:41741
2025-09-03 10:52:30,943 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,943 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,943 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,943 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,943 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-iph35fo7
2025-09-03 10:52:30,943 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,949 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43295
2025-09-03 10:52:30,949 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43295
2025-09-03 10:52:30,949 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44943
2025-09-03 10:52:30,949 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,949 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,949 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,949 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,949 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-clrh1916
2025-09-03 10:52:30,949 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,027 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:44433
2025-09-03 10:52:31,028 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:44433
2025-09-03 10:52:31,028 - distributed.worker - INFO -          dashboard at:          10.6.102.33:40205
2025-09-03 10:52:31,028 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,028 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,028 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,028 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-9lnv6coy
2025-09-03 10:52:31,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,086 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:38377
2025-09-03 10:52:31,086 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:38377
2025-09-03 10:52:31,086 - distributed.worker - INFO -          dashboard at:          10.6.102.33:38297
2025-09-03 10:52:31,086 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,086 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,086 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,086 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,086 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-yd58zz6_
2025-09-03 10:52:31,086 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,094 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:39757
2025-09-03 10:52:31,094 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:39757
2025-09-03 10:52:31,094 - distributed.worker - INFO -          dashboard at:          10.6.102.33:33079
2025-09-03 10:52:31,094 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,094 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,094 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,094 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,094 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-k353v0xd
2025-09-03 10:52:31,094 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,156 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45447
2025-09-03 10:52:31,156 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45447
2025-09-03 10:52:31,156 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44175
2025-09-03 10:52:31,156 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,156 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,156 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,156 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,156 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-x9kfv0fe
2025-09-03 10:52:31,156 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,162 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:46029
2025-09-03 10:52:31,162 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:46029
2025-09-03 10:52:31,162 - distributed.worker - INFO -          dashboard at:          10.6.102.33:33491
2025-09-03 10:52:31,162 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,163 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,163 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,163 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,163 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-d4ef67fy
2025-09-03 10:52:31,163 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,235 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:39155
2025-09-03 10:52:31,235 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:39155
2025-09-03 10:52:31,235 - distributed.worker - INFO -          dashboard at:          10.6.102.33:37143
2025-09-03 10:52:31,235 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,235 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,235 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,235 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,235 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-fesfgkr1
2025-09-03 10:52:31,235 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,236 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:42919
2025-09-03 10:52:31,236 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:42919
2025-09-03 10:52:31,236 - distributed.worker - INFO -          dashboard at:          10.6.102.33:36221
2025-09-03 10:52:31,236 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,236 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,236 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,236 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,236 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-swxav2d6
2025-09-03 10:52:31,237 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,243 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,245 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,245 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,246 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,255 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,256 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,257 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,286 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:40021
2025-09-03 10:52:31,286 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:40021
2025-09-03 10:52:31,286 - distributed.worker - INFO -          dashboard at:          10.6.102.33:46813
2025-09-03 10:52:31,286 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,286 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,286 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,286 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,287 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-au__l30g
2025-09-03 10:52:31,287 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,291 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:42153
2025-09-03 10:52:31,291 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:42153
2025-09-03 10:52:31,291 - distributed.worker - INFO -          dashboard at:          10.6.102.33:34567
2025-09-03 10:52:31,291 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,291 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,291 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,291 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-5wjxnazs
2025-09-03 10:52:31,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,295 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:46007
2025-09-03 10:52:31,295 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:46007
2025-09-03 10:52:31,295 - distributed.worker - INFO -          dashboard at:          10.6.102.33:38057
2025-09-03 10:52:31,295 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,295 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,295 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,295 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-s4q__sv3
2025-09-03 10:52:31,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,314 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:42625
2025-09-03 10:52:31,314 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:42625
2025-09-03 10:52:31,314 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44109
2025-09-03 10:52:31,314 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,314 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,314 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,314 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-g23kizb8
2025-09-03 10:52:31,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,336 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:35367
2025-09-03 10:52:31,336 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:35367
2025-09-03 10:52:31,336 - distributed.worker - INFO -          dashboard at:          10.6.102.33:35109
2025-09-03 10:52:31,336 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,336 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,336 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,336 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8wvtn6z_
2025-09-03 10:52:31,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,347 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:35949
2025-09-03 10:52:31,347 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:35949
2025-09-03 10:52:31,347 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39765
2025-09-03 10:52:31,347 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,347 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,347 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,347 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-md69clrg
2025-09-03 10:52:31,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,359 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37279
2025-09-03 10:52:31,360 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37279
2025-09-03 10:52:31,360 - distributed.worker - INFO -          dashboard at:          10.6.102.33:42891
2025-09-03 10:52:31,360 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,360 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,360 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,360 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-37xb15y4
2025-09-03 10:52:31,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,372 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:41305
2025-09-03 10:52:31,372 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:41305
2025-09-03 10:52:31,372 - distributed.worker - INFO -          dashboard at:          10.6.102.33:37787
2025-09-03 10:52:31,372 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,372 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,372 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,372 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,372 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-44b94pc6
2025-09-03 10:52:31,372 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,384 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,385 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,385 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,386 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37119
2025-09-03 10:52:31,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37119
2025-09-03 10:52:31,388 - distributed.worker - INFO -          dashboard at:          10.6.102.33:35687
2025-09-03 10:52:31,388 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,388 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,388 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,388 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-sj5c8m8z
2025-09-03 10:52:31,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,391 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43983
2025-09-03 10:52:31,391 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43983
2025-09-03 10:52:31,391 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39445
2025-09-03 10:52:31,391 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,391 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,391 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,391 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-fv5no2q2
2025-09-03 10:52:31,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,407 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:39839
2025-09-03 10:52:31,407 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:39839
2025-09-03 10:52:31,407 - distributed.worker - INFO -          dashboard at:          10.6.102.33:38097
2025-09-03 10:52:31,408 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,408 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,408 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,408 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-aqfwfrcz
2025-09-03 10:52:31,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,409 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,410 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,412 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,413 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:33003
2025-09-03 10:52:31,414 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:33003
2025-09-03 10:52:31,414 - distributed.worker - INFO -          dashboard at:          10.6.102.33:45535
2025-09-03 10:52:31,414 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,414 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,414 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,414 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,414 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-t_kjoes7
2025-09-03 10:52:31,414 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,429 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43749
2025-09-03 10:52:31,430 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43749
2025-09-03 10:52:31,430 - distributed.worker - INFO -          dashboard at:          10.6.102.33:45223
2025-09-03 10:52:31,430 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,430 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,430 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,430 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,430 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-o_8uxrth
2025-09-03 10:52:31,430 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,439 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:34053
2025-09-03 10:52:31,439 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:34053
2025-09-03 10:52:31,439 - distributed.worker - INFO -          dashboard at:          10.6.102.33:45345
2025-09-03 10:52:31,439 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,439 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,439 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,439 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,439 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-f85ns1e7
2025-09-03 10:52:31,439 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,450 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37941
2025-09-03 10:52:31,450 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37941
2025-09-03 10:52:31,450 - distributed.worker - INFO -          dashboard at:          10.6.102.33:40475
2025-09-03 10:52:31,450 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,450 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,450 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,450 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,450 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-0qqsuh69
2025-09-03 10:52:31,450 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,459 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:41829
2025-09-03 10:52:31,459 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:41829
2025-09-03 10:52:31,459 - distributed.worker - INFO -          dashboard at:          10.6.102.33:37741
2025-09-03 10:52:31,459 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,459 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,459 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,459 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-jl50rl03
2025-09-03 10:52:31,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,542 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:46789
2025-09-03 10:52:31,542 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:46789
2025-09-03 10:52:31,542 - distributed.worker - INFO -          dashboard at:          10.6.102.33:41049
2025-09-03 10:52:31,542 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,542 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,542 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,542 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,542 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-z_q44ykm
2025-09-03 10:52:31,542 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,549 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:44171
2025-09-03 10:52:31,549 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:44171
2025-09-03 10:52:31,549 - distributed.worker - INFO -          dashboard at:          10.6.102.33:33615
2025-09-03 10:52:31,549 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,549 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,549 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,549 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,549 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6usb2v6q
2025-09-03 10:52:31,549 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,594 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:36719
2025-09-03 10:52:31,594 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:36719
2025-09-03 10:52:31,594 - distributed.worker - INFO -          dashboard at:          10.6.102.33:42807
2025-09-03 10:52:31,594 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,594 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,594 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,594 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-1a1e6xvo
2025-09-03 10:52:31,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,599 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:36723
2025-09-03 10:52:31,599 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:36723
2025-09-03 10:52:31,599 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39187
2025-09-03 10:52:31,599 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,599 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,600 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,600 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-l2a4ss2l
2025-09-03 10:52:31,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,628 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:35223
2025-09-03 10:52:31,628 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:35223
2025-09-03 10:52:31,628 - distributed.worker - INFO -          dashboard at:          10.6.102.33:46097
2025-09-03 10:52:31,628 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,628 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,628 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,628 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kk1j2lcd
2025-09-03 10:52:31,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,641 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,642 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,642 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,644 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,667 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,668 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,668 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,669 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,692 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,694 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,694 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,695 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,695 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43223
2025-09-03 10:52:31,696 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43223
2025-09-03 10:52:31,696 - distributed.worker - INFO -          dashboard at:          10.6.102.33:45491
2025-09-03 10:52:31,696 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,696 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,696 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,696 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,696 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-x844m2qg
2025-09-03 10:52:31,696 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,697 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37779
2025-09-03 10:52:31,697 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37779
2025-09-03 10:52:31,697 - distributed.worker - INFO -          dashboard at:          10.6.102.33:45815
2025-09-03 10:52:31,698 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,698 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,698 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,698 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,698 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_q9j7sor
2025-09-03 10:52:31,698 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,718 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37931
2025-09-03 10:52:31,718 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37931
2025-09-03 10:52:31,718 - distributed.worker - INFO -          dashboard at:          10.6.102.33:42119
2025-09-03 10:52:31,718 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,718 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,718 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,718 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,718 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-aws029zn
2025-09-03 10:52:31,718 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,720 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:34479
2025-09-03 10:52:31,720 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:34479
2025-09-03 10:52:31,720 - distributed.worker - INFO -          dashboard at:          10.6.102.33:41817
2025-09-03 10:52:31,720 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,720 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,720 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,720 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,720 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-pjvzpvhe
2025-09-03 10:52:31,720 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,731 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,732 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,732 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,734 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,804 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,806 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,806 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,807 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,857 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:44523
2025-09-03 10:52:31,857 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:44523
2025-09-03 10:52:31,858 - distributed.worker - INFO -          dashboard at:          10.6.102.33:36653
2025-09-03 10:52:31,858 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,858 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,858 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,858 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-5gwdgcn9
2025-09-03 10:52:31,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,860 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,861 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,861 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,866 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,874 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,876 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,876 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,879 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,886 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,888 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,888 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,891 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45539
2025-09-03 10:52:31,892 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45539
2025-09-03 10:52:31,892 - distributed.worker - INFO -          dashboard at:          10.6.102.33:41433
2025-09-03 10:52:31,892 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,892 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,892 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,892 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,892 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-66a_g40_
2025-09-03 10:52:31,892 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,892 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,899 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,901 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,901 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,905 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,911 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,912 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,912 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,914 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,914 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:41893
2025-09-03 10:52:31,915 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:41893
2025-09-03 10:52:31,915 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44713
2025-09-03 10:52:31,915 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,915 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,915 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,915 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,915 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-vjgzsafp
2025-09-03 10:52:31,915 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,924 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,925 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,925 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,927 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,936 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,937 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,938 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,939 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,949 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,950 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,950 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,952 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,962 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,963 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,963 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,965 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,975 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,976 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,977 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,978 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,986 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45081
2025-09-03 10:52:31,986 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45081
2025-09-03 10:52:31,986 - distributed.worker - INFO -          dashboard at:          10.6.102.33:33307
2025-09-03 10:52:31,986 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,986 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,986 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:31,986 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:31,986 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-cb4f18z6
2025-09-03 10:52:31,986 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,988 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,989 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,989 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,991 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,001 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,002 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,002 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,004 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,007 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:44813
2025-09-03 10:52:32,007 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:44813
2025-09-03 10:52:32,007 - distributed.worker - INFO -          dashboard at:          10.6.102.33:36613
2025-09-03 10:52:32,007 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,007 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,007 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,007 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-mkgl_tv9
2025-09-03 10:52:32,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,012 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:34291
2025-09-03 10:52:32,012 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:34291
2025-09-03 10:52:32,012 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44205
2025-09-03 10:52:32,012 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,012 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,012 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,012 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-u3i8pg6z
2025-09-03 10:52:32,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,014 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,014 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43093
2025-09-03 10:52:32,014 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43093
2025-09-03 10:52:32,014 - distributed.worker - INFO -          dashboard at:          10.6.102.33:33915
2025-09-03 10:52:32,014 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,014 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,014 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,014 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,014 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6k4vdacg
2025-09-03 10:52:32,014 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,015 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,015 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,017 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,021 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37615
2025-09-03 10:52:32,021 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37615
2025-09-03 10:52:32,021 - distributed.worker - INFO -          dashboard at:          10.6.102.33:41319
2025-09-03 10:52:32,021 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,021 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,021 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,021 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,021 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-hmhd2z_2
2025-09-03 10:52:32,021 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,024 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:46633
2025-09-03 10:52:32,024 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:46633
2025-09-03 10:52:32,024 - distributed.worker - INFO -          dashboard at:          10.6.102.33:40827
2025-09-03 10:52:32,024 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,024 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,024 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,024 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-mb9mtjqu
2025-09-03 10:52:32,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,024 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:34319
2025-09-03 10:52:32,024 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:34319
2025-09-03 10:52:32,024 - distributed.worker - INFO -          dashboard at:          10.6.102.33:42755
2025-09-03 10:52:32,024 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,024 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,025 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,025 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kl17ed4t
2025-09-03 10:52:32,025 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,026 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37815
2025-09-03 10:52:32,026 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37815
2025-09-03 10:52:32,026 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39741
2025-09-03 10:52:32,026 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,026 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,026 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,026 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,026 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-0qdyw28y
2025-09-03 10:52:32,026 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,026 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,027 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,029 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,030 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:33055
2025-09-03 10:52:32,030 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:33055
2025-09-03 10:52:32,030 - distributed.worker - INFO -          dashboard at:          10.6.102.33:37635
2025-09-03 10:52:32,030 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,030 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,030 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,030 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wdrt2bwn
2025-09-03 10:52:32,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,033 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:41301
2025-09-03 10:52:32,033 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:41301
2025-09-03 10:52:32,033 - distributed.worker - INFO -          dashboard at:          10.6.102.33:35627
2025-09-03 10:52:32,033 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,033 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,033 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,033 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,033 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-v4n_j7aj
2025-09-03 10:52:32,033 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,039 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,040 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,040 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,042 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,052 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,053 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,053 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,054 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43721
2025-09-03 10:52:32,054 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43721
2025-09-03 10:52:32,054 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39563
2025-09-03 10:52:32,054 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,054 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,054 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,054 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,054 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wotx9ol2
2025-09-03 10:52:32,054 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,054 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,064 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:34969
2025-09-03 10:52:32,064 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:34969
2025-09-03 10:52:32,064 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39089
2025-09-03 10:52:32,064 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,064 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,064 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,064 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,064 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-12rovxc0
2025-09-03 10:52:32,064 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,064 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,066 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,066 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,067 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,078 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,079 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,081 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,090 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,091 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,091 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,093 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,105 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,106 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,106 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,108 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,157 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:45685
2025-09-03 10:52:32,157 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:45685
2025-09-03 10:52:32,157 - distributed.worker - INFO -          dashboard at:          10.6.102.33:42665
2025-09-03 10:52:32,157 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,157 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,157 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,157 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,157 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-vdmr9sza
2025-09-03 10:52:32,157 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,196 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:43759
2025-09-03 10:52:32,196 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:43759
2025-09-03 10:52:32,196 - distributed.worker - INFO -          dashboard at:          10.6.102.33:41777
2025-09-03 10:52:32,196 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,196 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,196 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,196 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ih9honrl
2025-09-03 10:52:32,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,223 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:42025
2025-09-03 10:52:32,223 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:42025
2025-09-03 10:52:32,223 - distributed.worker - INFO -          dashboard at:          10.6.102.33:45813
2025-09-03 10:52:32,223 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,223 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,223 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:34697
2025-09-03 10:52:32,224 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,224 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,224 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:34697
2025-09-03 10:52:32,224 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-zzrpfb10
2025-09-03 10:52:32,224 - distributed.worker - INFO -          dashboard at:          10.6.102.33:37799
2025-09-03 10:52:32,224 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,224 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,224 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,224 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,224 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,224 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ac0wg5np
2025-09-03 10:52:32,224 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,224 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:32889
2025-09-03 10:52:32,224 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:32889
2025-09-03 10:52:32,224 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39193
2025-09-03 10:52:32,224 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,224 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,224 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,224 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,224 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-5tovrkmt
2025-09-03 10:52:32,224 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,226 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37125
2025-09-03 10:52:32,226 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37125
2025-09-03 10:52:32,226 - distributed.worker - INFO -          dashboard at:          10.6.102.33:44629
2025-09-03 10:52:32,226 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,226 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,226 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,226 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,226 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_8grip76
2025-09-03 10:52:32,226 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,228 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:39309
2025-09-03 10:52:32,228 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:39309
2025-09-03 10:52:32,228 - distributed.worker - INFO -          dashboard at:          10.6.102.33:34597
2025-09-03 10:52:32,228 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,228 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,228 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,228 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,228 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-h811s9bl
2025-09-03 10:52:32,228 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,229 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:41367
2025-09-03 10:52:32,229 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:41367
2025-09-03 10:52:32,229 - distributed.worker - INFO -          dashboard at:          10.6.102.33:32857
2025-09-03 10:52:32,229 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,229 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,229 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,229 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,229 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-enk9__5k
2025-09-03 10:52:32,229 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,230 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:34923
2025-09-03 10:52:32,230 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:34923
2025-09-03 10:52:32,230 - distributed.worker - INFO -          dashboard at:          10.6.102.33:43981
2025-09-03 10:52:32,230 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,230 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,230 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,230 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,230 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-fd3bvmre
2025-09-03 10:52:32,230 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,231 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:35277
2025-09-03 10:52:32,231 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:35277
2025-09-03 10:52:32,231 - distributed.worker - INFO -          dashboard at:          10.6.102.33:46763
2025-09-03 10:52:32,231 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,231 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,231 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,231 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,231 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-x01pzvo2
2025-09-03 10:52:32,231 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,233 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:34783
2025-09-03 10:52:32,233 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:34783
2025-09-03 10:52:32,233 - distributed.worker - INFO -          dashboard at:          10.6.102.33:39797
2025-09-03 10:52:32,233 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,233 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,233 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,233 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,233 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7mfhkp5z
2025-09-03 10:52:32,233 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,241 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:42309
2025-09-03 10:52:32,241 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:42309
2025-09-03 10:52:32,241 - distributed.worker - INFO -          dashboard at:          10.6.102.33:32921
2025-09-03 10:52:32,241 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,241 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,241 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,241 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,241 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-56_vc88x
2025-09-03 10:52:32,241 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,245 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.33:37885
2025-09-03 10:52:32,245 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.33:37885
2025-09-03 10:52:32,245 - distributed.worker - INFO -          dashboard at:          10.6.102.33:37379
2025-09-03 10:52:32,245 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,245 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,245 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:32,245 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:32,245 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-qkal_ha8
2025-09-03 10:52:32,245 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,303 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,304 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,304 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,306 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,316 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,317 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,317 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,319 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,407 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,408 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,410 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,420 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,421 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,421 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,423 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,433 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,434 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,434 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,436 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,524 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,525 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,525 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,527 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,536 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,537 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,538 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,539 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,550 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,551 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,551 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,553 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,589 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,590 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,592 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,602 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,603 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,605 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,615 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,616 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,616 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,618 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,628 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,629 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,630 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,632 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,641 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,642 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,643 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,644 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,693 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,694 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,694 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,696 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,706 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,707 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,708 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,709 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,719 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,721 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,721 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,723 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,732 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,733 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,733 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,735 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,771 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,773 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,775 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,784 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,785 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,786 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,788 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,797 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,798 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,799 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,801 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,810 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,811 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,813 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,824 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,825 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,825 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,827 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,904 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,905 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,905 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,907 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,061 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,063 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,063 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,065 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,074 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,075 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,076 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,078 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,087 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,088 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,089 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,090 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,101 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,102 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,102 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,104 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,115 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,117 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,127 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,129 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,129 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,131 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,140 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,141 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,141 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,143 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,153 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,154 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,156 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,179 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,180 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,180 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,182 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,192 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,193 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,193 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,195 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,205 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,206 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,206 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,208 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,494 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,495 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,495 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,497 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,919 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,920 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,922 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,932 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,933 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,933 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,935 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,945 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,946 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,946 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,948 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,224 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,225 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,225 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,227 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,652 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,653 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,655 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,665 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,666 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,667 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,669 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,678 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,679 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,679 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,681 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,691 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,693 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,693 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,695 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,704 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,706 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,706 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,708 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,795 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,796 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,796 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,798 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,292 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,293 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,295 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,305 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,306 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,306 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,308 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,319 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,320 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,320 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,322 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,337 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,341 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,345 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,347 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,347 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,349 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,359 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,360 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,362 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,372 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,373 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,373 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,375 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,385 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,386 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,386 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,388 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,639 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,640 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,640 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,642 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,652 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,653 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,654 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,656 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,666 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,667 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,667 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,669 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,679 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,680 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,680 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,682 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,693 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,694 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,694 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,696 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:35,851 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:35,852 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:35,853 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:35,854 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,903 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,904 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,904 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,906 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,917 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,918 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,918 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,920 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,944 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,946 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,946 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,947 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,972 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,974 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,974 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,976 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:37,533 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:37,534 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:37,535 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:37,536 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:37,548 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:37,550 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:37,550 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:37,551 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:37,624 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:37,626 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:37,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:37,627 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:37,725 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:37,727 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:37,727 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:37,728 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:37,759 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:37,761 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:37,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:37,763 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,070 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,071 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,071 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,073 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,097 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,098 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,098 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,100 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,112 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,112 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,114 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,365 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,366 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,366 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,368 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,901 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,903 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,903 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,905 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,915 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,916 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,917 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,918 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,964 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,966 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,966 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,968 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:03,528 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:03,541 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:03,557 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:03,595 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:03,607 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:05,657 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:05,671 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:08,539 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:08,554 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:56:37,884 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:37,887 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,444 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,443 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,445 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,448 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,450 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,452 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,476 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,478 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,673 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,674 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,778 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,779 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,338 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,339 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,534 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,536 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,630 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,634 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,644 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,422 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,424 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,559 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,560 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,660 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,662 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,859 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,860 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,140 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,141 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,316 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,317 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,339 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,346 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,363 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,368 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,433 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,434 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,797 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,799 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,907 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,914 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,984 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,988 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,998 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,007 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,175 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,177 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,258 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,260 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,513 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,514 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,555 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,561 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,812 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,813 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,076 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,078 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,137 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,138 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,353 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,358 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,696 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,907 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,909 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,232 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,238 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,404 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,405 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,517 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,519 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,830 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,836 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,945 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,951 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,110 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,115 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,139 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,141 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,431 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,434 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,727 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,734 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,847 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,855 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,856 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,861 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,867 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,872 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,900 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,905 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,952 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,958 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,898 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,900 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,328 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,331 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,332 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,333 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,539 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,545 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,594 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,599 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,920 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,926 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,105 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,107 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,137 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,138 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,761 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,766 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,814 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,816 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,045 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,048 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,267 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,270 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,290 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,290 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,294 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,295 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,521 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,526 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,552 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,557 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,769 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,774 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,189 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,191 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,616 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,622 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,640 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,641 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,674 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,679 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,870 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,875 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,211 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,215 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,265 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,267 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,274 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,279 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,537 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,539 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,640 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,648 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,821 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,823 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,994 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,996 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,032 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,037 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,094 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,095 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,763 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,764 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,291 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,293 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,371 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,374 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,752 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,754 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,484 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,486 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,521 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,527 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,568 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,575 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,883 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,884 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,990 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,995 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,996 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,999 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:55,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:55,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,061 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,063 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,257 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,258 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,303 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,304 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,513 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,518 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,697 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:58,079 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:58,081 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:58,335 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:58,336 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:59,016 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:59,018 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:59,305 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:59,308 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:59,980 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:59,986 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:01,859 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:01,861 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:02,571 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:02,576 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:03,399 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:03,406 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:03,559 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:03,564 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:09,476 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:09,478 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:09,993 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:09,995 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,004 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,009 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,018 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,020 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,029 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,032 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,354 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,356 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,358 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,359 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,361 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,361 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,624 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,625 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,626 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,627 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,735 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,737 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,737 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,739 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,741 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,743 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,742 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,746 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,747 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,748 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,753 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,755 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,754 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,757 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,760 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,762 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,787 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,792 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,794 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,884 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,886 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,889 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,892 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,912 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,914 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,914 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,919 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,918 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,923 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,120 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,122 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,172 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,174 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,180 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,182 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,182 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,184 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,186 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,187 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,296 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,298 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,313 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,315 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,316 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,318 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,378 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,380 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,405 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,405 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,407 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,407 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,409 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,412 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,417 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,420 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,436 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,461 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,463 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,485 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,486 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,487 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,488 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,530 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,532 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,541 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,564 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,566 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,574 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,574 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,574 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,576 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,576 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,577 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,590 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,598 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,630 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,632 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,636 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,638 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,679 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,681 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,681 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,683 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,686 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,688 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,695 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,697 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,703 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,705 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,799 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,801 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,807 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,812 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,935 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,937 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,978 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,983 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,029 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,047 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,052 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,059 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,058 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,062 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,063 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,122 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,124 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,126 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,128 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,184 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,186 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,196 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,198 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,207 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,209 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,215 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,220 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,242 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,245 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,254 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,254 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,257 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,259 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,287 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,290 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,314 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,316 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,399 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,401 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,480 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,506 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,508 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,577 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,602 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,611 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,746 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,748 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,749 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,751 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,858 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,860 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,862 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,864 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,875 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,878 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,934 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,936 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,986 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,988 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,103 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,105 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,130 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,132 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,148 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,150 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,151 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,153 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,167 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,169 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,238 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,240 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,355 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,357 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,703 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,705 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:14,797 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:14,800 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:14,918 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:14,920 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:15,111 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:15,114 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:16,247 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:16,249 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:17,946 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:17,948 - distributed.utils - INFO - Reload module qme_vars from .py file
