Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:52:37,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:36119'
2025-09-03 10:52:37,664 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:44893'
2025-09-03 10:52:37,669 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:43027'
2025-09-03 10:52:38,441 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:35693
2025-09-03 10:52:38,441 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:40219
2025-09-03 10:52:38,441 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43641
2025-09-03 10:52:38,441 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:35693
2025-09-03 10:52:38,441 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:40219
2025-09-03 10:52:38,442 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43641
2025-09-03 10:52:38,442 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45801
2025-09-03 10:52:38,442 - distributed.worker - INFO -          dashboard at:          10.6.102.36:46681
2025-09-03 10:52:38,442 - distributed.worker - INFO -          dashboard at:          10.6.102.36:35293
2025-09-03 10:52:38,442 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,442 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,442 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,442 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,442 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,442 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,442 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:38,442 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:38,442 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:38,442 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:38,442 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:38,442 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:38,442 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-affklshk
2025-09-03 10:52:38,442 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-16dindpg
2025-09-03 10:52:38,442 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-48k7gkk3
2025-09-03 10:52:38,442 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,442 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,442 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,708 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,709 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,709 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,711 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,722 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,723 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,723 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,725 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,735 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:38,736 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:38,737 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:38,738 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:38,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:36457'
2025-09-03 10:52:38,869 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:32833'
2025-09-03 10:52:38,872 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:41431'
2025-09-03 10:52:38,877 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:44835'
2025-09-03 10:52:38,882 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:41927'
2025-09-03 10:52:38,885 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:38269'
2025-09-03 10:52:38,890 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:44543'
2025-09-03 10:52:38,894 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:34667'
2025-09-03 10:52:38,898 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:44425'
2025-09-03 10:52:38,902 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:42505'
2025-09-03 10:52:38,908 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:41105'
2025-09-03 10:52:38,917 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:44301'
2025-09-03 10:52:38,921 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:43657'
2025-09-03 10:52:38,926 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:45615'
2025-09-03 10:52:38,932 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:42465'
2025-09-03 10:52:38,939 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:42679'
2025-09-03 10:52:38,944 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:44101'
2025-09-03 10:52:38,949 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:37095'
2025-09-03 10:52:38,954 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:33827'
2025-09-03 10:52:38,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:37593'
2025-09-03 10:52:38,966 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:39685'
2025-09-03 10:52:38,971 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:42153'
2025-09-03 10:52:38,976 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:36677'
2025-09-03 10:52:38,981 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:46461'
2025-09-03 10:52:38,986 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:41165'
2025-09-03 10:52:39,074 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:33685'
2025-09-03 10:52:39,080 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:37833'
2025-09-03 10:52:39,084 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:33159'
2025-09-03 10:52:39,089 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:40021'
2025-09-03 10:52:39,094 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:35599'
2025-09-03 10:52:39,098 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:34035'
2025-09-03 10:52:39,102 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:36045'
2025-09-03 10:52:39,106 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:38581'
2025-09-03 10:52:39,111 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:37575'
2025-09-03 10:52:39,116 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:36557'
2025-09-03 10:52:39,121 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:40223'
2025-09-03 10:52:39,126 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:45257'
2025-09-03 10:52:39,130 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:45937'
2025-09-03 10:52:39,134 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:41631'
2025-09-03 10:52:39,139 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:39721'
2025-09-03 10:52:39,144 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:34733'
2025-09-03 10:52:39,149 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:39391'
2025-09-03 10:52:39,153 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:37857'
2025-09-03 10:52:39,157 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:33687'
2025-09-03 10:52:39,162 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:45771'
2025-09-03 10:52:39,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:37465'
2025-09-03 10:52:39,169 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:34079'
2025-09-03 10:52:39,173 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:44497'
2025-09-03 10:52:39,178 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:34297'
2025-09-03 10:52:39,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:38829'
2025-09-03 10:52:39,189 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:43993'
2025-09-03 10:52:39,193 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:39655'
2025-09-03 10:52:39,198 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:41679'
2025-09-03 10:52:39,203 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:39737'
2025-09-03 10:52:39,207 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:39717'
2025-09-03 10:52:39,211 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:35337'
2025-09-03 10:52:39,214 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:37135'
2025-09-03 10:52:39,218 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:44107'
2025-09-03 10:52:39,222 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:39741'
2025-09-03 10:52:39,225 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:43295'
2025-09-03 10:52:39,230 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:39317'
2025-09-03 10:52:39,250 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:38509'
2025-09-03 10:52:39,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:40895'
2025-09-03 10:52:39,258 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:33673'
2025-09-03 10:52:39,262 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:42033'
2025-09-03 10:52:39,266 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:43471'
2025-09-03 10:52:39,271 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:33829'
2025-09-03 10:52:39,276 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:34585'
2025-09-03 10:52:39,280 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:41637'
2025-09-03 10:52:39,284 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:38813'
2025-09-03 10:52:39,288 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:42555'
2025-09-03 10:52:39,291 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:46421'
2025-09-03 10:52:39,295 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:40013'
2025-09-03 10:52:39,299 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:41619'
2025-09-03 10:52:39,304 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:35425'
2025-09-03 10:52:39,309 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:33937'
2025-09-03 10:52:39,314 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:41915'
2025-09-03 10:52:39,319 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:38021'
2025-09-03 10:52:39,325 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:35041'
2025-09-03 10:52:39,331 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:37769'
2025-09-03 10:52:39,334 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:38415'
2025-09-03 10:52:39,339 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:34069'
2025-09-03 10:52:39,344 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:44221'
2025-09-03 10:52:39,347 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:43487'
2025-09-03 10:52:39,356 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:42745'
2025-09-03 10:52:39,362 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:36001'
2025-09-03 10:52:39,365 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:33521'
2025-09-03 10:52:39,369 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:39113'
2025-09-03 10:52:39,374 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:42131'
2025-09-03 10:52:39,377 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:35603'
2025-09-03 10:52:39,381 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:34665'
2025-09-03 10:52:39,385 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:36969'
2025-09-03 10:52:39,390 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:43927'
2025-09-03 10:52:39,394 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:40743'
2025-09-03 10:52:39,398 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:34167'
2025-09-03 10:52:39,402 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:36975'
2025-09-03 10:52:39,406 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:37673'
2025-09-03 10:52:39,514 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:45575'
2025-09-03 10:52:39,516 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:43377'
2025-09-03 10:52:39,520 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:45635'
2025-09-03 10:52:39,525 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.36:46259'
2025-09-03 10:52:39,824 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43025
2025-09-03 10:52:39,825 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43025
2025-09-03 10:52:39,825 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39207
2025-09-03 10:52:39,825 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,825 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,825 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,825 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,825 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kbo8i0t6
2025-09-03 10:52:39,825 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,829 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:39583
2025-09-03 10:52:39,829 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:39583
2025-09-03 10:52:39,829 - distributed.worker - INFO -          dashboard at:          10.6.102.36:37321
2025-09-03 10:52:39,829 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,829 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,829 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,829 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,829 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-yr2w6j9i
2025-09-03 10:52:39,829 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,833 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43865
2025-09-03 10:52:39,833 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43865
2025-09-03 10:52:39,833 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:35453
2025-09-03 10:52:39,833 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45539
2025-09-03 10:52:39,834 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,834 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:35453
2025-09-03 10:52:39,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,834 - distributed.worker - INFO -          dashboard at:          10.6.102.36:42185
2025-09-03 10:52:39,834 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,834 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,834 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,834 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:39,834 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-m74expw1
2025-09-03 10:52:39,834 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:39,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,834 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-y04xc8p5
2025-09-03 10:52:39,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,121 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:45957
2025-09-03 10:52:40,121 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:45957
2025-09-03 10:52:40,121 - distributed.worker - INFO -          dashboard at:          10.6.102.36:34581
2025-09-03 10:52:40,121 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,121 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,121 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,121 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-z2ggzjvp
2025-09-03 10:52:40,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,268 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:39825
2025-09-03 10:52:40,269 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:39825
2025-09-03 10:52:40,269 - distributed.worker - INFO -          dashboard at:          10.6.102.36:33255
2025-09-03 10:52:40,269 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,269 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,269 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,269 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,269 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8rbarigq
2025-09-03 10:52:40,269 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,272 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43337
2025-09-03 10:52:40,272 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43337
2025-09-03 10:52:40,272 - distributed.worker - INFO -          dashboard at:          10.6.102.36:41243
2025-09-03 10:52:40,272 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,272 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,272 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,272 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,272 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-3dz21060
2025-09-03 10:52:40,273 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,278 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:34591
2025-09-03 10:52:40,279 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:34591
2025-09-03 10:52:40,279 - distributed.worker - INFO -          dashboard at:          10.6.102.36:34933
2025-09-03 10:52:40,279 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,279 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,279 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,279 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,279 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8crlqwin
2025-09-03 10:52:40,279 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,291 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43387
2025-09-03 10:52:40,291 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43387
2025-09-03 10:52:40,291 - distributed.worker - INFO -          dashboard at:          10.6.102.36:44375
2025-09-03 10:52:40,291 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,291 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,291 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,291 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-cgug8tq_
2025-09-03 10:52:40,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,297 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:45329
2025-09-03 10:52:40,297 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:45329
2025-09-03 10:52:40,297 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45403
2025-09-03 10:52:40,297 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,297 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,297 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,297 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-80hq067q
2025-09-03 10:52:40,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,307 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:37831
2025-09-03 10:52:40,307 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:37831
2025-09-03 10:52:40,307 - distributed.worker - INFO -          dashboard at:          10.6.102.36:36751
2025-09-03 10:52:40,307 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,307 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,307 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,307 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-yus85mec
2025-09-03 10:52:40,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,313 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43261
2025-09-03 10:52:40,313 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43261
2025-09-03 10:52:40,313 - distributed.worker - INFO -          dashboard at:          10.6.102.36:33777
2025-09-03 10:52:40,313 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,313 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,313 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,313 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ei9ory2y
2025-09-03 10:52:40,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,317 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44833
2025-09-03 10:52:40,317 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44833
2025-09-03 10:52:40,317 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38807
2025-09-03 10:52:40,317 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,317 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,317 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,318 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,318 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-j4neo6ln
2025-09-03 10:52:40,318 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,323 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:35555
2025-09-03 10:52:40,323 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:35555
2025-09-03 10:52:40,323 - distributed.worker - INFO -          dashboard at:          10.6.102.36:37421
2025-09-03 10:52:40,323 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,323 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,323 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,323 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,323 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6e7jp_jg
2025-09-03 10:52:40,323 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,325 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:42949
2025-09-03 10:52:40,325 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:42949
2025-09-03 10:52:40,325 - distributed.worker - INFO -          dashboard at:          10.6.102.36:46813
2025-09-03 10:52:40,325 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,325 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,325 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,325 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,325 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-xr0beir2
2025-09-03 10:52:40,325 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,325 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:34435
2025-09-03 10:52:40,326 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:34435
2025-09-03 10:52:40,326 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39871
2025-09-03 10:52:40,326 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,326 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,326 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,326 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,326 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-m2ru1w2c
2025-09-03 10:52:40,326 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,331 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:42357
2025-09-03 10:52:40,331 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:42357
2025-09-03 10:52:40,331 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45703
2025-09-03 10:52:40,331 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,331 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,331 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,331 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-sgl490mw
2025-09-03 10:52:40,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,333 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:37157
2025-09-03 10:52:40,333 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:37157
2025-09-03 10:52:40,333 - distributed.worker - INFO -          dashboard at:          10.6.102.36:34283
2025-09-03 10:52:40,333 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,333 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,333 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,333 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7tjfkwwf
2025-09-03 10:52:40,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,334 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:34037
2025-09-03 10:52:40,334 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:34037
2025-09-03 10:52:40,334 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39567
2025-09-03 10:52:40,334 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,334 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,334 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,334 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,334 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-1n617m6d
2025-09-03 10:52:40,334 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,336 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:39047
2025-09-03 10:52:40,336 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:39047
2025-09-03 10:52:40,336 - distributed.worker - INFO -          dashboard at:          10.6.102.36:36069
2025-09-03 10:52:40,336 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,336 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,336 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,336 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-87j93_hl
2025-09-03 10:52:40,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,337 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:40513
2025-09-03 10:52:40,337 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:40513
2025-09-03 10:52:40,337 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38511
2025-09-03 10:52:40,337 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,337 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,337 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,337 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,337 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-mmsbwnks
2025-09-03 10:52:40,337 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,356 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:39891
2025-09-03 10:52:40,357 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:39891
2025-09-03 10:52:40,357 - distributed.worker - INFO -          dashboard at:          10.6.102.36:33935
2025-09-03 10:52:40,357 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,357 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,357 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,357 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,357 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2imepqv5
2025-09-03 10:52:40,357 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,358 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41257
2025-09-03 10:52:40,358 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41257
2025-09-03 10:52:40,358 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45795
2025-09-03 10:52:40,358 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,358 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,358 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,358 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,358 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-460ol1qs
2025-09-03 10:52:40,359 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,757 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,758 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,758 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,760 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,785 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,786 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,788 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,813 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,814 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,815 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,828 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:40,829 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,829 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,831 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:40,913 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:34365
2025-09-03 10:52:40,913 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:34365
2025-09-03 10:52:40,913 - distributed.worker - INFO -          dashboard at:          10.6.102.36:34931
2025-09-03 10:52:40,913 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:40,913 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:40,913 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:40,913 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:40,913 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ok8veg5g
2025-09-03 10:52:40,913 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,138 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:37669
2025-09-03 10:52:41,138 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:37669
2025-09-03 10:52:41,138 - distributed.worker - INFO -          dashboard at:          10.6.102.36:33093
2025-09-03 10:52:41,138 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,138 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,138 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,138 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,138 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-0c97tr8k
2025-09-03 10:52:41,138 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,187 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44775
2025-09-03 10:52:41,187 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44775
2025-09-03 10:52:41,187 - distributed.worker - INFO -          dashboard at:          10.6.102.36:40247
2025-09-03 10:52:41,188 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,188 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,188 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,188 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,188 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wdgx8j2a
2025-09-03 10:52:41,188 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,194 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44317
2025-09-03 10:52:41,194 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44317
2025-09-03 10:52:41,194 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39303
2025-09-03 10:52:41,194 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,194 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,194 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,194 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,194 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-a6o9yapu
2025-09-03 10:52:41,194 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,201 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43919
2025-09-03 10:52:41,201 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43919
2025-09-03 10:52:41,201 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45337
2025-09-03 10:52:41,201 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,201 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,201 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,201 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,201 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-05lsslh3
2025-09-03 10:52:41,201 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,203 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:33317
2025-09-03 10:52:41,203 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:33317
2025-09-03 10:52:41,203 - distributed.worker - INFO -          dashboard at:          10.6.102.36:35647
2025-09-03 10:52:41,203 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,203 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,203 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,203 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,203 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-bldce5ng
2025-09-03 10:52:41,203 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,204 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43615
2025-09-03 10:52:41,204 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43615
2025-09-03 10:52:41,204 - distributed.worker - INFO -          dashboard at:          10.6.102.36:43791
2025-09-03 10:52:41,204 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,204 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,204 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,204 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,204 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-a8bo3q6y
2025-09-03 10:52:41,204 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,206 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:36031
2025-09-03 10:52:41,207 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:36031
2025-09-03 10:52:41,207 - distributed.worker - INFO -          dashboard at:          10.6.102.36:44063
2025-09-03 10:52:41,207 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,207 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,207 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,207 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,207 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2r1hh44v
2025-09-03 10:52:41,207 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:37323
2025-09-03 10:52:41,216 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:37323
2025-09-03 10:52:41,216 - distributed.worker - INFO -          dashboard at:          10.6.102.36:41365
2025-09-03 10:52:41,216 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,216 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,216 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,216 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,216 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_33jvook
2025-09-03 10:52:41,216 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,266 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44717
2025-09-03 10:52:41,266 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44717
2025-09-03 10:52:41,266 - distributed.worker - INFO -          dashboard at:          10.6.102.36:37195
2025-09-03 10:52:41,266 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,266 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,266 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,266 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,266 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-iy18wxoc
2025-09-03 10:52:41,266 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,283 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:40713
2025-09-03 10:52:41,283 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:40713
2025-09-03 10:52:41,284 - distributed.worker - INFO -          dashboard at:          10.6.102.36:34427
2025-09-03 10:52:41,284 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,284 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,284 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,284 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,284 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-r83_njq3
2025-09-03 10:52:41,284 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,288 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:37125
2025-09-03 10:52:41,288 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:37125
2025-09-03 10:52:41,288 - distributed.worker - INFO -          dashboard at:          10.6.102.36:37799
2025-09-03 10:52:41,288 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,288 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,288 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,288 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-d5caz5qz
2025-09-03 10:52:41,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,292 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:39593
2025-09-03 10:52:41,292 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:39593
2025-09-03 10:52:41,292 - distributed.worker - INFO -          dashboard at:          10.6.102.36:40431
2025-09-03 10:52:41,293 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,293 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,293 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,293 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-g3011tvi
2025-09-03 10:52:41,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,309 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:33427
2025-09-03 10:52:41,309 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:33427
2025-09-03 10:52:41,309 - distributed.worker - INFO -          dashboard at:          10.6.102.36:35749
2025-09-03 10:52:41,309 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,309 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,310 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,310 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,310 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-lcbqc_6d
2025-09-03 10:52:41,310 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,313 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:45685
2025-09-03 10:52:41,313 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:45685
2025-09-03 10:52:41,313 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45989
2025-09-03 10:52:41,313 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,313 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,313 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,313 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-1rziygb1
2025-09-03 10:52:41,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,321 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:42893
2025-09-03 10:52:41,321 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:42893
2025-09-03 10:52:41,321 - distributed.worker - INFO -          dashboard at:          10.6.102.36:43011
2025-09-03 10:52:41,321 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,321 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,321 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,321 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,321 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-aei30y8c
2025-09-03 10:52:41,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,325 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43875
2025-09-03 10:52:41,325 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43875
2025-09-03 10:52:41,325 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38561
2025-09-03 10:52:41,325 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,325 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,325 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,325 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,325 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-viazr_9t
2025-09-03 10:52:41,325 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,328 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:35121
2025-09-03 10:52:41,328 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:35121
2025-09-03 10:52:41,328 - distributed.worker - INFO -          dashboard at:          10.6.102.36:41209
2025-09-03 10:52:41,328 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,328 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,328 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,328 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,328 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kxshlcms
2025-09-03 10:52:41,328 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,334 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:46551
2025-09-03 10:52:41,334 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:46551
2025-09-03 10:52:41,334 - distributed.worker - INFO -          dashboard at:          10.6.102.36:35345
2025-09-03 10:52:41,334 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,334 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,334 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,334 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,334 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-jonc6g6e
2025-09-03 10:52:41,335 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,345 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:39797
2025-09-03 10:52:41,345 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:39797
2025-09-03 10:52:41,345 - distributed.worker - INFO -          dashboard at:          10.6.102.36:37823
2025-09-03 10:52:41,345 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,345 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,345 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,345 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,345 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-vcq_et1c
2025-09-03 10:52:41,345 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,347 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:34309
2025-09-03 10:52:41,347 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:34309
2025-09-03 10:52:41,347 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39335
2025-09-03 10:52:41,347 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,347 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,347 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,347 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-v8app7mz
2025-09-03 10:52:41,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,357 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:33131
2025-09-03 10:52:41,357 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:33131
2025-09-03 10:52:41,357 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39229
2025-09-03 10:52:41,357 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,357 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,357 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,357 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,357 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-qsj2l6sh
2025-09-03 10:52:41,357 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,382 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:42099
2025-09-03 10:52:41,382 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:42099
2025-09-03 10:52:41,382 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45687
2025-09-03 10:52:41,382 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,382 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,382 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,382 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,382 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-qt3p71_h
2025-09-03 10:52:41,382 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,396 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41079
2025-09-03 10:52:41,396 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41079
2025-09-03 10:52:41,396 - distributed.worker - INFO -          dashboard at:          10.6.102.36:40855
2025-09-03 10:52:41,397 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,397 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,397 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,397 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,397 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-jw7h322j
2025-09-03 10:52:41,397 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,402 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:40335
2025-09-03 10:52:41,402 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:40335
2025-09-03 10:52:41,402 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45553
2025-09-03 10:52:41,402 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,402 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,402 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,402 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,402 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-jfcl4poy
2025-09-03 10:52:41,402 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,426 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:36085
2025-09-03 10:52:41,426 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:36085
2025-09-03 10:52:41,426 - distributed.worker - INFO -          dashboard at:          10.6.102.36:41107
2025-09-03 10:52:41,426 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,427 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,427 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,427 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,427 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-9uy_dgfm
2025-09-03 10:52:41,427 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,436 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:33495
2025-09-03 10:52:41,437 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:33495
2025-09-03 10:52:41,437 - distributed.worker - INFO -          dashboard at:          10.6.102.36:46159
2025-09-03 10:52:41,437 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,437 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,437 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,437 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,437 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6oo9_eyv
2025-09-03 10:52:41,437 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,503 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:45125
2025-09-03 10:52:41,503 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:45125
2025-09-03 10:52:41,503 - distributed.worker - INFO -          dashboard at:          10.6.102.36:44175
2025-09-03 10:52:41,503 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,503 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,503 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,503 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,503 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_ilu6k4z
2025-09-03 10:52:41,503 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41695
2025-09-03 10:52:41,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41695
2025-09-03 10:52:41,562 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38287
2025-09-03 10:52:41,562 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,562 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,562 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,562 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-y8xz18qp
2025-09-03 10:52:41,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,575 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:36377
2025-09-03 10:52:41,575 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:36377
2025-09-03 10:52:41,576 - distributed.worker - INFO -          dashboard at:          10.6.102.36:35147
2025-09-03 10:52:41,576 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,576 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,576 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,576 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,576 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7gm_pnd8
2025-09-03 10:52:41,576 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,638 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44199
2025-09-03 10:52:41,638 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44199
2025-09-03 10:52:41,638 - distributed.worker - INFO -          dashboard at:          10.6.102.36:35725
2025-09-03 10:52:41,638 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,638 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,638 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,638 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,638 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ccw3gafu
2025-09-03 10:52:41,638 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,644 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:34553
2025-09-03 10:52:41,644 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:34553
2025-09-03 10:52:41,644 - distributed.worker - INFO -          dashboard at:          10.6.102.36:43327
2025-09-03 10:52:41,644 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,644 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,644 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,644 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-r8r7qtq8
2025-09-03 10:52:41,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,656 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41255
2025-09-03 10:52:41,656 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41255
2025-09-03 10:52:41,656 - distributed.worker - INFO -          dashboard at:          10.6.102.36:40981
2025-09-03 10:52:41,656 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,656 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,656 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,656 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,656 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4x5kx1bk
2025-09-03 10:52:41,657 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,659 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,660 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,660 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,661 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,749 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41783
2025-09-03 10:52:41,749 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41783
2025-09-03 10:52:41,749 - distributed.worker - INFO -          dashboard at:          10.6.102.36:37493
2025-09-03 10:52:41,749 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,749 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,749 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,749 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,749 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-n_4le07o
2025-09-03 10:52:41,749 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,764 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43467
2025-09-03 10:52:41,764 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43467
2025-09-03 10:52:41,764 - distributed.worker - INFO -          dashboard at:          10.6.102.36:44679
2025-09-03 10:52:41,765 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,765 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,765 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,765 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,765 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-g_pb8f7f
2025-09-03 10:52:41,765 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,777 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43395
2025-09-03 10:52:41,777 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43395
2025-09-03 10:52:41,777 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45667
2025-09-03 10:52:41,777 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,778 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,778 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,778 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-rt6qxp33
2025-09-03 10:52:41,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,802 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44239
2025-09-03 10:52:41,802 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44239
2025-09-03 10:52:41,802 - distributed.worker - INFO -          dashboard at:          10.6.102.36:32881
2025-09-03 10:52:41,802 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,802 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,802 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,802 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ma8m2_y1
2025-09-03 10:52:41,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,815 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:45163
2025-09-03 10:52:41,816 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:45163
2025-09-03 10:52:41,816 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38945
2025-09-03 10:52:41,816 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,816 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,816 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,816 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,816 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-1mbfvb78
2025-09-03 10:52:41,816 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,860 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,861 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,862 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,863 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,878 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:46739
2025-09-03 10:52:41,878 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:46739
2025-09-03 10:52:41,878 - distributed.worker - INFO -          dashboard at:          10.6.102.36:34063
2025-09-03 10:52:41,878 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,878 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,878 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,878 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,878 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6af56eis
2025-09-03 10:52:41,878 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,886 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44535
2025-09-03 10:52:41,886 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44535
2025-09-03 10:52:41,886 - distributed.worker - INFO -          dashboard at:          10.6.102.36:42599
2025-09-03 10:52:41,886 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,886 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,887 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,887 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,887 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-mt8a4qb1
2025-09-03 10:52:41,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,892 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:36125
2025-09-03 10:52:41,892 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:36125
2025-09-03 10:52:41,892 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39853
2025-09-03 10:52:41,892 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,892 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,892 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:41,892 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:41,892 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-l6oek0a7
2025-09-03 10:52:41,892 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,903 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,904 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,904 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,905 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,919 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,919 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,920 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,961 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,962 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,962 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,964 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:41,975 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:41,976 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:41,977 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:41,978 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,045 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44589
2025-09-03 10:52:42,045 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44589
2025-09-03 10:52:42,045 - distributed.worker - INFO -          dashboard at:          10.6.102.36:41425
2025-09-03 10:52:42,045 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,045 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,045 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,045 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,045 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-izuiec49
2025-09-03 10:52:42,045 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,046 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,047 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,047 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,049 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,061 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,062 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,062 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,063 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,075 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,076 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,076 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,078 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,106 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:46271
2025-09-03 10:52:42,106 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:46271
2025-09-03 10:52:42,106 - distributed.worker - INFO -          dashboard at:          10.6.102.36:43123
2025-09-03 10:52:42,106 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,106 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,106 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,106 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,106 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ghud2c0j
2025-09-03 10:52:42,106 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,119 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,121 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,125 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,127 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:40331
2025-09-03 10:52:42,127 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:40331
2025-09-03 10:52:42,127 - distributed.worker - INFO -          dashboard at:          10.6.102.36:35497
2025-09-03 10:52:42,127 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,127 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,127 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,127 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,127 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-z9q484au
2025-09-03 10:52:42,127 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,132 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,133 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,133 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,135 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,144 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:40727
2025-09-03 10:52:42,144 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:40727
2025-09-03 10:52:42,144 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39215
2025-09-03 10:52:42,144 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,144 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,144 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,144 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,144 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-zy5edtjz
2025-09-03 10:52:42,144 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,146 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,148 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,148 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,149 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,161 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,162 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,162 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,164 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,169 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:37483
2025-09-03 10:52:42,170 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:37483
2025-09-03 10:52:42,170 - distributed.worker - INFO -          dashboard at:          10.6.102.36:37049
2025-09-03 10:52:42,170 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,170 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,170 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,170 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,170 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4ues0nf_
2025-09-03 10:52:42,170 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,175 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,177 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,177 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,178 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,186 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:34869
2025-09-03 10:52:42,186 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:34869
2025-09-03 10:52:42,186 - distributed.worker - INFO -          dashboard at:          10.6.102.36:41819
2025-09-03 10:52:42,186 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,186 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,186 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,186 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,186 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-dreri1q4
2025-09-03 10:52:42,186 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,190 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,191 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,191 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,193 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,194 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:42177
2025-09-03 10:52:42,194 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:42177
2025-09-03 10:52:42,194 - distributed.worker - INFO -          dashboard at:          10.6.102.36:42775
2025-09-03 10:52:42,194 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,194 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,194 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,194 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,194 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-hotsu49m
2025-09-03 10:52:42,194 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,204 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,206 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,206 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,208 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,219 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,220 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,220 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,221 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,247 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,248 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,248 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,250 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,262 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:42,263 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,263 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,265 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:42,292 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41359
2025-09-03 10:52:42,292 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41359
2025-09-03 10:52:42,293 - distributed.worker - INFO -          dashboard at:          10.6.102.36:33967
2025-09-03 10:52:42,293 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,293 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,293 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,293 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wvgmams8
2025-09-03 10:52:42,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,293 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:33831
2025-09-03 10:52:42,294 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:33831
2025-09-03 10:52:42,294 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39985
2025-09-03 10:52:42,294 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,294 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,294 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,294 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,294 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_mpx9jwv
2025-09-03 10:52:42,294 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,295 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:33385
2025-09-03 10:52:42,295 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:33385
2025-09-03 10:52:42,295 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45303
2025-09-03 10:52:42,295 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,295 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,295 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,295 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-z20x19m_
2025-09-03 10:52:42,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,302 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:33739
2025-09-03 10:52:42,302 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:33739
2025-09-03 10:52:42,302 - distributed.worker - INFO -          dashboard at:          10.6.102.36:41769
2025-09-03 10:52:42,302 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,302 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,302 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,302 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2s8hellf
2025-09-03 10:52:42,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,302 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:36297
2025-09-03 10:52:42,302 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:36297
2025-09-03 10:52:42,302 - distributed.worker - INFO -          dashboard at:          10.6.102.36:40661
2025-09-03 10:52:42,302 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,302 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,302 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,302 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-bdyny0af
2025-09-03 10:52:42,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,304 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41033
2025-09-03 10:52:42,304 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41033
2025-09-03 10:52:42,304 - distributed.worker - INFO -          dashboard at:          10.6.102.36:42627
2025-09-03 10:52:42,304 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,304 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,304 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,304 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,304 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-isbgh8jq
2025-09-03 10:52:42,304 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,307 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:35301
2025-09-03 10:52:42,307 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44161
2025-09-03 10:52:42,307 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:35301
2025-09-03 10:52:42,307 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44161
2025-09-03 10:52:42,307 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38325
2025-09-03 10:52:42,307 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,307 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45267
2025-09-03 10:52:42,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,307 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,307 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,307 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,307 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,307 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,307 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ow0serm0
2025-09-03 10:52:42,307 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-octaou14
2025-09-03 10:52:42,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,308 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,312 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:34973
2025-09-03 10:52:42,312 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:34973
2025-09-03 10:52:42,312 - distributed.worker - INFO -          dashboard at:          10.6.102.36:43057
2025-09-03 10:52:42,312 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,312 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,312 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,312 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,312 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4byc4m8v
2025-09-03 10:52:42,312 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:33365
2025-09-03 10:52:42,312 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,312 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:33365
2025-09-03 10:52:42,312 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38985
2025-09-03 10:52:42,313 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,313 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,313 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,313 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-i0ppxwqp
2025-09-03 10:52:42,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,314 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43219
2025-09-03 10:52:42,314 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43219
2025-09-03 10:52:42,314 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39171
2025-09-03 10:52:42,314 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,314 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,314 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,314 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-h2n9scvg
2025-09-03 10:52:42,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,314 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:36241
2025-09-03 10:52:42,314 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:36241
2025-09-03 10:52:42,314 - distributed.worker - INFO -          dashboard at:          10.6.102.36:37183
2025-09-03 10:52:42,314 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,314 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,314 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,314 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-tiodbwr2
2025-09-03 10:52:42,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,316 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:35581
2025-09-03 10:52:42,316 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:35581
2025-09-03 10:52:42,316 - distributed.worker - INFO -          dashboard at:          10.6.102.36:43841
2025-09-03 10:52:42,316 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,316 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,316 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,316 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,316 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-y83mwduc
2025-09-03 10:52:42,316 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,317 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41545
2025-09-03 10:52:42,317 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41545
2025-09-03 10:52:42,317 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38263
2025-09-03 10:52:42,317 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,317 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,317 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,318 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,318 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-901ycr5k
2025-09-03 10:52:42,318 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,318 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:42267
2025-09-03 10:52:42,318 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:42267
2025-09-03 10:52:42,318 - distributed.worker - INFO -          dashboard at:          10.6.102.36:43205
2025-09-03 10:52:42,318 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,318 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,318 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,318 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,318 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-c_j2237a
2025-09-03 10:52:42,318 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,322 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:42125
2025-09-03 10:52:42,322 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:42125
2025-09-03 10:52:42,322 - distributed.worker - INFO -          dashboard at:          10.6.102.36:33063
2025-09-03 10:52:42,322 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,322 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,322 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,322 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wiu7tpso
2025-09-03 10:52:42,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,326 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43773
2025-09-03 10:52:42,326 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43773
2025-09-03 10:52:42,326 - distributed.worker - INFO -          dashboard at:          10.6.102.36:44347
2025-09-03 10:52:42,326 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,326 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,327 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,327 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,327 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-pqixn4f6
2025-09-03 10:52:42,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,327 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:46443
2025-09-03 10:52:42,327 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:46443
2025-09-03 10:52:42,327 - distributed.worker - INFO -          dashboard at:          10.6.102.36:43329
2025-09-03 10:52:42,327 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,327 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,327 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,327 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-p919m07q
2025-09-03 10:52:42,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,328 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:44071
2025-09-03 10:52:42,328 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:44071
2025-09-03 10:52:42,328 - distributed.worker - INFO -          dashboard at:          10.6.102.36:39081
2025-09-03 10:52:42,328 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,328 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,328 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,328 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,328 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-b9ih7nb9
2025-09-03 10:52:42,328 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,331 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:37495
2025-09-03 10:52:42,331 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:37495
2025-09-03 10:52:42,331 - distributed.worker - INFO -          dashboard at:          10.6.102.36:37001
2025-09-03 10:52:42,331 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,331 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,331 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,331 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8jk9kcpx
2025-09-03 10:52:42,331 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41541
2025-09-03 10:52:42,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,331 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41541
2025-09-03 10:52:42,331 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38097
2025-09-03 10:52:42,331 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,331 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,331 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,331 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-zk846bm8
2025-09-03 10:52:42,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,331 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:33545
2025-09-03 10:52:42,332 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:33545
2025-09-03 10:52:42,332 - distributed.worker - INFO -          dashboard at:          10.6.102.36:38475
2025-09-03 10:52:42,332 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,332 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,332 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,332 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8mknd18q
2025-09-03 10:52:42,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,333 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:42457
2025-09-03 10:52:42,333 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:42457
2025-09-03 10:52:42,333 - distributed.worker - INFO -          dashboard at:          10.6.102.36:36421
2025-09-03 10:52:42,333 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,333 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,333 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,333 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ze4l_m5n
2025-09-03 10:52:42,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,334 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:46413
2025-09-03 10:52:42,334 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:46413
2025-09-03 10:52:42,334 - distributed.worker - INFO -          dashboard at:          10.6.102.36:41339
2025-09-03 10:52:42,335 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,335 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,335 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,335 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,335 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-3sozls9e
2025-09-03 10:52:42,335 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,335 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:37111
2025-09-03 10:52:42,335 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:37111
2025-09-03 10:52:42,335 - distributed.worker - INFO -          dashboard at:          10.6.102.36:40377
2025-09-03 10:52:42,335 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,335 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,335 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,335 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,335 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-y9kt1obz
2025-09-03 10:52:42,335 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,336 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:38379
2025-09-03 10:52:42,336 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:38379
2025-09-03 10:52:42,336 - distributed.worker - INFO -          dashboard at:          10.6.102.36:36977
2025-09-03 10:52:42,336 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,336 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,336 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,336 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-adf8a9at
2025-09-03 10:52:42,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,339 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:39575
2025-09-03 10:52:42,339 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:39575
2025-09-03 10:52:42,339 - distributed.worker - INFO -          dashboard at:          10.6.102.36:36797
2025-09-03 10:52:42,339 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,339 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,339 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,339 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,339 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-0o8u71u7
2025-09-03 10:52:42,339 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,339 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:41139
2025-09-03 10:52:42,340 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:41139
2025-09-03 10:52:42,340 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45241
2025-09-03 10:52:42,340 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,340 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,340 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,340 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-w2oh_vnz
2025-09-03 10:52:42,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,348 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:43397
2025-09-03 10:52:42,348 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:43397
2025-09-03 10:52:42,349 - distributed.worker - INFO -          dashboard at:          10.6.102.36:41005
2025-09-03 10:52:42,349 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,349 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,349 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,349 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,349 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-g1h2bhfg
2025-09-03 10:52:42,349 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,353 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.36:45753
2025-09-03 10:52:42,353 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.36:45753
2025-09-03 10:52:42,353 - distributed.worker - INFO -          dashboard at:          10.6.102.36:45545
2025-09-03 10:52:42,353 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:42,353 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:42,353 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:42,353 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:42,353 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-j63i633a
2025-09-03 10:52:42,353 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:43,367 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:43,368 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:43,368 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:43,370 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:43,642 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:43,644 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:43,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:43,646 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:43,658 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:43,659 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:43,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:43,662 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:43,673 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:43,674 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:43,674 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:43,676 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:43,687 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:43,688 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:43,689 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:43,690 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:43,702 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:43,703 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:43,703 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:43,705 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,167 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,168 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,168 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,170 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,183 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,184 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,184 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,186 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,198 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,199 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,199 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,201 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,212 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,213 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,213 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,215 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,227 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,228 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,229 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,231 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,287 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,288 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,290 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,301 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,303 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,303 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,305 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,375 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,377 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,377 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,379 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,391 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,393 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,397 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,404 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,405 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,406 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,407 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,419 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,420 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,420 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,422 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,433 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,435 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,435 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,437 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,448 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,449 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,449 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,451 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,462 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,463 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,463 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,465 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,477 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,478 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,478 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,480 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,492 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,493 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,493 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,495 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,506 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,507 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,507 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,509 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,521 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,522 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,522 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,524 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,535 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,536 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,536 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,538 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,550 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,551 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,551 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,553 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,565 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,566 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,568 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,579 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,581 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,581 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,582 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,594 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,596 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,598 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,610 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,611 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,613 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,625 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,626 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,628 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,639 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,640 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,640 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,642 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,654 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,655 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,656 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,658 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,669 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,670 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,671 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,673 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,684 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,685 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,685 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,687 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,699 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,700 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,700 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,702 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,713 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,714 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,715 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,717 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,728 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,729 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,729 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,731 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,742 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,743 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,744 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,745 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,758 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,759 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,759 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,761 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,772 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,774 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,774 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,776 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,817 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,818 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,820 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:44,832 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:44,833 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:44,833 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:44,835 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:46,613 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:46,614 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:46,614 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:46,616 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,066 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,068 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,068 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,070 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,082 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,083 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,083 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,085 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,096 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,097 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,097 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,099 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,113 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,113 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,115 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,126 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,127 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,129 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,142 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,143 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,143 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,145 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,156 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,157 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,157 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,159 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,597 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,599 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,600 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,613 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,614 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,614 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,616 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:47,628 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:47,629 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:47,629 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:47,631 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:48,187 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:48,189 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:48,189 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:48,191 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:48,325 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:48,327 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:48,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:48,329 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:48,416 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:48,417 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:48,417 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:48,419 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:48,446 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:48,448 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:48,448 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:48,449 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:48,523 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:48,524 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:48,525 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:48,526 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:48,707 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:48,709 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:48,709 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:48,710 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:48,738 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:48,740 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:48,740 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:48,741 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:50,064 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:50,065 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:50,066 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:50,067 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:50,080 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:50,082 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:50,082 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:50,084 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:50,095 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:50,097 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:50,097 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:50,099 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:50,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:50,113 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:50,113 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:50,114 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:51,744 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:51,745 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:51,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:51,747 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:51,760 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:51,761 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:51,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:51,762 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:51,811 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:51,812 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:51,813 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:51,814 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:51,827 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:51,828 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:51,828 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:51,830 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:51,843 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:51,844 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:51,844 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:51,846 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:51,907 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:51,908 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:51,909 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:51,910 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:51,923 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:51,925 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:51,925 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:51,926 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:05,182 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:05,184 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:05,184 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:05,186 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:05,199 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:05,201 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:05,201 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:05,202 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:05,216 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:05,217 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:05,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:05,219 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:05,232 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:05,234 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:05,234 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:05,235 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:05,249 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:05,251 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:05,251 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:05,253 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:10,914 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:15,381 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,398 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,411 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,426 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,438 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,454 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,467 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,485 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,498 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,512 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,527 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,540 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,555 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,571 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,585 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,601 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,617 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,631 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,644 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,659 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,675 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,690 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,706 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,719 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:15,734 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:22,750 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:22,765 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:22,818 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:22,833 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:22,849 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:22,915 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:22,929 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:33,424 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:33,425 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:33,425 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:33,427 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:46,381 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,398 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,411 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,425 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,440 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,453 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,469 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,483 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,497 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,511 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,526 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,540 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,555 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,570 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,660 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,675 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,690 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,705 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,718 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:46,734 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:56:38,168 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,174 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,624 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,626 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,694 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,704 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,709 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,729 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,735 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,751 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,754 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,289 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,290 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,601 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,604 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,648 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,649 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,794 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,799 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,957 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,958 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,203 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,204 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,231 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,236 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,303 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,306 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,449 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,450 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,752 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,755 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,773 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,774 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,191 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,197 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,320 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,325 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,529 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,531 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,751 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,752 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,254 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,255 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,281 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,286 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,363 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,365 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,634 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,636 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,078 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,083 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,318 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,319 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,913 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,914 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,979 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,980 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,903 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,908 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,986 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,990 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,033 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,037 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,101 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,103 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,253 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,257 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,389 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,394 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,799 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,801 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,896 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,899 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,985 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,987 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,274 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,275 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,320 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,328 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,414 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,419 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,521 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,527 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,795 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,191 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,196 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,250 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,252 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,630 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,647 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,650 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,762 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,298 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,302 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,820 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,826 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,836 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,288 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,290 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,350 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,361 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,462 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,463 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,465 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,470 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,766 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,767 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,069 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,070 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,257 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,262 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,618 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,620 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,653 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,063 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,065 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,206 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,208 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,552 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,557 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,566 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,567 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,589 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,595 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,824 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,826 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,854 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,860 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,909 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,914 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,032 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,034 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,119 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,124 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,280 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,286 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,845 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,847 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,114 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,118 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,143 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,145 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,153 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,159 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,320 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,323 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,344 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,345 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,839 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,841 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,325 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,326 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,823 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,826 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,007 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,012 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,608 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,610 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,758 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,760 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,120 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,125 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,249 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,250 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,695 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:58,944 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:58,945 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:00,684 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:00,687 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:00,949 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:00,956 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:00,959 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:00,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:01,193 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:01,194 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:01,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:01,696 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:01,784 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:01,786 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:02,128 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:02,131 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:02,397 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:02,403 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:02,608 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:02,613 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:02,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:02,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:03,307 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:03,312 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:03,470 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:03,471 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:03,599 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:03,604 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:04,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:04,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:09,477 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:09,478 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:09,479 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:09,480 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:09,994 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:09,995 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:09,996 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:09,997 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:09,996 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:09,998 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,012 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,014 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,027 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,346 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,348 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,351 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,353 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,353 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,355 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,509 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,511 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,523 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,525 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,530 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,532 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,541 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,543 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,622 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,624 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,627 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,629 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,633 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,635 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,664 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,666 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,740 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,742 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,746 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,748 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,756 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,755 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,758 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,760 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,783 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,783 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,789 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,796 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,801 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,803 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,884 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,887 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,913 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,915 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,929 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,931 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,104 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,106 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,122 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,124 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,128 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,130 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,131 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,133 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,171 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,173 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,270 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,272 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,272 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,274 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,276 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,278 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,306 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,310 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,312 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,312 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,314 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,315 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,320 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,368 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,370 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,405 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,409 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,414 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,417 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,465 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,467 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,491 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,542 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,555 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,555 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,557 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,557 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,589 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,591 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,602 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,604 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,703 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,706 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,771 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,772 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,789 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,791 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,806 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,809 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,861 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,863 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,878 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,880 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,957 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,959 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,976 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,978 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,054 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,056 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,063 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,065 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,180 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,184 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,192 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,194 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,239 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,240 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,242 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,246 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,290 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,292 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,386 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,388 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,403 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,405 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,446 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,475 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,477 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,482 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,484 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,503 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,506 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,556 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,561 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,645 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,647 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,660 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,664 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,825 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,827 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,833 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,833 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,835 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,836 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,907 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,909 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,925 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,927 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,935 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,937 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,938 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,940 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,979 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,984 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,992 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,994 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,010 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,012 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,093 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,095 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,161 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,163 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,353 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,355 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,398 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,400 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,904 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,906 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,907 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,910 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,961 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,963 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:14,026 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:14,028 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:14,287 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:14,289 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:15,411 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:15,413 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:15,524 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:15,530 - distributed.utils - INFO - Reload module qme_vars from .py file
