Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:31:34,834 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:39127'
2025-09-03 10:31:34,843 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:44629'
2025-09-03 10:31:34,848 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36069'
2025-09-03 10:31:34,855 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36893'
2025-09-03 10:31:34,859 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:33227'
2025-09-03 10:31:34,938 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:41907'
2025-09-03 10:31:34,942 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:43317'
2025-09-03 10:31:34,946 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:43677'
2025-09-03 10:31:34,950 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:35947'
2025-09-03 10:31:34,954 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36437'
2025-09-03 10:31:34,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38195'
2025-09-03 10:31:34,964 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36905'
2025-09-03 10:31:34,968 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:33579'
2025-09-03 10:31:34,973 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:42703'
2025-09-03 10:31:34,977 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:33469'
2025-09-03 10:31:34,982 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:34809'
2025-09-03 10:31:34,986 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:44841'
2025-09-03 10:31:34,991 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:43965'
2025-09-03 10:31:34,995 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:45301'
2025-09-03 10:31:35,000 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:42127'
2025-09-03 10:31:35,004 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:46499'
2025-09-03 10:31:35,009 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:40519'
2025-09-03 10:31:35,013 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38975'
2025-09-03 10:31:35,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:37987'
2025-09-03 10:31:35,021 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:41201'
2025-09-03 10:31:35,024 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:40095'
2025-09-03 10:31:35,028 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:34667'
2025-09-03 10:31:35,034 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:43303'
2025-09-03 10:31:35,039 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:40913'
2025-09-03 10:31:35,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:43611'
2025-09-03 10:31:35,048 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:45783'
2025-09-03 10:31:35,053 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38521'
2025-09-03 10:31:35,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:43799'
2025-09-03 10:31:35,061 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:34901'
2025-09-03 10:31:35,066 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:39311'
2025-09-03 10:31:35,071 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:34199'
2025-09-03 10:31:35,076 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:42607'
2025-09-03 10:31:35,081 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36845'
2025-09-03 10:31:35,085 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:37633'
2025-09-03 10:31:35,088 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:46783'
2025-09-03 10:31:35,092 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:35707'
2025-09-03 10:31:35,096 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:44141'
2025-09-03 10:31:35,197 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:44479'
2025-09-03 10:31:35,202 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36209'
2025-09-03 10:31:35,208 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38707'
2025-09-03 10:31:35,213 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:34175'
2025-09-03 10:31:35,218 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36433'
2025-09-03 10:31:35,222 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:45059'
2025-09-03 10:31:35,228 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:45535'
2025-09-03 10:31:35,233 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:37843'
2025-09-03 10:31:35,236 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:46809'
2025-09-03 10:31:35,241 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:41583'
2025-09-03 10:31:35,246 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:44585'
2025-09-03 10:31:35,251 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:41727'
2025-09-03 10:31:35,256 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:39521'
2025-09-03 10:31:35,260 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:39739'
2025-09-03 10:31:35,263 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:34433'
2025-09-03 10:31:35,267 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:37541'
2025-09-03 10:31:35,272 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:46655'
2025-09-03 10:31:35,277 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:32831'
2025-09-03 10:31:35,285 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:41909'
2025-09-03 10:31:35,290 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36641'
2025-09-03 10:31:35,296 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:37367'
2025-09-03 10:31:35,301 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:44897'
2025-09-03 10:31:35,306 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:45217'
2025-09-03 10:31:35,312 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:43431'
2025-09-03 10:31:35,317 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36013'
2025-09-03 10:31:35,322 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38075'
2025-09-03 10:31:35,325 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:41671'
2025-09-03 10:31:35,331 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36591'
2025-09-03 10:31:35,335 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:35805'
2025-09-03 10:31:35,340 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:45563'
2025-09-03 10:31:35,346 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:40795'
2025-09-03 10:31:35,351 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38979'
2025-09-03 10:31:35,356 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38995'
2025-09-03 10:31:35,361 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:43067'
2025-09-03 10:31:35,365 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:45127'
2025-09-03 10:31:35,382 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:46301'
2025-09-03 10:31:35,387 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:46261'
2025-09-03 10:31:35,393 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:40359'
2025-09-03 10:31:35,397 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36729'
2025-09-03 10:31:35,399 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36245'
2025-09-03 10:31:35,405 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:40987'
2025-09-03 10:31:35,408 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:33869'
2025-09-03 10:31:35,412 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:42957'
2025-09-03 10:31:35,418 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:40463'
2025-09-03 10:31:35,423 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:36857'
2025-09-03 10:31:35,426 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:35905'
2025-09-03 10:31:35,429 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:39255'
2025-09-03 10:31:35,433 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38359'
2025-09-03 10:31:35,438 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:35871'
2025-09-03 10:31:35,443 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:46085'
2025-09-03 10:31:35,448 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:44069'
2025-09-03 10:31:35,452 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:44451'
2025-09-03 10:31:35,459 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38093'
2025-09-03 10:31:35,463 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:43893'
2025-09-03 10:31:35,468 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:33729'
2025-09-03 10:31:35,472 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:39179'
2025-09-03 10:31:35,477 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:42961'
2025-09-03 10:31:35,482 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:38381'
2025-09-03 10:31:35,487 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:41005'
2025-09-03 10:31:35,492 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:44599'
2025-09-03 10:31:35,498 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:46431'
2025-09-03 10:31:35,500 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.8:46835'
2025-09-03 10:31:36,777 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:41839
2025-09-03 10:31:36,777 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:41957
2025-09-03 10:31:36,777 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:41839
2025-09-03 10:31:36,777 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:44273
2025-09-03 10:31:36,777 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:38221
2025-09-03 10:31:36,777 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:46061
2025-09-03 10:31:36,777 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:41957
2025-09-03 10:31:36,777 - distributed.worker - INFO -          dashboard at:           10.6.102.8:44389
2025-09-03 10:31:36,778 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:44273
2025-09-03 10:31:36,778 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:38221
2025-09-03 10:31:36,777 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:32853
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:39581
2025-09-03 10:31:36,778 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:46061
2025-09-03 10:31:36,778 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35113
2025-09-03 10:31:36,778 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,778 - distributed.worker - INFO -          dashboard at:           10.6.102.8:43153
2025-09-03 10:31:36,778 - distributed.worker - INFO -          dashboard at:           10.6.102.8:45503
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:42371
2025-09-03 10:31:36,778 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:32853
2025-09-03 10:31:36,778 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:39581
2025-09-03 10:31:36,778 - distributed.worker - INFO -          dashboard at:           10.6.102.8:38909
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,778 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,778 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,778 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:42371
2025-09-03 10:31:36,778 - distributed.worker - INFO -          dashboard at:           10.6.102.8:38659
2025-09-03 10:31:36,778 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,778 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,778 - distributed.worker - INFO -          dashboard at:           10.6.102.8:44575
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,778 - distributed.worker - INFO -          dashboard at:           10.6.102.8:44729
2025-09-03 10:31:36,778 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,778 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,778 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,778 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,778 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,778 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,778 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x92xbbsb
2025-09-03 10:31:36,778 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,778 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,778 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,778 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4tok2wxn
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dwno5jgz
2025-09-03 10:31:36,778 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,778 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-isi0e96w
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-t8k7gvpg
2025-09-03 10:31:36,778 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gabmb09n
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9jzar0ke
2025-09-03 10:31:36,778 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tz9up0c4
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,779 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:37097
2025-09-03 10:31:36,779 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:37097
2025-09-03 10:31:36,779 - distributed.worker - INFO -          dashboard at:           10.6.102.8:45927
2025-09-03 10:31:36,779 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,779 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,779 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,779 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hmcxzjfl
2025-09-03 10:31:36,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,930 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:39109
2025-09-03 10:31:36,930 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:39109
2025-09-03 10:31:36,930 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41911
2025-09-03 10:31:36,930 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,930 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,930 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,930 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,930 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zjwykz5m
2025-09-03 10:31:36,931 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,474 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:41631
2025-09-03 10:31:37,474 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:41631
2025-09-03 10:31:37,474 - distributed.worker - INFO -          dashboard at:           10.6.102.8:38963
2025-09-03 10:31:37,474 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,474 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,474 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,474 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,474 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-10f3k_zq
2025-09-03 10:31:37,474 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,498 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:42249
2025-09-03 10:31:37,498 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:42249
2025-09-03 10:31:37,498 - distributed.worker - INFO -          dashboard at:           10.6.102.8:38475
2025-09-03 10:31:37,499 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,499 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,499 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,499 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rkqog_pm
2025-09-03 10:31:37,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,566 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:35139
2025-09-03 10:31:37,567 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:35139
2025-09-03 10:31:37,567 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41093
2025-09-03 10:31:37,567 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,567 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,567 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,567 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3tdshcqp
2025-09-03 10:31:37,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,597 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:36343
2025-09-03 10:31:37,597 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:36343
2025-09-03 10:31:37,597 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41311
2025-09-03 10:31:37,597 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,597 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,597 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,597 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pjhr3y15
2025-09-03 10:31:37,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,600 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:45801
2025-09-03 10:31:37,600 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:45801
2025-09-03 10:31:37,600 - distributed.worker - INFO -          dashboard at:           10.6.102.8:34605
2025-09-03 10:31:37,600 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,600 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,600 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,600 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-y5oivnbr
2025-09-03 10:31:37,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,610 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:33569
2025-09-03 10:31:37,610 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:33569
2025-09-03 10:31:37,610 - distributed.worker - INFO -          dashboard at:           10.6.102.8:42059
2025-09-03 10:31:37,610 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,610 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,610 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,610 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,611 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fxaxidsq
2025-09-03 10:31:37,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,633 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:43489
2025-09-03 10:31:37,633 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:43489
2025-09-03 10:31:37,633 - distributed.worker - INFO -          dashboard at:           10.6.102.8:44765
2025-09-03 10:31:37,633 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,633 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,633 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,633 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,633 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zot5dpzh
2025-09-03 10:31:37,633 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,654 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:37975
2025-09-03 10:31:37,654 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:37975
2025-09-03 10:31:37,654 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35797
2025-09-03 10:31:37,654 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,654 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,654 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,654 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,654 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cnfkxokf
2025-09-03 10:31:37,654 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,665 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:44671
2025-09-03 10:31:37,665 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:44671
2025-09-03 10:31:37,665 - distributed.worker - INFO -          dashboard at:           10.6.102.8:46045
2025-09-03 10:31:37,665 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,665 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,665 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,665 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,665 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-mjbe8guo
2025-09-03 10:31:37,665 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,675 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:44623
2025-09-03 10:31:37,675 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:44623
2025-09-03 10:31:37,676 - distributed.worker - INFO -          dashboard at:           10.6.102.8:42963
2025-09-03 10:31:37,676 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,676 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,676 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,676 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,676 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-q1zb7arc
2025-09-03 10:31:37,676 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,681 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:37649
2025-09-03 10:31:37,681 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:37649
2025-09-03 10:31:37,681 - distributed.worker - INFO -          dashboard at:           10.6.102.8:42017
2025-09-03 10:31:37,681 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,681 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,681 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,681 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,681 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-p5gdor0x
2025-09-03 10:31:37,681 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,689 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:45909
2025-09-03 10:31:37,689 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:45909
2025-09-03 10:31:37,689 - distributed.worker - INFO -          dashboard at:           10.6.102.8:39403
2025-09-03 10:31:37,689 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,689 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,689 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,689 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,689 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wi1noyo8
2025-09-03 10:31:37,689 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,703 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:34909
2025-09-03 10:31:37,703 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:34909
2025-09-03 10:31:37,703 - distributed.worker - INFO -          dashboard at:           10.6.102.8:39439
2025-09-03 10:31:37,704 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,704 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,704 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,704 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,704 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-70z1t4_l
2025-09-03 10:31:37,704 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,708 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:38505
2025-09-03 10:31:37,708 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:38505
2025-09-03 10:31:37,708 - distributed.worker - INFO -          dashboard at:           10.6.102.8:34195
2025-09-03 10:31:37,708 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,708 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,708 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,708 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,708 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-y2n4s1o9
2025-09-03 10:31:37,708 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,714 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:41929
2025-09-03 10:31:37,714 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:41929
2025-09-03 10:31:37,714 - distributed.worker - INFO -          dashboard at:           10.6.102.8:39365
2025-09-03 10:31:37,714 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,714 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,714 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,714 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,714 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dnckxyz8
2025-09-03 10:31:37,714 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,729 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:43943
2025-09-03 10:31:37,729 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:43943
2025-09-03 10:31:37,729 - distributed.worker - INFO -          dashboard at:           10.6.102.8:43477
2025-09-03 10:31:37,729 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,729 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,729 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,729 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,729 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_vh5u6y9
2025-09-03 10:31:37,729 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,732 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:37977
2025-09-03 10:31:37,732 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:37977
2025-09-03 10:31:37,732 - distributed.worker - INFO -          dashboard at:           10.6.102.8:37981
2025-09-03 10:31:37,732 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,732 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,733 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,733 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,733 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-o9_z2djh
2025-09-03 10:31:37,733 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,745 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:43471
2025-09-03 10:31:37,745 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:43471
2025-09-03 10:31:37,746 - distributed.worker - INFO -          dashboard at:           10.6.102.8:46065
2025-09-03 10:31:37,746 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,746 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,746 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,746 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,746 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uggrtdn9
2025-09-03 10:31:37,746 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,748 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:39679
2025-09-03 10:31:37,748 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:39679
2025-09-03 10:31:37,748 - distributed.worker - INFO -          dashboard at:           10.6.102.8:39715
2025-09-03 10:31:37,748 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,748 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,748 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,748 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,748 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4txds6u2
2025-09-03 10:31:37,749 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,753 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:44319
2025-09-03 10:31:37,754 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:44319
2025-09-03 10:31:37,754 - distributed.worker - INFO -          dashboard at:           10.6.102.8:37461
2025-09-03 10:31:37,754 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,754 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,754 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,754 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zwzwze67
2025-09-03 10:31:37,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,755 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:33699
2025-09-03 10:31:37,755 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:33699
2025-09-03 10:31:37,755 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35971
2025-09-03 10:31:37,755 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,755 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,755 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,755 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-450_yk0_
2025-09-03 10:31:37,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,761 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:41133
2025-09-03 10:31:37,761 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:41133
2025-09-03 10:31:37,761 - distributed.worker - INFO -          dashboard at:           10.6.102.8:34859
2025-09-03 10:31:37,761 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,761 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,761 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,761 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hv0dyot6
2025-09-03 10:31:37,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,763 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:45895
2025-09-03 10:31:37,763 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:45895
2025-09-03 10:31:37,763 - distributed.worker - INFO -          dashboard at:           10.6.102.8:37475
2025-09-03 10:31:37,763 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,763 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,763 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,763 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,763 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-oq14wswz
2025-09-03 10:31:37,764 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,765 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:43373
2025-09-03 10:31:37,765 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:43373
2025-09-03 10:31:37,765 - distributed.worker - INFO -          dashboard at:           10.6.102.8:32799
2025-09-03 10:31:37,765 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,765 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,765 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,765 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,765 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-efw75fg0
2025-09-03 10:31:37,765 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,767 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:40875
2025-09-03 10:31:37,767 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:40875
2025-09-03 10:31:37,767 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41347
2025-09-03 10:31:37,767 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,767 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,767 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,767 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l1fhpdgx
2025-09-03 10:31:37,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,772 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:38885
2025-09-03 10:31:37,772 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:38885
2025-09-03 10:31:37,772 - distributed.worker - INFO -          dashboard at:           10.6.102.8:46753
2025-09-03 10:31:37,772 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,772 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,772 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,772 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,772 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lw_dnnjr
2025-09-03 10:31:37,772 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,773 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:39605
2025-09-03 10:31:37,773 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:45147
2025-09-03 10:31:37,773 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:39605
2025-09-03 10:31:37,773 - distributed.worker - INFO -          dashboard at:           10.6.102.8:46493
2025-09-03 10:31:37,773 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:45147
2025-09-03 10:31:37,774 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,774 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,774 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35365
2025-09-03 10:31:37,774 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,774 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,774 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,774 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,774 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-e1t5n5nk
2025-09-03 10:31:37,774 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,774 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,774 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,774 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-p5c6h5le
2025-09-03 10:31:37,774 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,775 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:40413
2025-09-03 10:31:37,775 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:40413
2025-09-03 10:31:37,775 - distributed.worker - INFO -          dashboard at:           10.6.102.8:39753
2025-09-03 10:31:37,775 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,775 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,775 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,775 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_k_bv6qf
2025-09-03 10:31:37,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,778 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:39643
2025-09-03 10:31:37,778 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:39643
2025-09-03 10:31:37,779 - distributed.worker - INFO -          dashboard at:           10.6.102.8:40493
2025-09-03 10:31:37,779 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,779 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,779 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,779 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lsg_nujt
2025-09-03 10:31:37,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,779 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:41415
2025-09-03 10:31:37,779 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:41415
2025-09-03 10:31:37,779 - distributed.worker - INFO -          dashboard at:           10.6.102.8:38477
2025-09-03 10:31:37,779 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,779 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,779 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,779 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1ycbqizt
2025-09-03 10:31:37,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,788 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:34485
2025-09-03 10:31:37,788 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:34485
2025-09-03 10:31:37,788 - distributed.worker - INFO -          dashboard at:           10.6.102.8:33317
2025-09-03 10:31:37,788 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,788 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,788 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,788 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,788 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1lxrx32_
2025-09-03 10:31:37,788 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,792 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:45893
2025-09-03 10:31:37,792 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:45893
2025-09-03 10:31:37,792 - distributed.worker - INFO -          dashboard at:           10.6.102.8:45191
2025-09-03 10:31:37,792 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,793 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,793 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,793 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,793 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qxcc5o41
2025-09-03 10:31:37,793 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,797 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:35695
2025-09-03 10:31:37,797 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:35695
2025-09-03 10:31:37,797 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35241
2025-09-03 10:31:37,797 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,797 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,797 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,797 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,797 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hr61dvbh
2025-09-03 10:31:37,798 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:46201
2025-09-03 10:31:37,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:46201
2025-09-03 10:31:37,801 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35023
2025-09-03 10:31:37,801 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,801 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,802 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,802 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l2o3qwb6
2025-09-03 10:31:37,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,810 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:32883
2025-09-03 10:31:37,810 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:32883
2025-09-03 10:31:37,810 - distributed.worker - INFO -          dashboard at:           10.6.102.8:39821
2025-09-03 10:31:37,810 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,810 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,810 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,810 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,811 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-b7o47snm
2025-09-03 10:31:37,811 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,946 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:37897
2025-09-03 10:31:37,946 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:37897
2025-09-03 10:31:37,946 - distributed.worker - INFO -          dashboard at:           10.6.102.8:36113
2025-09-03 10:31:37,946 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,946 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,946 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,946 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,946 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_4z0kr8j
2025-09-03 10:31:37,946 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,039 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:38349
2025-09-03 10:31:38,039 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:38349
2025-09-03 10:31:38,039 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41895
2025-09-03 10:31:38,039 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,039 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,039 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,039 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,039 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-t31feqsu
2025-09-03 10:31:38,039 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,059 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:35085
2025-09-03 10:31:38,059 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:35085
2025-09-03 10:31:38,059 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35025
2025-09-03 10:31:38,059 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,059 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7qy8wstf
2025-09-03 10:31:38,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,072 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:43815
2025-09-03 10:31:38,072 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:43815
2025-09-03 10:31:38,072 - distributed.worker - INFO -          dashboard at:           10.6.102.8:34989
2025-09-03 10:31:38,072 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,072 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,072 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,072 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,072 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6cf9a4ly
2025-09-03 10:31:38,072 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,114 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:46725
2025-09-03 10:31:38,114 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:46725
2025-09-03 10:31:38,114 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35659
2025-09-03 10:31:38,114 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,114 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,114 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,114 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,114 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ivqc0enr
2025-09-03 10:31:38,114 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,126 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:35929
2025-09-03 10:31:38,126 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:35929
2025-09-03 10:31:38,126 - distributed.worker - INFO -          dashboard at:           10.6.102.8:46011
2025-09-03 10:31:38,126 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,126 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,126 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,126 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,126 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9art8u95
2025-09-03 10:31:38,126 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,136 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:35219
2025-09-03 10:31:38,137 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:35219
2025-09-03 10:31:38,137 - distributed.worker - INFO -          dashboard at:           10.6.102.8:45433
2025-09-03 10:31:38,137 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,137 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,137 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,137 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,137 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9omy3x_o
2025-09-03 10:31:38,137 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,145 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:33829
2025-09-03 10:31:38,145 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:33829
2025-09-03 10:31:38,145 - distributed.worker - INFO -          dashboard at:           10.6.102.8:34927
2025-09-03 10:31:38,145 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,145 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,145 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,145 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,145 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x0whethl
2025-09-03 10:31:38,145 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,170 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:46825
2025-09-03 10:31:38,171 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:46825
2025-09-03 10:31:38,171 - distributed.worker - INFO -          dashboard at:           10.6.102.8:43825
2025-09-03 10:31:38,171 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,171 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,171 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,171 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,171 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2e26_blr
2025-09-03 10:31:38,171 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,175 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:35691
2025-09-03 10:31:38,175 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:35691
2025-09-03 10:31:38,175 - distributed.worker - INFO -          dashboard at:           10.6.102.8:40655
2025-09-03 10:31:38,175 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,175 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,175 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,175 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-i8brh4vt
2025-09-03 10:31:38,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,178 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:42473
2025-09-03 10:31:38,178 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:42473
2025-09-03 10:31:38,178 - distributed.worker - INFO -          dashboard at:           10.6.102.8:32993
2025-09-03 10:31:38,178 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,178 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,178 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,178 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,178 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vxq3ny0f
2025-09-03 10:31:38,178 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,179 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:42521
2025-09-03 10:31:38,179 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:42521
2025-09-03 10:31:38,179 - distributed.worker - INFO -          dashboard at:           10.6.102.8:40123
2025-09-03 10:31:38,179 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,179 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,179 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,180 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,180 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-e3r7h2bq
2025-09-03 10:31:38,180 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,182 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:36047
2025-09-03 10:31:38,182 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:36047
2025-09-03 10:31:38,183 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35963
2025-09-03 10:31:38,183 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,183 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,183 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,183 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,183 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ipccsh20
2025-09-03 10:31:38,183 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,192 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:45759
2025-09-03 10:31:38,192 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:45759
2025-09-03 10:31:38,192 - distributed.worker - INFO -          dashboard at:           10.6.102.8:46309
2025-09-03 10:31:38,193 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,193 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,193 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,193 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,193 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3748_fjr
2025-09-03 10:31:38,193 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,196 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:39845
2025-09-03 10:31:38,196 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:39845
2025-09-03 10:31:38,196 - distributed.worker - INFO -          dashboard at:           10.6.102.8:44761
2025-09-03 10:31:38,196 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,196 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,196 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,196 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-sgn_yr5j
2025-09-03 10:31:38,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,198 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:39355
2025-09-03 10:31:38,198 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:39355
2025-09-03 10:31:38,198 - distributed.worker - INFO -          dashboard at:           10.6.102.8:37661
2025-09-03 10:31:38,198 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,198 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,198 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,198 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,198 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n15tgl3m
2025-09-03 10:31:38,198 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,204 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:40025
2025-09-03 10:31:38,204 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:40025
2025-09-03 10:31:38,204 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41959
2025-09-03 10:31:38,204 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,204 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,204 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,204 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,204 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bocj10eb
2025-09-03 10:31:38,204 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,206 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:45525
2025-09-03 10:31:38,206 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:45525
2025-09-03 10:31:38,206 - distributed.worker - INFO -          dashboard at:           10.6.102.8:40989
2025-09-03 10:31:38,206 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,206 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,206 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,206 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,206 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-yleoc039
2025-09-03 10:31:38,206 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,209 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:37489
2025-09-03 10:31:38,209 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:37489
2025-09-03 10:31:38,209 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41045
2025-09-03 10:31:38,209 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,209 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,209 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,209 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,209 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-eawaaqez
2025-09-03 10:31:38,209 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,213 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:33011
2025-09-03 10:31:38,214 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:33011
2025-09-03 10:31:38,214 - distributed.worker - INFO -          dashboard at:           10.6.102.8:36725
2025-09-03 10:31:38,214 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,214 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,214 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,214 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,214 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-67dtzl79
2025-09-03 10:31:38,214 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,218 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:42259
2025-09-03 10:31:38,218 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:42259
2025-09-03 10:31:38,218 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35177
2025-09-03 10:31:38,218 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,218 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,218 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,218 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-h9pgrs4q
2025-09-03 10:31:38,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,223 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:38203
2025-09-03 10:31:38,223 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:38203
2025-09-03 10:31:38,223 - distributed.worker - INFO -          dashboard at:           10.6.102.8:45175
2025-09-03 10:31:38,223 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,223 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,223 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,223 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,223 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6594os2a
2025-09-03 10:31:38,223 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,224 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:32947
2025-09-03 10:31:38,224 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:32947
2025-09-03 10:31:38,224 - distributed.worker - INFO -          dashboard at:           10.6.102.8:33017
2025-09-03 10:31:38,224 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,224 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,224 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,224 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,224 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-38gsic0g
2025-09-03 10:31:38,224 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,382 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:44193
2025-09-03 10:31:38,383 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:44193
2025-09-03 10:31:38,383 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41545
2025-09-03 10:31:38,383 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,383 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,383 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,383 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6herk9t9
2025-09-03 10:31:38,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,414 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:44617
2025-09-03 10:31:38,414 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:44617
2025-09-03 10:31:38,414 - distributed.worker - INFO -          dashboard at:           10.6.102.8:46371
2025-09-03 10:31:38,414 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,414 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,414 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,414 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,414 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-iklhg2jy
2025-09-03 10:31:38,414 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,524 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:33611
2025-09-03 10:31:38,524 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:33611
2025-09-03 10:31:38,524 - distributed.worker - INFO -          dashboard at:           10.6.102.8:43463
2025-09-03 10:31:38,524 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,524 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,524 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,524 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,524 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3km5o3my
2025-09-03 10:31:38,524 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,593 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:33039
2025-09-03 10:31:38,593 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:33039
2025-09-03 10:31:38,593 - distributed.worker - INFO -          dashboard at:           10.6.102.8:34287
2025-09-03 10:31:38,594 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,594 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,594 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,594 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-i0ocmd4k
2025-09-03 10:31:38,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,595 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:33719
2025-09-03 10:31:38,595 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:33719
2025-09-03 10:31:38,595 - distributed.worker - INFO -          dashboard at:           10.6.102.8:36091
2025-09-03 10:31:38,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,595 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,595 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,595 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-75b0mxrg
2025-09-03 10:31:38,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,596 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:40617
2025-09-03 10:31:38,596 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:40617
2025-09-03 10:31:38,596 - distributed.worker - INFO -          dashboard at:           10.6.102.8:39031
2025-09-03 10:31:38,596 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,597 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,597 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-r_u9okpm
2025-09-03 10:31:38,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,628 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:39303
2025-09-03 10:31:38,628 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:39303
2025-09-03 10:31:38,628 - distributed.worker - INFO -          dashboard at:           10.6.102.8:45153
2025-09-03 10:31:38,628 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,628 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,628 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,628 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5m0nh5ad
2025-09-03 10:31:38,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,799 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:37061
2025-09-03 10:31:38,799 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:37061
2025-09-03 10:31:38,799 - distributed.worker - INFO -          dashboard at:           10.6.102.8:34045
2025-09-03 10:31:38,799 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,799 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,799 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,799 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,799 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0ho837p3
2025-09-03 10:31:38,799 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,816 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:34289
2025-09-03 10:31:38,816 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:34289
2025-09-03 10:31:38,816 - distributed.worker - INFO -          dashboard at:           10.6.102.8:35127
2025-09-03 10:31:38,816 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,816 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,816 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,816 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,816 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-666eoxzy
2025-09-03 10:31:38,816 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,824 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:40545
2025-09-03 10:31:38,824 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:40545
2025-09-03 10:31:38,825 - distributed.worker - INFO -          dashboard at:           10.6.102.8:43003
2025-09-03 10:31:38,825 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,825 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,825 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,825 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,825 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-f7b7zdvc
2025-09-03 10:31:38,825 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,836 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:44925
2025-09-03 10:31:38,836 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:44925
2025-09-03 10:31:38,836 - distributed.worker - INFO -          dashboard at:           10.6.102.8:40469
2025-09-03 10:31:38,836 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,836 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,836 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,836 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,836 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-d8jfrn10
2025-09-03 10:31:38,836 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,857 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:44921
2025-09-03 10:31:38,858 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:44921
2025-09-03 10:31:38,858 - distributed.worker - INFO -          dashboard at:           10.6.102.8:34495
2025-09-03 10:31:38,858 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,858 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,858 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,858 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ry_401mb
2025-09-03 10:31:38,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,859 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:41309
2025-09-03 10:31:38,860 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:41309
2025-09-03 10:31:38,860 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41027
2025-09-03 10:31:38,860 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,860 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,860 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,860 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,860 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-b8mt65k7
2025-09-03 10:31:38,860 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,866 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:37217
2025-09-03 10:31:38,866 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:37217
2025-09-03 10:31:38,866 - distributed.worker - INFO -          dashboard at:           10.6.102.8:41585
2025-09-03 10:31:38,866 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,866 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,866 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,866 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,866 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kwtyzo2n
2025-09-03 10:31:38,866 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,906 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:33319
2025-09-03 10:31:38,906 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:33319
2025-09-03 10:31:38,906 - distributed.worker - INFO -          dashboard at:           10.6.102.8:39761
2025-09-03 10:31:38,906 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,906 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,906 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,906 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3eb3yv6q
2025-09-03 10:31:38,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,921 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:35883
2025-09-03 10:31:38,922 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:35883
2025-09-03 10:31:38,922 - distributed.worker - INFO -          dashboard at:           10.6.102.8:39993
2025-09-03 10:31:38,922 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,922 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,922 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,922 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,922 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tr2nwo1g
2025-09-03 10:31:38,922 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,922 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:40027
2025-09-03 10:31:38,922 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:40027
2025-09-03 10:31:38,922 - distributed.worker - INFO -          dashboard at:           10.6.102.8:45675
2025-09-03 10:31:38,922 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,922 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,922 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,922 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,922 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3zonbt34
2025-09-03 10:31:38,922 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,939 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:43843
2025-09-03 10:31:38,939 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:43843
2025-09-03 10:31:38,939 - distributed.worker - INFO -          dashboard at:           10.6.102.8:43473
2025-09-03 10:31:38,939 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,939 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,939 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,940 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,940 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_eb5xqrk
2025-09-03 10:31:38,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,947 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:40347
2025-09-03 10:31:38,947 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:40347
2025-09-03 10:31:38,947 - distributed.worker - INFO -          dashboard at:           10.6.102.8:46505
2025-09-03 10:31:38,947 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,947 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,947 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,947 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,947 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cow6f7n2
2025-09-03 10:31:38,947 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,958 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:36619
2025-09-03 10:31:38,958 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:36619
2025-09-03 10:31:38,958 - distributed.worker - INFO -          dashboard at:           10.6.102.8:37015
2025-09-03 10:31:38,959 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,959 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,959 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:38,959 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:38,959 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-f2th34xs
2025-09-03 10:31:38,959 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,010 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:45545
2025-09-03 10:31:39,010 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:45545
2025-09-03 10:31:39,010 - distributed.worker - INFO -          dashboard at:           10.6.102.8:40931
2025-09-03 10:31:39,010 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,010 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,010 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,010 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,010 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l71ehqod
2025-09-03 10:31:39,010 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,012 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:40737
2025-09-03 10:31:39,012 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:40737
2025-09-03 10:31:39,012 - distributed.worker - INFO -          dashboard at:           10.6.102.8:43279
2025-09-03 10:31:39,012 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,012 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,012 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,012 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9nvgom6e
2025-09-03 10:31:39,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,015 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:35859
2025-09-03 10:31:39,015 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:35859
2025-09-03 10:31:39,015 - distributed.worker - INFO -          dashboard at:           10.6.102.8:44625
2025-09-03 10:31:39,015 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,016 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,016 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,016 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,016 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3kxs2bq3
2025-09-03 10:31:39,016 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,016 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:37507
2025-09-03 10:31:39,016 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:37507
2025-09-03 10:31:39,016 - distributed.worker - INFO -          dashboard at:           10.6.102.8:43601
2025-09-03 10:31:39,016 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,016 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,016 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,016 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,016 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pygiy_jj
2025-09-03 10:31:39,016 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,017 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:46525
2025-09-03 10:31:39,017 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:46525
2025-09-03 10:31:39,017 - distributed.worker - INFO -          dashboard at:           10.6.102.8:40845
2025-09-03 10:31:39,017 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,017 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,017 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,017 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gq02pa4y
2025-09-03 10:31:39,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,017 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:38933
2025-09-03 10:31:39,017 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:38933
2025-09-03 10:31:39,017 - distributed.worker - INFO -          dashboard at:           10.6.102.8:42857
2025-09-03 10:31:39,017 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,017 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,017 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,017 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8t6aoxnt
2025-09-03 10:31:39,018 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,019 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:45953
2025-09-03 10:31:39,019 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:45953
2025-09-03 10:31:39,019 - distributed.worker - INFO -          dashboard at:           10.6.102.8:46203
2025-09-03 10:31:39,019 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,019 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,019 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,019 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,019 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gq_jdtco
2025-09-03 10:31:39,020 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,022 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:36327
2025-09-03 10:31:39,022 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:36327
2025-09-03 10:31:39,022 - distributed.worker - INFO -          dashboard at:           10.6.102.8:43903
2025-09-03 10:31:39,022 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,022 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,022 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,022 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,022 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1myh7hmv
2025-09-03 10:31:39,022 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,022 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:35897
2025-09-03 10:31:39,023 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:35897
2025-09-03 10:31:39,023 - distributed.worker - INFO -          dashboard at:           10.6.102.8:40999
2025-09-03 10:31:39,023 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,023 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,023 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,023 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-91w8252k
2025-09-03 10:31:39,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,024 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:43183
2025-09-03 10:31:39,024 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:43183
2025-09-03 10:31:39,024 - distributed.worker - INFO -          dashboard at:           10.6.102.8:34569
2025-09-03 10:31:39,024 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,024 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,024 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,024 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-miop0_cf
2025-09-03 10:31:39,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,026 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:38439
2025-09-03 10:31:39,027 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:38439
2025-09-03 10:31:39,027 - distributed.worker - INFO -          dashboard at:           10.6.102.8:42865
2025-09-03 10:31:39,027 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,027 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,027 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,027 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,027 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dufqr4r7
2025-09-03 10:31:39,027 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,032 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:43465
2025-09-03 10:31:39,032 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:43465
2025-09-03 10:31:39,032 - distributed.worker - INFO -          dashboard at:           10.6.102.8:32817
2025-09-03 10:31:39,032 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,032 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,032 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,032 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3xxhymvs
2025-09-03 10:31:39,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,033 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:44721
2025-09-03 10:31:39,033 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:44721
2025-09-03 10:31:39,033 - distributed.worker - INFO -          dashboard at:           10.6.102.8:33343
2025-09-03 10:31:39,033 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,033 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,033 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,033 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,033 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-e3vljn5x
2025-09-03 10:31:39,033 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,042 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:38281
2025-09-03 10:31:39,042 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:38281
2025-09-03 10:31:39,042 - distributed.worker - INFO -          dashboard at:           10.6.102.8:38071
2025-09-03 10:31:39,042 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,042 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,042 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,042 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,042 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0xba8ibg
2025-09-03 10:31:39,042 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,051 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.8:41851
2025-09-03 10:31:39,051 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.8:41851
2025-09-03 10:31:39,051 - distributed.worker - INFO -          dashboard at:           10.6.102.8:42269
2025-09-03 10:31:39,051 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,051 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:39,051 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:39,051 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4auk_51z
2025-09-03 10:31:39,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,129 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,130 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,130 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,132 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,151 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,152 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,152 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,153 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,162 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,163 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,163 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,165 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,175 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,177 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,177 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,178 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,209 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,210 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,210 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,212 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,221 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,222 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,223 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,224 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,244 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,245 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,245 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,246 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,278 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,279 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,279 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,281 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,358 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,359 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,359 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,361 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,370 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,371 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,373 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,381 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,382 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,384 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,393 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,394 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,394 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,396 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,404 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,405 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,405 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,407 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,415 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,416 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,417 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,418 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,427 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,428 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,428 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,430 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,438 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,439 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,439 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,441 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,450 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,452 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,453 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,457 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,964 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,965 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,965 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,967 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,435 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,437 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,437 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,439 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,657 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,658 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,658 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,660 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,715 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,716 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,716 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,718 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,727 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,728 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,728 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,730 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,751 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,753 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,753 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,755 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:40,824 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:40,825 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:40,825 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:40,827 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,024 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,025 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,025 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,027 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,036 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,037 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,037 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,039 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,047 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,048 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,049 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,050 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,059 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,061 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,061 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,063 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,070 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,071 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,072 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,074 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,082 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,083 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,083 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,085 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,094 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,095 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,095 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,097 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,516 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,517 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,517 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,519 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,527 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,528 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,528 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,531 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,539 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,540 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,540 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,542 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,551 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,552 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,554 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,563 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,564 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,566 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,574 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,576 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,576 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,578 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,586 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,587 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,588 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,590 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,597 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,598 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,600 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,609 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,610 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,610 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,612 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:41,621 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:41,622 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:41,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:41,624 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,222 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,223 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,223 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,226 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,234 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,235 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,235 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,237 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,366 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,367 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,367 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,369 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,379 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,380 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,380 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,382 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,390 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,391 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,393 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,402 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,403 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,403 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,405 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,413 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,415 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,415 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,417 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,473 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,475 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,475 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,477 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,486 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,487 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,487 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,489 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,498 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,499 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,501 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,509 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,511 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,513 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,521 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,522 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,522 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,525 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,533 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,534 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,534 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,536 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,545 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,546 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,549 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,557 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,558 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,558 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,560 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,568 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,569 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,570 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,571 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,580 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,581 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,581 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,583 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,592 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,593 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,593 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,595 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,603 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,605 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,605 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,607 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,676 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,677 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,677 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,679 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,609 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,610 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,610 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,612 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,621 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,623 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,624 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,269 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,270 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,272 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,293 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,295 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,297 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,306 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,307 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,309 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,563 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,565 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,565 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,566 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,576 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,577 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,579 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,588 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,590 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,592 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,600 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,601 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,601 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,603 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,811 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,813 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,813 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,815 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,907 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,908 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,909 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,910 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,944 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,945 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,945 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,947 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,927 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,929 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,929 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,931 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,940 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,941 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,941 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,943 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,952 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,953 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,954 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,956 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,964 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,966 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,966 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,968 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,977 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,978 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,978 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,980 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,990 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,991 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,991 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,994 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:48,002 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:48,003 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,003 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,005 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:48,015 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:48,016 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,019 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,986 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:51,988 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:51,988 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:51,989 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,013 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,014 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,014 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,016 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,026 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,027 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,029 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,039 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,041 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,041 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,043 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,053 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,055 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,055 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,056 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,067 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,068 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,068 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,070 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:07,705 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,710 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,715 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,730 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,734 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,747 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,750 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,755 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,757 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,763 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,765 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,766 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,768 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,773 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,775 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:07,775 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:08,525 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,283 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,364 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,374 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,387 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,397 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,410 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,420 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,431 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,533 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,543 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,557 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,569 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,580 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,592 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,601 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,615 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:12,626 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:13,681 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:14,661 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:14,663 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:14,663 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:14,665 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:14,679 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:14,683 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:14,683 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:14,688 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:14,693 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:14,694 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:14,695 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:14,696 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:14,709 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:14,710 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:14,711 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:14,712 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:14,725 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:14,726 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:14,727 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:14,728 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:14,740 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:14,742 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:14,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:14,744 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:16,274 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,299 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,312 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,570 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,581 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,594 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,818 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:18,933 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:18,947 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:18,962 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:18,971 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:37,807 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,811 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,816 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,832 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,836 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,849 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,852 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,856 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,858 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,864 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,628 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,537 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,538 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,538 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,540 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,554 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,556 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,558 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,557 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:43,568 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:43,572 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,574 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,575 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,581 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:43,589 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,590 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,592 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,592 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:43,602 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:43,608 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,609 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,609 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,611 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,616 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:43,626 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,627 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,628 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,643 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,644 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,646 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,660 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,662 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,663 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,679 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,680 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,680 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,682 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,696 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,697 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,697 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,699 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:44,681 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:47,583 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:47,586 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:47,586 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:47,591 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:47,819 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,934 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,946 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,957 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,970 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:35:51,104 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,106 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,132 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,138 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,381 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,383 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,463 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,472 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,666 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,866 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,869 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,887 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,893 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,057 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,062 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,064 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,069 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,136 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,138 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,184 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,186 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,128 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,129 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,133 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,135 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,167 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,169 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,343 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,347 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,455 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,457 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,468 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,470 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,022 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,023 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,026 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,031 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,075 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,077 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,237 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,243 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,299 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,305 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,306 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,312 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,357 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,359 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,393 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,399 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,414 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,420 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,562 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,564 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,855 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,858 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,893 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,895 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,926 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,928 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,985 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,986 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,130 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,132 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,265 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,266 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,383 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,389 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,441 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,442 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,473 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,475 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,740 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,744 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,797 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,799 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,863 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,864 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,137 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,138 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,140 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,140 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,150 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,153 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,155 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,156 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,226 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,228 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,358 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,360 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,383 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,388 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,392 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,620 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,621 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,623 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,623 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,625 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,628 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,639 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,642 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,680 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,749 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,755 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,942 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,944 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,954 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,956 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,997 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,003 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,015 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,020 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,026 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,032 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,146 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,147 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,162 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,164 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,224 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,226 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,428 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,433 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,794 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,796 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,797 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,799 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,799 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,801 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,830 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,832 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,833 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,914 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,920 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,983 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,984 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,033 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,034 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,098 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,100 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,144 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,150 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,175 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,181 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,293 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,295 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,375 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,380 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,381 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,509 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,517 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,518 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,522 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,521 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,529 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,586 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,592 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,743 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,748 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,750 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,752 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,767 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,773 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,780 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,786 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,047 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,049 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,518 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,520 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,652 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,653 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,998 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,000 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,345 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,349 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,767 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,769 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,015 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,017 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,255 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,256 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,412 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,413 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,956 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,957 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,099 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,104 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,106 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,110 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,622 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,626 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,953 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,954 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,401 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,407 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,475 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,476 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,119 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,121 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:05,922 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:05,928 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:10,109 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:10,112 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:12,552 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:12,561 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:22,887 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,889 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,898 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,900 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,911 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,913 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,913 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,917 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,926 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,929 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,929 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,931 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,932 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,934 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,936 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,938 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,949 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,951 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,952 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,954 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,387 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,389 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,390 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,392 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,400 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,402 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,405 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,410 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,507 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,509 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,514 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,516 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,527 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,529 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,530 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,530 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,531 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,532 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,534 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,537 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,544 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,560 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,561 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,561 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,563 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,563 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,563 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,564 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,563 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,565 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,565 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,565 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,567 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,571 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,571 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,573 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,573 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,799 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,802 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,804 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,807 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,828 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,829 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,830 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,831 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,833 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,835 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,835 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,840 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,841 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,843 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,847 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,849 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,856 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,858 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,859 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,861 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,870 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,873 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,879 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,879 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,881 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,881 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,892 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,893 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,895 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,897 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,898 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,025 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,035 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,037 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,038 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,040 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,063 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,066 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,066 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,068 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,095 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,097 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,097 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,099 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,116 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,117 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,118 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,119 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,125 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,127 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,130 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,132 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,232 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,232 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,234 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,240 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,342 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,349 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,351 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,400 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,402 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,435 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,456 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,458 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,463 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,465 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,501 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,503 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,507 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,509 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,511 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,516 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,581 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,582 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,582 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,583 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,584 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,584 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,626 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,628 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,668 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,673 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,672 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,679 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,683 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,685 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,687 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,689 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,744 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,746 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,752 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,760 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,793 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,795 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,864 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,870 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,937 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,939 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,939 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,941 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,943 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,946 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,963 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,965 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,966 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,968 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,965 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,971 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,970 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,965 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,973 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,977 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,971 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,985 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,988 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,991 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,992 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,993 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,994 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,995 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,037 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,040 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,154 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,156 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,075 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,077 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,130 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,133 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,227 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,230 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,259 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,281 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,283 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,310 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,884 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,886 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,922 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,924 - distributed.utils - INFO - Reload module qme_vars from .py file
