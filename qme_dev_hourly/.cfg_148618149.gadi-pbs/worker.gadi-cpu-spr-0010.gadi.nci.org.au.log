Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 13:14:40,446 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:43325'
2025-09-03 13:14:40,457 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:45117'
2025-09-03 13:14:40,461 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:45867'
2025-09-03 13:14:40,465 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:41673'
2025-09-03 13:14:40,470 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:46163'
2025-09-03 13:14:40,474 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:35519'
2025-09-03 13:14:40,478 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:37307'
2025-09-03 13:14:40,482 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:33033'
2025-09-03 13:14:40,487 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:36605'
2025-09-03 13:14:40,493 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:44857'
2025-09-03 13:14:40,497 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:37473'
2025-09-03 13:14:40,502 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:38873'
2025-09-03 13:14:40,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:36973'
2025-09-03 13:14:40,511 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:39305'
2025-09-03 13:14:40,516 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:44533'
2025-09-03 13:14:40,520 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:45885'
2025-09-03 13:14:40,525 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:36589'
2025-09-03 13:14:40,529 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:44503'
2025-09-03 13:14:40,533 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:37089'
2025-09-03 13:14:40,537 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:46077'
2025-09-03 13:14:40,611 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:34155'
2025-09-03 13:14:40,616 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:44833'
2025-09-03 13:14:40,620 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:42783'
2025-09-03 13:14:40,625 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:33435'
2025-09-03 13:14:40,629 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:33497'
2025-09-03 13:14:40,633 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:42775'
2025-09-03 13:14:40,639 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:39119'
2025-09-03 13:14:40,643 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:38303'
2025-09-03 13:14:40,648 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:39541'
2025-09-03 13:14:40,652 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:34197'
2025-09-03 13:14:40,657 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:36835'
2025-09-03 13:14:40,661 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:39889'
2025-09-03 13:14:40,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:40671'
2025-09-03 13:14:40,670 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:40883'
2025-09-03 13:14:40,675 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:43603'
2025-09-03 13:14:40,678 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:35875'
2025-09-03 13:14:40,682 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:34083'
2025-09-03 13:14:40,688 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:43277'
2025-09-03 13:14:40,693 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:33405'
2025-09-03 13:14:40,696 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:34107'
2025-09-03 13:14:40,700 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:40455'
2025-09-03 13:14:40,706 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:40547'
2025-09-03 13:14:40,711 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:37737'
2025-09-03 13:14:40,715 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:43043'
2025-09-03 13:14:40,718 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:38663'
2025-09-03 13:14:40,721 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:35511'
2025-09-03 13:14:40,726 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:42977'
2025-09-03 13:14:40,731 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:37051'
2025-09-03 13:14:40,736 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:39437'
2025-09-03 13:14:40,740 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:42951'
2025-09-03 13:14:40,745 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:44643'
2025-09-03 13:14:40,750 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.81.10:33025'
2025-09-03 13:14:41,627 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:35929
2025-09-03 13:14:41,627 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:35929
2025-09-03 13:14:41,627 - distributed.worker - INFO -          dashboard at:           10.6.81.10:36671
2025-09-03 13:14:41,627 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,628 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,628 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,628 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-vedkxhiy
2025-09-03 13:14:41,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,631 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:36675
2025-09-03 13:14:41,631 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:36675
2025-09-03 13:14:41,631 - distributed.worker - INFO -          dashboard at:           10.6.81.10:37507
2025-09-03 13:14:41,631 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,631 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,631 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,631 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-d5ipt1oi
2025-09-03 13:14:41,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,638 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:36651
2025-09-03 13:14:41,638 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:36651
2025-09-03 13:14:41,638 - distributed.worker - INFO -          dashboard at:           10.6.81.10:45373
2025-09-03 13:14:41,638 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,639 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,639 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,639 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,639 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-00godpmc
2025-09-03 13:14:41,639 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,640 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,641 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,641 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,641 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,644 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,645 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,645 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,645 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,661 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,661 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,661 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,663 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,665 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:37383
2025-09-03 13:14:41,665 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:37383
2025-09-03 13:14:41,665 - distributed.worker - INFO -          dashboard at:           10.6.81.10:44153
2025-09-03 13:14:41,665 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,665 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,665 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,665 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,665 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-bm_06noq
2025-09-03 13:14:41,665 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,669 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:35065
2025-09-03 13:14:41,669 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:35065
2025-09-03 13:14:41,669 - distributed.worker - INFO -          dashboard at:           10.6.81.10:41715
2025-09-03 13:14:41,669 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,669 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,669 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,669 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,669 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-2y04fanc
2025-09-03 13:14:41,669 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,687 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,688 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,688 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,690 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,691 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,691 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:45919
2025-09-03 13:14:41,691 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:45919
2025-09-03 13:14:41,691 - distributed.worker - INFO -          dashboard at:           10.6.81.10:41037
2025-09-03 13:14:41,691 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,691 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,691 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,691 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,691 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-uzg8rupt
2025-09-03 13:14:41,691 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,691 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,692 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,693 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,695 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:33881
2025-09-03 13:14:41,695 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:33881
2025-09-03 13:14:41,695 - distributed.worker - INFO -          dashboard at:           10.6.81.10:37185
2025-09-03 13:14:41,695 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,695 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,695 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,695 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,695 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-_j3v9vew
2025-09-03 13:14:41,695 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,696 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:40879
2025-09-03 13:14:41,696 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:40879
2025-09-03 13:14:41,696 - distributed.worker - INFO -          dashboard at:           10.6.81.10:42129
2025-09-03 13:14:41,696 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,696 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,696 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,696 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,696 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-3oabq2ua
2025-09-03 13:14:41,697 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,697 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:38215
2025-09-03 13:14:41,697 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:38215
2025-09-03 13:14:41,697 - distributed.worker - INFO -          dashboard at:           10.6.81.10:38901
2025-09-03 13:14:41,697 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,697 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,697 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,697 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,697 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-qb4bjudj
2025-09-03 13:14:41,697 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,705 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:45979
2025-09-03 13:14:41,705 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:45979
2025-09-03 13:14:41,705 - distributed.worker - INFO -          dashboard at:           10.6.81.10:36403
2025-09-03 13:14:41,705 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,705 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,705 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,705 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-hpio9t7b
2025-09-03 13:14:41,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,711 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,712 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,714 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,715 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:39051
2025-09-03 13:14:41,715 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:39051
2025-09-03 13:14:41,715 - distributed.worker - INFO -          dashboard at:           10.6.81.10:41047
2025-09-03 13:14:41,715 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,715 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,716 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,716 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,716 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-yma3105m
2025-09-03 13:14:41,716 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,717 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,718 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,718 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,719 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:35419
2025-09-03 13:14:41,719 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:35419
2025-09-03 13:14:41,719 - distributed.worker - INFO -          dashboard at:           10.6.81.10:40723
2025-09-03 13:14:41,719 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,719 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,719 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,719 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,719 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-1lb89m37
2025-09-03 13:14:41,719 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,719 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,720 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,721 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,721 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,723 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,723 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,724 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:40405
2025-09-03 13:14:41,724 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:40405
2025-09-03 13:14:41,724 - distributed.worker - INFO -          dashboard at:           10.6.81.10:43699
2025-09-03 13:14:41,724 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,724 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,724 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,724 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,724 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-dga7qlus
2025-09-03 13:14:41,724 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,724 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,724 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,726 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,726 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:38019
2025-09-03 13:14:41,726 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:38019
2025-09-03 13:14:41,726 - distributed.worker - INFO -          dashboard at:           10.6.81.10:40579
2025-09-03 13:14:41,726 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,726 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,726 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,726 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-4c1zfvxe
2025-09-03 13:14:41,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,728 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,728 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:38883
2025-09-03 13:14:41,728 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:38883
2025-09-03 13:14:41,728 - distributed.worker - INFO -          dashboard at:           10.6.81.10:42611
2025-09-03 13:14:41,728 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,728 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,728 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,728 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,728 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-bv7pbjk4
2025-09-03 13:14:41,728 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,729 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,729 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,730 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,738 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:35603
2025-09-03 13:14:41,738 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:35603
2025-09-03 13:14:41,738 - distributed.worker - INFO -          dashboard at:           10.6.81.10:42651
2025-09-03 13:14:41,739 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,739 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,739 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,739 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-ego8r889
2025-09-03 13:14:41,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,740 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,740 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,740 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,740 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,744 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,745 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,746 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,746 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,747 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:46623
2025-09-03 13:14:41,747 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:46623
2025-09-03 13:14:41,747 - distributed.worker - INFO -          dashboard at:           10.6.81.10:38915
2025-09-03 13:14:41,747 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,747 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,747 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,747 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,747 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-6a29w7mx
2025-09-03 13:14:41,747 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,747 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,748 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,748 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,749 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,749 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,749 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,751 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,751 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,751 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,751 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,752 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,755 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:35085
2025-09-03 13:14:41,755 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:35085
2025-09-03 13:14:41,755 - distributed.worker - INFO -          dashboard at:           10.6.81.10:44997
2025-09-03 13:14:41,755 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,755 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,755 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,755 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-72js5rvz
2025-09-03 13:14:41,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,760 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,761 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,762 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,772 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,772 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,772 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,774 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,778 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,778 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,780 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,888 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:40225
2025-09-03 13:14:41,888 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:40225
2025-09-03 13:14:41,888 - distributed.worker - INFO -          dashboard at:           10.6.81.10:35057
2025-09-03 13:14:41,888 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,888 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,888 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,888 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,888 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-t_vhoahc
2025-09-03 13:14:41,888 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,900 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,901 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,901 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,901 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:41,920 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:46033
2025-09-03 13:14:41,920 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:46033
2025-09-03 13:14:41,920 - distributed.worker - INFO -          dashboard at:           10.6.81.10:37513
2025-09-03 13:14:41,920 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,920 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,920 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:41,920 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:41,920 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-jsiwknwr
2025-09-03 13:14:41,920 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,941 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:41,941 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:41,942 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:41,943 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,027 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:33821
2025-09-03 13:14:42,027 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:33821
2025-09-03 13:14:42,027 - distributed.worker - INFO -          dashboard at:           10.6.81.10:43773
2025-09-03 13:14:42,027 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,027 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,027 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,027 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,027 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-pq526ikj
2025-09-03 13:14:42,027 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,028 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:41299
2025-09-03 13:14:42,028 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:41299
2025-09-03 13:14:42,028 - distributed.worker - INFO -          dashboard at:           10.6.81.10:43761
2025-09-03 13:14:42,028 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,028 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,028 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,028 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-bt40ysrp
2025-09-03 13:14:42,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,049 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,050 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,052 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,053 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,054 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,054 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,054 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:43139
2025-09-03 13:14:42,054 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:43139
2025-09-03 13:14:42,054 - distributed.worker - INFO -          dashboard at:           10.6.81.10:42291
2025-09-03 13:14:42,054 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,054 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,054 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,054 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,054 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-bjig_0h5
2025-09-03 13:14:42,054 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,056 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,068 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:35833
2025-09-03 13:14:42,068 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:35833
2025-09-03 13:14:42,068 - distributed.worker - INFO -          dashboard at:           10.6.81.10:34469
2025-09-03 13:14:42,068 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,068 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,068 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,068 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,068 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-o0oov0hp
2025-09-03 13:14:42,068 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,077 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,078 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,078 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,079 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,090 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,091 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,091 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,093 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,133 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:34445
2025-09-03 13:14:42,134 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:34445
2025-09-03 13:14:42,134 - distributed.worker - INFO -          dashboard at:           10.6.81.10:37981
2025-09-03 13:14:42,134 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,134 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,134 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,134 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,134 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-ukrfrmsc
2025-09-03 13:14:42,134 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,156 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,157 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,158 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,159 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,189 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:46669
2025-09-03 13:14:42,189 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:46669
2025-09-03 13:14:42,189 - distributed.worker - INFO -          dashboard at:           10.6.81.10:38935
2025-09-03 13:14:42,189 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,189 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,189 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,189 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,189 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-dkxoqxy4
2025-09-03 13:14:42,189 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,213 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,214 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,214 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,216 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,222 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:39825
2025-09-03 13:14:42,222 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:39825
2025-09-03 13:14:42,222 - distributed.worker - INFO -          dashboard at:           10.6.81.10:41421
2025-09-03 13:14:42,222 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,222 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,222 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,222 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,222 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-2owfm3y6
2025-09-03 13:14:42,222 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,232 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:45093
2025-09-03 13:14:42,232 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:45093
2025-09-03 13:14:42,232 - distributed.worker - INFO -          dashboard at:           10.6.81.10:34603
2025-09-03 13:14:42,232 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,232 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,232 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,232 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,232 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-mn9ovb55
2025-09-03 13:14:42,232 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,233 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:42481
2025-09-03 13:14:42,233 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:42481
2025-09-03 13:14:42,233 - distributed.worker - INFO -          dashboard at:           10.6.81.10:41637
2025-09-03 13:14:42,233 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,233 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,233 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,233 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,233 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-fjt1ph6g
2025-09-03 13:14:42,233 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,246 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,247 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,248 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,254 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,255 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,255 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,256 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,257 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,258 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,258 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,259 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,284 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:43137
2025-09-03 13:14:42,284 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:43137
2025-09-03 13:14:42,284 - distributed.worker - INFO -          dashboard at:           10.6.81.10:37457
2025-09-03 13:14:42,284 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,284 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,284 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,284 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,284 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-fvny58_h
2025-09-03 13:14:42,284 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,296 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:37333
2025-09-03 13:14:42,296 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:37333
2025-09-03 13:14:42,296 - distributed.worker - INFO -          dashboard at:           10.6.81.10:40575
2025-09-03 13:14:42,296 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,296 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,296 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,296 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,296 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-024dywxk
2025-09-03 13:14:42,296 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,299 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:38153
2025-09-03 13:14:42,299 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:38153
2025-09-03 13:14:42,299 - distributed.worker - INFO -          dashboard at:           10.6.81.10:34263
2025-09-03 13:14:42,300 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,300 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,300 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,300 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,300 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-6387lti2
2025-09-03 13:14:42,300 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,306 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,307 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,308 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,310 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:46289
2025-09-03 13:14:42,310 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:46289
2025-09-03 13:14:42,310 - distributed.worker - INFO -          dashboard at:           10.6.81.10:41939
2025-09-03 13:14:42,310 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,310 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,310 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,310 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,310 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-pfhz_tla
2025-09-03 13:14:42,310 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,311 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:33943
2025-09-03 13:14:42,311 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:33943
2025-09-03 13:14:42,311 - distributed.worker - INFO -          dashboard at:           10.6.81.10:42195
2025-09-03 13:14:42,311 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,311 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,311 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,311 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,311 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-93dqqt06
2025-09-03 13:14:42,311 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,312 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:46725
2025-09-03 13:14:42,312 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:46725
2025-09-03 13:14:42,312 - distributed.worker - INFO -          dashboard at:           10.6.81.10:35739
2025-09-03 13:14:42,312 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,312 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,312 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,312 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,312 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-6__oxdbn
2025-09-03 13:14:42,312 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,319 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:35815
2025-09-03 13:14:42,319 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:35815
2025-09-03 13:14:42,319 - distributed.worker - INFO -          dashboard at:           10.6.81.10:36249
2025-09-03 13:14:42,319 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,319 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,319 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,319 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,319 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,319 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-o6pq8dba
2025-09-03 13:14:42,319 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,320 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,320 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,321 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,323 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,323 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:45059
2025-09-03 13:14:42,323 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:45059
2025-09-03 13:14:42,323 - distributed.worker - INFO -          dashboard at:           10.6.81.10:34223
2025-09-03 13:14:42,323 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,323 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,323 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,323 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,323 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-4tm1t96f
2025-09-03 13:14:42,323 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,323 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,324 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,325 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,326 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,326 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,326 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,327 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,330 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:39497
2025-09-03 13:14:42,330 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:38519
2025-09-03 13:14:42,330 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:39497
2025-09-03 13:14:42,330 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:38519
2025-09-03 13:14:42,330 - distributed.worker - INFO -          dashboard at:           10.6.81.10:44531
2025-09-03 13:14:42,330 - distributed.worker - INFO -          dashboard at:           10.6.81.10:36285
2025-09-03 13:14:42,330 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,330 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,330 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,330 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,330 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,330 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,330 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-7sh2vvwt
2025-09-03 13:14:42,330 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-elasczuc
2025-09-03 13:14:42,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,330 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:40987
2025-09-03 13:14:42,331 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:40987
2025-09-03 13:14:42,331 - distributed.worker - INFO -          dashboard at:           10.6.81.10:43753
2025-09-03 13:14:42,331 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,331 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,331 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,331 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-hm1m4ex8
2025-09-03 13:14:42,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,331 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,332 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,334 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,334 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,335 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,335 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,336 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:35391
2025-09-03 13:14:42,336 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:35391
2025-09-03 13:14:42,336 - distributed.worker - INFO -          dashboard at:           10.6.81.10:38563
2025-09-03 13:14:42,336 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,336 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,336 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,336 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-322wo_7i
2025-09-03 13:14:42,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,336 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,337 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:38091
2025-09-03 13:14:42,337 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:38091
2025-09-03 13:14:42,337 - distributed.worker - INFO -          dashboard at:           10.6.81.10:41597
2025-09-03 13:14:42,337 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,337 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,337 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,337 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,338 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-powhylzt
2025-09-03 13:14:42,338 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,338 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:35337
2025-09-03 13:14:42,338 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:35337
2025-09-03 13:14:42,338 - distributed.worker - INFO -          dashboard at:           10.6.81.10:43617
2025-09-03 13:14:42,338 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,338 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,338 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,338 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,338 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-6o1d2fz1
2025-09-03 13:14:42,338 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,338 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:36663
2025-09-03 13:14:42,339 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:36663
2025-09-03 13:14:42,339 - distributed.worker - INFO -          dashboard at:           10.6.81.10:35365
2025-09-03 13:14:42,339 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,339 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,339 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,339 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,339 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-7_ya008s
2025-09-03 13:14:42,339 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,339 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:44185
2025-09-03 13:14:42,339 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:44185
2025-09-03 13:14:42,339 - distributed.worker - INFO -          dashboard at:           10.6.81.10:44741
2025-09-03 13:14:42,339 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,339 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,339 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,339 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,339 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-34ccyag2
2025-09-03 13:14:42,339 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,341 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:41925
2025-09-03 13:14:42,341 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:41925
2025-09-03 13:14:42,341 - distributed.worker - INFO -          dashboard at:           10.6.81.10:42745
2025-09-03 13:14:42,341 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,341 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,341 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,341 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-35a15ki0
2025-09-03 13:14:42,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,342 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,342 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,342 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,342 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,346 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,346 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,346 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,346 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:39139
2025-09-03 13:14:42,346 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:39139
2025-09-03 13:14:42,346 - distributed.worker - INFO -          dashboard at:           10.6.81.10:43141
2025-09-03 13:14:42,346 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,346 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,346 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,347 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,347 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-ia2nqj6d
2025-09-03 13:14:42,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,348 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,348 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:41323
2025-09-03 13:14:42,348 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:41323
2025-09-03 13:14:42,348 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,348 - distributed.worker - INFO -          dashboard at:           10.6.81.10:43911
2025-09-03 13:14:42,348 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,348 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,348 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,348 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,348 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-bwlj2zc_
2025-09-03 13:14:42,348 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,349 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,349 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,350 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:43823
2025-09-03 13:14:42,350 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:43823
2025-09-03 13:14:42,350 - distributed.worker - INFO -          dashboard at:           10.6.81.10:33161
2025-09-03 13:14:42,350 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,350 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,350 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,350 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,350 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-wsj1nbu1
2025-09-03 13:14:42,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,351 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,351 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,352 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,352 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,354 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,354 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,354 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,354 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,355 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,355 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,356 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,357 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:45479
2025-09-03 13:14:42,357 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:45479
2025-09-03 13:14:42,357 - distributed.worker - INFO -          dashboard at:           10.6.81.10:35797
2025-09-03 13:14:42,357 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,357 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,357 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,357 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,357 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-_le69sqt
2025-09-03 13:14:42,357 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,358 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,359 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,359 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,359 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,360 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,360 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:38587
2025-09-03 13:14:42,360 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:38587
2025-09-03 13:14:42,360 - distributed.worker - INFO -          dashboard at:           10.6.81.10:40159
2025-09-03 13:14:42,360 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,360 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,360 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,360 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-_68v3l5v
2025-09-03 13:14:42,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,360 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,361 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,361 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,361 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,361 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,361 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,361 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,361 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,362 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,362 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,363 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,364 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,364 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,364 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,365 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,365 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,365 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:40967
2025-09-03 13:14:42,365 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,365 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:40967
2025-09-03 13:14:42,365 - distributed.worker - INFO -          dashboard at:           10.6.81.10:35813
2025-09-03 13:14:42,365 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,365 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,365 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:14:42,365 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:14:42,365 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-grsskh9b
2025-09-03 13:14:42,366 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,366 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,369 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,370 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,370 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,371 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,371 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,371 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,372 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,373 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,373 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,374 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,374 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,374 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,375 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,375 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:14:42,380 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:14:42,381 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:14:42,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:14:42,382 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:16:21,579 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,579 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,579 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,579 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,579 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,580 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,580 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,580 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,580 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,580 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,580 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,581 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,581 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,581 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,581 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,581 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,581 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,581 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,582 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,582 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,582 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,582 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,582 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,582 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,582 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,582 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,582 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,582 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,582 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,583 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,583 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,582 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,583 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,583 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,583 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,583 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,583 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,583 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,583 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,584 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,584 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,584 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,582 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,584 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,584 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,582 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,584 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,584 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,584 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,584 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,583 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,585 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,585 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,585 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,585 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,585 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,585 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,586 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,586 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,586 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,586 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,585 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,587 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,585 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,585 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,587 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,587 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,587 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,588 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,586 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,586 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,586 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,588 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,586 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,587 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,587 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,587 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,588 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,589 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,589 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,589 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,593 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,593 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,590 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,591 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,595 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,596 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,596 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,597 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,597 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,597 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,597 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,598 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,598 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,599 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,599 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,601 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,602 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,600 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,603 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,603 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,603 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,606 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,610 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:25,256 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,256 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,256 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,258 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,258 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,258 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,258 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,258 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,258 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,258 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,259 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,259 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,259 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,259 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,260 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,259 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,259 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,259 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,260 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,260 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,260 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,259 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,260 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,260 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,260 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,260 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,260 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,260 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,260 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,260 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,260 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,260 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,260 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,260 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,260 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,261 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,261 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,262 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,262 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,262 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,262 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,262 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,262 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,262 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,262 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,263 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,262 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,262 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,263 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,262 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,262 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,262 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,263 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,262 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,263 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,263 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,263 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,263 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,262 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,261 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,264 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,264 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,261 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,264 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,264 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,264 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,265 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,265 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,265 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,265 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,265 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,266 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,266 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,266 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,266 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,266 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,266 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,267 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,267 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,267 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:26,689 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,689 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,689 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,690 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,691 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,691 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,691 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,691 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,691 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,692 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,693 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,693 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,693 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,693 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,693 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,693 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,693 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,693 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,693 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,693 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,694 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,694 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,694 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,694 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,694 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,694 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,694 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,694 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,694 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,694 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,695 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,695 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,695 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,695 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,695 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,695 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,695 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,695 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,695 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,695 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,695 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,695 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,696 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,697 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,697 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,697 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,697 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,697 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,698 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,699 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,701 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,711 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:28,140 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,140 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,140 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,141 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,141 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,141 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,141 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,141 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,141 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,141 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,141 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,142 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,141 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,142 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,142 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,142 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,142 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,142 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,143 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,143 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,143 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,143 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,143 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,144 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,144 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,144 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,144 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,144 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,144 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,145 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,145 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,145 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,145 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,145 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,145 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,145 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,145 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,145 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,145 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,145 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,145 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,145 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,145 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,145 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,146 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,146 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,146 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,146 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,146 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,147 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,146 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,146 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,146 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,146 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,146 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,146 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,146 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,146 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,146 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,147 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,147 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,147 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,147 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,147 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,148 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,148 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,148 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,148 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,148 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,149 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,149 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,149 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,149 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,149 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,149 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,150 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,150 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,150 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,150 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,150 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,150 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:20:02,634 - distributed.worker - ERROR - Compute Failed
Key:       ('mean_chunk-7da713590608fb324cd86576d9869a58', 2504, 0, 0)
State:     executing
Task:  <Task ('mean_chunk-7da713590608fb324cd86576d9869a58', 2504, 0, 0) _execute_subgraph(...)>
Exception: "KeyError('tas')"
Traceback: '  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/dask/array/core.py", line 141, in getter\n    c = np.asarray(c)\n        ^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 577, in __array__\n    return np.asarray(self.get_duck_array(), dtype=dtype)\n                      ^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 580, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 791, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 661, in get_duck_array\n    array = array.get_duck_array()\n            ^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/coding/common.py", line 76, in get_duck_array\n    return self.func(self.array.get_duck_array())\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 654, in get_duck_array\n    array = self.array[self.key]\n            ~~~~~~~~~~^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 103, in __getitem__\n    return indexing.explicit_indexing_adapter(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 1015, in explicit_indexing_adapter\n    result = raw_indexing_method(raw_key.tuple)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 115, in _getitem\n    original_array = self.get_array(needs_lock=False)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 95, in get_array\n    variable = ds.variables[self.variable_name]\n               ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n'

2025-09-03 13:20:02,636 - distributed.worker - ERROR - Compute Failed
Key:       ('mean_chunk-7da713590608fb324cd86576d9869a58', 8072, 0, 0)
State:     executing
Task:  <Task ('mean_chunk-7da713590608fb324cd86576d9869a58', 8072, 0, 0) _execute_subgraph(...)>
Exception: "KeyError('tas')"
Traceback: '  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/dask/array/core.py", line 141, in getter\n    c = np.asarray(c)\n        ^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 577, in __array__\n    return np.asarray(self.get_duck_array(), dtype=dtype)\n                      ^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 580, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 791, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 661, in get_duck_array\n    array = array.get_duck_array()\n            ^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/coding/common.py", line 76, in get_duck_array\n    return self.func(self.array.get_duck_array())\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 654, in get_duck_array\n    array = self.array[self.key]\n            ~~~~~~~~~~^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 103, in __getitem__\n    return indexing.explicit_indexing_adapter(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 1015, in explicit_indexing_adapter\n    result = raw_indexing_method(raw_key.tuple)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 115, in _getitem\n    original_array = self.get_array(needs_lock=False)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 95, in get_array\n    variable = ds.variables[self.variable_name]\n               ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n'

2025-09-03 13:20:02,718 - distributed.worker - ERROR - Compute Failed
Key:       ('mean_chunk-7da713590608fb324cd86576d9869a58', 7478, 0, 0)
State:     executing
Task:  <Task ('mean_chunk-7da713590608fb324cd86576d9869a58', 7478, 0, 0) _execute_subgraph(...)>
Exception: "KeyError('tas')"
Traceback: '  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/dask/array/core.py", line 141, in getter\n    c = np.asarray(c)\n        ^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 577, in __array__\n    return np.asarray(self.get_duck_array(), dtype=dtype)\n                      ^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 580, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 791, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 661, in get_duck_array\n    array = array.get_duck_array()\n            ^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/coding/common.py", line 76, in get_duck_array\n    return self.func(self.array.get_duck_array())\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 654, in get_duck_array\n    array = self.array[self.key]\n            ~~~~~~~~~~^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 103, in __getitem__\n    return indexing.explicit_indexing_adapter(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 1015, in explicit_indexing_adapter\n    result = raw_indexing_method(raw_key.tuple)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 115, in _getitem\n    original_array = self.get_array(needs_lock=False)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 95, in get_array\n    variable = ds.variables[self.variable_name]\n               ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n'

2025-09-03 13:20:02,720 - distributed.worker - ERROR - Compute Failed
Key:       ('mean_chunk-7da713590608fb324cd86576d9869a58', 2998, 0, 0)
State:     executing
Task:  <Task ('mean_chunk-7da713590608fb324cd86576d9869a58', 2998, 0, 0) _execute_subgraph(...)>
Exception: "KeyError('tas')"
Traceback: '  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/dask/array/core.py", line 141, in getter\n    c = np.asarray(c)\n        ^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 577, in __array__\n    return np.asarray(self.get_duck_array(), dtype=dtype)\n                      ^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 580, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 791, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 661, in get_duck_array\n    array = array.get_duck_array()\n            ^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/coding/common.py", line 76, in get_duck_array\n    return self.func(self.array.get_duck_array())\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 654, in get_duck_array\n    array = self.array[self.key]\n            ~~~~~~~~~~^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 103, in __getitem__\n    return indexing.explicit_indexing_adapter(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 1015, in explicit_indexing_adapter\n    result = raw_indexing_method(raw_key.tuple)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 115, in _getitem\n    original_array = self.get_array(needs_lock=False)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 95, in get_array\n    variable = ds.variables[self.variable_name]\n               ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n'

[gadi-cpu-spr-0010:1351241:0:1351241] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x78)
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
BFD: Dwarf Error: Can't find .debug_ranges section.
==== backtrace (tid:1351241) ====
 0 0x0000000000012990 __funlockfile()  :0
 1 0x00000000000a100b nc4_find_nc_grp_h5()  ???:0
 2 0x00000000000af7f8 NC4_close()  ???:0
 3 0x0000000000036966 nc_close()  ???:0
 4 0x0000000000061425 __pyx_pw_7netCDF4_8_netCDF4_7Dataset_15_close()  _netCDF4.c:0
 5 0x0000000000060a08 __pyx_pw_7netCDF4_8_netCDF4_7Dataset_19close()  _netCDF4.c:0
 6 0x00000000001f08cc PyObject_Vectorcall()  ???:0
 7 0x00000000001e3d2a _PyEval_EvalFrameDefault()  ???:0
 8 0x0000000000208a4f _PyFunction_Vectorcall()  ???:0
 9 0x000000000020dc62 PyObject_CallOneArg()  ???:0
10 0x00000000002dfc3f slot_tp_finalize()  :0
11 0x00000000001cbfd2 gc_collect_main()  :0
12 0x0000000000296ecb gc_collect_with_callback()  :0
13 0x00000000001d253e make_new_set()  :0
14 0x000000000028a55a _PyObject_CallNoArgs.lto_priv.18()  :0
15 0x00000000002f4f9c defdict_missing()  :0
16 0x00000000001f7a3a cfunction_vectorcall_O()  :0
17 0x000000000020dc62 PyObject_CallOneArg()  ???:0
18 0x00000000001ceabf dict_subscript()  :0
19 0x00000000001e4699 _PyEval_EvalFrameDefault()  ???:0
20 0x0000000000227218 method_vectorcall()  :0
21 0x00000000001e8049 _PyEval_EvalFrameDefault()  ???:0
22 0x0000000000227218 method_vectorcall()  :0
23 0x00000000001e8049 _PyEval_EvalFrameDefault()  ???:0
24 0x0000000000227218 method_vectorcall()  :0
25 0x00000000001e8049 _PyEval_EvalFrameDefault()  ???:0
26 0x0000000000208a4f _PyFunction_Vectorcall()  ???:0
27 0x00000000001e8049 _PyEval_EvalFrameDefault()  ???:0
28 0x0000000000208a4f _PyFunction_Vectorcall()  ???:0
29 0x0000000000212964 PyObject_Call()  ???:0
30 0x00000000001e8049 _PyEval_EvalFrameDefault()  ???:0
31 0x00000000002ae6e8 gen_send_ex2()  :0
32 0x00000000001e69e1 _PyEval_EvalFrameDefault()  ???:0
33 0x00000000002ae6e8 gen_send_ex2()  :0
34 0x00000000001e69e1 _PyEval_EvalFrameDefault()  ???:0
35 0x00000000002ae6e8 gen_send_ex2()  :0
36 0x00000000000076a6 task_step()  :0
37 0x00000000001f7a3a cfunction_vectorcall_O()  :0
38 0x0000000000191bf9 _PyObject_VectorcallTstate.lto_priv.7()  :0
39 0x0000000000193c79 context_run()  :0
40 0x00000000001f09df cfunction_vectorcall_FASTCALL_KEYWORDS()  :0
41 0x00000000001ec44c _PyEval_EvalFrameDefault()  ???:0
42 0x0000000000227a92 _PyObject_VectorcallTstate.lto_priv.4()  :0
43 0x0000000000227316 method_vectorcall()  :0
44 0x0000000000212964 PyObject_Call()  ???:0
45 0x00000000002dd10d partial_call()  :0
46 0x00000000001d66ab _PyObject_MakeTpCall.localalias()  :0
47 0x00000000001e8049 _PyEval_EvalFrameDefault()  ???:0
48 0x0000000000227218 method_vectorcall()  :0
49 0x00000000001e8049 _PyEval_EvalFrameDefault()  ???:0
50 0x000000000029b0ad _PyEval_Vector()  :0
51 0x000000000029a7ef PyEval_EvalCode()  ???:0
52 0x00000000002b872a run_eval_code_obj()  :0
53 0x00000000002b43b3 run_mod()  :0
54 0x00000000002a8e02 PyRun_StringFlags.localalias()  :0
55 0x00000000002a8bbc PyRun_SimpleStringFlags.localalias()  :0
56 0x00000000002c350c Py_RunMain.localalias()  :0
57 0x000000000028aa17 Py_BytesMain()  ???:0
=================================
2025-09-03 13:20:30,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:31,821 - distributed.nanny - INFO - Worker process 1351241 was killed by signal 11
2025-09-03 13:20:33,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:33,826 - distributed.comm.tcp - INFO - Connection from tcp://10.6.81.30:46042 closed before handshake completed
2025-09-03 13:20:41,514 - distributed.nanny - WARNING - Restarting worker
2025-09-03 13:20:42,293 - distributed.worker - INFO -       Start worker at:     tcp://10.6.81.10:40681
2025-09-03 13:20:42,293 - distributed.worker - INFO -          Listening to:     tcp://10.6.81.10:40681
2025-09-03 13:20:42,293 - distributed.worker - INFO -          dashboard at:           10.6.81.10:42103
2025-09-03 13:20:42,293 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:20:42,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:20:42,293 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:20:42,293 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:20:42,293 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-ezl_o90w
2025-09-03 13:20:42,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:20:44,202 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:20:44,202 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:20:44,204 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:20:45,023 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:20:45,024 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:20:45,025 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:20:45,025 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:20:45,026 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:20:45,027 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:20:45,029 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:20:45,029 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:20:45,029 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:20:46,350 - distributed.worker - ERROR - Compute Failed
Key:       ('mean_chunk-99880c1b373332b8e0d7a5c43e3323ec', 7589, 0, 0)
State:     executing
Task:  <Task ('mean_chunk-99880c1b373332b8e0d7a5c43e3323ec', 7589, 0, 0) _execute_subgraph(...)>
Exception: "RuntimeError('NetCDF: Not a valid ID')"
Traceback: '  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/dask/array/core.py", line 141, in getter\n    c = np.asarray(c)\n        ^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 577, in __array__\n    return np.asarray(self.get_duck_array(), dtype=dtype)\n                      ^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 580, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 791, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 661, in get_duck_array\n    array = array.get_duck_array()\n            ^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/coding/common.py", line 76, in get_duck_array\n    return self.func(self.array.get_duck_array())\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 654, in get_duck_array\n    array = self.array[self.key]\n            ~~~~~~~~~~^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 103, in __getitem__\n    return indexing.explicit_indexing_adapter(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 1015, in explicit_indexing_adapter\n    result = raw_indexing_method(raw_key.tuple)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 116, in _getitem\n    array = getitem(original_array, key)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "src/netCDF4/_netCDF4.pyx", line 5055, in netCDF4._netCDF4.Variable.__getitem__\n  File "src/netCDF4/_netCDF4.pyx", line 4628, in netCDF4._netCDF4.Variable.shape.__get__\n  File "src/netCDF4/_netCDF4.pyx", line 4580, in netCDF4._netCDF4.Variable._getdims\n  File "src/netCDF4/_netCDF4.pyx", line 2193, in netCDF4._netCDF4._inq_vardimid\n  File "src/netCDF4/_netCDF4.pyx", line 2185, in netCDF4._netCDF4._inq_varndims\n  File "src/netCDF4/_netCDF4.pyx", line 2164, in netCDF4._netCDF4._ensure_nc_success\n'

2025-09-03 13:20:46,363 - distributed.worker - ERROR - Compute Failed
Key:       ('mean_chunk-99880c1b373332b8e0d7a5c43e3323ec', 7077, 0, 0)
State:     executing
Task:  <Task ('mean_chunk-99880c1b373332b8e0d7a5c43e3323ec', 7077, 0, 0) _execute_subgraph(...)>
Exception: "RuntimeError('NetCDF: Not a valid ID')"
Traceback: '  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/dask/array/core.py", line 141, in getter\n    c = np.asarray(c)\n        ^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 577, in __array__\n    return np.asarray(self.get_duck_array(), dtype=dtype)\n                      ^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 580, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 791, in get_duck_array\n    return self.array.get_duck_array()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 661, in get_duck_array\n    array = array.get_duck_array()\n            ^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/coding/common.py", line 76, in get_duck_array\n    return self.func(self.array.get_duck_array())\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 654, in get_duck_array\n    array = self.array[self.key]\n            ~~~~~~~~~~^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 103, in __getitem__\n    return indexing.explicit_indexing_adapter(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/core/indexing.py", line 1015, in explicit_indexing_adapter\n    result = raw_indexing_method(raw_key.tuple)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/netCDF4_.py", line 116, in _getitem\n    array = getitem(original_array, key)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File "src/netCDF4/_netCDF4.pyx", line 5055, in netCDF4._netCDF4.Variable.__getitem__\n  File "src/netCDF4/_netCDF4.pyx", line 4628, in netCDF4._netCDF4.Variable.shape.__get__\n  File "src/netCDF4/_netCDF4.pyx", line 4580, in netCDF4._netCDF4.Variable._getdims\n  File "src/netCDF4/_netCDF4.pyx", line 2193, in netCDF4._netCDF4._inq_vardimid\n  File "src/netCDF4/_netCDF4.pyx", line 2185, in netCDF4._netCDF4._inq_varndims\n  File "src/netCDF4/_netCDF4.pyx", line 2164, in netCDF4._netCDF4._ensure_nc_success\n'

2025-09-03 13:20:52,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:52,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:52,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:53,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:53,263 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:53,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:53,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:55,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:55,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:55,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:58,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:58,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:58,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:00,001 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:01,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:01,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:02,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:03,938 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:06,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
Exception ignored in: <function CachingFileManager.__del__ at 0x1519ff714400>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/file_manager.py", line 250, in __del__
    self.close(needs_lock=False)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/file_manager.py", line 234, in close
    file.close()
  File "src/netCDF4/_netCDF4.pyx", line 2669, in netCDF4._netCDF4.Dataset.close
  File "src/netCDF4/_netCDF4.pyx", line 2636, in netCDF4._netCDF4.Dataset._close
  File "src/netCDF4/_netCDF4.pyx", line 2164, in netCDF4._netCDF4._ensure_nc_success
RuntimeError: NetCDF: Not a valid ID
2025-09-03 13:21:06,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:08,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:13,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:16,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:25,801 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:25,805 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:25,809 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:25,811 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:43,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:50,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:51,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:51,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:54,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:55,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:55,570 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:55,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:55,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:56,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:57,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:57,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:57,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:02,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:03,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:04,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:04,847 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:06,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:06,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:07,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:09,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:09,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:09,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:09,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:09,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:09,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:10,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:10,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:11,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:11,146 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:11,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:11,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:11,436 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:11,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:11,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:12,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:12,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:14,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:15,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:16,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:17,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:18,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:20,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:22,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:23,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:23,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:26,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:26,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:27,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:27,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:28,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
Exception ignored in: <function CachingFileManager.__del__ at 0x1519ff714400>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/file_manager.py", line 250, in __del__
    self.close(needs_lock=False)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/xarray/backends/file_manager.py", line 234, in close
    file.close()
  File "src/netCDF4/_netCDF4.pyx", line 2669, in netCDF4._netCDF4.Dataset.close
  File "src/netCDF4/_netCDF4.pyx", line 2636, in netCDF4._netCDF4.Dataset._close
  File "src/netCDF4/_netCDF4.pyx", line 2164, in netCDF4._netCDF4._ensure_nc_success
RuntimeError: NetCDF: Not a valid ID
2025-09-03 13:22:42,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:44,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:45,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:45,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:46,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:46,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:46,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:46,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:47,570 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:47,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:48,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:48,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:48,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:48,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:48,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:48,599 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:48,824 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:49,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:49,153 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:50,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:50,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:52,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:52,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:55,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:57,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:58,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:58,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:58,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:58,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:58,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:58,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:00,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:02,426 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:02,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:02,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:02,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:02,847 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:02,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:03,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:03,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:04,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:04,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:05,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:05,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:05,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:06,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:06,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:06,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:07,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:07,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:07,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:09,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:10,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:12,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:17,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:17,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:23,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:23,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:24,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:26,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:26,223 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:35,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:37,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:37,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:37,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:39,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:40,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:40,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:42,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:42,314 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:42,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:42,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:46,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:47,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:47,812 - distributed.comm.tcp - INFO - Connection from tcp://10.6.83.16:34862 closed before handshake completed
2025-09-03 13:23:47,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:47,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:48,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:48,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:48,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:49,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:50,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:50,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:50,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:51,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:51,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:51,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:51,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:52,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:52,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:53,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:53,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:53,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:53,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:54,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:54,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:55,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:55,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:56,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:56,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:56,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:57,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:58,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:03,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:06,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:09,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:11,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:12,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:12,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:13,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:14,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:14,592 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:14,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:15,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:15,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:15,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:15,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
