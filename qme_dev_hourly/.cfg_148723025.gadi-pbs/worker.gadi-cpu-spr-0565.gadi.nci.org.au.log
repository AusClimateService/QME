Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-04 11:46:32,784 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:35895'
2025-09-04 11:46:32,792 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:44923'
2025-09-04 11:46:32,798 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:41075'
2025-09-04 11:46:32,801 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:35695'
2025-09-04 11:46:32,806 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:41135'
2025-09-04 11:46:32,810 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:34089'
2025-09-04 11:46:32,813 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:46309'
2025-09-04 11:46:32,817 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:43341'
2025-09-04 11:46:32,821 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:35091'
2025-09-04 11:46:32,826 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:35019'
2025-09-04 11:46:32,833 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:34063'
2025-09-04 11:46:32,837 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:36667'
2025-09-04 11:46:32,843 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:34935'
2025-09-04 11:46:32,847 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:35919'
2025-09-04 11:46:32,852 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:41175'
2025-09-04 11:46:32,857 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:34703'
2025-09-04 11:46:32,861 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:42777'
2025-09-04 11:46:32,865 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:35121'
2025-09-04 11:46:32,870 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:42853'
2025-09-04 11:46:32,875 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:36591'
2025-09-04 11:46:32,996 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:38927'
2025-09-04 11:46:33,000 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:41381'
2025-09-04 11:46:33,004 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:43389'
2025-09-04 11:46:33,008 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:41925'
2025-09-04 11:46:33,013 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:44905'
2025-09-04 11:46:33,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:43883'
2025-09-04 11:46:33,022 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:44457'
2025-09-04 11:46:33,028 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:42273'
2025-09-04 11:46:33,032 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:41017'
2025-09-04 11:46:33,036 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:43907'
2025-09-04 11:46:33,040 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:34129'
2025-09-04 11:46:33,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:43481'
2025-09-04 11:46:33,048 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:37553'
2025-09-04 11:46:33,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:44175'
2025-09-04 11:46:33,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:41405'
2025-09-04 11:46:33,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:35627'
2025-09-04 11:46:33,068 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:38693'
2025-09-04 11:46:33,074 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:40211'
2025-09-04 11:46:33,079 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:37493'
2025-09-04 11:46:33,082 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:43195'
2025-09-04 11:46:33,087 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:38597'
2025-09-04 11:46:33,091 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:42383'
2025-09-04 11:46:33,095 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:39591'
2025-09-04 11:46:33,099 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:42097'
2025-09-04 11:46:33,105 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:44537'
2025-09-04 11:46:33,109 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:39181'
2025-09-04 11:46:33,113 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:42199'
2025-09-04 11:46:33,116 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:40453'
2025-09-04 11:46:33,118 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:41385'
2025-09-04 11:46:33,121 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:40777'
2025-09-04 11:46:33,128 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:36895'
2025-09-04 11:46:33,131 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.61:37421'
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:35469
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:38795
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:38717
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:45373
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:38749
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:41019
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:33815
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:42089
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:32965
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:37181
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:33361
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:39823
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:46119
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:35469
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:38795
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:38717
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:45373
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:39437
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:38749
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:41019
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:33815
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:42089
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:32965
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:37181
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:33361
2025-09-04 11:46:34,029 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:33507
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:39823
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:46119
2025-09-04 11:46:34,029 - distributed.worker - INFO -          dashboard at:          10.6.103.61:36399
2025-09-04 11:46:34,029 - distributed.worker - INFO -          dashboard at:          10.6.103.61:46543
2025-09-04 11:46:34,029 - distributed.worker - INFO -          dashboard at:          10.6.103.61:42397
2025-09-04 11:46:34,029 - distributed.worker - INFO -          dashboard at:          10.6.103.61:38315
2025-09-04 11:46:34,029 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:39437
2025-09-04 11:46:34,029 - distributed.worker - INFO -          dashboard at:          10.6.103.61:44147
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:35059
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:42095
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:35519
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:39505
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:45333
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:38613
2025-09-04 11:46:34,030 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:33507
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:38781
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:35109
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:39035
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO -          dashboard at:          10.6.103.61:37425
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-5_pmmx5_
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-mzdavmyh
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-8dmcxeb4
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-ujlee38_
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-5j8vcjtv
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-yl8akxlf
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-clb04b6i
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-af7jd30v
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-as04v3uy
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-w_rd6td3
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-grxd6g28
2025-09-04 11:46:34,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-aui_5ktp
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-sqmhifz3
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-633r3opb
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-h7dhqdbx
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,032 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:40071
2025-09-04 11:46:34,032 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:40071
2025-09-04 11:46:34,032 - distributed.worker - INFO -          dashboard at:          10.6.103.61:39831
2025-09-04 11:46:34,032 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,032 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,032 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,032 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-8vgxr6jn
2025-09-04 11:46:34,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,040 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:44105
2025-09-04 11:46:34,040 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:44205
2025-09-04 11:46:34,040 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:44105
2025-09-04 11:46:34,040 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:44205
2025-09-04 11:46:34,040 - distributed.worker - INFO -          dashboard at:          10.6.103.61:44693
2025-09-04 11:46:34,040 - distributed.worker - INFO -          dashboard at:          10.6.103.61:38247
2025-09-04 11:46:34,040 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,040 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,040 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,040 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,040 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,040 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,040 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,041 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,041 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-bn5ux3c0
2025-09-04 11:46:34,041 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,041 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-aqt1tgjf
2025-09-04 11:46:34,041 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,057 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,058 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,059 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,066 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,067 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,067 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,068 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,074 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,075 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,075 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,077 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,080 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,081 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,081 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,083 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,084 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,085 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,086 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,087 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,089 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,090 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,090 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,092 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,093 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,094 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,094 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,096 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,096 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,097 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,097 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,099 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,100 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,101 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,101 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,102 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,103 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,103 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,104 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,105 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,105 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,106 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,107 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,108 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,108 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,109 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,110 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,111 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,112 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,112 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,113 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,114 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,114 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,114 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,116 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,116 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,117 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,117 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,118 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,119 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,120 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,120 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,121 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,121 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,122 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,122 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,124 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,124 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,125 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,126 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,127 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:34777
2025-09-04 11:46:34,127 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:34777
2025-09-04 11:46:34,127 - distributed.worker - INFO -          dashboard at:          10.6.103.61:34855
2025-09-04 11:46:34,127 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,127 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,127 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,127 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,127 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-hlu_v3i6
2025-09-04 11:46:34,127 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,127 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,174 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,176 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,176 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,178 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,259 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:42317
2025-09-04 11:46:34,259 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:42317
2025-09-04 11:46:34,259 - distributed.worker - INFO -          dashboard at:          10.6.103.61:35299
2025-09-04 11:46:34,260 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,260 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,260 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,260 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-i1pcp53i
2025-09-04 11:46:34,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,284 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,285 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,285 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,286 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,294 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:35023
2025-09-04 11:46:34,294 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:32771
2025-09-04 11:46:34,294 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:35023
2025-09-04 11:46:34,294 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:32771
2025-09-04 11:46:34,294 - distributed.worker - INFO -          dashboard at:          10.6.103.61:41603
2025-09-04 11:46:34,295 - distributed.worker - INFO -          dashboard at:          10.6.103.61:39357
2025-09-04 11:46:34,295 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,295 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,295 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,295 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,295 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,295 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,295 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-u7yhn715
2025-09-04 11:46:34,295 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-uukdss6o
2025-09-04 11:46:34,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,297 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:44081
2025-09-04 11:46:34,297 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:44081
2025-09-04 11:46:34,297 - distributed.worker - INFO -          dashboard at:          10.6.103.61:39165
2025-09-04 11:46:34,297 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,297 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,297 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,297 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-dj_1aown
2025-09-04 11:46:34,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,301 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:40095
2025-09-04 11:46:34,301 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:40095
2025-09-04 11:46:34,302 - distributed.worker - INFO -          dashboard at:          10.6.103.61:42801
2025-09-04 11:46:34,302 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,302 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,302 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,302 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-e8vsck3h
2025-09-04 11:46:34,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,303 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:43313
2025-09-04 11:46:34,303 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:43313
2025-09-04 11:46:34,303 - distributed.worker - INFO -          dashboard at:          10.6.103.61:36433
2025-09-04 11:46:34,303 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,303 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,303 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,303 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,303 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-m6o7y13o
2025-09-04 11:46:34,303 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,307 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,308 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,308 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,308 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,316 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:42255
2025-09-04 11:46:34,316 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:42255
2025-09-04 11:46:34,316 - distributed.worker - INFO -          dashboard at:          10.6.103.61:46019
2025-09-04 11:46:34,316 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,316 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,316 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,316 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,316 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-_c_pf4q1
2025-09-04 11:46:34,316 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,317 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,318 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,318 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,319 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,321 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,321 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:33159
2025-09-04 11:46:34,322 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:33159
2025-09-04 11:46:34,322 - distributed.worker - INFO -          dashboard at:          10.6.103.61:45649
2025-09-04 11:46:34,322 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,322 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,322 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,322 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-byux_j9z
2025-09-04 11:46:34,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,322 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,323 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,324 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:36783
2025-09-04 11:46:34,324 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:36783
2025-09-04 11:46:34,324 - distributed.worker - INFO -          dashboard at:          10.6.103.61:40999
2025-09-04 11:46:34,324 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,324 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,324 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,324 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,324 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-14xle4rt
2025-09-04 11:46:34,324 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,326 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,326 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,326 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:46697
2025-09-04 11:46:34,327 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:46697
2025-09-04 11:46:34,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,327 - distributed.worker - INFO -          dashboard at:          10.6.103.61:44471
2025-09-04 11:46:34,327 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,327 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,327 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,327 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-y7tkuicc
2025-09-04 11:46:34,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,327 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:46493
2025-09-04 11:46:34,327 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:46493
2025-09-04 11:46:34,327 - distributed.worker - INFO -          dashboard at:          10.6.103.61:44027
2025-09-04 11:46:34,327 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,327 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,327 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,328 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-0ze40ntr
2025-09-04 11:46:34,328 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,328 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,334 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,335 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,335 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,336 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,340 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:41665
2025-09-04 11:46:34,340 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:41665
2025-09-04 11:46:34,340 - distributed.worker - INFO -          dashboard at:          10.6.103.61:44695
2025-09-04 11:46:34,340 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,340 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,340 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,340 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-z3ozcc6h
2025-09-04 11:46:34,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,340 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,341 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,341 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,343 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:42123
2025-09-04 11:46:34,344 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:42123
2025-09-04 11:46:34,344 - distributed.worker - INFO -          dashboard at:          10.6.103.61:38537
2025-09-04 11:46:34,344 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,344 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,344 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,344 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,344 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-87vm99xu
2025-09-04 11:46:34,344 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,344 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,345 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,345 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,347 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,348 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,349 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,349 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,350 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,351 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,351 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:37985
2025-09-04 11:46:34,351 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:37985
2025-09-04 11:46:34,351 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:45195
2025-09-04 11:46:34,351 - distributed.worker - INFO -          dashboard at:          10.6.103.61:37973
2025-09-04 11:46:34,351 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:45195
2025-09-04 11:46:34,351 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,351 - distributed.worker - INFO -          dashboard at:          10.6.103.61:41597
2025-09-04 11:46:34,351 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,351 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,351 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,351 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,351 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-2c7gs_17
2025-09-04 11:46:34,351 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,351 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-o4sfsjlw
2025-09-04 11:46:34,352 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,352 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,352 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,353 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,353 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:40697
2025-09-04 11:46:34,353 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:40697
2025-09-04 11:46:34,353 - distributed.worker - INFO -          dashboard at:          10.6.103.61:41897
2025-09-04 11:46:34,353 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,353 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,353 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,353 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,353 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,353 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-cb0vd81p
2025-09-04 11:46:34,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,354 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,356 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,364 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,365 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,365 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,367 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,367 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,367 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,368 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,369 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,372 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,373 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,373 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,374 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,374 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,375 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,377 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,377 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,378 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,379 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,380 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,473 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:42595
2025-09-04 11:46:34,473 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:42595
2025-09-04 11:46:34,473 - distributed.worker - INFO -          dashboard at:          10.6.103.61:38085
2025-09-04 11:46:34,473 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,473 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,473 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,473 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,473 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-eksb6h6b
2025-09-04 11:46:34,473 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,477 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:35301
2025-09-04 11:46:34,477 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:35301
2025-09-04 11:46:34,477 - distributed.worker - INFO -          dashboard at:          10.6.103.61:39497
2025-09-04 11:46:34,477 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,477 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,477 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,477 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,477 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-11nybfdw
2025-09-04 11:46:34,477 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,484 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:35409
2025-09-04 11:46:34,484 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:35409
2025-09-04 11:46:34,484 - distributed.worker - INFO -          dashboard at:          10.6.103.61:43705
2025-09-04 11:46:34,484 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,484 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,484 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,484 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,484 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-wiw05ad6
2025-09-04 11:46:34,484 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,485 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:42665
2025-09-04 11:46:34,485 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:42665
2025-09-04 11:46:34,485 - distributed.worker - INFO -          dashboard at:          10.6.103.61:40675
2025-09-04 11:46:34,486 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,486 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,486 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,486 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,486 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-ope627kk
2025-09-04 11:46:34,486 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,486 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:37463
2025-09-04 11:46:34,486 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:37463
2025-09-04 11:46:34,486 - distributed.worker - INFO -          dashboard at:          10.6.103.61:37451
2025-09-04 11:46:34,486 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,486 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,486 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,486 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,486 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-u_j4h8yp
2025-09-04 11:46:34,486 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,488 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:38763
2025-09-04 11:46:34,488 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:38763
2025-09-04 11:46:34,488 - distributed.worker - INFO -          dashboard at:          10.6.103.61:33971
2025-09-04 11:46:34,488 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,488 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,488 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,488 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,488 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-mf64w7gt
2025-09-04 11:46:34,488 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,491 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:37107
2025-09-04 11:46:34,491 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:37107
2025-09-04 11:46:34,491 - distributed.worker - INFO -          dashboard at:          10.6.103.61:39623
2025-09-04 11:46:34,491 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,492 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,492 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,492 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,492 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-oj06ibk4
2025-09-04 11:46:34,492 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,498 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:46375
2025-09-04 11:46:34,498 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:46375
2025-09-04 11:46:34,498 - distributed.worker - INFO -          dashboard at:          10.6.103.61:42193
2025-09-04 11:46:34,498 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,498 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,498 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,498 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,498 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-_e_hkqsr
2025-09-04 11:46:34,498 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,498 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:36929
2025-09-04 11:46:34,498 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:36929
2025-09-04 11:46:34,498 - distributed.worker - INFO -          dashboard at:          10.6.103.61:38509
2025-09-04 11:46:34,498 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,498 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,498 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,498 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,498 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-k0156r3y
2025-09-04 11:46:34,498 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,499 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:33797
2025-09-04 11:46:34,499 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:33797
2025-09-04 11:46:34,499 - distributed.worker - INFO -          dashboard at:          10.6.103.61:46721
2025-09-04 11:46:34,499 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,499 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,499 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,499 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-xlvz6x00
2025-09-04 11:46:34,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,499 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:42709
2025-09-04 11:46:34,500 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:42709
2025-09-04 11:46:34,500 - distributed.worker - INFO -          dashboard at:          10.6.103.61:34947
2025-09-04 11:46:34,500 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,500 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,500 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,500 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,500 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-zik2o4xn
2025-09-04 11:46:34,500 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,501 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,501 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:40717
2025-09-04 11:46:34,501 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:40717
2025-09-04 11:46:34,501 - distributed.worker - INFO -          dashboard at:          10.6.103.61:44515
2025-09-04 11:46:34,501 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,501 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,502 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,502 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,502 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,502 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-xm5tvwre
2025-09-04 11:46:34,502 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,502 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,503 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,505 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:43597
2025-09-04 11:46:34,505 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:43597
2025-09-04 11:46:34,505 - distributed.worker - INFO -          dashboard at:          10.6.103.61:46213
2025-09-04 11:46:34,505 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,505 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,505 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,505 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-uo0sdbsx
2025-09-04 11:46:34,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,505 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:37569
2025-09-04 11:46:34,505 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:37569
2025-09-04 11:46:34,505 - distributed.worker - INFO -          dashboard at:          10.6.103.61:33729
2025-09-04 11:46:34,505 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,505 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,505 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,505 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-arbywpl5
2025-09-04 11:46:34,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,511 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,511 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,512 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,517 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,517 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:43923
2025-09-04 11:46:34,517 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:43923
2025-09-04 11:46:34,517 - distributed.worker - INFO -          dashboard at:          10.6.103.61:35041
2025-09-04 11:46:34,518 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,518 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,518 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,518 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,518 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-gpmj8mp3
2025-09-04 11:46:34,518 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,518 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,518 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,519 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:44659
2025-09-04 11:46:34,519 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:44659
2025-09-04 11:46:34,519 - distributed.worker - INFO -          dashboard at:          10.6.103.61:43303
2025-09-04 11:46:34,519 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,519 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,519 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,519 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,519 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-bli26cmp
2025-09-04 11:46:34,519 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,520 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,520 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.61:46699
2025-09-04 11:46:34,520 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.61:46699
2025-09-04 11:46:34,520 - distributed.worker - INFO -          dashboard at:          10.6.103.61:41237
2025-09-04 11:46:34,520 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,520 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,520 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:34,520 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:34,520 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-ek6wq2y7
2025-09-04 11:46:34,520 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,521 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,521 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,521 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,522 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,526 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,527 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,527 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,529 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,530 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,531 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,531 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,533 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,533 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,534 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,534 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,536 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,536 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,537 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,537 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,539 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,539 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,540 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,540 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,541 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,543 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,544 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,544 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,546 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,548 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,549 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,549 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,550 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,562 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,563 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,563 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,564 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,564 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,565 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,565 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,566 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,566 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,567 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,568 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,569 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,570 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,570 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,571 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,571 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,572 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,573 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,573 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:34,574 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:34,574 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:34,575 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:34,576 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:42,782 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,782 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,782 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,782 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,783 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,784 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,784 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,784 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,784 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,784 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,784 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,784 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,784 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,784 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,784 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,785 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,785 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,785 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,785 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,785 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,785 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,785 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,785 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,785 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,785 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,785 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,785 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,785 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,786 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,786 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,786 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,787 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,787 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,787 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,787 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,787 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,787 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,787 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,787 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,788 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,788 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,788 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,788 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,788 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,788 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,790 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,790 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,790 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,789 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,790 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,790 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,790 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,790 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,790 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,794 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,796 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,797 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,797 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,802 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:45,811 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,811 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,811 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,811 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,811 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,813 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,813 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,813 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,813 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,813 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,813 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,813 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,813 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,814 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,814 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,812 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,814 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,814 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,814 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,814 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,814 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,814 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,813 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,814 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,815 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,816 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,816 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,816 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,816 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,816 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,816 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,817 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,816 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,817 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,817 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,814 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,816 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,815 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,817 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,818 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,819 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,816 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,819 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,819 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,820 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,820 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,820 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,820 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,820 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,820 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,817 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,820 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,821 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,821 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,822 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,822 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,822 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:46,264 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,264 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,264 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,264 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,264 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,264 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,264 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,264 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,265 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,265 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,265 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,265 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,265 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,265 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,265 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,265 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,266 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,266 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,266 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,266 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,266 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,267 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,268 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,268 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,269 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,269 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,269 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,269 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,269 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,269 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,269 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,269 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,269 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,269 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,269 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,269 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,269 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,269 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,270 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,270 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,270 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,270 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,270 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,270 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,270 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,270 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,270 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,270 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,271 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,271 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,271 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,271 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,271 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,271 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,271 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,271 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,272 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,273 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,274 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,274 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,274 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,274 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,274 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,274 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,275 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,275 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,275 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,280 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,695 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,695 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,695 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,696 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,696 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,696 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,696 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,696 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,696 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,696 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,696 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,697 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,697 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,697 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,696 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,697 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,697 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,697 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,697 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,697 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,697 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,698 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,698 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,698 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,698 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,698 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,698 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,698 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,698 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,698 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,698 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,698 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,698 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,698 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,698 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,699 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,699 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,699 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,699 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,699 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,699 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,699 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,699 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,700 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,700 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,700 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,700 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,700 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,701 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,701 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,701 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,701 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,701 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,701 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,701 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,701 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,702 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,702 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,702 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,703 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,703 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,703 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,703 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,703 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,703 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,704 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,704 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,704 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,704 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,704 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,704 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,704 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,705 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,707 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,710 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,711 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,714 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,715 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,720 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:13,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:49,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:50,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:50,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:51,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:51,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:52,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:52,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:53,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:53,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:53,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:53,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:53,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:53,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:53,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:54,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:54,026 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:54,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:54,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:55,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:55,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:56,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:56,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:56,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:56,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:57,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:57,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:57,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:58,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:58,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:58,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:00,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:00,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:00,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:01,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:03,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:03,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:03,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:04,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:04,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:04,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:04,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:05,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:05,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:16,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:16,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:17,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:17,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:18,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:18,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:20,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:21,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:21,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:21,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:22,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:23,467 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:23,472 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:23,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:26,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:26,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:28,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:28,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:29,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:30,582 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:30,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:36,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:40,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 29.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:49,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:51,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:52,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:53,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:53,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:53,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:54,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:54,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:54,263 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:54,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:54,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:55,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:55,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:55,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:55,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:02,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:02,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:02,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:05,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:06,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:06,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:06,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:13,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:13,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:14,224 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:14,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:16,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:17,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:17,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:17,654 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:17,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:17,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:17,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:17,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:17,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:18,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:19,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:19,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:19,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:19,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:19,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:19,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:20,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:20,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:20,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:20,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,263 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,599 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:22,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:22,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:22,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:23,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:23,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:23,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:39,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:39,947 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:39,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:39,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:39,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:40,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:40,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:41,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:41,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:41,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:42,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:42,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:44,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:44,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:44,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:44,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:44,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:44,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:44,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:45,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:46,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:49,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:50,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:50,810 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:51,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:51,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:51,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:54,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:54,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:54,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:56,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:59,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:02,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:04,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:06,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:11,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:11,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:11,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:11,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:12,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:13,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:13,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:13,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:13,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:13,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:13,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:13,774 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:13,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:14,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:15,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:15,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:16,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:16,028 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:16,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:16,570 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:17,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:18,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:18,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:18,442 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:18,442 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:18,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:19,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:19,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:19,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:19,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:21,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:21,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:23,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:25,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:25,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:26,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:26,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:27,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:31,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:31,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:31,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:32,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:32,693 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:32,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:32,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:32,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:33,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:33,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:34,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:34,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:35,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:37,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:37,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:37,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:39,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:40,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:40,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:40,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:42,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:42,113 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:42,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:42,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:42,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:43,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:43,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:43,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:43,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:43,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:43,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:43,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:44,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:44,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:44,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:45,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:45,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:45,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:48,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:51,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:51,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:51,943 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:51,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:52,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:52,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:53,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:53,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:53,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:54,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:54,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:54,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:54,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:54,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:55,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:55,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:56,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:56,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:56,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:56,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:56,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:58,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:58,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:58,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:58,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:59,116 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,654 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:01,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:01,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:01,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:01,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:04,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:04,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:04,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:04,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:09,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:10,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:10,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:10,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:10,945 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:13,001 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:13,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:13,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:13,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:14,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:14,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:14,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:15,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:16,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:17,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:17,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:17,864 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:18,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:19,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:19,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:19,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:20,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:25,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:30,467 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:34,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:34,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:34,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 29.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:34,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 29.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:35,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:35,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:40,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:40,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:41,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:42,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:42,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:42,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,161 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:45,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:45,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:45,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:46,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:46,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:46,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:47,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:47,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:47,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:47,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:47,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:47,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:48,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:48,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:48,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:48,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:48,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:48,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:48,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:49,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:50,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:50,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:50,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:50,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:50,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:50,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:50,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:51,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:51,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:52,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:52,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:53,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:53,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:53,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:53,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:55,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:55,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:56,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:56,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:01,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:01,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:02,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:02,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:02,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:02,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:03,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:03,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:03,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:06,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:06,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:06,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:06,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:06,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:07,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:07,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:07,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:07,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:07,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:08,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:08,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:08,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:09,072 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:09,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:16,556 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:17,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:18,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,436 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:20,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:20,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:21,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:21,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:21,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:22,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:22,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:23,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:24,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:24,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:24,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:25,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:25,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:25,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:25,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:26,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:29,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:31,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:32,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:38,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:40,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:40,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:41,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:44,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:46,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:47,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:49,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:49,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:51,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:51,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:52,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:52,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:53,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:55,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:55,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:55,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:55,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:55,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:55,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:55,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:56,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:56,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:56,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:57,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:57,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:57,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:57,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:58,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:58,108 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:58,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:58,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:59,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:00,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:02,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:05,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:05,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:05,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:05,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:05,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:07,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:07,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:07,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:07,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:07,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:08,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:08,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:09,263 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:09,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:09,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:09,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:09,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:09,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:10,083 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:10,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:10,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:11,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:12,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:12,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:12,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:12,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:13,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:13,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:13,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:13,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:15,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:15,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:15,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:15,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:16,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:16,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:17,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:18,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:18,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:18,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:24,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:24,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:26,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:26,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:26,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:28,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:30,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:52,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:52,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:56,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:56,469 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:56,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:56,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:56,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:56,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:56,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:57,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:57,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:58,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:59,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:59,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:59,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:00,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:00,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:01,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:01,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:01,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:01,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:01,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:09,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:09,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:10,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:10,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:10,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:10,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:10,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:11,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:11,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:11,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:12,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:12,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:12,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:12,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:13,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:13,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:13,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:13,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:13,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:13,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:13,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:15,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:15,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:15,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:16,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:17,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:17,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:17,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:18,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:18,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:19,651 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:19,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:21,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:21,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:25,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:27,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:28,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:28,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:30,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:31,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:38,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:38,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:39,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:39,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:39,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:39,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:40,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:40,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:41,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:42,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:42,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:42,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:42,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:42,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:42,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:42,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:43,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:43,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:44,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:45,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,592 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:47,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:47,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:48,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:48,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:48,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:49,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:49,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:50,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:55,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:57,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:59,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:01,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:02,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:04,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:04,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:05,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:05,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:05,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:10,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:10,078 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:10,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:10,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:10,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:10,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:11,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:11,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:11,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:12,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:13,101 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:13,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:14,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:14,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:14,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:15,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:16,232 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:16,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:16,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:16,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:16,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:17,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:18,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:21,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:21,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:21,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:21,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:23,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:23,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:23,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:24,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:24,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:24,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:28,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:28,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:28,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:28,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:29,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:29,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:29,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:29,447 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:30,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,422 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:31,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:32,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:32,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:33,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:33,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:33,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:33,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:33,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:33,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:33,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:34,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:34,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:34,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:34,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:35,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:35,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:37,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:37,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:37,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:38,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:39,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:40,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:42,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:43,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:45,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:45,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:49,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:49,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:49,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:51,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:54,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:55,200 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:56,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:56,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:57,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:57,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:58,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:58,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:58,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:00,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:00,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:00,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:02,078 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:02,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:03,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:03,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:03,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:05,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:06,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:06,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:06,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:06,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:06,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:06,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:06,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:06,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:07,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:07,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:07,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:07,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:08,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:08,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:08,654 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:09,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:09,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:09,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:09,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:10,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:10,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:11,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:24,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:24,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:27,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:27,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:28,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:28,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:30,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:31,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:31,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:33,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:33,642 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:33,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:34,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:34,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:34,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:36,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:36,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:37,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:37,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:37,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:37,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:37,570 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:38,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:39,075 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:41,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:43,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:44,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:46,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:46,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:46,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:46,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:47,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:47,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:47,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:47,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:47,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:47,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:50,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:50,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:50,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:02,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:04,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:05,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:05,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:06,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:08,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:08,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,713 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:11,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:25,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:27,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:27,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:27,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:27,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:27,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:28,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:28,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:28,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:28,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:28,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:32,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:32,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:32,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:33,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:33,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:33,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:33,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:33,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:33,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:33,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:34,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:34,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:34,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:34,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:34,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:35,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:40,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:41,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:42,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:42,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:42,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:42,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:42,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:43,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:44,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:44,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:44,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:45,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:45,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:46,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:46,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:46,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:47,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:47,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:47,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:49,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:49,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:50,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:50,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:51,442 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:52,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:53,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:53,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:53,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:54,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:57,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:57,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:00,805 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:00,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:05,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:11,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:11,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:11,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:14,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:14,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:15,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:16,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:17,438 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:17,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:17,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:17,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:18,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:18,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:18,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:18,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:19,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:20,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:20,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:21,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:21,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:21,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:29,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:29,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:30,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:30,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:35,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:36,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:36,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:37,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:40,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:40,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:42,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:43,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:43,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:45,023 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:45,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:46,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:46,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:46,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:48,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:49,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:49,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:49,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:49,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:50,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:50,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:50,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:50,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:50,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:50,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:50,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:50,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:50,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:51,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:51,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:51,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:51,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:51,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:51,779 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:09,651 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:12,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:13,142 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:14,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:14,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:14,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:15,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:15,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:16,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:16,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:16,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:16,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:17,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:17,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:18,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:18,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:18,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:21,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,436 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:24,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:24,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:24,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:24,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:24,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:25,187 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:25,316 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:25,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:25,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:25,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:25,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:26,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:27,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:27,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:27,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:27,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:27,774 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:27,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:28,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:29,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:30,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:31,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:33,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:33,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:35,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:35,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:37,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:37,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:38,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,482 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,482 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:42,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:43,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:44,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:44,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:45,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:45,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:45,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:48,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:48,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:48,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:49,153 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:49,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:49,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:49,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:50,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:52,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:52,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:53,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:54,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:58,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:58,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:58,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:58,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:59,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:59,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:59,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:59,469 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:59,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:59,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:59,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,910 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:02,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:02,314 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:02,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:02,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:03,006 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:04,589 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:04,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:04,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:05,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:05,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:06,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:06,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:06,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:06,142 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:06,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:06,805 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:06,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:08,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:09,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:09,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:12,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:14,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:17,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:18,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:29,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:30,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:31,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:31,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:31,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:31,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:33,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:33,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:34,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:34,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:35,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:35,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:35,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:35,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:35,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:35,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:37,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:37,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:38,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:38,589 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:38,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:40,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:40,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:41,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:41,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:42,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:42,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:42,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:42,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:42,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:42,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:42,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:43,220 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:48,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,026 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:55,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:55,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:55,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:55,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:56,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:56,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:56,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:56,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:56,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:56,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:57,023 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:58,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:58,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:58,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:01,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:01,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:01,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:01,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:01,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:04,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:05,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:08,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:08,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:09,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:09,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:09,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:10,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:10,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:10,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:10,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,260 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:12,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:13,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:13,026 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:13,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:13,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:13,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:13,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:14,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:15,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:16,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:18,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:18,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:26,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:28,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:28,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:29,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:29,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:29,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:30,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:31,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:31,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,422 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,422 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,426 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:33,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:34,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:34,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:34,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:34,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:35,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:35,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:35,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:36,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:36,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:36,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:36,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:37,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:37,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:38,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:38,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:39,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:39,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:39,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:40,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:40,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:40,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:40,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:40,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:40,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:44,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:46,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:46,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:46,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:46,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:48,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:48,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:48,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:48,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:49,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:49,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:49,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:50,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:51,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:52,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:52,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:52,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:53,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:53,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:54,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:55,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:55,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:55,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:55,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:55,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:58,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:58,161 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:16,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:16,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:18,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:18,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:22,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,207 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,207 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,600 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:24,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:25,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:25,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:25,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:25,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:25,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:26,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:26,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:30,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:30,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:31,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:32,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:32,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,227 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:39,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:39,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:40,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:40,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:40,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:40,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:42,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:42,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:42,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:42,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:44,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:45,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:45,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:47,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:48,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:53,335 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:54,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:55,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:57,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:57,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:58,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:58,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:58,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:03,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:03,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:03,088 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:03,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:04,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:06,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:06,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:06,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:06,810 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:06,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:08,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:09,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:14,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:14,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:14,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:16,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:17,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:18,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:18,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:18,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:20,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:22,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:22,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:22,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:22,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:22,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:22,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:23,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:23,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:23,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:23,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:23,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:24,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:24,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:25,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:26,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:27,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:27,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:28,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:30,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:30,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:30,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:30,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:30,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:31,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:31,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:31,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:32,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:38,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:39,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:39,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:40,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:40,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:44,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:46,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:46,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:49,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:49,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:53,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:53,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:54,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:54,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:55,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:55,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:56,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:57,442 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:58,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:58,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,029 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:00,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:00,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:00,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:00,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:01,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:01,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:01,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:02,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:02,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:03,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:03,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:03,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:03,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:04,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:06,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:10,227 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:11,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:14,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:22,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:28,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:32,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:48,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,654 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:51,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:52,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:53,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:53,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:53,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:53,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:53,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:53,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:55,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:55,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:55,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:56,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:56,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:58,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:58,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:00,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:01,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:02,153 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:02,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:03,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:04,847 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:06,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:08,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:11,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:11,437 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:16,810 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:16,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:16,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:17,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:17,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:18,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:19,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:19,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:19,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:21,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:21,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:21,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:21,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:21,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:22,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:22,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:22,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:24,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:24,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:24,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:24,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:24,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:26,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:29,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:32,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:32,774 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:32,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:32,984 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:32,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:33,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:33,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:33,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:34,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:35,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:35,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:35,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:35,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:35,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:36,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:36,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:36,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:36,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:37,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:38,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:38,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:38,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:39,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:39,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:39,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:40,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:40,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:40,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:43,422 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:47,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:47,316 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:54,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:02,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:02,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,101 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:05,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:05,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:12,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:13,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:13,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:13,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:13,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:13,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:13,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:13,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:15,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:15,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:15,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:15,599 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:17,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:19,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:19,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:20,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:20,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:20,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:20,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:20,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:21,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:21,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:21,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:21,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:21,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:21,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:22,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:22,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:24,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:24,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:25,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:25,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:25,469 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:42,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:42,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:42,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,824 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:46,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:46,150 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:46,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:46,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:46,910 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:47,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:47,482 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:47,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:48,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:48,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:48,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:49,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:49,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:49,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:49,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:50,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:51,438 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:51,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:51,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:51,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:51,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:51,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:56,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:56,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:57,161 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:57,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:57,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:57,224 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:57,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:58,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:58,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:58,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:59,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:59,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:59,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:59,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:00,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:03,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:03,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:03,378 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:03,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:05,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:05,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,472 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,909 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:09,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:09,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:11,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:11,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:11,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:11,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:11,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:15,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:20,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:20,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:22,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:22,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:26,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:26,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:27,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:28,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:28,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:28,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:28,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:30,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:30,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:30,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:30,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:30,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:30,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:31,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:32,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:32,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:34,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:37,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:37,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:39,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:41,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:41,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:41,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:41,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:44,259 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:44,263 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:46,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:46,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:46,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:47,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:53,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 29.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:53,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:53,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:53,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:54,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:54,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:55,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:56,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:56,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:56,911 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:56,911 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:59,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:59,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:59,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:00,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:00,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:01,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:01,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:01,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,187 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:06,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:06,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:10,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:10,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:10,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:10,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:19,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:19,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:19,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:21,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:21,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:21,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:22,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:23,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:26,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:26,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:31,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:31,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:31,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:37,909 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:38,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:42,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:42,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:42,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:42,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:43,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:43,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:43,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:44,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:44,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:44,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:44,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:45,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:45,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:46,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:47,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:48,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:49,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:49,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:49,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:50,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:50,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:50,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:52,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:52,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:54,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:54,938 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:54,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:54,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:55,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:55,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:55,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:56,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:56,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:56,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:56,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:57,703 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,705 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:42123. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,703 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,704 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,705 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:44659. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,703 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,704 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,705 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:44081. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,703 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,704 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,704 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,704 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,706 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:43923. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,706 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:36783. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,703 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,706 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:40717. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,704 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,706 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:42709. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,704 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,706 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:41665. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,704 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,706 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:36929. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,707 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:37569. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,707 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:40095. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,707 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:35409. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,707 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:42595. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,705 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,708 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:44105. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,706 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,708 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,705 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,709 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:33361. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,709 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:35469. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,708 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,708 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,710 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:42089. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,708 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,708 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,708 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,711 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:35301. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,711 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:38795. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,711 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:41019. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,711 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:37181. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,711 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:33507. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,708 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,711 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:37553'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,712 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:33815. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,713 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4098, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,713 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4779, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,714 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,714 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,714 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,714 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,714 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,718 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:43481'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,719 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:42853'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,720 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7720, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,720 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7199, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,720 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,721 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.46:40215, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,721 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,721 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,721 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,721 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,721 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,721 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,722 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,722 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,722 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,722 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,726 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:43389'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,727 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:41405'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,727 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:40211'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,727 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5369, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,727 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:40453'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,728 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5388, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,728 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4592, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,728 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,728 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:41385'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,728 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7377, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,728 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,728 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:39591'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,728 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,728 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,729 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5661, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,729 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,729 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.61:46493, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,729 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:41381'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4178, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,729 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.57:38407, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,729 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.61:40697, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.40:40083, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,729 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,729 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:35627'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.63:45255, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,729 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5621, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,730 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:44175'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,730 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5649, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,730 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:43195'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,730 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5693, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,730 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:35919'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,731 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6752, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,731 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7385, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,731 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.61:46493, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,731 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4604, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,731 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,731 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,732 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,732 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,732 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6815, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,732 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,732 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,732 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,732 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,732 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6827, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,732 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,732 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,732 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,733 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,734 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,734 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,734 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:41075'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,735 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:35091'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,735 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:34935'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,736 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:46309'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,736 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4869, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,736 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:36667'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,736 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4542, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,736 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:34089'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,736 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:34063'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,736 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,736 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6519, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,736 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4758, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,737 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,737 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5349, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,737 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:43341'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,737 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 8108, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,737 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5381, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,737 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,737 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6589, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,737 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,737 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:36895'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,737 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,737 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7663, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,737 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7905, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,737 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,737 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,738 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4153, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,738 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7202, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,738 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,739 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,739 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,739 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,739 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,739 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.46:38511, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,739 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.40:37359, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,739 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,739 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.61:40071, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,739 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.53:43595, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,739 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,739 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.44:38111, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,740 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,740 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.61:46493, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,740 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,740 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,787 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,789 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,789 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,790 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,792 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:32965. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,793 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,799 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,799 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,803 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,804 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,816 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34154 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:57,828 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:35121'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,831 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,831 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,831 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,831 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,831 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,851 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,925 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,928 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:35023. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,949 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34300 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:57,953 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:41017'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,953 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6889, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,954 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,954 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,954 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,954 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,954 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:58,167 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:58,169 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:38749. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,170 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:58,172 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:33159. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,192 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34094 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:58,196 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:35695'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,195 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34358 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:58,197 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6787, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,197 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.51:39475, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,198 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:58,198 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:58,198 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:58,198 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:58,198 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:58,199 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:36591'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,200 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4811, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,200 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:58,200 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:58,200 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:58,200 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:58,200 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:58,314 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:58,316 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:42317. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,319 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:58,321 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:46493. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,323 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34284 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34284 remote=tcp://10.6.103.37:8707>: Stream is closed
2025-09-04 12:11:58,323 - distributed.worker - ERROR - failed during get data with tcp://10.6.103.61:46493 -> tcp://10.6.103.61:35301
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.103.61:46493 remote=tcp://10.6.103.61:51352>: Stream is closed
2025-09-04 12:11:58,327 - distributed.worker - ERROR - failed during get data with tcp://10.6.103.61:46493 -> tcp://10.6.103.61:40717
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.103.61:46493 remote=tcp://10.6.103.61:43176>: Stream is closed
2025-09-04 12:11:58,328 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:43883'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,328 - distributed.worker - ERROR - failed during get data with tcp://10.6.103.61:46493 -> tcp://10.6.103.61:37569
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.103.61:46493 remote=tcp://10.6.103.61:33994>: Stream is closed
2025-09-04 12:11:58,329 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.38:33555, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,329 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:45227, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,329 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.49:43399, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,329 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.46:44199, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,329 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.62:36717, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,329 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.40:37993, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,329 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:58,329 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:58,329 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:58,329 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:58,329 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:58,335 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34394 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34394 remote=tcp://10.6.103.37:8707>: Stream is closed
2025-09-04 12:11:58,339 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:44457'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,339 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.56:36265, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.64:39089, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6550, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.46:46861, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,340 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:58,340 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:58,340 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:58,340 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:58,340 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:58,343 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:58,487 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:58,562 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:58,564 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:46375. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:58,589 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34520 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:58,593 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:39181'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,594 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7090, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:58,594 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:58,594 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:58,594 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:58,594 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:58,594 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:58,713 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:58,716 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:46119. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:58,744 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34210 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:58,748 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:41135'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,749 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:58,749 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:58,749 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:58,749 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:58,749 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:58,758 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1527d959d450>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:58,767 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:58,895 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,384 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,386 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:34777. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,386 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,388 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:42255. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,417 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.103.45:33899
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.103.61:32796 remote=tcp://10.6.103.45:33899>: Stream is closed
2025-09-04 12:11:59,420 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34274 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,423 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34342 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,429 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:43907'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,430 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:44905'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,430 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.40:44481, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:59,430 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.61:40071, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:59,431 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,431 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,431 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,431 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,431 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,431 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.42:36869, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:59,431 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:40655, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:59,431 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,431 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,431 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,432 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,432 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,439 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14d861be1b50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,440 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x154a333b1c10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,448 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,450 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,791 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,792 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,793 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,797 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,803 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,803 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,807 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,807 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,854 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,345 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,367 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:00,369 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:40071. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,389 - distributed.worker - ERROR - failed during get data with tcp://10.6.103.61:40071 -> tcp://10.6.103.61:33507
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.103.61:40071 remote=tcp://10.6.103.61:37756>: Stream is closed
2025-09-04 12:12:00,392 - distributed.worker - ERROR - failed during get data with tcp://10.6.103.61:40071 -> tcp://10.6.103.61:34777
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.103.61:40071 remote=tcp://10.6.103.61:53232>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-04 12:12:00,436 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:00,443 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34236 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:00,447 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:41175'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,448 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:00,448 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:00,449 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:00,449 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:00,449 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:00,456 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14b2dbe48a90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:00,464 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,467 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,469 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,492 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,532 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:35121'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,536 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:42853'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,536 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:35627'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,537 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:36895'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,539 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:34063'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,539 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:40211'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,539 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:41385'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,540 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:43195'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,542 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:35121' closed.
2025-09-04 12:12:00,542 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:42853' closed.
2025-09-04 12:12:00,542 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:35627' closed.
2025-09-04 12:12:00,543 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:36895' closed.
2025-09-04 12:12:00,543 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:34063' closed.
2025-09-04 12:12:00,544 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:40211' closed.
2025-09-04 12:12:00,544 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:41385' closed.
2025-09-04 12:12:00,544 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:43195' closed.
2025-09-04 12:12:00,591 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:00,593 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:45195. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:00,623 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:43341'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,624 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:43341' closed.
2025-09-04 12:12:00,622 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34432 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:00,627 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:44537'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,628 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4879, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:00,628 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:00,628 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:00,628 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:00,628 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:00,628 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:00,632 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x15051ad9d7d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:00,635 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:00,637 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:37107. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:00,666 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:00,668 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:38717. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,669 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34504 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:00,672 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:40777'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,673 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:00,673 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:00,673 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:00,673 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:00,673 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:00,677 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ed2e8303d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:00,684 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:00,701 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34078 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:00,704 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:42777'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,705 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:00,705 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:00,705 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:00,705 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:00,705 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:00,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x153d92f8ac50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:00,715 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,770 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,840 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,841 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,847 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:43883'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,848 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:43883' closed.
2025-09-04 12:12:00,855 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,857 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,899 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,912 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,023 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:35695'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,024 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:35695' closed.
2025-09-04 12:12:01,108 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,110 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:39823. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,118 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,119 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:45373. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,136 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,138 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:37463. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,142 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,144 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34200 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,145 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34090 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,147 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:35019'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,147 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,147 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,147 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,148 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,148 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,148 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:35895'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,148 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,149 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,149 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,149 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,149 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,151 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14fa81f70190>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,152 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1521f84aff10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,158 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,160 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,171 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34496 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,174 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:38693'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,175 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,175 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,175 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,175 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,175 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,178 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x149c6f12bd50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,184 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,263 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,265 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:42665. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,268 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:41135'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,270 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:41135' closed.
2025-09-04 12:12:01,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,295 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34484 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,298 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:38597'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,298 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,299 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,299 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,299 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,299 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,302 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x153e1183bbd0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,307 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:36591'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,396 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:36591' closed.
2025-09-04 12:12:01,427 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,429 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:43597. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,451 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,452 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,461 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34578 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,464 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:42273'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,465 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,465 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,465 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,465 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,465 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,468 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14decf077190>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,474 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,480 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,483 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:33797. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,481 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,483 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:37985. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,483 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,485 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:43313. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,506 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,507 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:40697. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,507 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,507 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:44205. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,509 - distributed.worker - ERROR - failed during get data with tcp://10.6.103.61:40697 -> tcp://10.6.103.61:41665
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.103.61:40697 remote=tcp://10.6.103.61:37274>: Stream is closed
2025-09-04 12:12:01,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,510 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.103.37:40797
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.103.61:45260 remote=tcp://10.6.103.37:40797>: Stream is closed
2025-09-04 12:12:01,511 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,513 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:46699. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,514 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,515 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34546 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,515 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,517 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:32771. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,517 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.103.41:34489
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.103.61:36900 remote=tcp://10.6.103.41:34489>: Stream is closed
2025-09-04 12:12:01,517 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34252 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34252 remote=tcp://10.6.103.37:8707>: Stream is closed
2025-09-04 12:12:01,517 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34422 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,520 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34442 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34442 remote=tcp://10.6.103.37:8707>: Stream is closed
2025-09-04 12:12:01,520 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:42199'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,521 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7770, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,521 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,521 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,521 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,521 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,521 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,523 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:34703'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,522 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34336 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,523 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6554, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,523 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,524 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,524 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,524 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,524 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,524 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:42383'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,524 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.52:41909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,524 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6795, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,524 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,525 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,525 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,525 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,525 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,525 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:37493'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,525 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 8060, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,526 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,524 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1499f4493490>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,526 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,526 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,526 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,526 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,526 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:41925'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,527 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6819, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,527 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,527 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,527 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,527 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,527 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,527 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1499ee9b0bd0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,527 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14b5d4a71d50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,529 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x153ccde10550>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,530 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1540bd606e90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,537 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,547 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.103.53:37819
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 231, in read
    buffer = await read_bytes_rw(stream, buffer_nbytes)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 367, in read_bytes_rw
    actual = await stream.read_into(chunk)  # type: ignore[arg-type]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.103.61:53228 remote=tcp://10.6.103.53:37819>: Stream is closed
2025-09-04 12:12:01,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,552 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,552 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34626 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,555 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:37421'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,554 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34310 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,556 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,556 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,556 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,556 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,556 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,557 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:38927'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,558 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,558 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,558 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,558 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,558 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,559 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14a8e6803990>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,561 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,563 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:38763. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,561 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x149b375dd190>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,564 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,568 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,594 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34500 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,597 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:42097'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,598 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6850, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,598 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,598 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,598 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,598 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,598 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,601 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14bb7774d090>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,637 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,639 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:39437. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,668 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,672 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34224 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,675 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:44923'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,676 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,676 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,676 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,676 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,676 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,679 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x150e4fd88810>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,684 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,803 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,805 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,928 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,929 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,929 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,960 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,960 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,973 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,013 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:02,015 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.61:46697. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:02,044 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:02,051 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,051 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.61:34386 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:02,055 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.61:34129'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:02,056 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:02,056 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:02,056 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:02,056 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:02,056 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:02,058 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14bc3becad90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:02,061 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:43907'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,062 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:43907' closed.
2025-09-04 12:12:02,063 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,081 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:44905'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,083 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:44905' closed.
2025-09-04 12:12:02,086 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,128 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,206 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,350 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,417 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,468 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,471 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,474 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,686 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,718 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,844 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,845 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,859 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,860 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,916 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,963 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:36667'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,964 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:36667' closed.
2025-09-04 12:12:02,970 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:41075'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,971 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:41075' closed.
2025-09-04 12:12:02,991 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:41175'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,992 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:41175' closed.
2025-09-04 12:12:03,161 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,164 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,187 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,200 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:40777'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,201 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:40777' closed.
2025-09-04 12:12:03,246 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:42777'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,247 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:42777' closed.
2025-09-04 12:12:03,310 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,375 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:41381'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,376 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:41381' closed.
2025-09-04 12:12:03,380 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:44457'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,381 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:44457' closed.
2025-09-04 12:12:03,452 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:35091'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,453 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:35091' closed.
2025-09-04 12:12:03,456 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:43389'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,457 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:43389' closed.
2025-09-04 12:12:03,461 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:37553'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,462 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:37553' closed.
2025-09-04 12:12:03,477 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,519 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,541 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,555 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,567 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,570 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,687 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,731 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:38693'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,732 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:38693' closed.
2025-09-04 12:12:03,806 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:35019'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,807 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,807 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:35019' closed.
2025-09-04 12:12:03,809 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,811 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:35895'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,812 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:35895' closed.
2025-09-04 12:12:03,854 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:38597'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,855 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:38597' closed.
2025-09-04 12:12:03,932 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,933 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,933 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,964 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,964 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,977 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,023 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:43481'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,024 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:43481' closed.
2025-09-04 12:12:04,048 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,055 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,066 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,090 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,093 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:37421'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,094 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:37421' closed.
2025-09-04 12:12:04,115 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:34703'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,116 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:42273'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,119 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:34703' closed.
2025-09-04 12:12:04,119 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:42273' closed.
2025-09-04 12:12:04,132 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,159 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:39181'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,162 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:39181' closed.
2025-09-04 12:12:04,210 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,283 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:38927'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,284 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:38927' closed.
2025-09-04 12:12:04,328 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:42097'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,329 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:42097' closed.
2025-09-04 12:12:04,353 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:44923'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,353 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:44923' closed.
2025-09-04 12:12:04,354 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,421 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,458 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:35919'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,459 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:35919' closed.
2025-09-04 12:12:04,464 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:42383'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,465 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:42383' closed.
2025-09-04 12:12:04,553 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:37493'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,554 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:37493' closed.
2025-09-04 12:12:04,596 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:34089'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,596 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:34089' closed.
2025-09-04 12:12:04,623 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:41405'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,624 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:41405' closed.
2025-09-04 12:12:04,629 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:41925'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,630 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:41925' closed.
2025-09-04 12:12:04,632 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:44537'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,633 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:44537' closed.
2025-09-04 12:12:04,687 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:46309'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,688 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:46309' closed.
2025-09-04 12:12:04,708 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:44175'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,709 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:44175' closed.
2025-09-04 12:12:04,717 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:39591'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,718 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:39591' closed.
2025-09-04 12:12:04,762 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:41017'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,763 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:41017' closed.
2025-09-04 12:12:04,766 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:34129'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,767 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:34129' closed.
2025-09-04 12:12:04,842 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:40453'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,843 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:40453' closed.
2025-09-04 12:12:04,854 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:42199'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,855 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:42199' closed.
2025-09-04 12:12:04,939 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.61:34935'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,939 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.61:34935' closed.
2025-09-04 12:12:04,941 - distributed.dask_worker - INFO - End worker
