Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-05 09:11:37,135 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:44427'
2025-09-05 09:11:37,144 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:34565'
2025-09-05 09:11:37,148 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:32769'
2025-09-05 09:11:37,152 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:40087'
2025-09-05 09:11:37,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:40379'
2025-09-05 09:11:37,160 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:46413'
2025-09-05 09:11:37,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:41947'
2025-09-05 09:11:37,170 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:35323'
2025-09-05 09:11:37,174 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:45987'
2025-09-05 09:11:37,179 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:37469'
2025-09-05 09:11:37,183 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:41527'
2025-09-05 09:11:37,186 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:41687'
2025-09-05 09:11:37,190 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:37633'
2025-09-05 09:11:37,194 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:41349'
2025-09-05 09:11:37,198 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:42347'
2025-09-05 09:11:37,203 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:37415'
2025-09-05 09:11:37,206 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:38077'
2025-09-05 09:11:37,211 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:37159'
2025-09-05 09:11:37,216 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:38565'
2025-09-05 09:11:37,221 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:46825'
2025-09-05 09:11:37,359 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:40421'
2025-09-05 09:11:37,363 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:37177'
2025-09-05 09:11:37,368 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:36093'
2025-09-05 09:11:37,373 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:44525'
2025-09-05 09:11:37,378 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:39937'
2025-09-05 09:11:37,382 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:35639'
2025-09-05 09:11:37,387 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:39599'
2025-09-05 09:11:37,396 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:43919'
2025-09-05 09:11:37,401 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:37315'
2025-09-05 09:11:37,405 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:38575'
2025-09-05 09:11:37,409 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:34109'
2025-09-05 09:11:37,414 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:46433'
2025-09-05 09:11:37,418 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:37345'
2025-09-05 09:11:37,422 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:34117'
2025-09-05 09:11:37,426 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:34805'
2025-09-05 09:11:37,431 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:44241'
2025-09-05 09:11:37,435 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:34587'
2025-09-05 09:11:37,439 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:37743'
2025-09-05 09:11:37,445 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:45429'
2025-09-05 09:11:37,450 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:35425'
2025-09-05 09:11:37,454 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:45663'
2025-09-05 09:11:37,458 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:46713'
2025-09-05 09:11:37,462 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:36463'
2025-09-05 09:11:37,466 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:38813'
2025-09-05 09:11:37,470 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:40693'
2025-09-05 09:11:37,473 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:42033'
2025-09-05 09:11:37,479 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:46569'
2025-09-05 09:11:37,483 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:41599'
2025-09-05 09:11:37,488 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:45671'
2025-09-05 09:11:37,492 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:33287'
2025-09-05 09:11:37,496 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:34347'
2025-09-05 09:11:37,502 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.49:34683'
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:36843
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:41983
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:37687
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:39907
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:44921
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:36843
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:35935
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:41983
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:45161
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:37687
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:38005
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:43507
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:35635
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:39847
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:37559
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:39907
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:35285
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:39023
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:46499
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:44921
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:44057
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:35935
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:46755
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:45161
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:41951
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:38005
2025-09-05 09:11:38,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:41561
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:43507
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:35635
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:39847
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:37559
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:40355
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:46123
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:35285
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:39023
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:46499
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:41997
2025-09-05 09:11:38,388 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,388 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:43731
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:42573
2025-09-05 09:11:38,388 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:44507
2025-09-05 09:11:38,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:41561
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:32967
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:36241
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:39487
2025-09-05 09:11:38,388 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,388 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:35311
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:38643
2025-09-05 09:11:38,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,388 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,388 - distributed.worker - INFO -          dashboard at:          10.6.101.49:34569
2025-09-05 09:11:38,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,388 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,388 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,388 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,389 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,389 - distributed.worker - INFO -          dashboard at:          10.6.101.49:33349
2025-09-05 09:11:38,389 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-adkvd1yn
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-nne771wo
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-zcdp6a0z
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-0fmwwnf2
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-5ryqlq9r
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-oo58rud9
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ggb2rpif
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-bhohjs33
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ai087ssq
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-4w7_sy4c
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-0olhhp5n
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-a39ctqyn
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-xykulxr9
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-pxaubhlb
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-9casucz2
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:33919
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-isorlzln
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:33919
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -          dashboard at:          10.6.101.49:43291
2025-09-05 09:11:38,389 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,389 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,389 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,389 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-j9disezl
2025-09-05 09:11:38,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,401 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:42699
2025-09-05 09:11:38,401 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:42699
2025-09-05 09:11:38,401 - distributed.worker - INFO -          dashboard at:          10.6.101.49:43211
2025-09-05 09:11:38,401 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,401 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,401 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,401 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,401 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-hm0d3014
2025-09-05 09:11:38,402 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,421 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,421 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,421 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,422 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,427 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,428 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,428 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,430 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,430 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,431 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,431 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,432 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,433 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,434 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,434 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,435 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,437 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,439 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,439 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,440 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,441 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,442 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,442 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,443 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,444 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,444 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,444 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,446 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,446 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,447 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,447 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,448 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,449 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,450 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,450 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,451 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,451 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,452 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,452 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,452 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,454 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,454 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,454 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,454 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,455 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,456 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,456 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,456 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,457 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,457 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,458 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,458 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,459 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,459 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,460 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,473 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,474 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,474 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,475 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,476 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,476 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,476 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,476 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,477 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,477 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,477 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,478 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,478 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,478 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,479 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,480 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,505 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:46125
2025-09-05 09:11:38,505 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:46125
2025-09-05 09:11:38,505 - distributed.worker - INFO -          dashboard at:          10.6.101.49:39079
2025-09-05 09:11:38,505 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,505 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,505 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,505 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-5ti5cebt
2025-09-05 09:11:38,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,518 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:33193
2025-09-05 09:11:38,518 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:33193
2025-09-05 09:11:38,518 - distributed.worker - INFO -          dashboard at:          10.6.101.49:38967
2025-09-05 09:11:38,518 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,518 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,518 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,518 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,518 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-v61bfjmu
2025-09-05 09:11:38,518 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,530 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,531 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,531 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,533 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,541 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,542 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,542 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,544 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,554 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:44169
2025-09-05 09:11:38,554 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:44169
2025-09-05 09:11:38,554 - distributed.worker - INFO -          dashboard at:          10.6.101.49:42319
2025-09-05 09:11:38,554 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,554 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,554 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,554 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,554 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-uw2kum48
2025-09-05 09:11:38,554 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,578 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,579 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,580 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,581 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,599 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:40451
2025-09-05 09:11:38,599 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:40451
2025-09-05 09:11:38,599 - distributed.worker - INFO -          dashboard at:          10.6.101.49:35237
2025-09-05 09:11:38,599 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,599 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,599 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,599 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8zspl6c9
2025-09-05 09:11:38,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,625 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,626 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,627 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,699 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:38733
2025-09-05 09:11:38,699 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:33403
2025-09-05 09:11:38,699 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:38733
2025-09-05 09:11:38,699 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:33403
2025-09-05 09:11:38,699 - distributed.worker - INFO -          dashboard at:          10.6.101.49:41273
2025-09-05 09:11:38,700 - distributed.worker - INFO -          dashboard at:          10.6.101.49:42439
2025-09-05 09:11:38,700 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,700 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,700 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,700 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,700 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,700 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,700 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,700 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,700 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-35yr_x5d
2025-09-05 09:11:38,700 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-qx5mti2u
2025-09-05 09:11:38,700 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,700 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,705 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:45229
2025-09-05 09:11:38,705 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:45229
2025-09-05 09:11:38,705 - distributed.worker - INFO -          dashboard at:          10.6.101.49:40983
2025-09-05 09:11:38,705 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,705 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,705 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,705 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-s_lbm7s9
2025-09-05 09:11:38,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,722 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:44277
2025-09-05 09:11:38,723 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:44277
2025-09-05 09:11:38,723 - distributed.worker - INFO -          dashboard at:          10.6.101.49:45225
2025-09-05 09:11:38,723 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,723 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,723 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,723 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,723 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-h7p7e_cu
2025-09-05 09:11:38,723 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,724 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,725 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,725 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,726 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:40931
2025-09-05 09:11:38,726 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:40931
2025-09-05 09:11:38,726 - distributed.worker - INFO -          dashboard at:          10.6.101.49:34549
2025-09-05 09:11:38,726 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,726 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,726 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,726 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-o5anr04z
2025-09-05 09:11:38,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,727 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,730 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,731 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,731 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,733 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,737 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,738 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,738 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,740 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,747 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,748 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,748 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,749 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,758 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,759 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,759 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,760 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,778 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:41763
2025-09-05 09:11:38,778 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:41763
2025-09-05 09:11:38,778 - distributed.worker - INFO -          dashboard at:          10.6.101.49:41227
2025-09-05 09:11:38,778 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,778 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,778 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,778 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ytp5ds09
2025-09-05 09:11:38,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,802 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,803 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,805 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,886 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:46145
2025-09-05 09:11:38,886 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:46145
2025-09-05 09:11:38,886 - distributed.worker - INFO -          dashboard at:          10.6.101.49:44459
2025-09-05 09:11:38,886 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,886 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,886 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,886 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,886 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-i65s4ijb
2025-09-05 09:11:38,886 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,893 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:39243
2025-09-05 09:11:38,893 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:39243
2025-09-05 09:11:38,893 - distributed.worker - INFO -          dashboard at:          10.6.101.49:44101
2025-09-05 09:11:38,893 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,893 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,893 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,893 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,893 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-xde2dgj_
2025-09-05 09:11:38,893 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,903 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:42415
2025-09-05 09:11:38,903 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:42415
2025-09-05 09:11:38,903 - distributed.worker - INFO -          dashboard at:          10.6.101.49:33145
2025-09-05 09:11:38,904 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,904 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,904 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,904 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,904 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-58bgwmyv
2025-09-05 09:11:38,904 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,908 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:43403
2025-09-05 09:11:38,908 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:43403
2025-09-05 09:11:38,908 - distributed.worker - INFO -          dashboard at:          10.6.101.49:34597
2025-09-05 09:11:38,908 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,908 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,908 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,908 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,908 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-5yjxrqt7
2025-09-05 09:11:38,908 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,911 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,911 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,912 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,913 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,913 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:36635
2025-09-05 09:11:38,914 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:36635
2025-09-05 09:11:38,914 - distributed.worker - INFO -          dashboard at:          10.6.101.49:44953
2025-09-05 09:11:38,914 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,914 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,914 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,914 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,914 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-7l5nxw71
2025-09-05 09:11:38,914 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,917 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:39479
2025-09-05 09:11:38,917 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:39479
2025-09-05 09:11:38,917 - distributed.worker - INFO -          dashboard at:          10.6.101.49:38925
2025-09-05 09:11:38,917 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,917 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,917 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,917 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,917 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-p5bg_586
2025-09-05 09:11:38,917 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,919 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,919 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,920 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:35101
2025-09-05 09:11:38,920 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:35101
2025-09-05 09:11:38,920 - distributed.worker - INFO -          dashboard at:          10.6.101.49:34327
2025-09-05 09:11:38,920 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,920 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,920 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,920 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,920 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-uwfnx5ea
2025-09-05 09:11:38,920 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,920 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,921 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,922 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,922 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,927 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:40143
2025-09-05 09:11:38,927 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:40143
2025-09-05 09:11:38,927 - distributed.worker - INFO -          dashboard at:          10.6.101.49:37665
2025-09-05 09:11:38,927 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:36741
2025-09-05 09:11:38,927 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,928 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:36741
2025-09-05 09:11:38,928 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,928 - distributed.worker - INFO -          dashboard at:          10.6.101.49:43957
2025-09-05 09:11:38,928 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,928 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,928 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-6y_x43li
2025-09-05 09:11:38,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,928 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,928 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,928 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-4o7dxtnl
2025-09-05 09:11:38,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,929 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:35519
2025-09-05 09:11:38,929 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:35519
2025-09-05 09:11:38,929 - distributed.worker - INFO -          dashboard at:          10.6.101.49:41463
2025-09-05 09:11:38,929 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:42115
2025-09-05 09:11:38,929 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,929 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,929 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:42115
2025-09-05 09:11:38,929 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,929 - distributed.worker - INFO -          dashboard at:          10.6.101.49:35845
2025-09-05 09:11:38,929 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,929 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,929 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-p9pughga
2025-09-05 09:11:38,929 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,930 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,930 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,930 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,930 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-wenzfzlo
2025-09-05 09:11:38,930 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,931 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:35529
2025-09-05 09:11:38,931 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:35529
2025-09-05 09:11:38,931 - distributed.worker - INFO -          dashboard at:          10.6.101.49:40927
2025-09-05 09:11:38,931 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,931 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,931 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,931 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,931 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-3if6ua2k
2025-09-05 09:11:38,931 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,933 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,933 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,934 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:35035
2025-09-05 09:11:38,934 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:35035
2025-09-05 09:11:38,934 - distributed.worker - INFO -          dashboard at:          10.6.101.49:35957
2025-09-05 09:11:38,934 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,934 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,934 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,934 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-jzn691ts
2025-09-05 09:11:38,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,934 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:39051
2025-09-05 09:11:38,934 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:34131
2025-09-05 09:11:38,934 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:39051
2025-09-05 09:11:38,934 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:34131
2025-09-05 09:11:38,934 - distributed.worker - INFO -          dashboard at:          10.6.101.49:39437
2025-09-05 09:11:38,934 - distributed.worker - INFO -          dashboard at:          10.6.101.49:43137
2025-09-05 09:11:38,934 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,934 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,934 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,934 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,934 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,934 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,934 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-xgnqk_zu
2025-09-05 09:11:38,934 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-u3fel80x
2025-09-05 09:11:38,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,934 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:42031
2025-09-05 09:11:38,935 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:42031
2025-09-05 09:11:38,935 - distributed.worker - INFO -          dashboard at:          10.6.101.49:38447
2025-09-05 09:11:38,935 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,935 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,935 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,935 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,935 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-5puob58r
2025-09-05 09:11:38,935 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,935 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,936 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:42471
2025-09-05 09:11:38,936 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:42471
2025-09-05 09:11:38,936 - distributed.worker - INFO -          dashboard at:          10.6.101.49:46419
2025-09-05 09:11:38,936 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,936 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,936 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,936 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,936 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-2ni8kqaq
2025-09-05 09:11:38,936 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,939 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:34643
2025-09-05 09:11:38,939 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:34643
2025-09-05 09:11:38,939 - distributed.worker - INFO -          dashboard at:          10.6.101.49:42181
2025-09-05 09:11:38,939 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,939 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,939 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,939 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,939 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-xj7mflta
2025-09-05 09:11:38,939 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,940 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:33655
2025-09-05 09:11:38,940 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:33655
2025-09-05 09:11:38,940 - distributed.worker - INFO -          dashboard at:          10.6.101.49:41879
2025-09-05 09:11:38,940 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,940 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,940 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,940 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-vuhh_qxw
2025-09-05 09:11:38,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,941 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:40397
2025-09-05 09:11:38,941 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:40929
2025-09-05 09:11:38,941 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:40397
2025-09-05 09:11:38,941 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:40929
2025-09-05 09:11:38,941 - distributed.worker - INFO -          dashboard at:          10.6.101.49:37127
2025-09-05 09:11:38,941 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,941 - distributed.worker - INFO -          dashboard at:          10.6.101.49:42891
2025-09-05 09:11:38,941 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,941 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,941 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,941 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,941 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,941 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,941 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,941 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-tof10ra5
2025-09-05 09:11:38,941 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-a4ldv5lk
2025-09-05 09:11:38,941 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,941 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,942 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,943 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,943 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,944 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,944 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:43829
2025-09-05 09:11:38,944 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:43829
2025-09-05 09:11:38,944 - distributed.worker - INFO -          dashboard at:          10.6.101.49:46303
2025-09-05 09:11:38,945 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,944 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,945 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,945 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,945 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,945 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-v2bee3m8
2025-09-05 09:11:38,945 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,945 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,945 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,947 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,947 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,948 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,948 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,950 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,950 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,950 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,950 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,951 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,954 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,954 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:41023
2025-09-05 09:11:38,954 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:41023
2025-09-05 09:11:38,954 - distributed.worker - INFO -          dashboard at:          10.6.101.49:45901
2025-09-05 09:11:38,954 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,954 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,954 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,954 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,954 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-10b3lobs
2025-09-05 09:11:38,954 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,955 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,955 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,955 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,956 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,956 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,956 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,957 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,958 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,958 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,958 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,959 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,959 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,960 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,960 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,960 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,961 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,961 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,961 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,962 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.49:40303
2025-09-05 09:11:38,962 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.49:40303
2025-09-05 09:11:38,962 - distributed.worker - INFO -          dashboard at:          10.6.101.49:38697
2025-09-05 09:11:38,962 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,962 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,962 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:38,962 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:38,962 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-j1h4wl3p
2025-09-05 09:11:38,962 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,963 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,963 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,964 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,964 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,965 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,966 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,966 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,966 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,966 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,966 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,967 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,967 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,967 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,968 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,969 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,969 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,969 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,970 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,970 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,971 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,971 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,972 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,972 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,972 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,973 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,978 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,980 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,980 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,980 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,981 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,981 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,981 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,981 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,982 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,982 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,983 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,984 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,984 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,984 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,984 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,985 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:38,989 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:38,991 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:38,991 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:38,992 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:12:06,640 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,640 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,640 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,641 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,641 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,641 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,641 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,641 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,641 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,641 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,642 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,642 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,642 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,642 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,642 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,642 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,642 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,642 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,642 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,643 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,643 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,643 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,644 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,644 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,644 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,644 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,644 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,645 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,645 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,645 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,645 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,646 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,644 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,644 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,647 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,647 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,645 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,647 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,647 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,648 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,648 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,648 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,648 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,647 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,647 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,649 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,647 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,649 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,647 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,648 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,649 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,649 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,649 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,650 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,650 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,653 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,657 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,657 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,657 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,658 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,661 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,661 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,662 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,661 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:09,441 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,441 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,441 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,441 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,441 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,441 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,442 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,442 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,442 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,442 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,442 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,442 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,443 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,442 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,443 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,443 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,443 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,443 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,443 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,443 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,443 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,444 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,443 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,445 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,446 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,446 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,446 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,446 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,446 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,446 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,446 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,446 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,446 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,446 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,446 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,447 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,447 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,448 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,448 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,448 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,447 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,448 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,448 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,449 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,450 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,450 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,450 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,822 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,822 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,823 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,823 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,823 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,823 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,823 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,823 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,824 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,825 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,825 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,825 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,825 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,825 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,825 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,825 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,826 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,826 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,827 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,827 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,827 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,827 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,827 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,827 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,827 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,827 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,827 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,827 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,828 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,828 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,828 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,828 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,828 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,828 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,828 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,828 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,828 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,828 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,828 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,828 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,828 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,828 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,828 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,828 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,829 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,829 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,829 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,829 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,829 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,829 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,829 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,830 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,830 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,830 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,830 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,830 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,830 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,830 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,830 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,831 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,831 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,831 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,831 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,831 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,831 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,831 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,831 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,831 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,832 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,833 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,833 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,834 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,834 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,834 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:10,282 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,282 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,282 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,282 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,283 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,283 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,283 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,283 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,283 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,283 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,283 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,283 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,284 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,284 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,284 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,284 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,284 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,284 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,284 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,284 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,285 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,285 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,285 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,285 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,285 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,285 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,285 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,285 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,285 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,285 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,285 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,285 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,285 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,285 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,285 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,285 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,286 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,287 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,287 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,287 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,287 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,287 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,287 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,287 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,287 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,288 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,288 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,288 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,288 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,288 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,288 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,288 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,288 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,288 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,288 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,288 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,289 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,289 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,289 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,289 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,289 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,289 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,290 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,290 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,290 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,290 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,290 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,290 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,291 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,291 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,291 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,291 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,291 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,291 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,291 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,291 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:16:17,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:56,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:56,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:56,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:56,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:56,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,196 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,200 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:59,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:59,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:59,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:00,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:00,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:00,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:05,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:05,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:05,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:05,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:09,467 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:10,803 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,187 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:23,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:23,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:23,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:24,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:25,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:25,227 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:25,227 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:26,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,651 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,482 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,484 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:41,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:42,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:43,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:48,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:55,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:55,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:56,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:57,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:57,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:57,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:01,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:06,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:08,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:12,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:13,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:13,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:13,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:13,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:14,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,116 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,260 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:18,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,944 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,101 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,170 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:40,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:42,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,100 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,903 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,936 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,373 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:51,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:51,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:51,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:52,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:53,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:06,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:06,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,075 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,378 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,484 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,150 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,592 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:15,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:15,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:18,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:18,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:18,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:20,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:20,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:20,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:23,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:24,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:24,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:25,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:26,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:32,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:32,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:32,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:33,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,144 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,088 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,200 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:52,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:57,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:11,279 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,280 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,280 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,280 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,280 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,280 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:41023. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,280 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:34131. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:39243. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:39051. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:43403. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:35519. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:40303. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:35529. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:42031. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:35101. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:40929. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:40397. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:42415. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:46145. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:39479. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:42471. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:33655. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:40143. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:34643. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:40931. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:44277. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:37559. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:42699. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:41561. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:35285. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:41983. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:36843. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:35635. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:43507. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:44921. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:35935. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:37687. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:46499. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:45229. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:39023. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:38005. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:39847. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:46125. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:38733. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:40451. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,288 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:33403. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,288 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:33193. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,288 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:41763. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,288 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:44169. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,290 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:42115. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,291 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.49:47782 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:42033'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:46433'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:34347'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:34805'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1314, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:34109'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:44261, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 797, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:40421'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3760, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:34117'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:46713'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 425, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:37345'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7145, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.65:41157, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:35639'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:44231, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:46569'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1312, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 172, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.48:42633, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:43919'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3732, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.48:37229, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:33791, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7056, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 871, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:44241'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 355, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4063, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:44525'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 426, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.58:42983, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 173, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:33287'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1937, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:34587'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2295, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:40789, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.47:37477, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 368, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2756, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.54:45943, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3733, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 346, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1263, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 171, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 817, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.49:45161, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1307, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7227, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1247, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 860, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.45:36631, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7149, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,328 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:36463'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,329 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:38813'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,329 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:40693'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,329 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:46825'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,329 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:40379'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,330 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:41947'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,330 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:46413'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,330 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7144, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,330 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:37159'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,330 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 422, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,330 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:45671'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,330 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:35021, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:42347'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,330 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2138, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.49:36635, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1017, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:41349'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1311, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.45:36631, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:45987'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1537, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,331 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1883, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:37633'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,331 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.49:35035, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,331 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,331 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:38077'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,331 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1879, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 893, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:40087'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.49:36635, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1871, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 970, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:45663'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 210, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1880, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2725, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.49:39907, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,332 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:37415'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1080, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2737, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,332 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,332 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 858, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 359, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,333 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:41687'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.43:39093, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3617, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 8681, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,333 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:37469'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5439, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 799, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 8340, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3252, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,333 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:38565'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,333 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,333 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1405, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.70:39651, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 8680, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2561, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3332, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:35425'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 541, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,334 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 888, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,334 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,335 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:36093'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,335 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3453, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,335 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:44427'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,335 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 8279, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,335 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:39937'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,335 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,336 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7229, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,336 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:34565'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,336 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:37177'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,336 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 892, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,336 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2292, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,336 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:38575'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,336 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.49:35035, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,336 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1881, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2885, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.49:36635, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5438, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.44:38281, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,337 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2892, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,337 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,338 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2916, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,338 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1331, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,337 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:34683'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,338 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,339 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:36079, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,339 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:39599'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,339 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3728, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,340 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,340 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 618, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,340 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,340 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:11,340 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5683, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,341 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3374, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,341 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.58:46017, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,341 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.47:35233, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,341 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:32909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,341 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.37:38377, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,342 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,343 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,343 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,343 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,346 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,347 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,347 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,348 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,348 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,350 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:11,356 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:11,356 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:11,710 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,096 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,187 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,541 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,550 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,713 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:12,715 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:33919. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,719 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:12,721 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:36741. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,726 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.49:33919 -> tcp://10.6.101.44:39735
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.49:33919 remote=tcp://10.6.101.44:58266>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-05 09:20:12,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:12,732 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.49:47568 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:12,731 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.49:36741 -> tcp://10.6.101.46:38393
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.49:36741 remote=tcp://10.6.101.46:60538>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-05 09:20:12,736 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:35323'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,737 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:12,737 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:12,737 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:12,737 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:12,737 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:12,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:12,740 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.49:47766 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:12,743 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:37743'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,744 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:12,744 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:12,741 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1529fa121ad0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:12,745 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:12,745 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:12,745 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:12,749 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,752 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,893 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,896 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,898 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,344 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,354 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,360 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,360 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:13,662 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,664 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,663 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:13,664 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:36635. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,675 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.49:36635 -> tcp://10.6.101.49:35285
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.49:36635 remote=tcp://10.6.101.49:38762>: Stream is closed
2025-09-05 09:20:13,684 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.49:47728 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:13,686 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:41599'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,687 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:13,688 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:13,688 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:13,688 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:13,688 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:13,692 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1461bcb98650>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:13,697 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,714 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,875 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:39599'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,878 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:39599' closed.
2025-09-05 09:20:13,882 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:33287'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,883 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:41947'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,885 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:33287' closed.
2025-09-05 09:20:13,886 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:41947' closed.
2025-09-05 09:20:13,888 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:36093'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,889 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:36093' closed.
2025-09-05 09:20:14,100 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,113 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:41349'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,114 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:41349' closed.
2025-09-05 09:20:14,191 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,469 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:43919'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,470 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:43919' closed.
2025-09-05 09:20:14,545 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,555 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,582 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:37159'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,585 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:37159' closed.
2025-09-05 09:20:14,746 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:14,749 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:39907. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:14,751 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,755 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:14,764 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.49:47464 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:14,768 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:32769'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:14,769 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:14,769 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:14,769 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:14,769 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:14,769 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:14,772 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:14,777 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:14,810 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:14,897 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,900 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,903 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,948 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:46713'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,949 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:37415'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,950 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:46713' closed.
2025-09-05 09:20:14,950 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:37415' closed.
2025-09-05 09:20:15,174 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:37743'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,175 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:37743' closed.
2025-09-05 09:20:15,178 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:35323'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,179 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:35323' closed.
2025-09-05 09:20:15,270 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:15,299 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:36463'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,301 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:36463' closed.
2025-09-05 09:20:15,355 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:38565'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,357 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:38565' closed.
2025-09-05 09:20:15,484 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:44427'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,493 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:44427' closed.
2025-09-05 09:20:15,666 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,668 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,700 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,982 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:15,984 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:35035. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:15,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:16,001 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.49:47794 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:16,018 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:37315'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,019 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:16,019 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:16,019 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:16,019 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:16,019 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:16,022 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x151d5177f390>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:16,030 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,060 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:45663'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,061 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:45663' closed.
2025-09-05 09:20:16,115 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:39937'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,116 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:39937' closed.
2025-09-05 09:20:16,173 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:41599'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,174 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:41599' closed.
2025-09-05 09:20:16,286 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:16,288 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:43829. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:16,304 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.49:47868 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:16,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:45429'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,309 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:16,309 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:16,309 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:16,309 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:16,309 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:16,312 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:16,320 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,663 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,781 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,815 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:17,198 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:32769'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,199 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:32769' closed.
2025-09-05 09:20:17,214 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:44525'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,215 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:44525' closed.
2025-09-05 09:20:17,274 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:17,654 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:34805'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,655 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:34805' closed.
2025-09-05 09:20:17,818 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,872 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,907 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,033 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,323 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,343 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,442 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:37315'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,444 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:37315' closed.
2025-09-05 09:20:18,507 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,508 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,539 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,580 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,667 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,691 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,693 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,703 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:45429'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,704 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:45429' closed.
2025-09-05 09:20:18,728 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,934 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,004 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,060 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:46569'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,061 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:46569' closed.
2025-09-05 09:20:19,673 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,751 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,822 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,877 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,898 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:19,900 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.49:45161. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:19,912 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,910 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.49:45161 -> tcp://10.6.101.49:39479
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.49:45161 remote=tcp://10.6.101.49:35918>: Stream is closed
2025-09-05 09:20:19,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:19,916 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,920 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.49:47492 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:19,923 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.49:41527'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:19,924 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:19,924 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:19,924 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:19,924 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:19,924 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:19,926 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:19,932 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,015 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,063 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,104 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,192 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,228 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:37633'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,229 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:37633' closed.
2025-09-05 09:20:20,265 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,265 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,265 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,267 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,268 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,268 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,269 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,270 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,274 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:40693'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,275 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:40693' closed.
2025-09-05 09:20:20,291 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:34683'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,292 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:34683' closed.
2025-09-05 09:20:20,347 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,511 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,513 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,585 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,695 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,697 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,732 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,742 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:45671'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,743 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:45671' closed.
2025-09-05 09:20:20,921 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:40421'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,923 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:40421' closed.
2025-09-05 09:20:20,925 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:37345'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,926 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:37345' closed.
2025-09-05 09:20:20,938 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,994 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:38813'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,995 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:38813' closed.
2025-09-05 09:20:21,008 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,010 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:40379'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,011 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:40379' closed.
2025-09-05 09:20:21,095 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:34117'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,097 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:34117' closed.
2025-09-05 09:20:21,173 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:40087'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,174 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:40087' closed.
2025-09-05 09:20:21,215 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:41687'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,217 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:41687' closed.
2025-09-05 09:20:21,393 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:45987'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,394 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:45987' closed.
2025-09-05 09:20:21,508 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:35639'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,510 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:35639' closed.
2025-09-05 09:20:21,679 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,755 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,920 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,935 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,019 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,062 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:46825'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,062 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:46825' closed.
2025-09-05 09:20:22,068 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,108 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,153 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:46433'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,155 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:46433' closed.
2025-09-05 09:20:22,196 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,268 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,269 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,270 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,272 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,272 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,273 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,274 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,311 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:44241'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,312 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:44241' closed.
2025-09-05 09:20:22,329 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:41527'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,330 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:41527' closed.
2025-09-05 09:20:22,464 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:42347'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,465 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:42347' closed.
2025-09-05 09:20:22,542 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:37177'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,543 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:37177' closed.
2025-09-05 09:20:22,633 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:38077'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,633 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:38077' closed.
2025-09-05 09:20:22,656 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:34565'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,657 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:34565' closed.
2025-09-05 09:20:22,664 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:46413'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,665 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:46413' closed.
2025-09-05 09:20:22,674 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:37469'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,675 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:37469' closed.
2025-09-05 09:20:22,764 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:34109'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,765 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:34109' closed.
2025-09-05 09:20:22,785 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:34587'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,786 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:34587' closed.
2025-09-05 09:20:22,790 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:35425'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,790 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:34347'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,792 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:42033'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,792 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:35425' closed.
2025-09-05 09:20:22,793 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:34347' closed.
2025-09-05 09:20:22,794 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:42033' closed.
2025-09-05 09:20:22,795 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.49:38575'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,795 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.49:38575' closed.
2025-09-05 09:20:22,798 - distributed.dask_worker - INFO - End worker
