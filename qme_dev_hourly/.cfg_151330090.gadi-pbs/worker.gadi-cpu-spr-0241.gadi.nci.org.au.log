Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-10-01 11:26:40,047 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:43995'
2025-10-01 11:26:40,055 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:33149'
2025-10-01 11:26:40,060 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:42205'
2025-10-01 11:26:40,065 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:40177'
2025-10-01 11:26:40,069 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:44873'
2025-10-01 11:26:40,072 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:44477'
2025-10-01 11:26:40,076 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:39069'
2025-10-01 11:26:40,081 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:46545'
2025-10-01 11:26:40,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:41911'
2025-10-01 11:26:40,091 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:34933'
2025-10-01 11:26:40,097 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:39897'
2025-10-01 11:26:40,101 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:40765'
2025-10-01 11:26:40,106 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:41057'
2025-10-01 11:26:40,111 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:39741'
2025-10-01 11:26:40,115 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:36729'
2025-10-01 11:26:40,120 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:34009'
2025-10-01 11:26:40,125 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:39593'
2025-10-01 11:26:40,131 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:42137'
2025-10-01 11:26:40,135 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:33213'
2025-10-01 11:26:40,139 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:35885'
2025-10-01 11:26:40,205 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:41941'
2025-10-01 11:26:40,210 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:33075'
2025-10-01 11:26:40,215 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:40003'
2025-10-01 11:26:40,219 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:42043'
2025-10-01 11:26:40,223 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:46733'
2025-10-01 11:26:40,227 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:38731'
2025-10-01 11:26:40,233 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:35705'
2025-10-01 11:26:40,237 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:39453'
2025-10-01 11:26:40,240 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:35071'
2025-10-01 11:26:40,244 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:33545'
2025-10-01 11:26:40,248 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:41373'
2025-10-01 11:26:40,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:45769'
2025-10-01 11:26:40,257 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:33709'
2025-10-01 11:26:40,260 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:35785'
2025-10-01 11:26:40,266 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:39067'
2025-10-01 11:26:40,270 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:40087'
2025-10-01 11:26:40,274 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:34717'
2025-10-01 11:26:40,278 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:43537'
2025-10-01 11:26:40,283 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:40525'
2025-10-01 11:26:40,287 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:45719'
2025-10-01 11:26:40,290 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:36433'
2025-10-01 11:26:40,294 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:41743'
2025-10-01 11:26:40,298 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:37207'
2025-10-01 11:26:40,302 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:37807'
2025-10-01 11:26:40,307 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:40399'
2025-10-01 11:26:40,314 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:39759'
2025-10-01 11:26:40,318 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:42419'
2025-10-01 11:26:40,322 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:38723'
2025-10-01 11:26:40,327 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:35579'
2025-10-01 11:26:40,331 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:35913'
2025-10-01 11:26:40,335 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:34321'
2025-10-01 11:26:40,340 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.84.25:36739'
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:45843
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:43503
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:40795
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:34937
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:34821
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:42157
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:39405
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:33399
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:42605
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:41149
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:38569
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:32883
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:45843
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:33303
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:43503
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:40795
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:46693
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:34937
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:34821
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:42157
2025-10-01 11:26:41,500 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:37491
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:39405
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:33399
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:42605
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:41149
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:38569
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:32883
2025-10-01 11:26:41,500 - distributed.worker - INFO -          dashboard at:           10.6.84.25:43113
2025-10-01 11:26:41,501 - distributed.worker - INFO -          dashboard at:           10.6.84.25:42139
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:33303
2025-10-01 11:26:41,500 - distributed.worker - INFO -          dashboard at:           10.6.84.25:34983
2025-10-01 11:26:41,500 - distributed.worker - INFO -          dashboard at:           10.6.84.25:44597
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:46693
2025-10-01 11:26:41,500 - distributed.worker - INFO -          dashboard at:           10.6.84.25:32949
2025-10-01 11:26:41,500 - distributed.worker - INFO -          dashboard at:           10.6.84.25:39283
2025-10-01 11:26:41,500 - distributed.worker - INFO -          dashboard at:           10.6.84.25:39993
2025-10-01 11:26:41,500 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:37491
2025-10-01 11:26:41,500 - distributed.worker - INFO -          dashboard at:           10.6.84.25:33183
2025-10-01 11:26:41,500 - distributed.worker - INFO -          dashboard at:           10.6.84.25:46543
2025-10-01 11:26:41,501 - distributed.worker - INFO -          dashboard at:           10.6.84.25:34173
2025-10-01 11:26:41,501 - distributed.worker - INFO -          dashboard at:           10.6.84.25:43925
2025-10-01 11:26:41,501 - distributed.worker - INFO -          dashboard at:           10.6.84.25:39507
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO -          dashboard at:           10.6.84.25:44699
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO -          dashboard at:           10.6.84.25:36853
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO -          dashboard at:           10.6.84.25:42273
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-9v8q24b7
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-p5n5s3vj
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-ckeg47y9
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-_dy1gkpz
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-kwwnc8bl
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-o8zo6rt3
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-ya2bcgb3
2025-10-01 11:26:41,501 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-ge8calp7
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-__snrszy
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-nywwumz7
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-pzv7vwo6
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-dyzdfngy
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-z99vh5ny
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-wt6o7wl1
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-0n98m51b
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,501 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,503 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:43021
2025-10-01 11:26:41,503 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:43021
2025-10-01 11:26:41,503 - distributed.worker - INFO -          dashboard at:           10.6.84.25:44713
2025-10-01 11:26:41,503 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,503 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,503 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,503 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,503 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-v98y6dob
2025-10-01 11:26:41,503 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,503 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:39887
2025-10-01 11:26:41,503 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:39887
2025-10-01 11:26:41,503 - distributed.worker - INFO -          dashboard at:           10.6.84.25:36463
2025-10-01 11:26:41,503 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,503 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,503 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,503 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,504 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-38ls7_in
2025-10-01 11:26:41,504 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,504 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:41927
2025-10-01 11:26:41,504 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:41927
2025-10-01 11:26:41,504 - distributed.worker - INFO -          dashboard at:           10.6.84.25:41895
2025-10-01 11:26:41,504 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,504 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,504 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,504 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,504 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-o5c06jr3
2025-10-01 11:26:41,504 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,506 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:36705
2025-10-01 11:26:41,506 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:36705
2025-10-01 11:26:41,506 - distributed.worker - INFO -          dashboard at:           10.6.84.25:35827
2025-10-01 11:26:41,506 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,506 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,506 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,506 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,506 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-3jga6e64
2025-10-01 11:26:41,506 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,514 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:46127
2025-10-01 11:26:41,514 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:46127
2025-10-01 11:26:41,514 - distributed.worker - INFO -          dashboard at:           10.6.84.25:35421
2025-10-01 11:26:41,514 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,514 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,514 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,515 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,515 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-d5l86qj0
2025-10-01 11:26:41,515 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:36669
2025-10-01 11:26:41,515 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,515 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:36669
2025-10-01 11:26:41,515 - distributed.worker - INFO -          dashboard at:           10.6.84.25:40089
2025-10-01 11:26:41,515 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,515 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,515 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,515 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,515 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-v0hi_tnb
2025-10-01 11:26:41,515 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,516 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:44711
2025-10-01 11:26:41,516 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:44711
2025-10-01 11:26:41,516 - distributed.worker - INFO -          dashboard at:           10.6.84.25:43189
2025-10-01 11:26:41,516 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,516 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,516 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,516 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,516 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-maef5hz_
2025-10-01 11:26:41,516 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,521 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,521 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,521 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,521 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,529 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,530 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,530 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,532 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,532 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:39127
2025-10-01 11:26:41,532 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:39127
2025-10-01 11:26:41,532 - distributed.worker - INFO -          dashboard at:           10.6.84.25:44739
2025-10-01 11:26:41,532 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,532 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,532 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,532 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,532 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-a8q5jvo5
2025-10-01 11:26:41,532 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,533 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,534 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,534 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,535 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:33589
2025-10-01 11:26:41,535 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:33589
2025-10-01 11:26:41,535 - distributed.worker - INFO -          dashboard at:           10.6.84.25:39777
2025-10-01 11:26:41,535 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,535 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,535 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,535 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,535 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-8cgf2eot
2025-10-01 11:26:41,535 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,535 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,538 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,538 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,538 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,539 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,543 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,544 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,544 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,546 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,546 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,547 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,547 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,548 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,549 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:43727
2025-10-01 11:26:41,549 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:43727
2025-10-01 11:26:41,549 - distributed.worker - INFO -          dashboard at:           10.6.84.25:45385
2025-10-01 11:26:41,549 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,549 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,549 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,549 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,549 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-qmse0s_i
2025-10-01 11:26:41,549 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,550 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,551 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,551 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,552 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,553 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,553 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,554 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,555 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,555 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,556 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,556 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,558 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,558 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,559 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,559 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,560 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,561 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,561 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,561 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,562 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,562 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,563 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,563 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,564 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,565 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,566 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,566 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,567 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,568 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,569 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,569 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,569 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,569 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,569 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,570 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,571 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,572 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,573 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,574 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,574 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,575 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,575 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,575 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,576 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,577 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,577 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,577 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,579 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,579 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,580 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,580 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,581 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,582 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,582 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,582 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,583 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,584 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,584 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,584 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,586 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,586 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,587 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,587 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,589 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,591 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:36779
2025-10-01 11:26:41,591 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:36779
2025-10-01 11:26:41,591 - distributed.worker - INFO -          dashboard at:           10.6.84.25:46827
2025-10-01 11:26:41,591 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,591 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,591 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,591 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,591 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-h1b68iht
2025-10-01 11:26:41,591 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,606 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,607 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:42511
2025-10-01 11:26:41,607 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:42511
2025-10-01 11:26:41,607 - distributed.worker - INFO -          dashboard at:           10.6.84.25:41111
2025-10-01 11:26:41,607 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,607 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,607 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,607 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,607 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-ohz2jnzu
2025-10-01 11:26:41,607 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,607 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,608 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,609 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,609 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,611 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,611 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,612 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,612 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,613 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,613 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,615 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,615 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,616 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,616 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,617 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,618 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:42313
2025-10-01 11:26:41,618 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:42313
2025-10-01 11:26:41,618 - distributed.worker - INFO -          dashboard at:           10.6.84.25:45787
2025-10-01 11:26:41,618 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,618 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,618 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,618 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,618 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-qjtl1_fq
2025-10-01 11:26:41,618 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,632 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,633 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,633 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,635 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,640 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,641 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,641 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,644 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,648 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:33211
2025-10-01 11:26:41,649 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:33211
2025-10-01 11:26:41,649 - distributed.worker - INFO -          dashboard at:           10.6.84.25:46799
2025-10-01 11:26:41,649 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,649 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,649 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,649 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,649 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-rp1e5i62
2025-10-01 11:26:41,649 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,676 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,677 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,677 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,679 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,719 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:41687
2025-10-01 11:26:41,720 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:41687
2025-10-01 11:26:41,720 - distributed.worker - INFO -          dashboard at:           10.6.84.25:43635
2025-10-01 11:26:41,720 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,720 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,720 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,720 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,720 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-z0yd4x6q
2025-10-01 11:26:41,720 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,738 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:35427
2025-10-01 11:26:41,738 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:35427
2025-10-01 11:26:41,738 - distributed.worker - INFO -          dashboard at:           10.6.84.25:37553
2025-10-01 11:26:41,738 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,738 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,738 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,738 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,738 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-oe1d_ha2
2025-10-01 11:26:41,738 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,741 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:43339
2025-10-01 11:26:41,741 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:43339
2025-10-01 11:26:41,741 - distributed.worker - INFO -          dashboard at:           10.6.84.25:36551
2025-10-01 11:26:41,741 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,741 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,741 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,741 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,741 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-y5wcqhvv
2025-10-01 11:26:41,741 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,747 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,748 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,749 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,750 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,764 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,764 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,764 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,765 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,781 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,782 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,782 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,784 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,785 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:41041
2025-10-01 11:26:41,785 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:41041
2025-10-01 11:26:41,785 - distributed.worker - INFO -          dashboard at:           10.6.84.25:34307
2025-10-01 11:26:41,785 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,785 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,785 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,785 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,785 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-exn0dyxw
2025-10-01 11:26:41,785 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,797 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:33641
2025-10-01 11:26:41,797 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:33641
2025-10-01 11:26:41,797 - distributed.worker - INFO -          dashboard at:           10.6.84.25:38137
2025-10-01 11:26:41,797 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,797 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,797 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,797 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,797 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-1rbnm4_w
2025-10-01 11:26:41,797 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,811 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,812 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,813 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,813 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:38293
2025-10-01 11:26:41,813 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:38293
2025-10-01 11:26:41,813 - distributed.worker - INFO -          dashboard at:           10.6.84.25:40447
2025-10-01 11:26:41,813 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,813 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,813 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,813 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,813 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-2d8748z4
2025-10-01 11:26:41,813 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,814 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,822 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,823 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,823 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,824 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,841 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,841 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,843 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,952 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:38925
2025-10-01 11:26:41,952 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:38925
2025-10-01 11:26:41,952 - distributed.worker - INFO -          dashboard at:           10.6.84.25:43191
2025-10-01 11:26:41,952 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,952 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,952 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,952 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,952 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-b6t1tys4
2025-10-01 11:26:41,953 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,953 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:43327
2025-10-01 11:26:41,953 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:43327
2025-10-01 11:26:41,953 - distributed.worker - INFO -          dashboard at:           10.6.84.25:39225
2025-10-01 11:26:41,953 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,953 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,953 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,953 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,953 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-zb4d4w68
2025-10-01 11:26:41,954 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,954 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:36545
2025-10-01 11:26:41,955 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:36545
2025-10-01 11:26:41,955 - distributed.worker - INFO -          dashboard at:           10.6.84.25:45837
2025-10-01 11:26:41,955 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,955 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,955 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,955 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,955 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-j9t4jjbx
2025-10-01 11:26:41,955 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,956 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:33157
2025-10-01 11:26:41,956 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:33157
2025-10-01 11:26:41,956 - distributed.worker - INFO -          dashboard at:           10.6.84.25:35263
2025-10-01 11:26:41,956 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,956 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,956 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,956 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,956 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-1tibouze
2025-10-01 11:26:41,956 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,957 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:42209
2025-10-01 11:26:41,957 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:42209
2025-10-01 11:26:41,957 - distributed.worker - INFO -          dashboard at:           10.6.84.25:44709
2025-10-01 11:26:41,957 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,957 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,957 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,957 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,957 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-bq7x98sh
2025-10-01 11:26:41,957 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,961 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:33521
2025-10-01 11:26:41,961 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:33521
2025-10-01 11:26:41,961 - distributed.worker - INFO -          dashboard at:           10.6.84.25:41511
2025-10-01 11:26:41,961 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,961 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,961 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,961 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,961 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-0ifwbx2k
2025-10-01 11:26:41,961 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,962 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:41537
2025-10-01 11:26:41,962 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:41537
2025-10-01 11:26:41,962 - distributed.worker - INFO -          dashboard at:           10.6.84.25:44365
2025-10-01 11:26:41,962 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,962 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,962 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,962 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,962 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-8q_2eey0
2025-10-01 11:26:41,962 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,964 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:36115
2025-10-01 11:26:41,964 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:36115
2025-10-01 11:26:41,964 - distributed.worker - INFO -          dashboard at:           10.6.84.25:42047
2025-10-01 11:26:41,964 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,964 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,964 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,964 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,964 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-ddet9by1
2025-10-01 11:26:41,964 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,969 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:38591
2025-10-01 11:26:41,969 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:38591
2025-10-01 11:26:41,969 - distributed.worker - INFO -          dashboard at:           10.6.84.25:42215
2025-10-01 11:26:41,969 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,969 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,969 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,969 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,969 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-hlcp88uo
2025-10-01 11:26:41,969 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,970 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:39035
2025-10-01 11:26:41,970 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:39035
2025-10-01 11:26:41,970 - distributed.worker - INFO -          dashboard at:           10.6.84.25:41837
2025-10-01 11:26:41,970 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,970 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,970 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,970 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,970 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-weyyqbu1
2025-10-01 11:26:41,970 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,971 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,972 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,972 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,972 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,972 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:36283
2025-10-01 11:26:41,972 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:36283
2025-10-01 11:26:41,972 - distributed.worker - INFO -          dashboard at:           10.6.84.25:36717
2025-10-01 11:26:41,972 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,973 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,973 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,973 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,973 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-nywxjiib
2025-10-01 11:26:41,973 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,973 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:33881
2025-10-01 11:26:41,973 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:33881
2025-10-01 11:26:41,973 - distributed.worker - INFO -          dashboard at:           10.6.84.25:39171
2025-10-01 11:26:41,973 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,973 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,973 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,973 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,973 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-as78fm7d
2025-10-01 11:26:41,973 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,973 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:34843
2025-10-01 11:26:41,973 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:34843
2025-10-01 11:26:41,973 - distributed.worker - INFO -          dashboard at:           10.6.84.25:41947
2025-10-01 11:26:41,973 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,973 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,973 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,973 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,973 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-6zy7jxah
2025-10-01 11:26:41,974 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,974 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:46563
2025-10-01 11:26:41,974 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:46563
2025-10-01 11:26:41,974 - distributed.worker - INFO -          dashboard at:           10.6.84.25:42807
2025-10-01 11:26:41,974 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,974 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,974 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,974 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,974 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-_dvkp9o6
2025-10-01 11:26:41,974 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,981 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,982 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,982 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,982 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,989 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,990 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,990 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,990 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:40741
2025-10-01 11:26:41,991 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:40741
2025-10-01 11:26:41,991 - distributed.worker - INFO -          dashboard at:           10.6.84.25:43029
2025-10-01 11:26:41,991 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,991 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,991 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,991 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,991 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-xlg8mqgd
2025-10-01 11:26:41,991 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,991 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:46335
2025-10-01 11:26:41,991 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:46335
2025-10-01 11:26:41,991 - distributed.worker - INFO -          dashboard at:           10.6.84.25:38313
2025-10-01 11:26:41,991 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,992 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,992 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,992 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,992 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:41,992 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-hniqky1n
2025-10-01 11:26:41,992 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,993 - distributed.worker - INFO -       Start worker at:     tcp://10.6.84.25:45175
2025-10-01 11:26:41,993 - distributed.worker - INFO -          Listening to:     tcp://10.6.84.25:45175
2025-10-01 11:26:41,993 - distributed.worker - INFO -          dashboard at:           10.6.84.25:38487
2025-10-01 11:26:41,993 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,993 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,993 - distributed.worker - INFO -               Threads:                          2
2025-10-01 11:26:41,993 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-10-01 11:26:41,993 - distributed.worker - INFO -       Local Directory: /jobfs/151330090.gadi-pbs/dask-scratch-space/worker-m8jo96h3
2025-10-01 11:26:41,993 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,994 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:41,995 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:41,996 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:41,997 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,017 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,018 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,018 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,019 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,020 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,020 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,020 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,022 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,022 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,023 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,023 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,024 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,025 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,025 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,026 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,027 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,027 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,028 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,028 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,029 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,030 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,030 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,031 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,032 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,032 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,033 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,034 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,035 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,035 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,036 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,036 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,037 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,038 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,039 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,039 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,040 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,042 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,043 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,043 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,044 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,057 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,058 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,058 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,059 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,060 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,060 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,060 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,062 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:42,062 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-10-01 11:26:42,063 - distributed.worker - INFO -         Registered to:       tcp://10.6.84.1:8707
2025-10-01 11:26:42,063 - distributed.worker - INFO - -------------------------------------------------
2025-10-01 11:26:42,065 - distributed.core - INFO - Starting established connection to tcp://10.6.84.1:8707
2025-10-01 11:26:51,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,969 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,969 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,969 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,969 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,971 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,971 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,971 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,971 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,970 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,972 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,972 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,972 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,972 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,972 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,972 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,972 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,971 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,971 - distributed.worker - INFO - Starting Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 11:26:51,976 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,977 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,979 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:51,980 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-10-01 11:26:54,298 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,298 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,298 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,298 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,298 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,300 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,300 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,300 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,300 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,300 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,300 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,301 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,301 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,299 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,303 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,303 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,304 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,303 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,303 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,304 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,304 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,303 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,304 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,304 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,303 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,304 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,304 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,304 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,301 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,305 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,305 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,305 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,305 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,305 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,305 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,302 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,305 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,305 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,305 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,306 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,306 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,306 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,306 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,306 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,306 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,304 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,307 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,307 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,307 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,307 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,307 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,308 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,308 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,305 - distributed.worker - INFO - Starting Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 11:26:54,308 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,308 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,309 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,309 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,309 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,310 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-10-01 11:26:54,706 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,707 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,707 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,707 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,707 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,707 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,707 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,707 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,707 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,708 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,708 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,708 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,708 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,708 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,708 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,708 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,708 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,709 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,709 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,709 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,709 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,709 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,709 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,709 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,710 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,711 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,711 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,711 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,711 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,711 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,711 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,711 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,711 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,711 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,711 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,712 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,712 - distributed.worker - INFO - Starting Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 11:26:54,713 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,713 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,713 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,714 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,714 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,714 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,714 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,714 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,715 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,716 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,717 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,717 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,717 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,717 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,717 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,717 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,717 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,717 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,717 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:54,719 - distributed.utils - INFO - Reload module qme_train from .py file
2025-10-01 11:26:55,104 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,104 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,104 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,104 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,104 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,104 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,104 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,104 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,105 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,105 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,105 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,105 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,105 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,105 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,105 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,105 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,105 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,106 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,106 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,106 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,106 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,106 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,106 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,106 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,106 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,107 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,108 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,108 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,108 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,108 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,108 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,108 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,108 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,108 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,108 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,108 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,108 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,108 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,108 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,108 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,108 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,109 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,109 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,109 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,109 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,109 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,109 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,109 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,109 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,109 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,109 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,109 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,109 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,109 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,109 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,109 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,109 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,110 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,110 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 11:26:55,110 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,110 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,110 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,110 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,110 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,110 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,111 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,111 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,112 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,112 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,112 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,112 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,112 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,112 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,112 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,112 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,112 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,113 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,113 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,113 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,113 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 11:26:55,113 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:44711. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:36669. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:33399. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:38569. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,574 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:40795. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,574 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:39127. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,574 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:43021. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,574 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:46127. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,574 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:43503. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,574 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:34937. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,575 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:46335. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,575 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:32883. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,575 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:46563. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,575 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:33881. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,575 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:39405. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,575 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:36283. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,572 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,575 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:38591. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,575 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:36115. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,576 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:33521. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,576 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:33157. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,576 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:45843. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,576 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:40741. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,576 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:42209. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,576 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:33641. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,577 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:38925. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,577 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:41041. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,577 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:41927. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,577 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:42605. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,577 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:34821. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,577 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:37491. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,577 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:41149. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,578 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:46693. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,578 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:42157. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,578 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:33303. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,578 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:45175. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,578 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:39887. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,578 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:36705. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,579 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:39035. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,579 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:43327. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,579 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:36545. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,579 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:41537. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,579 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:34843. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,579 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:38293. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,573 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48864 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,581 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,581 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:36779. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,572 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48916 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,572 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48830 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,573 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48894 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,573 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48900 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,572 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48882 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,572 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48930 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,577 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48698 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,573 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48878 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,584 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,573 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48840 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,585 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:35427. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,584 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,577 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48708 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,579 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48812 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,578 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48762 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,578 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48684 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,585 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,579 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48674 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,585 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,585 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:42313. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,580 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48734 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,579 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48622 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,579 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48850 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,586 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:43339. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,584 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,584 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,586 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:43727. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,579 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48720 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,584 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,586 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:33589. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,586 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:33211. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,587 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:41687. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,581 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48740 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,585 - distributed.core - INFO - Connection to tcp://10.6.84.1:8707 has been closed.
2025-10-01 17:26:19,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48776 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48672 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48664 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48658 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,588 - distributed.worker - INFO - Stopping worker at tcp://10.6.84.25:42511. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48828 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,581 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48642 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48800 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48618 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,581 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48636 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48748 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48784 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,583 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.84.25:48686 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,593 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:42137'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,594 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:45719'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,594 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:34933'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,595 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:46733'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,595 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,595 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,595 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:40399'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,595 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,595 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:45769'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,595 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,595 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,595 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,595 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:34717'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,595 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,596 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:40765'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,596 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:39067'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,596 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:38731'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,596 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:33709'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,596 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,597 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,598 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,598 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,598 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,598 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,598 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,598 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,598 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,598 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,598 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,593 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
                ^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.84.25:33542 remote=tcp://10.6.84.1:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-10-01 17:26:19,601 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,601 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,601 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,602 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,602 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,603 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,604 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,604 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,604 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,605 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,605 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,606 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:40087'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,607 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:35913'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,607 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:41911'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,607 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:42419'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,607 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:39897'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,607 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,607 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:38723'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,607 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,607 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:41057'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,607 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,608 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:34009'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,608 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:44477'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,608 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:44873'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,608 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:41941'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,608 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:40177'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,608 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,609 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:35579'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,609 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:39741'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,609 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:39069'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,609 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,610 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:35071'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,610 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:36729'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,610 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:42043'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,610 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,611 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:37207'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,611 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:36433'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,611 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:41743'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,611 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:39759'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,611 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:35885'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,611 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:33149'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,611 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,612 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:37807'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,612 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:36739'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,612 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:43995'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,612 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,613 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,614 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,615 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,615 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,615 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,615 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,616 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,616 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,617 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,617 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,618 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,618 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,618 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,618 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,618 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,618 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,618 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,612 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-10-01 17:26:19,620 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,620 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,620 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,620 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,620 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,621 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,621 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,621 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,621 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,622 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,622 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,622 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,622 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:46545'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,622 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,622 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:35785'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,622 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,623 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:39593'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,623 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:42205'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,623 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:41373'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,623 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:33075'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,623 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,623 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:33545'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,623 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,623 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,623 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:39453'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,623 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,624 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:34321'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,624 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:40003'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,624 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:43537'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,624 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:40525'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,624 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:35705'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,624 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.84.25:33213'. Reason: worker-handle-scheduler-connection-broken
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,624 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,625 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_utils.py09885cb1-e9be-4fc3-ac9e-51e449096f1a
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,626 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,627 - distributed.worker - INFO - Removing Worker plugin qme_vars.pycc3a558a-d414-4877-958f-dcc94964550c
2025-10-01 17:26:19,627 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,627 - distributed.worker - INFO - Removing Worker plugin qme_train.pyd1b46f2c-cb4e-467a-8a21-212e03c56830
2025-10-01 17:26:19,627 - distributed.worker - INFO - Removing Worker plugin qme_apply.pya5db5a44-6f68-498c-9fd0-f4f67f585ec5
2025-10-01 17:26:19,628 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,630 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,630 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,631 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,631 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,631 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,632 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,632 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,632 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,633 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,633 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,634 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,634 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:19,634 - distributed.nanny - INFO - Worker closed
2025-10-01 17:26:21,605 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,605 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,606 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,606 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,606 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,608 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,608 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,608 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,609 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,609 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,609 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,620 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,620 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,620 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,620 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,622 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,622 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,622 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,622 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,622 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,622 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,622 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,623 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,624 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,624 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,624 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,624 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,624 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,624 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,625 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,626 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,626 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,626 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,627 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,627 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,628 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,631 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,634 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,635 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,635 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,635 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,636 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,636 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,636 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,637 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,638 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,638 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,639 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,639 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,640 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-10-01 17:26:21,977 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:38731'. Reason: nanny-close-gracefully
2025-10-01 17:26:21,980 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:45769'. Reason: nanny-close-gracefully
2025-10-01 17:26:21,981 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:38731' closed.
2025-10-01 17:26:21,982 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:45769' closed.
2025-10-01 17:26:21,986 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:40399'. Reason: nanny-close-gracefully
2025-10-01 17:26:21,987 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:35579'. Reason: nanny-close-gracefully
2025-10-01 17:26:21,988 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:40399' closed.
2025-10-01 17:26:21,988 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:35579' closed.
2025-10-01 17:26:21,995 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:40765'. Reason: nanny-close-gracefully
2025-10-01 17:26:21,995 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:40765' closed.
2025-10-01 17:26:22,002 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:33075'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,002 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:33075' closed.
2025-10-01 17:26:22,006 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:41743'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,007 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:41743' closed.
2025-10-01 17:26:22,010 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:35071'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,011 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:37207'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,012 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:41057'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,012 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:35071' closed.
2025-10-01 17:26:22,013 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:37207' closed.
2025-10-01 17:26:22,013 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:41057' closed.
2025-10-01 17:26:22,020 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:36739'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,024 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:36739' closed.
2025-10-01 17:26:22,024 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:39067'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,025 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:39067' closed.
2025-10-01 17:26:22,045 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:35785'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,046 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:35785' closed.
2025-10-01 17:26:22,052 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:39897'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,063 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:39897' closed.
2025-10-01 17:26:22,063 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:39593'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,064 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:35913'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,066 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:45719'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,067 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:41911'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,067 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:34717'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,068 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:39593' closed.
2025-10-01 17:26:22,068 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:35913' closed.
2025-10-01 17:26:22,069 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:45719' closed.
2025-10-01 17:26:22,069 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:41911' closed.
2025-10-01 17:26:22,069 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:34717' closed.
2025-10-01 17:26:22,075 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:43995'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,076 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:40087'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,077 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:34933'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,085 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:42137'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,086 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:43995' closed.
2025-10-01 17:26:22,086 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:44477'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,087 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:38723'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,087 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:40087' closed.
2025-10-01 17:26:22,088 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:34933' closed.
2025-10-01 17:26:22,088 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:33545'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,088 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:33709'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,088 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:34321'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,088 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:39453'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,090 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:42137' closed.
2025-10-01 17:26:22,094 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:44477' closed.
2025-10-01 17:26:22,095 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:36433'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,095 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:38723' closed.
2025-10-01 17:26:22,095 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:33545' closed.
2025-10-01 17:26:22,095 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:33709' closed.
2025-10-01 17:26:22,095 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:34321' closed.
2025-10-01 17:26:22,096 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:39453' closed.
2025-10-01 17:26:22,099 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:35885'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,102 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:36433' closed.
2025-10-01 17:26:22,102 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:44873'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,103 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:41373'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,104 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:34009'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,104 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:35885' closed.
2025-10-01 17:26:22,104 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:44873' closed.
2025-10-01 17:26:22,105 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:41373' closed.
2025-10-01 17:26:22,105 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:34009' closed.
2025-10-01 17:26:22,106 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:46733'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,106 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:46733' closed.
2025-10-01 17:26:22,116 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:40003'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,116 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:40003' closed.
2025-10-01 17:26:22,121 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:42205'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,122 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:33213'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,123 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:37807'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,124 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:42419'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,125 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:43537'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,126 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:42205' closed.
2025-10-01 17:26:22,128 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:33213' closed.
2025-10-01 17:26:22,128 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:37807' closed.
2025-10-01 17:26:22,129 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:42419' closed.
2025-10-01 17:26:22,130 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:40177'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,132 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:43537' closed.
2025-10-01 17:26:22,133 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:42043'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,134 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:46545'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,135 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:39759'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,136 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:33149'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,136 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:40177' closed.
2025-10-01 17:26:22,137 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:35705'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,137 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:42043' closed.
2025-10-01 17:26:22,137 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:46545' closed.
2025-10-01 17:26:22,138 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:39759' closed.
2025-10-01 17:26:22,138 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:33149' closed.
2025-10-01 17:26:22,140 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:35705' closed.
2025-10-01 17:26:22,145 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:41941'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,146 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:41941' closed.
2025-10-01 17:26:22,188 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:36729'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,189 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:36729' closed.
2025-10-01 17:26:22,201 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:39741'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,203 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:40525'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,203 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:39741' closed.
2025-10-01 17:26:22,204 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:40525' closed.
2025-10-01 17:26:22,212 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.84.25:39069'. Reason: nanny-close-gracefully
2025-10-01 17:26:22,213 - distributed.nanny - INFO - Nanny at 'tcp://10.6.84.25:39069' closed.
2025-10-01 17:26:22,215 - distributed.dask_worker - INFO - End worker
