Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:31:31,797 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:33403'
2025-09-03 10:31:31,806 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:43721'
2025-09-03 10:31:31,811 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45863'
2025-09-03 10:31:31,816 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:44541'
2025-09-03 10:31:31,822 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45167'
2025-09-03 10:31:31,951 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:37237'
2025-09-03 10:31:31,956 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45493'
2025-09-03 10:31:31,960 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:38595'
2025-09-03 10:31:31,966 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:40693'
2025-09-03 10:31:31,970 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:43483'
2025-09-03 10:31:31,975 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:35283'
2025-09-03 10:31:31,979 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:36575'
2025-09-03 10:31:31,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:44429'
2025-09-03 10:31:31,989 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:37943'
2025-09-03 10:31:31,993 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:37127'
2025-09-03 10:31:31,998 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:40407'
2025-09-03 10:31:32,002 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:38751'
2025-09-03 10:31:32,007 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:38895'
2025-09-03 10:31:32,012 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41019'
2025-09-03 10:31:32,016 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:44511'
2025-09-03 10:31:32,021 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:38871'
2025-09-03 10:31:32,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:39867'
2025-09-03 10:31:32,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45845'
2025-09-03 10:31:32,034 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:39647'
2025-09-03 10:31:32,039 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41383'
2025-09-03 10:31:32,044 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34621'
2025-09-03 10:31:32,050 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:44571'
2025-09-03 10:31:32,054 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45815'
2025-09-03 10:31:32,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41057'
2025-09-03 10:31:32,063 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45247'
2025-09-03 10:31:32,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41737'
2025-09-03 10:31:32,072 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41711'
2025-09-03 10:31:32,077 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:39213'
2025-09-03 10:31:32,081 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:33589'
2025-09-03 10:31:32,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:38193'
2025-09-03 10:31:32,091 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34749'
2025-09-03 10:31:32,094 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:40797'
2025-09-03 10:31:32,099 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:43839'
2025-09-03 10:31:32,104 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:40985'
2025-09-03 10:31:32,107 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34939'
2025-09-03 10:31:32,111 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41113'
2025-09-03 10:31:32,210 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:38661'
2025-09-03 10:31:32,217 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:42907'
2025-09-03 10:31:32,221 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41357'
2025-09-03 10:31:32,226 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:42335'
2025-09-03 10:31:32,478 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:37887'
2025-09-03 10:31:32,485 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34949'
2025-09-03 10:31:32,489 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41027'
2025-09-03 10:31:32,494 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:37121'
2025-09-03 10:31:32,498 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34885'
2025-09-03 10:31:32,503 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:39179'
2025-09-03 10:31:32,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:44763'
2025-09-03 10:31:32,510 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:35745'
2025-09-03 10:31:32,515 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:38867'
2025-09-03 10:31:32,521 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34581'
2025-09-03 10:31:32,524 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:43851'
2025-09-03 10:31:32,529 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:32883'
2025-09-03 10:31:32,533 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:33415'
2025-09-03 10:31:32,539 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41827'
2025-09-03 10:31:32,543 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:33283'
2025-09-03 10:31:32,548 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:37147'
2025-09-03 10:31:32,553 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:33725'
2025-09-03 10:31:32,561 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:39389'
2025-09-03 10:31:32,565 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34611'
2025-09-03 10:31:32,570 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:33873'
2025-09-03 10:31:32,574 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:36039'
2025-09-03 10:31:32,579 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:37725'
2025-09-03 10:31:32,581 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34123'
2025-09-03 10:31:32,584 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:46527'
2025-09-03 10:31:32,587 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:35003'
2025-09-03 10:31:32,589 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:38445'
2025-09-03 10:31:32,594 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:40641'
2025-09-03 10:31:32,598 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:39629'
2025-09-03 10:31:32,601 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45337'
2025-09-03 10:31:32,605 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34281'
2025-09-03 10:31:32,610 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:36231'
2025-09-03 10:31:32,614 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41031'
2025-09-03 10:31:32,618 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:40853'
2025-09-03 10:31:32,624 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45619'
2025-09-03 10:31:32,640 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:36099'
2025-09-03 10:31:32,645 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41601'
2025-09-03 10:31:32,649 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:44701'
2025-09-03 10:31:32,654 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:44747'
2025-09-03 10:31:32,660 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:42091'
2025-09-03 10:31:32,667 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34157'
2025-09-03 10:31:32,672 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:44507'
2025-09-03 10:31:32,677 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:46231'
2025-09-03 10:31:32,682 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:40753'
2025-09-03 10:31:32,686 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:36623'
2025-09-03 10:31:32,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:40777'
2025-09-03 10:31:32,695 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45645'
2025-09-03 10:31:32,699 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:37325'
2025-09-03 10:31:32,703 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:38781'
2025-09-03 10:31:32,707 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:46845'
2025-09-03 10:31:32,710 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41231'
2025-09-03 10:31:32,715 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:44457'
2025-09-03 10:31:32,720 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:35073'
2025-09-03 10:31:32,724 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:33227'
2025-09-03 10:31:32,729 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:43391'
2025-09-03 10:31:32,734 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:46057'
2025-09-03 10:31:32,739 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:36131'
2025-09-03 10:31:32,742 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:45087'
2025-09-03 10:31:32,746 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:34675'
2025-09-03 10:31:32,751 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.6:41969'
2025-09-03 10:31:33,196 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:37315
2025-09-03 10:31:33,196 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:37315
2025-09-03 10:31:33,196 - distributed.worker - INFO -          dashboard at:           10.6.102.6:45203
2025-09-03 10:31:33,196 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,196 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,196 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,196 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7szsc2m2
2025-09-03 10:31:33,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,196 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:34769
2025-09-03 10:31:33,196 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:36119
2025-09-03 10:31:33,196 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:35189
2025-09-03 10:31:33,196 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:34301
2025-09-03 10:31:33,196 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:43493
2025-09-03 10:31:33,196 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:34769
2025-09-03 10:31:33,196 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:36119
2025-09-03 10:31:33,197 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:35189
2025-09-03 10:31:33,197 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:34301
2025-09-03 10:31:33,197 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:43493
2025-09-03 10:31:33,197 - distributed.worker - INFO -          dashboard at:           10.6.102.6:38723
2025-09-03 10:31:33,197 - distributed.worker - INFO -          dashboard at:           10.6.102.6:36257
2025-09-03 10:31:33,197 - distributed.worker - INFO -          dashboard at:           10.6.102.6:46673
2025-09-03 10:31:33,197 - distributed.worker - INFO -          dashboard at:           10.6.102.6:44431
2025-09-03 10:31:33,197 - distributed.worker - INFO -          dashboard at:           10.6.102.6:46211
2025-09-03 10:31:33,197 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,197 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,197 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,197 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,197 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,197 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,197 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,197 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,197 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,197 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,197 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,197 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,197 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,197 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,197 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,197 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-w_24lhgt
2025-09-03 10:31:33,197 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g_ymrtoi
2025-09-03 10:31:33,197 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zjx99x6f
2025-09-03 10:31:33,197 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-eysbu8k5
2025-09-03 10:31:33,197 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5p0e6s94
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,199 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:36443
2025-09-03 10:31:33,199 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:36443
2025-09-03 10:31:33,199 - distributed.worker - INFO -          dashboard at:           10.6.102.6:43019
2025-09-03 10:31:33,200 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,200 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,200 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,200 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,200 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:44951
2025-09-03 10:31:33,200 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pmizofzi
2025-09-03 10:31:33,200 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:44951
2025-09-03 10:31:33,200 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,200 - distributed.worker - INFO -          dashboard at:           10.6.102.6:43277
2025-09-03 10:31:33,200 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,200 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,200 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,200 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,200 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-powjr2vq
2025-09-03 10:31:33,200 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,202 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:46705
2025-09-03 10:31:33,203 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:46705
2025-09-03 10:31:33,203 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39809
2025-09-03 10:31:33,203 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,203 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,203 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,203 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,203 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-m8q8m8kh
2025-09-03 10:31:33,204 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,234 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:37729
2025-09-03 10:31:33,234 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:37729
2025-09-03 10:31:33,234 - distributed.worker - INFO -          dashboard at:           10.6.102.6:33379
2025-09-03 10:31:33,234 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,234 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,234 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,234 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,234 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-c_o0n9lg
2025-09-03 10:31:33,234 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,252 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:42035
2025-09-03 10:31:33,252 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:42035
2025-09-03 10:31:33,252 - distributed.worker - INFO -          dashboard at:           10.6.102.6:33901
2025-09-03 10:31:33,253 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,253 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,253 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,253 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,253 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bunxltpu
2025-09-03 10:31:33,253 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,312 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,313 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,313 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,315 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,321 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,322 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,324 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,331 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,332 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,334 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,340 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,340 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,342 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,349 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,351 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,352 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,359 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,360 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,362 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,368 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,369 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,370 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,371 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,378 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,379 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,379 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,381 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,388 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,389 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,391 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,398 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,399 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,399 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,401 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,408 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,409 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,411 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,921 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:41861
2025-09-03 10:31:33,921 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:41861
2025-09-03 10:31:33,921 - distributed.worker - INFO -          dashboard at:           10.6.102.6:42647
2025-09-03 10:31:33,921 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,921 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,921 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,921 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,921 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8t99cql3
2025-09-03 10:31:33,921 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,924 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38853
2025-09-03 10:31:33,925 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38853
2025-09-03 10:31:33,925 - distributed.worker - INFO -          dashboard at:           10.6.102.6:42359
2025-09-03 10:31:33,925 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,925 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,925 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,925 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,925 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6_3_5cmy
2025-09-03 10:31:33,925 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,930 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:36529
2025-09-03 10:31:33,930 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:36529
2025-09-03 10:31:33,930 - distributed.worker - INFO -          dashboard at:           10.6.102.6:34427
2025-09-03 10:31:33,930 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,930 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,930 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,930 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,930 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-oah082jk
2025-09-03 10:31:33,930 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,945 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:46471
2025-09-03 10:31:33,945 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:46471
2025-09-03 10:31:33,945 - distributed.worker - INFO -          dashboard at:           10.6.102.6:43795
2025-09-03 10:31:33,945 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,945 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,945 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,945 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,945 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-sgio8oap
2025-09-03 10:31:33,945 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,950 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40393
2025-09-03 10:31:33,950 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40393
2025-09-03 10:31:33,950 - distributed.worker - INFO -          dashboard at:           10.6.102.6:35507
2025-09-03 10:31:33,950 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,950 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,950 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,950 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,950 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z0t_bk97
2025-09-03 10:31:33,950 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,961 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:37467
2025-09-03 10:31:33,961 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:37467
2025-09-03 10:31:33,961 - distributed.worker - INFO -          dashboard at:           10.6.102.6:44601
2025-09-03 10:31:33,961 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,961 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,961 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,961 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,962 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dmd5jyyk
2025-09-03 10:31:33,962 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,966 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,967 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:33847
2025-09-03 10:31:33,967 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:33847
2025-09-03 10:31:33,968 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39907
2025-09-03 10:31:33,968 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,968 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,968 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,968 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,968 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,968 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-b9ubno1t
2025-09-03 10:31:33,968 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,968 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,969 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,970 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40367
2025-09-03 10:31:33,970 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40367
2025-09-03 10:31:33,970 - distributed.worker - INFO -          dashboard at:           10.6.102.6:41985
2025-09-03 10:31:33,970 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,970 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,970 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,970 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,970 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-s8_rfrbv
2025-09-03 10:31:33,970 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,976 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:42165
2025-09-03 10:31:33,976 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:42165
2025-09-03 10:31:33,976 - distributed.worker - INFO -          dashboard at:           10.6.102.6:40287
2025-09-03 10:31:33,976 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,976 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,976 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,976 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,976 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ea90kxyd
2025-09-03 10:31:33,976 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,979 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38633
2025-09-03 10:31:33,979 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38633
2025-09-03 10:31:33,979 - distributed.worker - INFO -          dashboard at:           10.6.102.6:45629
2025-09-03 10:31:33,979 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,979 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,979 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,979 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,979 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6uobf03w
2025-09-03 10:31:33,979 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,979 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,980 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,980 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,982 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:46513
2025-09-03 10:31:33,982 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:46513
2025-09-03 10:31:33,982 - distributed.worker - INFO -          dashboard at:           10.6.102.6:42465
2025-09-03 10:31:33,982 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,982 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,982 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,982 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,982 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6jrtsytl
2025-09-03 10:31:33,982 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,982 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,986 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:41119
2025-09-03 10:31:33,986 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:41119
2025-09-03 10:31:33,986 - distributed.worker - INFO -          dashboard at:           10.6.102.6:45553
2025-09-03 10:31:33,986 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,986 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,986 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,986 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,986 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qql8kldg
2025-09-03 10:31:33,986 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,989 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:39397
2025-09-03 10:31:33,989 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:39397
2025-09-03 10:31:33,989 - distributed.worker - INFO -          dashboard at:           10.6.102.6:41175
2025-09-03 10:31:33,989 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,989 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,989 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,989 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,989 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-d0fci8k5
2025-09-03 10:31:33,989 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,996 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:33,997 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,997 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,999 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:33,999 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40987
2025-09-03 10:31:33,999 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40987
2025-09-03 10:31:33,999 - distributed.worker - INFO -          dashboard at:           10.6.102.6:38783
2025-09-03 10:31:33,999 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:33,999 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:33,999 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:33,999 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:33,999 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_23kiavj
2025-09-03 10:31:33,999 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,008 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:41525
2025-09-03 10:31:34,008 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,008 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:41525
2025-09-03 10:31:34,008 - distributed.worker - INFO -          dashboard at:           10.6.102.6:40859
2025-09-03 10:31:34,008 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,008 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,008 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,008 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,008 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3k73l6jv
2025-09-03 10:31:34,008 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,009 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,009 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,010 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,016 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40633
2025-09-03 10:31:34,017 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40633
2025-09-03 10:31:34,017 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39071
2025-09-03 10:31:34,017 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,017 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,017 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,017 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-y1p71m7p
2025-09-03 10:31:34,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,018 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,019 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,019 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,021 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,022 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:37063
2025-09-03 10:31:34,022 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:37063
2025-09-03 10:31:34,022 - distributed.worker - INFO -          dashboard at:           10.6.102.6:34031
2025-09-03 10:31:34,022 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,022 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,023 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,023 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,023 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-r7bzfs0p
2025-09-03 10:31:34,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,027 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,028 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,029 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,030 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,037 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,038 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,038 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,040 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,047 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,048 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,048 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,050 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,057 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,058 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,060 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,066 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,067 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,068 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,069 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,069 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:42637
2025-09-03 10:31:34,069 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:42637
2025-09-03 10:31:34,069 - distributed.worker - INFO -          dashboard at:           10.6.102.6:44293
2025-09-03 10:31:34,069 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,070 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,070 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,070 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-q2jnkk_g
2025-09-03 10:31:34,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,113 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,115 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,116 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,121 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:39181
2025-09-03 10:31:34,121 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:39181
2025-09-03 10:31:34,121 - distributed.worker - INFO -          dashboard at:           10.6.102.6:36587
2025-09-03 10:31:34,121 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,121 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,121 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,121 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0hdokkus
2025-09-03 10:31:34,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,123 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,124 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:34519
2025-09-03 10:31:34,124 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:34519
2025-09-03 10:31:34,124 - distributed.worker - INFO -          dashboard at:           10.6.102.6:41059
2025-09-03 10:31:34,124 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,124 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,124 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,124 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,124 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zmbcke21
2025-09-03 10:31:34,124 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,125 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,125 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,126 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,167 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:37929
2025-09-03 10:31:34,167 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:37929
2025-09-03 10:31:34,167 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39785
2025-09-03 10:31:34,167 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,167 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,167 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,167 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,167 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fi1foa79
2025-09-03 10:31:34,167 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,191 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,192 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,193 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,194 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,214 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,215 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,215 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,217 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,228 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:43675
2025-09-03 10:31:34,228 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:43675
2025-09-03 10:31:34,228 - distributed.worker - INFO -          dashboard at:           10.6.102.6:41911
2025-09-03 10:31:34,228 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,228 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,228 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,228 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,228 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vyoq8qsv
2025-09-03 10:31:34,228 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,228 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,229 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,230 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,231 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,238 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,240 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,240 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,241 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:33481
2025-09-03 10:31:34,241 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:33481
2025-09-03 10:31:34,241 - distributed.worker - INFO -          dashboard at:           10.6.102.6:33783
2025-09-03 10:31:34,241 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,242 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,242 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,241 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,242 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,242 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ns4ey1kc
2025-09-03 10:31:34,242 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,244 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:45263
2025-09-03 10:31:34,245 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:45263
2025-09-03 10:31:34,245 - distributed.worker - INFO -          dashboard at:           10.6.102.6:35781
2025-09-03 10:31:34,245 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,245 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,245 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,245 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,245 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4_0z1yj4
2025-09-03 10:31:34,245 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,247 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,247 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,248 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,248 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,258 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,259 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,259 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,260 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,326 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:45417
2025-09-03 10:31:34,326 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:45417
2025-09-03 10:31:34,326 - distributed.worker - INFO -          dashboard at:           10.6.102.6:35247
2025-09-03 10:31:34,326 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,326 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,326 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,326 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,326 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z3ho7pqz
2025-09-03 10:31:34,326 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,374 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,375 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,377 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,403 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,404 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,405 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,406 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,504 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:33291
2025-09-03 10:31:34,504 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:33291
2025-09-03 10:31:34,504 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39953
2025-09-03 10:31:34,504 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,504 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,504 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,504 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,504 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kyu_rrjw
2025-09-03 10:31:34,504 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,541 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40513
2025-09-03 10:31:34,542 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40513
2025-09-03 10:31:34,542 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39381
2025-09-03 10:31:34,542 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,542 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,542 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,542 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,542 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tb1fpiw8
2025-09-03 10:31:34,542 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,545 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:41457
2025-09-03 10:31:34,545 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:41457
2025-09-03 10:31:34,545 - distributed.worker - INFO -          dashboard at:           10.6.102.6:45789
2025-09-03 10:31:34,545 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,545 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,545 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,545 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,545 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1b5sbf76
2025-09-03 10:31:34,545 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,564 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:45573
2025-09-03 10:31:34,564 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:45573
2025-09-03 10:31:34,564 - distributed.worker - INFO -          dashboard at:           10.6.102.6:42379
2025-09-03 10:31:34,564 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,564 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,564 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,564 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-a6e82ume
2025-09-03 10:31:34,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,570 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:35677
2025-09-03 10:31:34,571 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:35677
2025-09-03 10:31:34,570 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38233
2025-09-03 10:31:34,571 - distributed.worker - INFO -          dashboard at:           10.6.102.6:35341
2025-09-03 10:31:34,571 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,571 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38233
2025-09-03 10:31:34,571 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,571 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,571 - distributed.worker - INFO -          dashboard at:           10.6.102.6:42867
2025-09-03 10:31:34,571 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,571 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,571 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,571 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-q0o0zdja
2025-09-03 10:31:34,571 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,571 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,571 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,571 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4gssy6_b
2025-09-03 10:31:34,571 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,579 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38697
2025-09-03 10:31:34,579 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38697
2025-09-03 10:31:34,579 - distributed.worker - INFO -          dashboard at:           10.6.102.6:42549
2025-09-03 10:31:34,579 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,579 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,579 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,579 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,579 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-m7_spb_y
2025-09-03 10:31:34,579 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,580 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,581 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,581 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,583 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:33345
2025-09-03 10:31:34,583 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,583 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:33345
2025-09-03 10:31:34,583 - distributed.worker - INFO -          dashboard at:           10.6.102.6:32909
2025-09-03 10:31:34,583 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,583 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,583 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,583 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,583 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-c3u2cs4u
2025-09-03 10:31:34,583 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,593 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38747
2025-09-03 10:31:34,593 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38747
2025-09-03 10:31:34,593 - distributed.worker - INFO -          dashboard at:           10.6.102.6:40125
2025-09-03 10:31:34,593 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,594 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,594 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,594 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-yhli6l8y
2025-09-03 10:31:34,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,595 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:34295
2025-09-03 10:31:34,595 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:34295
2025-09-03 10:31:34,595 - distributed.worker - INFO -          dashboard at:           10.6.102.6:36103
2025-09-03 10:31:34,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,595 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,595 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,595 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jvsq8dcp
2025-09-03 10:31:34,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,654 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:33715
2025-09-03 10:31:34,654 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:33715
2025-09-03 10:31:34,654 - distributed.worker - INFO -          dashboard at:           10.6.102.6:38195
2025-09-03 10:31:34,654 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,654 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,654 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,654 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,654 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u2q8t5lc
2025-09-03 10:31:34,654 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,728 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,729 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,730 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,731 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,738 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,739 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,740 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,745 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38477
2025-09-03 10:31:34,745 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38477
2025-09-03 10:31:34,745 - distributed.worker - INFO -          dashboard at:           10.6.102.6:43311
2025-09-03 10:31:34,745 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,745 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,745 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,745 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ontje9a0
2025-09-03 10:31:34,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,767 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,768 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,769 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,770 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,787 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,788 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,788 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,790 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,814 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:36993
2025-09-03 10:31:34,814 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:36993
2025-09-03 10:31:34,814 - distributed.worker - INFO -          dashboard at:           10.6.102.6:43241
2025-09-03 10:31:34,814 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,814 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,814 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,814 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-iz8doupa
2025-09-03 10:31:34,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,820 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:32809
2025-09-03 10:31:34,820 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:32809
2025-09-03 10:31:34,820 - distributed.worker - INFO -          dashboard at:           10.6.102.6:38509
2025-09-03 10:31:34,820 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,820 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,820 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,820 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lq4kmex2
2025-09-03 10:31:34,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,841 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,841 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,843 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,863 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,864 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,864 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,866 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,899 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,900 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,900 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,901 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,908 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:45667
2025-09-03 10:31:34,908 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:45667
2025-09-03 10:31:34,908 - distributed.worker - INFO -          dashboard at:           10.6.102.6:46239
2025-09-03 10:31:34,908 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,908 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,908 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,908 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,908 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-267lnx0n
2025-09-03 10:31:34,908 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,909 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:34,910 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,910 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,912 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:34,956 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38317
2025-09-03 10:31:34,956 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38317
2025-09-03 10:31:34,956 - distributed.worker - INFO -          dashboard at:           10.6.102.6:40489
2025-09-03 10:31:34,956 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,956 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,956 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,956 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,957 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-90hj0m1v
2025-09-03 10:31:34,957 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,957 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40695
2025-09-03 10:31:34,957 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40695
2025-09-03 10:31:34,957 - distributed.worker - INFO -          dashboard at:           10.6.102.6:34663
2025-09-03 10:31:34,957 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,957 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,957 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,957 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,957 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-soi0fz5r
2025-09-03 10:31:34,957 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,999 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40725
2025-09-03 10:31:34,999 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40725
2025-09-03 10:31:34,999 - distributed.worker - INFO -          dashboard at:           10.6.102.6:45649
2025-09-03 10:31:34,999 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:34,999 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:34,999 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:34,999 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:34,999 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7_vbdbbu
2025-09-03 10:31:34,999 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,005 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:42791
2025-09-03 10:31:35,005 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:42791
2025-09-03 10:31:35,005 - distributed.worker - INFO -          dashboard at:           10.6.102.6:44887
2025-09-03 10:31:35,005 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,005 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,005 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,005 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,005 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-aixmcc1e
2025-09-03 10:31:35,006 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,011 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38455
2025-09-03 10:31:35,011 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38455
2025-09-03 10:31:35,011 - distributed.worker - INFO -          dashboard at:           10.6.102.6:44937
2025-09-03 10:31:35,012 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,012 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,012 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,012 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3ndy3aw9
2025-09-03 10:31:35,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,023 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:35499
2025-09-03 10:31:35,023 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:35499
2025-09-03 10:31:35,023 - distributed.worker - INFO -          dashboard at:           10.6.102.6:42057
2025-09-03 10:31:35,023 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,023 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,023 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,023 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-16a_7pj0
2025-09-03 10:31:35,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:45339
2025-09-03 10:31:35,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:45339
2025-09-03 10:31:35,057 - distributed.worker - INFO -          dashboard at:           10.6.102.6:46707
2025-09-03 10:31:35,057 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,057 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,057 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,057 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-y9ual3ze
2025-09-03 10:31:35,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,144 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38369
2025-09-03 10:31:35,144 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38369
2025-09-03 10:31:35,144 - distributed.worker - INFO -          dashboard at:           10.6.102.6:34791
2025-09-03 10:31:35,144 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,144 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,144 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,144 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,144 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2mvw8j9e
2025-09-03 10:31:35,144 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,155 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:35203
2025-09-03 10:31:35,155 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:35203
2025-09-03 10:31:35,155 - distributed.worker - INFO -          dashboard at:           10.6.102.6:35357
2025-09-03 10:31:35,155 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,155 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,155 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,155 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nrvcntv_
2025-09-03 10:31:35,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,168 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:43023
2025-09-03 10:31:35,168 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:43023
2025-09-03 10:31:35,168 - distributed.worker - INFO -          dashboard at:           10.6.102.6:41863
2025-09-03 10:31:35,168 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,168 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,168 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,168 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,168 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wjv91yco
2025-09-03 10:31:35,168 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,172 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38467
2025-09-03 10:31:35,172 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38467
2025-09-03 10:31:35,172 - distributed.worker - INFO -          dashboard at:           10.6.102.6:44863
2025-09-03 10:31:35,172 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,172 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,172 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,172 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nq9dokh1
2025-09-03 10:31:35,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,237 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:42061
2025-09-03 10:31:35,237 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:42061
2025-09-03 10:31:35,237 - distributed.worker - INFO -          dashboard at:           10.6.102.6:45261
2025-09-03 10:31:35,237 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,237 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,237 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,237 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,237 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-oz7la5iy
2025-09-03 10:31:35,237 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,244 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:39409
2025-09-03 10:31:35,244 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:39409
2025-09-03 10:31:35,244 - distributed.worker - INFO -          dashboard at:           10.6.102.6:33373
2025-09-03 10:31:35,244 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,244 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,244 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,244 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,244 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g3cdz47w
2025-09-03 10:31:35,244 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,374 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:36799
2025-09-03 10:31:35,374 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:36799
2025-09-03 10:31:35,375 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39857
2025-09-03 10:31:35,375 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,375 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,375 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,375 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7awro34h
2025-09-03 10:31:35,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,377 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:44169
2025-09-03 10:31:35,377 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:44169
2025-09-03 10:31:35,377 - distributed.worker - INFO -          dashboard at:           10.6.102.6:41271
2025-09-03 10:31:35,377 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,377 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,377 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,377 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,377 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4rjek9a5
2025-09-03 10:31:35,377 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,388 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:44081
2025-09-03 10:31:35,388 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:44081
2025-09-03 10:31:35,388 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39365
2025-09-03 10:31:35,388 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,388 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,388 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,388 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zd2_7kzz
2025-09-03 10:31:35,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,456 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:39677
2025-09-03 10:31:35,456 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:39677
2025-09-03 10:31:35,456 - distributed.worker - INFO -          dashboard at:           10.6.102.6:37845
2025-09-03 10:31:35,456 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,456 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,456 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,456 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,456 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hzisuvif
2025-09-03 10:31:35,456 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,472 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40369
2025-09-03 10:31:35,472 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40369
2025-09-03 10:31:35,472 - distributed.worker - INFO -          dashboard at:           10.6.102.6:40539
2025-09-03 10:31:35,472 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,472 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,472 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,472 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,472 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z7v_u0w9
2025-09-03 10:31:35,472 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,475 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38427
2025-09-03 10:31:35,475 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38427
2025-09-03 10:31:35,475 - distributed.worker - INFO -          dashboard at:           10.6.102.6:35295
2025-09-03 10:31:35,475 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,475 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,475 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,475 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,475 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-b47rui7c
2025-09-03 10:31:35,475 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,497 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:46437
2025-09-03 10:31:35,498 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:46437
2025-09-03 10:31:35,498 - distributed.worker - INFO -          dashboard at:           10.6.102.6:34757
2025-09-03 10:31:35,498 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,498 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,498 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,498 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,498 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6mmn2zin
2025-09-03 10:31:35,498 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,526 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40047
2025-09-03 10:31:35,526 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40047
2025-09-03 10:31:35,526 - distributed.worker - INFO -          dashboard at:           10.6.102.6:34511
2025-09-03 10:31:35,526 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,526 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,526 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,526 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,526 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-icjetwtc
2025-09-03 10:31:35,526 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,536 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:33041
2025-09-03 10:31:35,536 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:33041
2025-09-03 10:31:35,536 - distributed.worker - INFO -          dashboard at:           10.6.102.6:34195
2025-09-03 10:31:35,536 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,536 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,536 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,536 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,536 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2087g__0
2025-09-03 10:31:35,536 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,540 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40347
2025-09-03 10:31:35,540 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40347
2025-09-03 10:31:35,540 - distributed.worker - INFO -          dashboard at:           10.6.102.6:40261
2025-09-03 10:31:35,540 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,540 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,540 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,540 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,540 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-w1ufuj6s
2025-09-03 10:31:35,540 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,649 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:43877
2025-09-03 10:31:35,650 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:43877
2025-09-03 10:31:35,650 - distributed.worker - INFO -          dashboard at:           10.6.102.6:44363
2025-09-03 10:31:35,650 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,650 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,650 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,650 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wj_7qgv0
2025-09-03 10:31:35,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,702 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:43369
2025-09-03 10:31:35,702 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:43369
2025-09-03 10:31:35,702 - distributed.worker - INFO -          dashboard at:           10.6.102.6:33669
2025-09-03 10:31:35,702 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,702 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,702 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,702 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8btza8tj
2025-09-03 10:31:35,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,781 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:37685
2025-09-03 10:31:35,781 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:37685
2025-09-03 10:31:35,781 - distributed.worker - INFO -          dashboard at:           10.6.102.6:45689
2025-09-03 10:31:35,781 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,781 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,781 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,781 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,781 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-yx8w7ic5
2025-09-03 10:31:35,781 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,803 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:42371
2025-09-03 10:31:35,804 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:42371
2025-09-03 10:31:35,804 - distributed.worker - INFO -          dashboard at:           10.6.102.6:33977
2025-09-03 10:31:35,804 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,804 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,804 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,804 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rm55vlpu
2025-09-03 10:31:35,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,804 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:34381
2025-09-03 10:31:35,805 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:34381
2025-09-03 10:31:35,805 - distributed.worker - INFO -          dashboard at:           10.6.102.6:33169
2025-09-03 10:31:35,805 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,805 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,805 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,805 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qiiiaas6
2025-09-03 10:31:35,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,805 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:36097
2025-09-03 10:31:35,805 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:36097
2025-09-03 10:31:35,805 - distributed.worker - INFO -          dashboard at:           10.6.102.6:46339
2025-09-03 10:31:35,805 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,805 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,805 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,805 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9bn6yo_t
2025-09-03 10:31:35,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,812 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38877
2025-09-03 10:31:35,812 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38877
2025-09-03 10:31:35,812 - distributed.worker - INFO -          dashboard at:           10.6.102.6:46277
2025-09-03 10:31:35,813 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,813 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,813 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,813 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,813 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-h6ayby8v
2025-09-03 10:31:35,813 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,816 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:36109
2025-09-03 10:31:35,817 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:36109
2025-09-03 10:31:35,817 - distributed.worker - INFO -          dashboard at:           10.6.102.6:45241
2025-09-03 10:31:35,817 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,817 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,817 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,817 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,817 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-og9lrui4
2025-09-03 10:31:35,817 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,818 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:38627
2025-09-03 10:31:35,818 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:38627
2025-09-03 10:31:35,818 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39699
2025-09-03 10:31:35,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,818 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,818 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,818 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-w6do2jfy
2025-09-03 10:31:35,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,835 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:35313
2025-09-03 10:31:35,836 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:35313
2025-09-03 10:31:35,836 - distributed.worker - INFO -          dashboard at:           10.6.102.6:35735
2025-09-03 10:31:35,836 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,836 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,836 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,836 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,836 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-88041uz8
2025-09-03 10:31:35,836 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,838 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40265
2025-09-03 10:31:35,838 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40265
2025-09-03 10:31:35,839 - distributed.worker - INFO -          dashboard at:           10.6.102.6:39303
2025-09-03 10:31:35,839 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,839 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,839 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,839 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,839 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9o4f4bvr
2025-09-03 10:31:35,839 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,840 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:45393
2025-09-03 10:31:35,840 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:45393
2025-09-03 10:31:35,840 - distributed.worker - INFO -          dashboard at:           10.6.102.6:41479
2025-09-03 10:31:35,840 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,840 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,840 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,840 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,840 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1atq68s4
2025-09-03 10:31:35,840 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,845 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:42725
2025-09-03 10:31:35,845 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:42725
2025-09-03 10:31:35,845 - distributed.worker - INFO -          dashboard at:           10.6.102.6:37103
2025-09-03 10:31:35,845 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,845 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,846 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,846 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,845 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:46269
2025-09-03 10:31:35,846 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dbblrs08
2025-09-03 10:31:35,846 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:46269
2025-09-03 10:31:35,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,846 - distributed.worker - INFO -          dashboard at:           10.6.102.6:45419
2025-09-03 10:31:35,846 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,846 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,846 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,846 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0j2hnzze
2025-09-03 10:31:35,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,857 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:41157
2025-09-03 10:31:35,857 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:41157
2025-09-03 10:31:35,857 - distributed.worker - INFO -          dashboard at:           10.6.102.6:41153
2025-09-03 10:31:35,857 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,857 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,857 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,857 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,857 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-f7hbpi_f
2025-09-03 10:31:35,857 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,858 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:41235
2025-09-03 10:31:35,858 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:41235
2025-09-03 10:31:35,858 - distributed.worker - INFO -          dashboard at:           10.6.102.6:37795
2025-09-03 10:31:35,858 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,858 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,858 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,858 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kannuqj8
2025-09-03 10:31:35,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,861 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:34607
2025-09-03 10:31:35,861 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:34607
2025-09-03 10:31:35,861 - distributed.worker - INFO -          dashboard at:           10.6.102.6:43625
2025-09-03 10:31:35,861 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,861 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,861 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,861 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,861 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0f0g4w0g
2025-09-03 10:31:35,861 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:39165
2025-09-03 10:31:35,861 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,861 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:39165
2025-09-03 10:31:35,861 - distributed.worker - INFO -          dashboard at:           10.6.102.6:40433
2025-09-03 10:31:35,861 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,861 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,861 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,861 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,861 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-t4vx0veo
2025-09-03 10:31:35,861 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,868 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:41729
2025-09-03 10:31:35,868 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:41729
2025-09-03 10:31:35,868 - distributed.worker - INFO -          dashboard at:           10.6.102.6:38025
2025-09-03 10:31:35,868 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,868 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,868 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,868 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,868 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-03swur4a
2025-09-03 10:31:35,868 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,869 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:40697
2025-09-03 10:31:35,869 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:40697
2025-09-03 10:31:35,869 - distributed.worker - INFO -          dashboard at:           10.6.102.6:38293
2025-09-03 10:31:35,869 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,869 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:43667
2025-09-03 10:31:35,869 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,869 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,869 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:43667
2025-09-03 10:31:35,869 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,869 - distributed.worker - INFO -          dashboard at:           10.6.102.6:42665
2025-09-03 10:31:35,869 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-49xbpx9i
2025-09-03 10:31:35,869 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,869 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,869 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,869 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,869 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,869 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-df47ugkx
2025-09-03 10:31:35,869 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,873 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:42161
2025-09-03 10:31:35,873 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:42161
2025-09-03 10:31:35,873 - distributed.worker - INFO -          dashboard at:           10.6.102.6:37989
2025-09-03 10:31:35,873 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,873 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,873 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,873 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,873 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ozi_5gp7
2025-09-03 10:31:35,873 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,879 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:39819
2025-09-03 10:31:35,879 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:39819
2025-09-03 10:31:35,879 - distributed.worker - INFO -          dashboard at:           10.6.102.6:44907
2025-09-03 10:31:35,879 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,879 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,879 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,879 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,879 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7rwped4e
2025-09-03 10:31:35,879 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,886 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:34923
2025-09-03 10:31:35,886 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:34923
2025-09-03 10:31:35,886 - distributed.worker - INFO -          dashboard at:           10.6.102.6:41643
2025-09-03 10:31:35,886 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,886 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,886 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,886 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,886 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-a5fvvnem
2025-09-03 10:31:35,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,886 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:37215
2025-09-03 10:31:35,887 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:37215
2025-09-03 10:31:35,887 - distributed.worker - INFO -          dashboard at:           10.6.102.6:35885
2025-09-03 10:31:35,887 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,887 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,887 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,887 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xvlo8m29
2025-09-03 10:31:35,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,887 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:42813
2025-09-03 10:31:35,887 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:42813
2025-09-03 10:31:35,887 - distributed.worker - INFO -          dashboard at:           10.6.102.6:42781
2025-09-03 10:31:35,887 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,887 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,887 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,887 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-y2en0jd6
2025-09-03 10:31:35,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,889 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:44415
2025-09-03 10:31:35,889 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:44415
2025-09-03 10:31:35,889 - distributed.worker - INFO -          dashboard at:           10.6.102.6:44941
2025-09-03 10:31:35,889 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,889 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,889 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,889 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-a4eq0qac
2025-09-03 10:31:35,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,891 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:34065
2025-09-03 10:31:35,891 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:34065
2025-09-03 10:31:35,891 - distributed.worker - INFO -          dashboard at:           10.6.102.6:33679
2025-09-03 10:31:35,891 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,891 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,891 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,891 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-s3i5hkun
2025-09-03 10:31:35,892 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,892 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:46801
2025-09-03 10:31:35,893 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:46801
2025-09-03 10:31:35,893 - distributed.worker - INFO -          dashboard at:           10.6.102.6:43451
2025-09-03 10:31:35,893 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,893 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,893 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,893 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,893 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vn7_hga9
2025-09-03 10:31:35,893 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,899 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.6:35213
2025-09-03 10:31:35,899 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.6:35213
2025-09-03 10:31:35,899 - distributed.worker - INFO -          dashboard at:           10.6.102.6:38301
2025-09-03 10:31:35,899 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,899 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:35,899 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:35,899 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uvi5dk27
2025-09-03 10:31:35,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,992 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:35,994 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,994 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,995 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,118 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,119 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,120 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,121 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,129 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,130 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,131 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,133 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,140 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,142 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,142 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,144 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,194 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,195 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,195 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,197 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,204 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,206 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,206 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,208 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,226 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,227 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,227 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,229 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,237 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,238 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,238 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,241 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,258 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,259 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,262 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,335 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,336 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,338 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,345 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,346 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,348 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,356 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,357 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,357 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,359 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,367 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,368 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,368 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,370 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,377 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,379 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,379 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,381 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,388 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,390 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,390 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,392 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,399 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,401 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,401 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,403 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,409 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,410 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,413 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,420 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,422 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,422 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,424 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,779 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,780 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,780 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,782 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:36,997 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:36,998 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,998 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,000 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:37,018 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:37,019 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,019 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,021 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:37,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:37,922 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,922 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,924 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:37,932 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:37,934 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,936 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,628 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,631 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,637 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,640 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,643 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,649 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,715 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,716 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,717 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,719 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,805 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,806 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,806 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,808 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,839 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,840 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,840 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,842 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,892 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,894 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,894 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,896 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,060 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,062 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,062 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,064 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,072 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,074 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,074 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,075 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,146 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,147 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,147 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,149 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,158 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,160 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,160 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,161 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,170 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,172 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,173 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,806 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,807 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,807 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,809 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,818 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,820 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,821 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,842 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,844 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,844 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,846 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,866 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,867 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,867 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,869 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,878 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,879 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,880 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,881 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,889 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,891 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,892 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,902 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,904 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,904 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,906 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,914 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,915 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,915 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,917 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,926 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,927 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,929 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,963 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,965 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,965 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,967 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,977 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,979 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,979 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,981 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:43,989 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:43,991 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:43,991 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:43,993 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,014 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,015 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,015 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,017 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,026 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,027 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,027 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,029 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,037 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,039 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,039 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,040 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,050 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,051 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,053 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,062 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,063 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,063 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,065 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,074 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,075 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,076 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,077 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,086 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,088 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,088 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,090 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,098 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,100 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,100 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,102 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,110 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,112 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,112 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,114 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,123 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,124 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,124 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,126 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,099 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,100 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,100 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,102 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,112 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,112 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,114 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,042 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,044 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,044 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,045 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,069 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,071 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,071 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,073 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,082 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,083 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,083 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,085 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,095 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,096 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,096 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,098 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:50,539 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:50,541 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:50,541 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:50,542 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:50,552 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:50,554 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:50,554 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:50,556 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:07,415 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:07,426 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:14,884 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:14,894 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:14,907 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:14,921 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:14,935 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,020 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,034 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,043 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,055 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,068 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,085 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,094 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,106 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,117 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:15,129 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:35:51,104 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,106 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,338 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,342 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,471 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,472 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,549 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,551 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,618 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,619 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,630 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,893 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,898 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,942 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,944 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,055 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,056 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,072 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,078 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,122 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,123 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,239 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,241 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,042 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,043 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,056 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,061 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,160 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,162 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,164 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,166 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,167 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,170 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,172 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,173 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,254 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,256 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,342 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,345 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,360 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,362 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,386 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,392 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,398 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,406 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,412 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,440 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,446 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,500 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,502 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,599 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,601 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,803 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,805 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,970 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,972 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,992 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,994 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,015 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,016 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,022 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,024 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,080 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,081 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,113 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,115 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,238 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,239 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,253 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,254 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,294 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,296 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,308 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,310 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,327 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,333 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,333 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,335 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,359 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,360 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,847 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,852 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,857 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,858 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,090 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,095 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,141 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,146 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,329 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,335 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,408 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,410 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,803 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,804 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,810 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,811 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,814 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,821 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,900 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,906 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,116 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,117 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,121 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,126 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,176 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,177 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,232 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,233 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,313 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,315 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,327 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,333 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,617 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,618 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,662 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,663 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,707 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,714 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,837 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,841 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,843 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,847 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,864 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,865 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,870 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,871 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,915 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,920 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,022 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,023 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,155 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,160 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,221 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,222 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,224 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,224 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,228 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,233 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,333 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,337 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,465 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,470 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,655 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,664 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,666 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,801 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,803 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,942 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,946 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,126 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,132 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,236 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,238 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,525 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,526 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,625 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,626 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,759 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,071 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,073 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,203 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,206 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,283 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,284 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,394 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,395 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,430 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,435 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,805 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,806 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,827 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,056 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,057 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,527 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,532 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,871 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,875 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,049 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,050 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,234 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,240 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,259 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,265 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,313 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,315 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,711 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,713 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,235 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,237 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,557 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,566 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,970 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,975 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,041 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,046 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,720 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,722 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:06,102 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:06,108 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:09,156 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:09,158 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:14,907 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:14,911 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:22,882 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,885 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,886 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,891 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,891 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,891 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,893 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,893 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,927 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,930 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,940 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,942 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,954 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,956 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,957 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,959 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,387 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,390 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,391 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,395 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,396 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,396 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,397 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,398 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,406 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,408 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,508 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,510 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,510 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,512 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,512 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,514 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,514 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,519 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,520 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,522 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,523 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,525 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,531 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,533 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,536 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,538 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,542 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,542 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,542 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,544 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,547 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,550 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,555 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,558 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,559 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,561 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,563 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,565 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,566 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,568 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,568 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,570 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,571 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,571 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,573 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,573 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,786 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,797 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,799 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,799 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,802 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,828 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,829 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,830 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,831 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,836 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,838 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,849 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,852 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,855 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,857 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,862 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,864 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,881 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,883 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,890 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,892 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,894 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,895 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,897 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,900 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,901 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,910 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,912 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,016 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,019 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,021 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,023 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,068 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,073 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,083 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,088 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,088 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,090 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,090 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,092 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,228 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,230 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,235 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,237 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,337 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,339 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,341 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,348 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,350 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,351 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,353 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,385 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,390 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,408 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,410 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,437 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,442 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,450 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,452 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,497 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,499 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,501 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,503 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,504 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,505 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,599 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,601 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,670 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,675 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,682 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,684 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,690 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,692 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,692 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,694 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,746 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,748 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,750 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,752 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,788 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,791 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,850 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,852 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,865 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,867 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,890 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,891 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,893 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,893 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,897 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,900 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,918 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,920 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,924 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,922 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,926 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,926 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,927 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,927 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,928 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,929 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,932 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,934 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,936 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,941 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,943 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,945 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,965 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,966 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,991 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,993 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,038 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,039 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,040 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,041 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,054 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,153 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,155 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,166 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,173 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,420 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,425 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,062 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,067 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,242 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,244 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,350 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,355 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,494 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:28,257 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:28,262 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:29,534 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:29,536 - distributed.utils - INFO - Reload module qme_vars from .py file
