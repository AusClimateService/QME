Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:31:34,019 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36973'
2025-09-03 10:31:34,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35347'
2025-09-03 10:31:34,035 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:38977'
2025-09-03 10:31:34,040 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44303'
2025-09-03 10:31:34,045 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:33583'
2025-09-03 10:31:34,083 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35557'
2025-09-03 10:31:34,087 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:37031'
2025-09-03 10:31:34,091 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:38149'
2025-09-03 10:31:34,096 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:34301'
2025-09-03 10:31:34,100 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:33561'
2025-09-03 10:31:34,106 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:42047'
2025-09-03 10:31:34,111 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:34335'
2025-09-03 10:31:34,115 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:33931'
2025-09-03 10:31:34,119 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36005'
2025-09-03 10:31:34,124 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40497'
2025-09-03 10:31:34,129 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:45883'
2025-09-03 10:31:34,134 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44617'
2025-09-03 10:31:34,139 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:43525'
2025-09-03 10:31:34,144 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:43167'
2025-09-03 10:31:34,150 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:43729'
2025-09-03 10:31:34,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36653'
2025-09-03 10:31:34,160 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:38401'
2025-09-03 10:31:34,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:38825'
2025-09-03 10:31:34,171 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40543'
2025-09-03 10:31:34,175 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40563'
2025-09-03 10:31:34,180 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35963'
2025-09-03 10:31:34,244 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:34205'
2025-09-03 10:31:34,249 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:42705'
2025-09-03 10:31:34,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40897'
2025-09-03 10:31:34,258 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:41159'
2025-09-03 10:31:34,262 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35867'
2025-09-03 10:31:34,271 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:33001'
2025-09-03 10:31:34,275 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35729'
2025-09-03 10:31:34,279 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:37025'
2025-09-03 10:31:34,283 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:38731'
2025-09-03 10:31:34,288 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:41289'
2025-09-03 10:31:34,292 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:42849'
2025-09-03 10:31:34,296 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:39891'
2025-09-03 10:31:34,299 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:38187'
2025-09-03 10:31:34,305 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:41409'
2025-09-03 10:31:34,310 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40049'
2025-09-03 10:31:34,313 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:38469'
2025-09-03 10:31:34,318 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36671'
2025-09-03 10:31:34,324 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:38817'
2025-09-03 10:31:34,330 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44807'
2025-09-03 10:31:34,347 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35123'
2025-09-03 10:31:34,350 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:33865'
2025-09-03 10:31:34,354 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40677'
2025-09-03 10:31:34,358 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:45765'
2025-09-03 10:31:34,361 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:34875'
2025-09-03 10:31:34,367 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:33681'
2025-09-03 10:31:34,370 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36235'
2025-09-03 10:31:34,375 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:45919'
2025-09-03 10:31:34,380 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:43191'
2025-09-03 10:31:34,383 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:41551'
2025-09-03 10:31:34,387 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44319'
2025-09-03 10:31:34,391 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:34117'
2025-09-03 10:31:34,396 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40121'
2025-09-03 10:31:34,400 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:41821'
2025-09-03 10:31:34,405 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:46725'
2025-09-03 10:31:34,409 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:46581'
2025-09-03 10:31:34,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40611'
2025-09-03 10:31:34,670 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:37541'
2025-09-03 10:31:34,674 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:46361'
2025-09-03 10:31:34,679 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35257'
2025-09-03 10:31:34,684 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44447'
2025-09-03 10:31:34,687 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44221'
2025-09-03 10:31:34,691 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:39785'
2025-09-03 10:31:34,698 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:42225'
2025-09-03 10:31:34,701 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36003'
2025-09-03 10:31:34,705 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:34913'
2025-09-03 10:31:34,709 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36453'
2025-09-03 10:31:34,713 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44119'
2025-09-03 10:31:34,715 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:33565'
2025-09-03 10:31:34,719 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35311'
2025-09-03 10:31:34,724 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36893'
2025-09-03 10:31:34,730 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:41487'
2025-09-03 10:31:34,735 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36123'
2025-09-03 10:31:34,740 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:43399'
2025-09-03 10:31:34,744 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35499'
2025-09-03 10:31:34,748 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:46369'
2025-09-03 10:31:34,752 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36167'
2025-09-03 10:31:34,755 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:41233'
2025-09-03 10:31:34,761 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35871'
2025-09-03 10:31:34,764 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44513'
2025-09-03 10:31:34,767 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35001'
2025-09-03 10:31:34,771 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:38175'
2025-09-03 10:31:34,776 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:39071'
2025-09-03 10:31:34,781 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:46549'
2025-09-03 10:31:34,786 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:45389'
2025-09-03 10:31:34,791 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35451'
2025-09-03 10:31:34,795 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:33161'
2025-09-03 10:31:34,798 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:42703'
2025-09-03 10:31:34,805 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:35691'
2025-09-03 10:31:34,809 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44909'
2025-09-03 10:31:34,812 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40337'
2025-09-03 10:31:34,817 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:41365'
2025-09-03 10:31:34,821 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44325'
2025-09-03 10:31:34,826 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:33699'
2025-09-03 10:31:34,829 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:40687'
2025-09-03 10:31:34,925 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:37423'
2025-09-03 10:31:34,929 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:36827'
2025-09-03 10:31:34,936 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:44903'
2025-09-03 10:31:34,941 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.3:37873'
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:36001
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:39095
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:39313
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:41223
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42735
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:43945
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:44795
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33843
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:45283
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:39261
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35501
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33977
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:38003
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:41335
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:36001
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:43001
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:44571
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:41433
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:37781
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34771
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:37183
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:39095
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:39313
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:41223
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42735
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:43945
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33765
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33501
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:44795
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33843
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:44779
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:45283
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:39261
2025-09-03 10:31:36,057 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35769
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35501
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33977
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:38003
2025-09-03 10:31:36,057 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:41335
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:36259
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:43001
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:44571
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:41433
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:37781
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34771
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:37183
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:37093
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:41815
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:45843
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:35617
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:40667
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33765
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33501
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:36929
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:33947
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:44779
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:36485
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:42337
2025-09-03 10:31:36,058 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35769
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:41271
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:37401
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:33271
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:39005
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:46685
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:37069
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:44873
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:33715
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:38987
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:39033
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:38773
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:36655
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:46493
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO -          dashboard at:           10.6.102.3:40753
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,058 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gi03ric9
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ydcc3uut
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zs59ke89
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0mi58ule
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5hhb9ozv
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fipkzy0q
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-v8t51t1l
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-myjt2q28
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hl7rrh2_
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jg_xugqc
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6w7b0c91
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g0veuo5q
2025-09-03 10:31:36,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gzy6f4jq
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jrul88xx
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-emoza217
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-mel5d3uz
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-czs70a9y
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hczt4d6q
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uknkxb3n
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cbydzrsw
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-aib1q7f_
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-oiaxaypa
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cyan53st
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9ib3_1cy
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,456 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:38143
2025-09-03 10:31:36,456 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:38143
2025-09-03 10:31:36,456 - distributed.worker - INFO -          dashboard at:           10.6.102.3:45609
2025-09-03 10:31:36,456 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,456 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,456 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,456 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,456 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-71bhvfig
2025-09-03 10:31:36,456 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,459 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:36267
2025-09-03 10:31:36,459 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:36267
2025-09-03 10:31:36,459 - distributed.worker - INFO -          dashboard at:           10.6.102.3:41449
2025-09-03 10:31:36,459 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,459 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,459 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,459 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xovkc9cd
2025-09-03 10:31:36,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,479 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34187
2025-09-03 10:31:36,479 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34187
2025-09-03 10:31:36,479 - distributed.worker - INFO -          dashboard at:           10.6.102.3:34371
2025-09-03 10:31:36,479 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,479 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,479 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,479 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,479 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_c3pc0li
2025-09-03 10:31:36,479 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,496 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42187
2025-09-03 10:31:36,497 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42187
2025-09-03 10:31:36,497 - distributed.worker - INFO -          dashboard at:           10.6.102.3:36343
2025-09-03 10:31:36,497 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,497 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,497 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,497 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,497 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-t_t0q4f6
2025-09-03 10:31:36,497 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,501 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33877
2025-09-03 10:31:36,501 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33877
2025-09-03 10:31:36,501 - distributed.worker - INFO -          dashboard at:           10.6.102.3:43247
2025-09-03 10:31:36,501 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,501 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,501 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,501 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,501 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-mgq051o7
2025-09-03 10:31:36,501 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,510 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:45301
2025-09-03 10:31:36,510 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:45301
2025-09-03 10:31:36,511 - distributed.worker - INFO -          dashboard at:           10.6.102.3:37255
2025-09-03 10:31:36,511 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,511 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,511 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,511 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qtdomfbq
2025-09-03 10:31:36,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,513 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35787
2025-09-03 10:31:36,513 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35787
2025-09-03 10:31:36,513 - distributed.worker - INFO -          dashboard at:           10.6.102.3:34763
2025-09-03 10:31:36,513 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,513 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,513 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,513 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,513 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fg7rpad0
2025-09-03 10:31:36,513 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,516 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:38981
2025-09-03 10:31:36,516 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:38981
2025-09-03 10:31:36,516 - distributed.worker - INFO -          dashboard at:           10.6.102.3:35115
2025-09-03 10:31:36,516 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,516 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,516 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,516 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,516 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fayytwo5
2025-09-03 10:31:36,517 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,518 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:37429
2025-09-03 10:31:36,519 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:37429
2025-09-03 10:31:36,519 - distributed.worker - INFO -          dashboard at:           10.6.102.3:33563
2025-09-03 10:31:36,519 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,519 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,519 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,519 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,519 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3pl9d5pl
2025-09-03 10:31:36,519 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,539 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:40285
2025-09-03 10:31:36,539 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:40285
2025-09-03 10:31:36,539 - distributed.worker - INFO -          dashboard at:           10.6.102.3:42453
2025-09-03 10:31:36,539 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,539 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,539 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,539 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-yfm9x0h6
2025-09-03 10:31:36,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,540 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34127
2025-09-03 10:31:36,541 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34127
2025-09-03 10:31:36,541 - distributed.worker - INFO -          dashboard at:           10.6.102.3:46653
2025-09-03 10:31:36,541 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,541 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,541 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,541 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,541 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z4ocx__4
2025-09-03 10:31:36,541 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,541 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:45563
2025-09-03 10:31:36,541 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:45563
2025-09-03 10:31:36,541 - distributed.worker - INFO -          dashboard at:           10.6.102.3:42127
2025-09-03 10:31:36,541 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,541 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,541 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,541 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,541 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4ojeyv1r
2025-09-03 10:31:36,541 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,544 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35327
2025-09-03 10:31:36,544 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35327
2025-09-03 10:31:36,544 - distributed.worker - INFO -          dashboard at:           10.6.102.3:39671
2025-09-03 10:31:36,544 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,544 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,544 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,544 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,544 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-27lkqt5x
2025-09-03 10:31:36,544 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,565 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35977
2025-09-03 10:31:36,565 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35977
2025-09-03 10:31:36,565 - distributed.worker - INFO -          dashboard at:           10.6.102.3:46563
2025-09-03 10:31:36,565 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,565 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,565 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,565 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,565 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bdouuhn9
2025-09-03 10:31:36,565 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,569 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:46559
2025-09-03 10:31:36,569 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:46559
2025-09-03 10:31:36,569 - distributed.worker - INFO -          dashboard at:           10.6.102.3:39299
2025-09-03 10:31:36,569 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,569 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,569 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,569 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,569 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hb_upqm7
2025-09-03 10:31:36,569 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,571 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:40813
2025-09-03 10:31:36,571 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:40813
2025-09-03 10:31:36,571 - distributed.worker - INFO -          dashboard at:           10.6.102.3:46113
2025-09-03 10:31:36,572 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,572 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,572 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,572 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,572 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gymxne5p
2025-09-03 10:31:36,572 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,593 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33395
2025-09-03 10:31:36,594 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33395
2025-09-03 10:31:36,594 - distributed.worker - INFO -          dashboard at:           10.6.102.3:43073
2025-09-03 10:31:36,594 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,594 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,594 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,594 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-r_4yl_8n
2025-09-03 10:31:36,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,634 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:43281
2025-09-03 10:31:36,634 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:43281
2025-09-03 10:31:36,634 - distributed.worker - INFO -          dashboard at:           10.6.102.3:45355
2025-09-03 10:31:36,634 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,634 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,634 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,634 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,634 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qq_tog9c
2025-09-03 10:31:36,635 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,702 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:41669
2025-09-03 10:31:36,702 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:41669
2025-09-03 10:31:36,702 - distributed.worker - INFO -          dashboard at:           10.6.102.3:41395
2025-09-03 10:31:36,702 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,702 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,702 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,702 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-89kd6xv_
2025-09-03 10:31:36,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,762 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42871
2025-09-03 10:31:36,762 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42871
2025-09-03 10:31:36,762 - distributed.worker - INFO -          dashboard at:           10.6.102.3:40613
2025-09-03 10:31:36,762 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:36,762 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:36,762 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:36,762 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:36,762 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ndgtaoff
2025-09-03 10:31:36,762 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,391 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:43359
2025-09-03 10:31:37,391 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:43359
2025-09-03 10:31:37,391 - distributed.worker - INFO -          dashboard at:           10.6.102.3:33919
2025-09-03 10:31:37,391 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,391 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,391 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,391 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-p3ffro0v
2025-09-03 10:31:37,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,392 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33663
2025-09-03 10:31:37,392 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33663
2025-09-03 10:31:37,392 - distributed.worker - INFO -          dashboard at:           10.6.102.3:46521
2025-09-03 10:31:37,392 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,392 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,392 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,392 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,392 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-os6ns_bj
2025-09-03 10:31:37,392 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,395 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:39383
2025-09-03 10:31:37,395 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:39383
2025-09-03 10:31:37,395 - distributed.worker - INFO -          dashboard at:           10.6.102.3:43381
2025-09-03 10:31:37,395 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,395 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,395 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,395 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,395 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4kyanbfj
2025-09-03 10:31:37,395 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,399 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35369
2025-09-03 10:31:37,399 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35369
2025-09-03 10:31:37,399 - distributed.worker - INFO -          dashboard at:           10.6.102.3:44143
2025-09-03 10:31:37,399 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,399 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,399 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,399 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,399 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-q2u_upg8
2025-09-03 10:31:37,399 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,400 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:38911
2025-09-03 10:31:37,400 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:38911
2025-09-03 10:31:37,400 - distributed.worker - INFO -          dashboard at:           10.6.102.3:44799
2025-09-03 10:31:37,400 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,400 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,400 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,400 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,400 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8rxkka17
2025-09-03 10:31:37,400 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,403 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:38701
2025-09-03 10:31:37,403 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:38701
2025-09-03 10:31:37,403 - distributed.worker - INFO -          dashboard at:           10.6.102.3:35071
2025-09-03 10:31:37,403 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,403 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,403 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,403 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,403 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-okh96g5k
2025-09-03 10:31:37,403 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,405 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35275
2025-09-03 10:31:37,405 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35275
2025-09-03 10:31:37,405 - distributed.worker - INFO -          dashboard at:           10.6.102.3:42901
2025-09-03 10:31:37,405 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,405 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,405 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,405 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,405 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vv64b7m_
2025-09-03 10:31:37,405 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,408 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:38071
2025-09-03 10:31:37,408 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:38071
2025-09-03 10:31:37,408 - distributed.worker - INFO -          dashboard at:           10.6.102.3:38635
2025-09-03 10:31:37,408 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,408 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,408 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,408 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2mha4gmx
2025-09-03 10:31:37,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,409 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:44083
2025-09-03 10:31:37,409 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:44083
2025-09-03 10:31:37,409 - distributed.worker - INFO -          dashboard at:           10.6.102.3:38691
2025-09-03 10:31:37,409 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:46417
2025-09-03 10:31:37,409 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,409 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:46417
2025-09-03 10:31:37,409 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,409 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,409 - distributed.worker - INFO -          dashboard at:           10.6.102.3:46221
2025-09-03 10:31:37,409 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,409 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7335im1x
2025-09-03 10:31:37,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,409 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,409 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,409 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l2j570ug
2025-09-03 10:31:37,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,410 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:38533
2025-09-03 10:31:37,410 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:38533
2025-09-03 10:31:37,410 - distributed.worker - INFO -          dashboard at:           10.6.102.3:38515
2025-09-03 10:31:37,410 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,410 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,410 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,410 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-os8hwiba
2025-09-03 10:31:37,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,415 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:46089
2025-09-03 10:31:37,415 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:46089
2025-09-03 10:31:37,416 - distributed.worker - INFO -          dashboard at:           10.6.102.3:46801
2025-09-03 10:31:37,416 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,416 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,416 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,416 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,416 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xbzjetod
2025-09-03 10:31:37,416 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,485 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34213
2025-09-03 10:31:37,485 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34213
2025-09-03 10:31:37,485 - distributed.worker - INFO -          dashboard at:           10.6.102.3:45885
2025-09-03 10:31:37,485 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,485 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,485 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,485 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,485 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-id68pp6l
2025-09-03 10:31:37,485 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,498 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42107
2025-09-03 10:31:37,498 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42107
2025-09-03 10:31:37,498 - distributed.worker - INFO -          dashboard at:           10.6.102.3:42371
2025-09-03 10:31:37,498 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,498 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,498 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,498 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,498 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6n_nnsdk
2025-09-03 10:31:37,498 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,499 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:36229
2025-09-03 10:31:37,499 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:36229
2025-09-03 10:31:37,499 - distributed.worker - INFO -          dashboard at:           10.6.102.3:34283
2025-09-03 10:31:37,499 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,499 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,499 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,499 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dmky8xiw
2025-09-03 10:31:37,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,503 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:45403
2025-09-03 10:31:37,503 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:45403
2025-09-03 10:31:37,503 - distributed.worker - INFO -          dashboard at:           10.6.102.3:42119
2025-09-03 10:31:37,503 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,503 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,503 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,503 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,503 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3lo4x7_f
2025-09-03 10:31:37,503 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,503 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33573
2025-09-03 10:31:37,503 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33573
2025-09-03 10:31:37,503 - distributed.worker - INFO -          dashboard at:           10.6.102.3:38859
2025-09-03 10:31:37,503 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,503 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,503 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,503 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,504 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6t7yn7ig
2025-09-03 10:31:37,504 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,505 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35191
2025-09-03 10:31:37,505 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35191
2025-09-03 10:31:37,505 - distributed.worker - INFO -          dashboard at:           10.6.102.3:46881
2025-09-03 10:31:37,506 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,506 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,506 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,506 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,506 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8gsz7jv8
2025-09-03 10:31:37,506 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,507 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:38355
2025-09-03 10:31:37,507 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:38355
2025-09-03 10:31:37,507 - distributed.worker - INFO -          dashboard at:           10.6.102.3:37493
2025-09-03 10:31:37,507 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,507 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,507 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,507 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,507 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-15oghyx5
2025-09-03 10:31:37,507 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,510 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42643
2025-09-03 10:31:37,510 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:45431
2025-09-03 10:31:37,510 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42643
2025-09-03 10:31:37,510 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:45431
2025-09-03 10:31:37,510 - distributed.worker - INFO -          dashboard at:           10.6.102.3:36435
2025-09-03 10:31:37,510 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,510 - distributed.worker - INFO -          dashboard at:           10.6.102.3:43355
2025-09-03 10:31:37,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,510 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,510 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,510 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,510 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,510 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ybj8f4yn
2025-09-03 10:31:37,510 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,510 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-98_ilum1
2025-09-03 10:31:37,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,511 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:41525
2025-09-03 10:31:37,511 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:41525
2025-09-03 10:31:37,511 - distributed.worker - INFO -          dashboard at:           10.6.102.3:45877
2025-09-03 10:31:37,511 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,511 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,511 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,511 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-injowk8e
2025-09-03 10:31:37,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,514 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42659
2025-09-03 10:31:37,514 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42659
2025-09-03 10:31:37,514 - distributed.worker - INFO -          dashboard at:           10.6.102.3:33783
2025-09-03 10:31:37,514 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,514 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,514 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,514 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,514 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7_h_krqp
2025-09-03 10:31:37,515 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,539 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:36011
2025-09-03 10:31:37,539 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:36011
2025-09-03 10:31:37,539 - distributed.worker - INFO -          dashboard at:           10.6.102.3:34357
2025-09-03 10:31:37,539 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,539 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,539 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,539 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2e6e_ymd
2025-09-03 10:31:37,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,543 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34641
2025-09-03 10:31:37,543 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34641
2025-09-03 10:31:37,543 - distributed.worker - INFO -          dashboard at:           10.6.102.3:43069
2025-09-03 10:31:37,543 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,543 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,543 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,543 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,543 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4mw6rnsn
2025-09-03 10:31:37,543 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,544 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:44975
2025-09-03 10:31:37,544 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:44975
2025-09-03 10:31:37,544 - distributed.worker - INFO -          dashboard at:           10.6.102.3:44073
2025-09-03 10:31:37,544 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,544 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,544 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,544 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,544 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-execrs8j
2025-09-03 10:31:37,544 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,545 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34337
2025-09-03 10:31:37,545 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34337
2025-09-03 10:31:37,545 - distributed.worker - INFO -          dashboard at:           10.6.102.3:42577
2025-09-03 10:31:37,545 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,545 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,545 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,545 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,545 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xodnx3yv
2025-09-03 10:31:37,545 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,546 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:41591
2025-09-03 10:31:37,546 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33949
2025-09-03 10:31:37,546 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:41591
2025-09-03 10:31:37,546 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33949
2025-09-03 10:31:37,546 - distributed.worker - INFO -          dashboard at:           10.6.102.3:36175
2025-09-03 10:31:37,547 - distributed.worker - INFO -          dashboard at:           10.6.102.3:35103
2025-09-03 10:31:37,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,547 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9qr_od71
2025-09-03 10:31:37,547 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4_tw4qna
2025-09-03 10:31:37,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,563 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42333
2025-09-03 10:31:37,563 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42333
2025-09-03 10:31:37,563 - distributed.worker - INFO -          dashboard at:           10.6.102.3:39707
2025-09-03 10:31:37,563 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,563 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,563 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,563 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,563 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uk3inj2s
2025-09-03 10:31:37,563 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,582 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:40093
2025-09-03 10:31:37,582 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:40093
2025-09-03 10:31:37,582 - distributed.worker - INFO -          dashboard at:           10.6.102.3:45285
2025-09-03 10:31:37,582 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,582 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,582 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,582 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gyvi8nq5
2025-09-03 10:31:37,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,583 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:41971
2025-09-03 10:31:37,583 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:41971
2025-09-03 10:31:37,583 - distributed.worker - INFO -          dashboard at:           10.6.102.3:43739
2025-09-03 10:31:37,583 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,583 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,583 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,583 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,583 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-i033r_y3
2025-09-03 10:31:37,583 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,583 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:40899
2025-09-03 10:31:37,583 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:40899
2025-09-03 10:31:37,583 - distributed.worker - INFO -          dashboard at:           10.6.102.3:42191
2025-09-03 10:31:37,583 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,583 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,583 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,583 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,583 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ixx5rsme
2025-09-03 10:31:37,583 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,587 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35843
2025-09-03 10:31:37,587 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35843
2025-09-03 10:31:37,587 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34543
2025-09-03 10:31:37,587 - distributed.worker - INFO -          dashboard at:           10.6.102.3:41529
2025-09-03 10:31:37,587 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,587 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34543
2025-09-03 10:31:37,587 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,587 - distributed.worker - INFO -          dashboard at:           10.6.102.3:32831
2025-09-03 10:31:37,587 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,587 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,587 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,587 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,587 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,587 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-46dac1ky
2025-09-03 10:31:37,587 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,587 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,587 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_6qdck12
2025-09-03 10:31:37,587 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,588 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:40339
2025-09-03 10:31:37,589 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:40339
2025-09-03 10:31:37,589 - distributed.worker - INFO -          dashboard at:           10.6.102.3:43303
2025-09-03 10:31:37,589 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,589 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:43021
2025-09-03 10:31:37,589 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,589 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,589 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:43021
2025-09-03 10:31:37,589 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,589 - distributed.worker - INFO -          dashboard at:           10.6.102.3:36341
2025-09-03 10:31:37,589 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zh8_8w45
2025-09-03 10:31:37,589 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,589 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,589 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,589 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,589 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,589 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l79a71qu
2025-09-03 10:31:37,589 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,590 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:46319
2025-09-03 10:31:37,590 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:46319
2025-09-03 10:31:37,590 - distributed.worker - INFO -          dashboard at:           10.6.102.3:39045
2025-09-03 10:31:37,591 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,591 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,591 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,591 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ndla7a_l
2025-09-03 10:31:37,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,591 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34163
2025-09-03 10:31:37,591 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34163
2025-09-03 10:31:37,591 - distributed.worker - INFO -          dashboard at:           10.6.102.3:38901
2025-09-03 10:31:37,591 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,591 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,591 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,591 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-d1mv7euh
2025-09-03 10:31:37,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,591 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33471
2025-09-03 10:31:37,591 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33471
2025-09-03 10:31:37,591 - distributed.worker - INFO -          dashboard at:           10.6.102.3:41401
2025-09-03 10:31:37,592 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,592 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,592 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,592 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xvu18s1i
2025-09-03 10:31:37,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,593 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:44999
2025-09-03 10:31:37,593 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:44999
2025-09-03 10:31:37,593 - distributed.worker - INFO -          dashboard at:           10.6.102.3:33961
2025-09-03 10:31:37,593 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,593 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,593 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,593 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,593 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7w8qyksh
2025-09-03 10:31:37,593 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,593 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42103
2025-09-03 10:31:37,593 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42103
2025-09-03 10:31:37,593 - distributed.worker - INFO -          dashboard at:           10.6.102.3:45193
2025-09-03 10:31:37,593 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,593 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,593 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,594 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,594 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-f__pbyn6
2025-09-03 10:31:37,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,595 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:37343
2025-09-03 10:31:37,595 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:37343
2025-09-03 10:31:37,595 - distributed.worker - INFO -          dashboard at:           10.6.102.3:44979
2025-09-03 10:31:37,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,595 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,595 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,595 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_e16feyw
2025-09-03 10:31:37,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,596 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33079
2025-09-03 10:31:37,596 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33079
2025-09-03 10:31:37,596 - distributed.worker - INFO -          dashboard at:           10.6.102.3:45677
2025-09-03 10:31:37,596 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,596 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cdjgku7j
2025-09-03 10:31:37,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,597 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:41923
2025-09-03 10:31:37,597 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:41923
2025-09-03 10:31:37,597 - distributed.worker - INFO -          dashboard at:           10.6.102.3:32939
2025-09-03 10:31:37,597 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,597 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,597 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,597 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-udfxxb_8
2025-09-03 10:31:37,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,598 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:36541
2025-09-03 10:31:37,598 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:36541
2025-09-03 10:31:37,598 - distributed.worker - INFO -          dashboard at:           10.6.102.3:34571
2025-09-03 10:31:37,598 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,598 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,598 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,598 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lwy4x5_4
2025-09-03 10:31:37,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,598 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42669
2025-09-03 10:31:37,598 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35979
2025-09-03 10:31:37,598 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42669
2025-09-03 10:31:37,598 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35979
2025-09-03 10:31:37,598 - distributed.worker - INFO -          dashboard at:           10.6.102.3:43877
2025-09-03 10:31:37,598 - distributed.worker - INFO -          dashboard at:           10.6.102.3:41569
2025-09-03 10:31:37,598 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,598 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34019
2025-09-03 10:31:37,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,598 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,598 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,598 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34019
2025-09-03 10:31:37,598 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,598 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,598 - distributed.worker - INFO -          dashboard at:           10.6.102.3:32867
2025-09-03 10:31:37,598 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,598 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z9n7suna
2025-09-03 10:31:37,598 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,598 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lfwzqjcg
2025-09-03 10:31:37,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,598 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,599 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,599 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n1f2t9li
2025-09-03 10:31:37,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,612 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:46863
2025-09-03 10:31:37,612 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:46863
2025-09-03 10:31:37,612 - distributed.worker - INFO -          dashboard at:           10.6.102.3:35439
2025-09-03 10:31:37,612 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,612 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,612 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,612 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,612 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-b_13ws0h
2025-09-03 10:31:37,612 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,679 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:43145
2025-09-03 10:31:37,679 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:43145
2025-09-03 10:31:37,679 - distributed.worker - INFO -          dashboard at:           10.6.102.3:40701
2025-09-03 10:31:37,679 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,679 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,679 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,679 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,679 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pd79jbze
2025-09-03 10:31:37,679 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,709 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:42039
2025-09-03 10:31:37,709 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:42039
2025-09-03 10:31:37,709 - distributed.worker - INFO -          dashboard at:           10.6.102.3:33391
2025-09-03 10:31:37,709 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,709 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,710 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,710 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,710 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_q0hpuee
2025-09-03 10:31:37,710 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,713 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:44949
2025-09-03 10:31:37,713 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:44949
2025-09-03 10:31:37,713 - distributed.worker - INFO -          dashboard at:           10.6.102.3:33963
2025-09-03 10:31:37,713 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,713 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,713 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,713 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6azc6esp
2025-09-03 10:31:37,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,714 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33933
2025-09-03 10:31:37,714 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33933
2025-09-03 10:31:37,714 - distributed.worker - INFO -          dashboard at:           10.6.102.3:44753
2025-09-03 10:31:37,714 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,714 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,714 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,714 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,714 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kqw56srh
2025-09-03 10:31:37,714 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,714 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:44429
2025-09-03 10:31:37,714 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:44429
2025-09-03 10:31:37,714 - distributed.worker - INFO -          dashboard at:           10.6.102.3:40509
2025-09-03 10:31:37,714 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,714 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,714 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,714 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,714 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-p69vxton
2025-09-03 10:31:37,714 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,720 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34583
2025-09-03 10:31:37,720 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34583
2025-09-03 10:31:37,720 - distributed.worker - INFO -          dashboard at:           10.6.102.3:34113
2025-09-03 10:31:37,720 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,720 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,720 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,720 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,720 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l6_iv8a6
2025-09-03 10:31:37,720 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,725 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:35775
2025-09-03 10:31:37,725 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:35775
2025-09-03 10:31:37,725 - distributed.worker - INFO -          dashboard at:           10.6.102.3:32921
2025-09-03 10:31:37,725 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,725 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,725 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,725 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,725 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2ygvv580
2025-09-03 10:31:37,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,733 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:41673
2025-09-03 10:31:37,733 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:41673
2025-09-03 10:31:37,733 - distributed.worker - INFO -          dashboard at:           10.6.102.3:37909
2025-09-03 10:31:37,733 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,733 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,733 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,733 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,733 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rjo0x6nl
2025-09-03 10:31:37,733 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,737 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:34743
2025-09-03 10:31:37,738 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:34743
2025-09-03 10:31:37,738 - distributed.worker - INFO -          dashboard at:           10.6.102.3:43925
2025-09-03 10:31:37,738 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,738 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,738 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,738 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,738 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jdk9v07n
2025-09-03 10:31:37,738 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,741 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.3:33807
2025-09-03 10:31:37,741 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.3:33807
2025-09-03 10:31:37,741 - distributed.worker - INFO -          dashboard at:           10.6.102.3:44875
2025-09-03 10:31:37,741 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:37,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:37,741 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:37,741 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:37,741 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9o_7bkjw
2025-09-03 10:31:37,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,012 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,013 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,014 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,015 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,023 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,024 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,026 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,034 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,035 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,035 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,037 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,045 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,046 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,046 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,048 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,056 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,058 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,058 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,060 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,067 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,068 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,068 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,070 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,079 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,080 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,081 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,089 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,090 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,091 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,092 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,101 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,102 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,102 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,104 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,112 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,113 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,113 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,115 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,122 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,123 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,124 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,125 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,134 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,135 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,135 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,137 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,145 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,146 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,146 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,148 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,156 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,157 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,157 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,159 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,167 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,168 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,168 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,170 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,178 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,179 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,179 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,181 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,189 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,190 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,190 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,192 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,200 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,201 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,202 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,203 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,211 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,212 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,213 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,214 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,222 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,224 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,224 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,226 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,234 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,235 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,235 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,239 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,245 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,247 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,252 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,256 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,257 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,257 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,259 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:38,267 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:38,269 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:38,269 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:38,271 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:39,564 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:39,565 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:39,565 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:39,567 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,209 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,210 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,211 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,212 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:42,329 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:42,330 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:42,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:42,332 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,977 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,979 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,979 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,981 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:44,990 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:44,991 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:44,991 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:44,993 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,823 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,824 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,826 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,836 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,837 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,837 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,839 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,848 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,849 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,849 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,851 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,860 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,861 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,861 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,863 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,872 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,874 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,874 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,876 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,885 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,886 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,888 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,901 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,905 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,909 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,911 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,911 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,911 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,913 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,923 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,923 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,925 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,934 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,935 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,936 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,937 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,946 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,947 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,947 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,949 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,958 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,959 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,959 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,961 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,970 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,972 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,972 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,974 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,983 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,984 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,984 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,986 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:45,995 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:45,996 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,996 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,998 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,007 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,008 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,009 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,010 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,020 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,022 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,022 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,023 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,032 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,034 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,034 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,036 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,044 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,046 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,046 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,048 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,057 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,058 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,060 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,071 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,072 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,072 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,074 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,083 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,085 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,085 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,086 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,108 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,110 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,110 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,112 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,132 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,134 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,134 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,136 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,144 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,146 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,146 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,148 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,170 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,171 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,174 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,194 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,195 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,195 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,197 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,218 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,220 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,220 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,221 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,231 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,232 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,232 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,234 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,243 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,244 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,244 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,246 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,268 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,270 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,271 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,280 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,282 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,284 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,292 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,294 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,294 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,296 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,305 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,306 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,308 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,317 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,319 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,319 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,321 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,457 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,459 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,459 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,460 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,397 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,399 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,399 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,401 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,188 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,189 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,189 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,191 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,268 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,270 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,272 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,619 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,620 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,620 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,622 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,646 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,647 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,648 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,649 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,659 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,661 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,661 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,663 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,740 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,742 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,744 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,754 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,755 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,756 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,757 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,781 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,783 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,783 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,784 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,822 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,823 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,825 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:52,849 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:52,851 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:52,851 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:52,853 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,803 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,807 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,807 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,812 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,816 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,817 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,819 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,830 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,831 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,831 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,833 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,845 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,847 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,847 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,851 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:58,858 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:58,860 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:58,860 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:58,862 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,171 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,172 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,174 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,186 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,187 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,187 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,189 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,200 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,202 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,202 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,204 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,215 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,216 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,218 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,229 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,231 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,231 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,233 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,244 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,245 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,246 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,247 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,259 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,261 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,261 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,263 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,274 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,276 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,276 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,278 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,289 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,291 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,293 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,303 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,305 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,307 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:00,318 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:00,320 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,320 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,321 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:06,512 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,515 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,517 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,520 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,541 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,541 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,543 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,546 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,566 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,570 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,573 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:06,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:09,020 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:09,032 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:09,042 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:09,052 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:09,064 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:09,075 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:10,186 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,187 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,188 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,189 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,202 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,203 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,203 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,205 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,218 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,219 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,220 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,221 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,234 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,235 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,235 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,237 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,251 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,255 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,255 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,260 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,265 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,266 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,266 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,268 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,280 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,282 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,284 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,297 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,298 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,298 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,300 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,312 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,314 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,315 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,329 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,330 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,332 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,344 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,346 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,346 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,347 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,569 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:16,829 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:23,195 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:23,828 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:23,856 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:29,811 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:31,310 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:36,697 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:41,570 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:46,163 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:46,164 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:46,164 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:46,166 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:47,829 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:33:02,309 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:35:51,428 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,430 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,455 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,457 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,576 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,578 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,631 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,636 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,643 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,720 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,724 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,725 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,726 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,795 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,801 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,879 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,884 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,892 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,898 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,082 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,083 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,086 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,090 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,092 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,095 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,223 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,224 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,078 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,079 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,084 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,084 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,085 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,088 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,126 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,127 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,231 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,232 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,232 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,238 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,379 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,382 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,455 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,461 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,463 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,468 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,480 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,481 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,492 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,493 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,505 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,506 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,571 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,573 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,599 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,600 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,601 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,603 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,605 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,611 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,612 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,617 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,860 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,862 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,937 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,938 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,989 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,995 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,003 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,010 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,053 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,059 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,293 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,298 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,307 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,317 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,320 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,322 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,353 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,358 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,869 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,875 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,903 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,905 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,907 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,913 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,136 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,138 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,225 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,228 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,282 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,287 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,297 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,299 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,317 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,324 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,326 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,329 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,388 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,395 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,650 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,651 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,761 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,763 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,887 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,889 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,005 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,006 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,082 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,084 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,225 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,228 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,266 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,267 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,523 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,525 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,639 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,794 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,795 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,997 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,998 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,026 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,033 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,109 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,115 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,159 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,165 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,227 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,232 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,334 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,339 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,369 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,379 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,493 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,494 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,639 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,645 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,663 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,665 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,706 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,708 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,725 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,726 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,878 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,880 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,902 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,904 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,904 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,909 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,914 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,915 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,338 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,340 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,348 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,349 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,400 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,402 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,628 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,631 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,803 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,808 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,897 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,898 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,915 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,917 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,296 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,633 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,906 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,907 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,229 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,237 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,820 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,822 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,829 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,911 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,916 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,026 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,028 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,989 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,994 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,338 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,343 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,412 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,417 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,620 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,622 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,305 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,310 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,229 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,236 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,616 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,618 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,801 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,807 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:05,015 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:05,020 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:05,612 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:05,614 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:08,970 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:08,976 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:22,886 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,888 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,888 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,894 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,900 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,903 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,905 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,905 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,911 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,914 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,928 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,930 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,933 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,938 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,944 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,946 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,389 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,391 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,396 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,398 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,400 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,402 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,402 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,404 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,408 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,416 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,500 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,501 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,502 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,503 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,508 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,511 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,510 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,515 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,526 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,526 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,528 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,528 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,530 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,532 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,531 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,534 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,536 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,536 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,550 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,552 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,554 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,556 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,572 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,574 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,793 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,798 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,798 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,803 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,833 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,835 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,837 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,839 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,841 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,846 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,845 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,848 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,850 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,853 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,862 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,864 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,869 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,872 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,876 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,878 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,884 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,884 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,887 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,887 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,036 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,038 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,071 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,075 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,076 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,078 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,084 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,089 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,094 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,097 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,100 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,102 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,117 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,120 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,119 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,124 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,126 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,131 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,227 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,229 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,230 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,232 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,237 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,239 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,333 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,388 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,390 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,390 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,393 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,439 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,441 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,459 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,462 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,499 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,502 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,580 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,596 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,598 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,630 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,633 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,633 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,633 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,635 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,635 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,646 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,668 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,670 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,674 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,677 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,678 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,686 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,739 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,742 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,743 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,745 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,749 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,752 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,757 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,759 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,854 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,854 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,856 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,856 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,857 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,859 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,901 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,907 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,925 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,925 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,927 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,928 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,932 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,934 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,938 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,940 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,941 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,943 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,943 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,946 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,947 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,949 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,014 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,016 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,017 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,019 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,036 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,047 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,049 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,077 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,079 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,155 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,157 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,218 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,220 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,394 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,396 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,403 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,405 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,659 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,661 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,707 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,708 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,709 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,716 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,078 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,085 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,297 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,299 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,399 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,401 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,506 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,508 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,525 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,527 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,676 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,678 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,791 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,796 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:28,930 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:28,933 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:28,961 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:28,963 - distributed.utils - INFO - Reload module qme_vars from .py file
