Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-04 11:46:25,090 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:35315'
2025-09-04 11:46:25,097 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:45895'
2025-09-04 11:46:25,100 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:36025'
2025-09-04 11:46:25,105 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:38167'
2025-09-04 11:46:25,110 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:46883'
2025-09-04 11:46:25,115 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:43007'
2025-09-04 11:46:25,118 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:34985'
2025-09-04 11:46:25,122 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:36073'
2025-09-04 11:46:25,127 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:42553'
2025-09-04 11:46:25,133 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:46775'
2025-09-04 11:46:25,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:36445'
2025-09-04 11:46:25,140 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:36519'
2025-09-04 11:46:25,144 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:39187'
2025-09-04 11:46:25,147 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:33397'
2025-09-04 11:46:25,152 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:32801'
2025-09-04 11:46:25,156 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:40763'
2025-09-04 11:46:25,160 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:43481'
2025-09-04 11:46:25,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:38259'
2025-09-04 11:46:25,170 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:43395'
2025-09-04 11:46:25,174 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:33295'
2025-09-04 11:46:25,245 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:41459'
2025-09-04 11:46:25,249 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:36083'
2025-09-04 11:46:25,254 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:39615'
2025-09-04 11:46:25,259 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:41103'
2025-09-04 11:46:25,263 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:39217'
2025-09-04 11:46:25,268 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:45679'
2025-09-04 11:46:25,272 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:34799'
2025-09-04 11:46:25,277 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:37993'
2025-09-04 11:46:25,281 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:38345'
2025-09-04 11:46:25,285 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:39019'
2025-09-04 11:46:25,289 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:46605'
2025-09-04 11:46:25,294 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:38805'
2025-09-04 11:46:25,298 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:33013'
2025-09-04 11:46:25,304 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:35567'
2025-09-04 11:46:25,309 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:44027'
2025-09-04 11:46:25,314 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:38183'
2025-09-04 11:46:25,318 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:41289'
2025-09-04 11:46:25,323 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:38783'
2025-09-04 11:46:25,327 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:34501'
2025-09-04 11:46:25,331 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:44323'
2025-09-04 11:46:25,335 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:37395'
2025-09-04 11:46:25,340 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:35041'
2025-09-04 11:46:25,345 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:37097'
2025-09-04 11:46:25,349 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:34285'
2025-09-04 11:46:25,355 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:46703'
2025-09-04 11:46:25,361 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:41223'
2025-09-04 11:46:25,365 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:34711'
2025-09-04 11:46:25,370 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:43781'
2025-09-04 11:46:25,374 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:38485'
2025-09-04 11:46:25,377 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:46369'
2025-09-04 11:46:25,382 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:45901'
2025-09-04 11:46:25,387 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.103.56:34317'
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:39133
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:35349
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:45703
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:33845
2025-09-04 11:46:26,561 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:39133
2025-09-04 11:46:26,561 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:35349
2025-09-04 11:46:26,561 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:45703
2025-09-04 11:46:26,561 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:33845
2025-09-04 11:46:26,561 - distributed.worker - INFO -          dashboard at:          10.6.103.56:38335
2025-09-04 11:46:26,561 - distributed.worker - INFO -          dashboard at:          10.6.103.56:41277
2025-09-04 11:46:26,561 - distributed.worker - INFO -          dashboard at:          10.6.103.56:45595
2025-09-04 11:46:26,561 - distributed.worker - INFO -          dashboard at:          10.6.103.56:44101
2025-09-04 11:46:26,561 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,561 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:41577
2025-09-04 11:46:26,561 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,561 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,561 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,561 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:36201
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:33023
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:45191
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:45717
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:32927
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:35595
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:41577
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:43307
2025-09-04 11:46:26,561 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:43169
2025-09-04 11:46:26,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:36201
2025-09-04 11:46:26,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:33023
2025-09-04 11:46:26,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:45191
2025-09-04 11:46:26,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:45717
2025-09-04 11:46:26,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:32927
2025-09-04 11:46:26,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:35595
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -          dashboard at:          10.6.103.56:46611
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:43307
2025-09-04 11:46:26,562 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:43169
2025-09-04 11:46:26,562 - distributed.worker - INFO -          dashboard at:          10.6.103.56:41221
2025-09-04 11:46:26,562 - distributed.worker - INFO -          dashboard at:          10.6.103.56:32847
2025-09-04 11:46:26,562 - distributed.worker - INFO -          dashboard at:          10.6.103.56:34427
2025-09-04 11:46:26,562 - distributed.worker - INFO -          dashboard at:          10.6.103.56:33271
2025-09-04 11:46:26,562 - distributed.worker - INFO -          dashboard at:          10.6.103.56:42367
2025-09-04 11:46:26,562 - distributed.worker - INFO -          dashboard at:          10.6.103.56:40385
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-uy3dquxo
2025-09-04 11:46:26,562 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-o2n6csta
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-45akue6i
2025-09-04 11:46:26,562 - distributed.worker - INFO -          dashboard at:          10.6.103.56:37089
2025-09-04 11:46:26,562 - distributed.worker - INFO -          dashboard at:          10.6.103.56:44577
2025-09-04 11:46:26,562 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,562 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,562 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,562 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,562 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,562 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-yoccb58d
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-yzpl5k5f
2025-09-04 11:46:26,562 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-_zh3iwkg
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-ege_ktk_
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-gioc0fk9
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-9645sivk
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-x42jo0gq
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-jbr2nwra
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-r0e1ct4q
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-5tk7p_90
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,562 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,570 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:39825
2025-09-04 11:46:26,570 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:39825
2025-09-04 11:46:26,570 - distributed.worker - INFO -          dashboard at:          10.6.103.56:37773
2025-09-04 11:46:26,570 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,570 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,570 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,570 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,570 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-9y5l4q7f
2025-09-04 11:46:26,571 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,573 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:40925
2025-09-04 11:46:26,573 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:40925
2025-09-04 11:46:26,573 - distributed.worker - INFO -          dashboard at:          10.6.103.56:42301
2025-09-04 11:46:26,573 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,573 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,573 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,573 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,574 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-qtzbq1dx
2025-09-04 11:46:26,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,577 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:39219
2025-09-04 11:46:26,577 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:39219
2025-09-04 11:46:26,577 - distributed.worker - INFO -          dashboard at:          10.6.103.56:36535
2025-09-04 11:46:26,577 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,577 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,577 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,577 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-c21bhe1t
2025-09-04 11:46:26,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,577 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:40659
2025-09-04 11:46:26,577 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:40659
2025-09-04 11:46:26,577 - distributed.worker - INFO -          dashboard at:          10.6.103.56:41463
2025-09-04 11:46:26,577 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,577 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,577 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,577 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-046zv3ob
2025-09-04 11:46:26,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,581 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:37227
2025-09-04 11:46:26,582 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:37227
2025-09-04 11:46:26,582 - distributed.worker - INFO -          dashboard at:          10.6.103.56:45611
2025-09-04 11:46:26,582 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,582 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,582 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,582 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-z9ieo69z
2025-09-04 11:46:26,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,584 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:41095
2025-09-04 11:46:26,584 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:41095
2025-09-04 11:46:26,584 - distributed.worker - INFO -          dashboard at:          10.6.103.56:34727
2025-09-04 11:46:26,584 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,584 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,584 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,584 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,584 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-6p8n7czj
2025-09-04 11:46:26,584 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,584 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:44871
2025-09-04 11:46:26,584 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:44871
2025-09-04 11:46:26,584 - distributed.worker - INFO -          dashboard at:          10.6.103.56:35193
2025-09-04 11:46:26,584 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,584 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,584 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,584 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,585 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-vgjxc433
2025-09-04 11:46:26,585 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,588 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:35311
2025-09-04 11:46:26,588 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:35311
2025-09-04 11:46:26,588 - distributed.worker - INFO -          dashboard at:          10.6.103.56:37189
2025-09-04 11:46:26,588 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,588 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,588 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,588 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,588 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-rbjsb2p1
2025-09-04 11:46:26,588 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,588 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,588 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,588 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,589 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,592 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:41029
2025-09-04 11:46:26,592 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:41029
2025-09-04 11:46:26,592 - distributed.worker - INFO -          dashboard at:          10.6.103.56:40375
2025-09-04 11:46:26,592 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,592 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,592 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,592 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-_vor4tp0
2025-09-04 11:46:26,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,596 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,596 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,597 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,601 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,602 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,604 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,606 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,607 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,607 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,609 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,610 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,612 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,612 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,613 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,614 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,615 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,615 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,617 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,619 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,620 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,620 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,621 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,622 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,622 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,624 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,624 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,625 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,627 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,627 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,628 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,629 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:46109
2025-09-04 11:46:26,629 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:46109
2025-09-04 11:46:26,629 - distributed.worker - INFO -          dashboard at:          10.6.103.56:32825
2025-09-04 11:46:26,629 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,629 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,629 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,629 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,629 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-9pxgkdhw
2025-09-04 11:46:26,629 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,630 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,630 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,631 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,632 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,633 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,633 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,633 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,634 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,635 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,635 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,635 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,636 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,637 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,637 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,637 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,638 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,638 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,639 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,639 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,641 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,641 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,642 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,642 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,643 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,643 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,644 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,645 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,645 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,646 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,647 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,647 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,648 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,648 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,648 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,649 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,650 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,650 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,651 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:37443
2025-09-04 11:46:26,651 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:37443
2025-09-04 11:46:26,651 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,652 - distributed.worker - INFO -          dashboard at:          10.6.103.56:45301
2025-09-04 11:46:26,652 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,652 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,652 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,652 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,652 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-n0962wa7
2025-09-04 11:46:26,652 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,652 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,652 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,653 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,654 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,654 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,654 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,656 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,676 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,677 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,677 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,679 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,679 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,680 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,680 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,682 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,688 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:34533
2025-09-04 11:46:26,688 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:34533
2025-09-04 11:46:26,688 - distributed.worker - INFO -          dashboard at:          10.6.103.56:39071
2025-09-04 11:46:26,688 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,688 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,688 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,688 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,688 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-u754cn7a
2025-09-04 11:46:26,688 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,691 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:33089
2025-09-04 11:46:26,691 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:33089
2025-09-04 11:46:26,692 - distributed.worker - INFO -          dashboard at:          10.6.103.56:45853
2025-09-04 11:46:26,692 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,692 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,692 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,692 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,692 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-5fbi5ml9
2025-09-04 11:46:26,692 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,711 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,712 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,713 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,714 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,715 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,715 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,716 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,719 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:46681
2025-09-04 11:46:26,719 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:46681
2025-09-04 11:46:26,719 - distributed.worker - INFO -          dashboard at:          10.6.103.56:40159
2025-09-04 11:46:26,719 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,719 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,719 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,719 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,719 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-6wf2ttke
2025-09-04 11:46:26,719 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,727 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:42961
2025-09-04 11:46:26,727 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:42961
2025-09-04 11:46:26,727 - distributed.worker - INFO -          dashboard at:          10.6.103.56:43541
2025-09-04 11:46:26,727 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,727 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,727 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,727 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,727 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-r17seh7x
2025-09-04 11:46:26,727 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,744 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,745 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,747 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,752 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,753 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,753 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,755 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,762 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:42427
2025-09-04 11:46:26,762 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:42427
2025-09-04 11:46:26,763 - distributed.worker - INFO -          dashboard at:          10.6.103.56:35233
2025-09-04 11:46:26,763 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,763 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,763 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,763 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,763 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-vg3ffpjj
2025-09-04 11:46:26,763 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,769 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:39089
2025-09-04 11:46:26,769 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:39089
2025-09-04 11:46:26,769 - distributed.worker - INFO -          dashboard at:          10.6.103.56:44129
2025-09-04 11:46:26,769 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,769 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,769 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,769 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,769 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-79wi9_lh
2025-09-04 11:46:26,769 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,790 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,790 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,791 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,792 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,798 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,799 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,799 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,800 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,807 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:33191
2025-09-04 11:46:26,807 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:33191
2025-09-04 11:46:26,807 - distributed.worker - INFO -          dashboard at:          10.6.103.56:33299
2025-09-04 11:46:26,807 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,807 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,807 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,807 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,807 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-z83ah8zw
2025-09-04 11:46:26,808 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,822 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:35707
2025-09-04 11:46:26,822 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:35707
2025-09-04 11:46:26,822 - distributed.worker - INFO -          dashboard at:          10.6.103.56:41359
2025-09-04 11:46:26,822 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,822 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,822 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,822 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,822 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-uy9plr01
2025-09-04 11:46:26,822 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,828 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:42573
2025-09-04 11:46:26,828 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:42573
2025-09-04 11:46:26,828 - distributed.worker - INFO -          dashboard at:          10.6.103.56:38085
2025-09-04 11:46:26,828 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,828 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,828 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,828 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,828 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-wo8pdgd9
2025-09-04 11:46:26,828 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,831 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:45557
2025-09-04 11:46:26,832 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:45557
2025-09-04 11:46:26,832 - distributed.worker - INFO -          dashboard at:          10.6.103.56:32819
2025-09-04 11:46:26,832 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,832 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,832 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,832 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,832 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-zxhgrsil
2025-09-04 11:46:26,832 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,833 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,834 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,836 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,848 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,849 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,849 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,850 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,854 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,854 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,854 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,856 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,858 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:26,859 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,859 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,861 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:26,999 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:34253
2025-09-04 11:46:26,999 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:34253
2025-09-04 11:46:26,999 - distributed.worker - INFO -          dashboard at:          10.6.103.56:39493
2025-09-04 11:46:26,999 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:26,999 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:26,999 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:26,999 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:26,999 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-ixkupmtr
2025-09-04 11:46:26,999 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,002 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:35795
2025-09-04 11:46:27,002 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:35795
2025-09-04 11:46:27,002 - distributed.worker - INFO -          dashboard at:          10.6.103.56:33307
2025-09-04 11:46:27,002 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,002 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,002 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,002 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,002 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-v1ace7jl
2025-09-04 11:46:27,002 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,003 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:38819
2025-09-04 11:46:27,003 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:38819
2025-09-04 11:46:27,003 - distributed.worker - INFO -          dashboard at:          10.6.103.56:37385
2025-09-04 11:46:27,003 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,003 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,003 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,003 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,003 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-fjo7p3m0
2025-09-04 11:46:27,003 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,007 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:39577
2025-09-04 11:46:27,007 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:39577
2025-09-04 11:46:27,007 - distributed.worker - INFO -          dashboard at:          10.6.103.56:38925
2025-09-04 11:46:27,007 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,007 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,007 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,007 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-up9eazr3
2025-09-04 11:46:27,007 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:34737
2025-09-04 11:46:27,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,007 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:34737
2025-09-04 11:46:27,007 - distributed.worker - INFO -          dashboard at:          10.6.103.56:38279
2025-09-04 11:46:27,007 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,007 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,007 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,007 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-jy5v186k
2025-09-04 11:46:27,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,012 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:43535
2025-09-04 11:46:27,012 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:43535
2025-09-04 11:46:27,012 - distributed.worker - INFO -          dashboard at:          10.6.103.56:43605
2025-09-04 11:46:27,012 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,012 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,012 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,012 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-vyfiwq9q
2025-09-04 11:46:27,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,012 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:42895
2025-09-04 11:46:27,012 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:42895
2025-09-04 11:46:27,012 - distributed.worker - INFO -          dashboard at:          10.6.103.56:40953
2025-09-04 11:46:27,012 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,012 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,012 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,012 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-m5mmlvbv
2025-09-04 11:46:27,013 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,013 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:41489
2025-09-04 11:46:27,013 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:41489
2025-09-04 11:46:27,013 - distributed.worker - INFO -          dashboard at:          10.6.103.56:35995
2025-09-04 11:46:27,013 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,013 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,013 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,013 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,013 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-8m0cb4s1
2025-09-04 11:46:27,013 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,013 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:44931
2025-09-04 11:46:27,013 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:44931
2025-09-04 11:46:27,014 - distributed.worker - INFO -          dashboard at:          10.6.103.56:33185
2025-09-04 11:46:27,014 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,014 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,014 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,014 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,014 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-kkx5d_4u
2025-09-04 11:46:27,014 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,015 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:40901
2025-09-04 11:46:27,016 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:40901
2025-09-04 11:46:27,016 - distributed.worker - INFO -          dashboard at:          10.6.103.56:44151
2025-09-04 11:46:27,016 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,016 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,016 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,016 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,016 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-4yblrpag
2025-09-04 11:46:27,016 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,016 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,016 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,016 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,017 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,018 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:37053
2025-09-04 11:46:27,018 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:37053
2025-09-04 11:46:27,018 - distributed.worker - INFO -          dashboard at:          10.6.103.56:41747
2025-09-04 11:46:27,018 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,018 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,018 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,018 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,018 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-_moo7pvj
2025-09-04 11:46:27,018 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,019 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:43623
2025-09-04 11:46:27,019 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:43623
2025-09-04 11:46:27,020 - distributed.worker - INFO -          dashboard at:          10.6.103.56:39321
2025-09-04 11:46:27,020 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,020 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,020 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,020 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,020 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-gg5arfpe
2025-09-04 11:46:27,020 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,021 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:39125
2025-09-04 11:46:27,021 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:39125
2025-09-04 11:46:27,021 - distributed.worker - INFO -          dashboard at:          10.6.103.56:41215
2025-09-04 11:46:27,021 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,021 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,021 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:36265
2025-09-04 11:46:27,021 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,021 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,021 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:36265
2025-09-04 11:46:27,022 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-e_34xcv4
2025-09-04 11:46:27,022 - distributed.worker - INFO -          dashboard at:          10.6.103.56:45479
2025-09-04 11:46:27,022 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,022 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,022 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,022 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,022 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,022 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-hviuxy_w
2025-09-04 11:46:27,022 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,023 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,023 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,024 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,031 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,031 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,031 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,032 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,033 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:32777
2025-09-04 11:46:27,034 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:32777
2025-09-04 11:46:27,034 - distributed.worker - INFO -          dashboard at:          10.6.103.56:38049
2025-09-04 11:46:27,034 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,034 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,034 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,034 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,034 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-8r1sgxwa
2025-09-04 11:46:27,034 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,035 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,037 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,037 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,038 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,039 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,039 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,039 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,040 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,042 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:38047
2025-09-04 11:46:27,042 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:38047
2025-09-04 11:46:27,042 - distributed.worker - INFO -          dashboard at:          10.6.103.56:43613
2025-09-04 11:46:27,042 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,042 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,042 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,042 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,042 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-65geegbw
2025-09-04 11:46:27,042 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,042 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:34945
2025-09-04 11:46:27,042 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:34945
2025-09-04 11:46:27,042 - distributed.worker - INFO -          dashboard at:          10.6.103.56:46621
2025-09-04 11:46:27,042 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,043 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,043 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,043 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,043 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-cwtogdwf
2025-09-04 11:46:27,043 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,043 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,043 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,043 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,044 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,045 - distributed.worker - INFO -       Start worker at:    tcp://10.6.103.56:34335
2025-09-04 11:46:27,045 - distributed.worker - INFO -          Listening to:    tcp://10.6.103.56:34335
2025-09-04 11:46:27,045 - distributed.worker - INFO -          dashboard at:          10.6.103.56:44357
2025-09-04 11:46:27,045 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,045 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,045 - distributed.worker - INFO -               Threads:                          2
2025-09-04 11:46:27,045 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-04 11:46:27,045 - distributed.worker - INFO -       Local Directory: /jobfs/148723025.gadi-pbs/dask-scratch-space/worker-c6msoyfu
2025-09-04 11:46:27,045 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,047 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,048 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,048 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,049 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,050 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,050 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,050 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,052 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,056 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,057 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,059 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,060 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,061 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,061 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,063 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,063 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,063 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,063 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,064 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,069 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,070 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,071 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,071 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,072 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,072 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,073 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,074 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,074 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,075 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,075 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,076 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,076 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,076 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,077 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,078 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,078 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,078 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,080 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,080 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,081 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,081 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,082 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-04 11:46:27,083 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:27,083 - distributed.worker - INFO -         Registered to:     tcp://10.6.103.37:8707
2025-09-04 11:46:27,083 - distributed.worker - INFO - -------------------------------------------------
2025-09-04 11:46:27,085 - distributed.core - INFO - Starting established connection to tcp://10.6.103.37:8707
2025-09-04 11:46:42,752 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,752 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,753 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,754 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,754 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,754 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,754 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,754 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,754 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,754 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,754 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,755 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,755 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,755 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,755 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,755 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,755 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,755 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,755 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,755 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,755 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,755 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,756 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,755 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,756 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,756 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,756 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,756 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,756 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,758 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,758 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,758 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,758 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,758 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,758 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,757 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,759 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,759 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,758 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,759 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,759 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,759 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,759 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,759 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,760 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,760 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,760 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,760 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,761 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,761 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,759 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,761 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,761 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,762 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,762 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,762 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,762 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,765 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,767 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,766 - distributed.worker - INFO - Starting Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 11:46:42,768 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,767 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:42,775 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-04 11:46:45,780 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,780 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,781 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,781 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,781 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,781 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,781 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,781 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,783 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,783 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,783 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,783 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,783 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,783 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,783 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,784 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,784 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,784 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,786 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,786 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,786 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,786 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,786 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,786 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,786 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,786 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,786 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,786 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,786 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,786 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,787 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,787 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,787 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,787 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,787 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,785 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,787 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,787 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,787 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,787 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,788 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,788 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,788 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,789 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,790 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,790 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,790 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,790 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,790 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,787 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,788 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 11:46:45,791 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,791 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,792 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,793 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:45,793 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-04 11:46:46,232 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,233 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,233 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,233 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,233 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,233 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,233 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,233 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,234 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,234 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,234 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,234 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,234 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,234 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,234 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,234 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,234 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,235 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,235 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,235 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,235 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,235 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,235 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,235 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,236 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,237 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,237 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,237 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,237 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,237 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,237 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,237 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,237 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,237 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,237 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,237 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,237 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,237 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,238 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,238 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,238 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,238 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,238 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,238 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,238 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,238 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,238 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,238 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,238 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,238 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,238 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,239 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,239 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,239 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,238 - distributed.worker - INFO - Starting Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 11:46:46,239 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,239 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,239 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,239 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,239 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,239 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,240 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,240 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,240 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,240 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,240 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,241 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,242 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,243 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,243 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,243 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,243 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,244 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,245 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-04 11:46:46,665 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,666 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,667 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,667 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,667 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,667 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,667 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,667 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,667 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,667 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,667 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,668 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,668 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,668 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,668 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,668 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,668 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,668 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,668 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,668 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,668 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,668 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,669 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,670 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,670 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,670 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,670 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,670 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,670 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,670 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,670 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,670 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,670 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,670 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,670 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,670 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,670 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,670 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,670 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,671 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,671 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,671 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,671 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,671 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,671 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,671 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,671 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,671 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,671 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,671 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,671 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,671 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 11:46:46,671 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,672 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,672 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,672 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,672 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,672 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,672 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,672 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,672 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,673 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,673 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,673 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,673 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,673 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,673 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,673 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,674 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,674 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,674 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,674 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,675 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,675 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:46:46,675 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-04 11:50:12,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:12,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:48,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:50,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:50,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:50,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:50,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:50,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:51,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:52,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:52,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:52,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:53,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:53,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:54,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:54,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:55,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:55,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:55,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:55,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:55,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:56,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:56,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:56,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:56,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:56,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:57,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:57,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:57,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:57,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:57,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:57,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:50:58,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:00,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:00,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:00,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:00,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:01,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:01,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:01,196 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:01,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:03,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:03,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:03,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:05,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:07,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:15,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:17,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:18,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:18,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:19,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:20,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:20,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:20,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:20,803 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:20,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:20,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:21,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:21,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:22,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:22,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:22,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:23,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:24,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:26,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:26,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:26,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:28,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:28,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:29,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:30,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:32,713 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:33,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:46,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:48,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:48,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:49,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:50,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:50,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:50,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:50,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:50,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:51,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:51,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:52,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:52,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:53,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:53,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:54,170 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:54,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:54,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:55,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:55,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:56,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:57,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:58,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:58,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:58,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:58,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:58,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:51:59,903 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:00,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:03,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:09,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:10,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:10,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:11,006 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:11,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:11,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:11,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:12,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:12,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:12,693 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:12,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:12,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:13,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:13,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:14,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:14,592 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:15,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:15,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:15,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:16,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:16,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:16,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:16,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:16,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:16,910 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:16,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:16,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:17,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:18,651 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:19,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:19,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:19,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:20,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:20,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:20,556 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:20,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:21,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:23,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:23,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:23,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:23,368 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:23,368 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:28,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:31,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:33,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:37,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:37,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:37,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:38,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:38,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:38,824 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:38,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:38,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:39,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:40,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:40,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:41,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:41,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:41,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:41,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:41,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:42,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:42,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:42,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:42,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:43,803 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:44,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:45,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:46,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:46,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:47,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:47,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:47,903 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:48,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:48,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:50,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:50,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:50,220 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:50,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:52,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:54,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:52:54,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:07,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:07,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:07,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:07,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:07,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:07,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:07,984 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:08,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:09,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:09,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:09,113 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:09,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:09,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:09,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:09,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:09,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:09,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,654 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:10,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:11,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:11,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:11,330 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:11,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:11,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:13,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:21,029 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:22,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:30,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:31,330 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:32,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:32,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:32,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:32,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:34,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:34,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:35,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,911 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,911 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:36,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:37,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,938 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:38,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:39,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:39,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:39,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:39,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:42,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:42,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:43,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:43,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:44,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:44,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:44,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:44,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:47,599 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,938 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:50,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:51,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:52,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:52,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:52,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:52,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:52,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:52,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:53,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:53,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:53,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:54,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:54,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:55,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:55,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:58,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:58,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:59,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:59,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:53:59,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:00,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:01,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:01,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,335 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:02,936 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:03,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:04,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:11,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:12,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:13,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:13,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:13,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:13,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:13,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:14,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:15,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:15,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:15,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:16,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:16,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:16,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:16,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:16,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:16,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:16,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:16,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:17,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:18,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:18,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:18,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:19,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:24,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:29,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:38,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:38,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:38,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:39,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:41,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:41,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:41,150 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:41,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:41,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:43,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:43,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:43,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:43,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:43,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:44,810 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:45,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:45,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:45,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:45,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:46,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:46,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:46,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:47,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:47,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:48,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:48,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:49,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:50,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:50,944 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:51,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:51,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:51,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:54:54,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:01,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:01,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:01,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:01,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:02,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:02,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:02,438 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:02,442 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:02,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:03,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:03,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:03,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:03,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:03,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:03,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:04,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:05,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:05,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:05,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:05,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:05,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:05,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:05,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:05,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:05,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:06,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:06,001 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:06,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:06,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:07,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:07,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:08,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:11,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:14,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:17,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:17,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:17,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:18,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:18,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:18,713 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:18,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:18,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:18,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:18,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:19,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:20,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:20,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:20,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:20,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:20,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:20,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:21,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:21,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:21,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:21,936 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:22,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:22,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:23,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:24,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:24,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:24,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:25,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:25,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:29,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:29,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:31,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:42,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:43,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:45,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:45,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:45,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:46,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:47,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:49,088 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:49,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:49,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:49,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:49,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:49,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:49,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:51,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:51,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:51,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:51,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:51,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:51,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:51,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:53,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:53,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:55,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:59,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:59,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:55:59,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:00,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:00,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:02,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:02,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:02,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:04,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:05,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:05,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:05,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:05,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:07,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:08,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:09,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:09,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:10,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:10,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:10,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:10,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:10,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:11,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:12,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:13,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:13,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:14,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:14,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:14,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:14,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:14,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:15,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:16,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:16,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:16,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:16,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:21,113 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:21,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:24,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:25,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,472 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:27,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:28,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:28,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:28,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:29,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:30,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:50,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:50,824 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:51,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:51,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:52,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:52,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:52,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:52,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:52,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,187 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,519 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,945 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:53,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:54,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:55,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:56,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:58,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:58,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:58,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:58,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:58,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:58,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:56:59,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:00,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:01,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:02,023 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:02,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:02,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:08,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:09,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:09,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:11,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:11,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:11,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:12,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:12,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:12,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:12,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:13,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:13,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:14,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:15,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:15,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:15,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:16,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:16,259 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:18,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:18,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:18,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:19,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:19,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:19,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:20,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:20,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:20,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:20,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:21,113 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:21,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:21,116 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:22,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:25,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:27,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:27,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:27,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:27,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:30,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:31,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:38,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:39,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:39,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:39,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:39,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:41,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:41,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:41,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:41,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:42,028 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:42,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:43,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:43,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:43,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:43,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:44,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:44,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:44,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:44,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:44,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:44,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:44,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:44,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:45,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:45,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:45,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:46,954 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:48,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:48,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:48,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:48,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:49,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:52,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:55,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:55,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:55,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:57:56,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:03,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:04,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:05,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:05,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:05,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:05,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:06,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:06,604 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:06,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:06,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:06,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:07,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:07,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:07,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:07,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,330 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,330 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,468 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:08,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:09,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:09,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:09,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:10,078 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:10,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:14,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:14,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:17,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:18,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:18,142 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:18,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:19,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:21,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:21,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:22,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:22,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:25,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:27,428 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:29,011 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:29,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:29,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:29,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:29,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:30,001 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:30,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:30,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:30,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:30,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:33,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:33,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:34,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:35,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:36,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:36,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:36,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:37,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:37,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:39,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:39,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:39,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:40,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:40,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:40,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:40,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:40,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:40,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:41,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:42,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:42,447 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:43,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:43,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:43,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:44,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:44,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:45,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:47,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:47,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:48,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:49,078 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:49,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:50,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:50,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:50,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:52,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:52,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:56,220 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:56,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:57,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:59,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:59,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:59,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:58:59,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:01,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:01,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:01,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:01,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:01,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:02,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:02,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:02,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:02,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:03,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:03,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:04,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:04,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:04,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:05,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:05,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:05,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:05,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:05,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:05,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:05,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:06,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:09,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:09,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:09,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:09,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:10,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:10,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:10,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:11,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:12,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:12,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:12,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:12,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:12,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:15,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:18,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:22,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:24,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:24,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:24,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:24,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:24,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:24,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,556 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:25,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:26,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:28,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:29,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:30,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:30,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:31,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:31,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:32,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:32,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:34,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:34,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:34,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:35,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:36,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:36,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:43,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:44,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:44,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:44,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:44,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:45,878 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:46,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:46,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:46,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:46,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:47,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:48,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:49,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:49,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:49,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:50,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:51,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:51,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:51,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:52,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:52,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 11:59:57,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:00,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:04,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:04,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:05,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:06,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:06,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:07,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:08,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:08,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:08,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:09,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:10,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:10,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:11,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:12,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:12,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:12,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:12,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:12,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:14,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:15,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:18,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:18,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:18,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:18,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:18,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:18,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:20,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:21,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:25,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:25,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:25,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,368 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:26,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:27,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:27,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:28,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:28,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:28,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:28,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:29,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,442 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:30,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:31,026 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:31,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:32,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:32,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:32,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:32,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:32,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:38,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:38,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:38,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:38,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:38,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:39,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:39,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:40,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:41,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:42,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:42,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:42,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:43,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:43,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:43,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:43,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:43,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:43,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:43,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:44,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:44,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:44,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:46,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:46,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:47,116 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:47,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:47,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:47,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:47,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:48,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:53,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:53,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:53,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:54,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:58,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:00:58,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:10,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:10,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:10,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:11,019 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:11,023 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:11,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:11,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:12,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:13,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:14,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:14,589 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:15,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:15,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:17,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:17,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:18,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:19,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:19,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:20,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:20,373 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:20,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:20,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:20,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:20,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:20,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:21,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:22,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:23,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:23,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:23,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:23,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:23,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:28,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:31,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:40,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:40,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:40,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:40,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:40,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:40,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:41,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:42,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:43,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:43,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:43,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:44,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:45,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:46,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:46,153 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,019 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:47,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:48,223 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:48,224 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:48,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:49,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:01:51,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:08,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:09,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:09,779 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:10,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:12,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:14,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:14,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:20,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:20,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:20,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:21,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:21,592 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:22,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:23,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:24,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:24,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:24,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:24,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:27,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:28,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:30,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:30,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:32,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:33,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:34,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:34,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:35,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:35,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:35,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:36,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:36,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:36,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:38,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:38,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:38,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:38,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:39,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:39,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:40,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:41,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:42,600 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:42,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:43,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:43,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:43,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:44,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:45,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:45,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:45,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:46,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:46,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:47,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:47,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:50,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:51,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:54,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:54,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:57,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:58,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:58,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:58,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:58,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:59,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:02:59,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:00,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:01,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:02,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:02,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:02,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:02,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:03,824 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:03,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:05,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:05,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:05,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:07,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:08,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:09,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:09,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:12,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:25,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:26,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:27,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:30,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:31,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:31,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:31,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:31,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:32,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:32,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:33,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:33,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:33,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:34,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:34,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:34,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:35,223 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:36,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:36,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:36,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:37,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:37,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:38,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:38,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:38,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:39,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:39,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:39,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:39,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:39,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:39,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:40,100 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:40,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:40,803 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:40,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:40,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:40,947 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:41,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:41,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:45,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:45,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:45,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:46,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:47,438 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:49,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:49,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:50,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:51,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:51,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:51,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:51,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:51,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:51,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:51,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,779 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:52,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:53,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:54,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:03:55,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:00,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:01,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:06,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:06,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:06,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:07,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:08,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:10,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:10,220 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:10,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:10,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:10,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:11,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:12,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:12,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:12,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:12,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:13,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:13,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:13,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:14,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:14,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:14,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:14,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:14,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:15,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:15,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:15,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:16,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:17,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:26,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:27,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:28,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:28,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:28,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:28,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:28,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:28,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:29,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:29,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:29,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:29,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:30,373 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:30,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:30,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:30,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:31,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:32,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:33,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:33,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:33,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:33,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:33,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:33,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:33,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:34,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:34,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:34,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:35,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:36,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:36,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:37,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:37,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:37,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:37,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:37,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:38,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:38,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:44,572 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:45,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:46,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:46,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:46,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:47,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:48,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:48,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:48,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:48,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:49,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:49,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:49,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:49,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:50,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:50,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:51,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:51,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:51,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:51,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:53,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:53,260 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:53,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:54,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:54,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:55,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:55,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:56,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:56,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:56,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:56,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:56,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:56,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:04:56,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:00,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:00,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:00,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:00,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:00,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:02,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:04,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:13,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:14,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:15,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:17,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:18,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:18,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:18,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,330 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:19,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:20,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:20,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:20,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:20,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:20,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:20,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:20,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:20,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:20,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,196 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,944 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,954 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:21,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:23,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:26,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:27,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:31,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:31,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:31,482 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:31,484 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:31,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:32,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:33,378 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,437 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:34,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:37,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:37,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:37,936 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:37,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,984 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:38,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:39,001 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:39,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:39,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:39,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:39,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:40,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:40,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:41,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:42,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:42,909 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:43,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:45,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:45,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:45,306 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:45,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:56,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:57,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:57,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:57,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:57,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:58,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:58,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:58,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:58,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:58,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:59,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:59,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:59,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:59,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:59,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:59,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:05:59,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:00,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:01,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,570 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:02,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:03,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:03,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:04,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:04,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:04,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:05,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:06,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:06,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:06,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:07,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:10,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:11,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:16,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:17,468 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:18,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:18,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,207 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,684 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:19,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:20,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:20,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:20,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:21,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:22,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:22,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:23,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:23,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:23,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:24,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:24,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:24,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:24,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:25,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:26,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:26,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:26,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:27,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:27,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:27,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:27,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:28,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:37,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:37,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:37,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:38,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:38,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:38,519 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:38,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:38,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:38,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:39,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:40,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:40,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:41,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:42,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:43,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:44,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:44,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:45,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:45,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:46,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:46,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:47,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:48,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:53,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:54,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:54,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:54,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:54,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:54,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:54,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:55,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:55,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:55,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:55,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:55,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:55,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:56,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:56,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:57,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:57,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:57,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:58,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:58,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:58,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:58,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:58,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:58,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,108 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:06:59,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:00,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:00,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:00,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:00,220 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:00,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:01,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:01,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:01,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:01,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:05,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:05,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:23,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:23,909 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:24,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:25,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:27,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:27,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:28,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:28,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:28,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:29,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:31,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:33,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:49,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:50,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:51,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:51,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:52,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:52,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:52,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:52,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:52,474 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:53,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:53,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:54,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:57,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:57,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:58,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:58,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:58,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:58,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:07:59,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:00,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:00,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:13,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:15,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:15,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:15,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:16,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:17,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:17,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:17,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:18,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:18,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:18,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:18,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:18,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:19,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:19,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:19,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:20,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:21,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:21,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:21,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:23,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:24,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:24,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:24,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:24,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,072 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:25,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:28,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:28,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:28,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:28,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:30,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:33,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:34,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:34,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:36,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:36,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:36,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:36,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:37,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:37,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:37,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:38,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:38,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:38,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:39,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:39,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:39,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:39,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:39,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:39,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:41,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:42,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:43,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:45,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:45,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:45,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:45,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:46,001 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:46,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:08:59,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,263 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:00,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:01,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:02,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:02,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:02,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:02,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:02,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:03,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:05,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:05,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:05,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:05,227 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:05,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:06,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:07,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:07,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:07,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:07,314 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:08,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:11,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:12,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:12,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:13,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:13,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,943 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,944 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:14,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:15,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:15,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:15,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:15,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:15,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:16,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:16,258 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:16,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:16,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:17,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:17,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:18,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:20,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:20,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:20,642 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:20,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:21,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:21,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:21,910 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:22,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:22,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:22,519 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:22,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:22,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:22,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:23,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:41,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:41,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:41,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:42,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:43,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:44,668 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:45,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:46,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:46,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:46,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:46,810 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:47,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:47,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:47,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:48,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:48,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:48,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:48,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:48,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:49,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:49,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:49,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:49,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:49,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:50,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:50,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:51,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:51,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:56,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:57,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:58,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:58,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:59,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:59,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:09:59,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:00,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:00,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:00,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:00,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:01,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:02,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:02,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:02,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:04,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:04,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:04,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:04,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:06,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:06,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:06,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:06,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:07,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:08,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:10,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:10,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:16,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:16,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:16,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:16,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:16,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:18,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:26,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:26,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:27,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:27,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:27,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:27,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:27,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:28,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:29,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:29,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:29,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:29,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:29,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:29,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:30,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:30,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:31,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:31,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:31,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:31,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:31,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:31,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:31,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:32,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:32,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:32,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:32,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:32,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:34,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:34,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:34,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:34,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:34,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:34,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:35,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:36,116 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:36,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:36,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:36,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:37,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:37,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:39,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:41,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:42,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:49,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:55,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:55,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:56,220 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:56,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:56,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,472 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:57,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,306 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:58,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:59,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:59,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:59,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:59,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:59,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:10:59,910 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:00,075 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:00,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,191 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:02,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:03,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:04,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:08,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:09,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:13,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:13,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:13,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:14,954 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:15,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:16,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:17,654 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,153 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:18,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:19,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:19,108 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:19,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:21,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:21,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:22,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:23,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:24,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:24,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:26,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:28,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:36,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:36,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:41,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:42,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:42,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:42,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:42,954 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:43,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:43,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:43,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:43,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:43,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:44,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:44,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:45,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:45,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:45,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:45,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:45,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:47,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:47,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:49,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:49,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:51,426 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:51,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:51,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:51,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:52,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:52,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:53,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:53,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:53,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:53,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:53,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:53,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:53,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:53,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:54,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:57,711 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:41029. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43888 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,711 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,713 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,714 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:39125. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,714 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:35311. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,714 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:43169. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,714 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:39219. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,712 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,714 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:36201. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,714 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:39825. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43710 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,715 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:37227. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,715 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:35595. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,715 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:39133. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,715 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:33845. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,715 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:40925. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,715 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:35349. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,715 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:33023. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,715 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:45703. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43862 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,716 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:45191. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43692 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43844 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43668 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43700 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43740 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43804 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43852 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43842 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43818 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43726 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43828 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43912 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,708 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43876 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,716 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,709 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.103.56:43784 remote=tcp://10.6.103.37:8707>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-04 12:11:57,718 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:35707. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,716 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,717 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,717 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,717 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,719 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:32777. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,719 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:42427. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,719 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:34945. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,717 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,717 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,717 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,717 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,719 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:46681. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,717 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,719 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:39089. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,719 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:44931. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,718 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,719 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:34253. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,720 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:43623. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,718 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,720 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:43535. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,720 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:40901. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,718 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,718 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,718 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,720 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:42573. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,720 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:38047. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,720 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:37053. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,720 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:35795. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,719 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:57,722 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:42895. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,723 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:34985'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,726 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6338, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,726 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4439, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,727 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,727 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,727 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,727 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,727 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,729 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:41289'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,730 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 8040, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,730 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6540, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,730 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,738 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:33397'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,739 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:40763'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,739 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:43007'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,739 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:42553'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,739 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,740 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:46775'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,740 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:41459'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,740 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,740 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:32801'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,740 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,740 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5126, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,740 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:36025'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,741 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 8170, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,741 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,741 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:33295'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,741 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,741 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 8109, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,741 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:38167'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,741 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 8110, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,741 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,741 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:39187'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,741 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,742 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:43481'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,742 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,742 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:43395'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,742 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,742 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:45895'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,742 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,742 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.63:40591, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,742 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:38783'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,742 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,742 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,743 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:37395'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,743 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.41:43081, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,743 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,743 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4401, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,743 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:45679'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,743 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4406, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,743 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 3750, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,743 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:37097'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,743 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,743 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.64:35301, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,744 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6772, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,744 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:33013'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,744 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5609, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,744 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 3788, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,744 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,744 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:43781'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,744 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 8039, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,744 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:38345'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,744 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,744 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,745 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:36083'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,745 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:38183'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,745 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,745 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,745 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,746 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,746 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,746 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5815, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,747 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,747 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,747 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4049, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,747 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,747 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,747 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,747 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,747 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,747 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,747 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,747 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,747 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:46455, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,748 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,748 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,748 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,748 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,748 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,748 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,749 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,749 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,749 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,749 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,750 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,750 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,750 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,750 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:38485'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,750 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:35567'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,751 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:44323'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,751 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:46605'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,751 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:34501'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,751 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:45901'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,751 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:38805'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:57,752 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4901, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,752 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4079, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,752 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6610, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,752 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4187, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,752 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7252, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,753 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,753 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,753 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,753 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,753 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5914, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,753 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,753 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,754 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4447, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,754 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,754 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7997, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,755 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,755 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,755 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 6212, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,755 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,755 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,755 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,755 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,755 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,755 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,756 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,756 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,756 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,756 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,758 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,759 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,759 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,759 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,759 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,775 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.60:34909, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:57,783 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:57,783 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:57,783 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:57,783 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:57,783 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:57,802 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,803 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,804 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,807 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,809 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,809 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,809 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,810 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,810 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,810 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,811 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,812 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,812 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,816 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,821 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,833 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,836 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:57,861 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:58,231 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:58,315 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:58,328 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:58,331 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:45557. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,363 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43262 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:58,368 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:34317'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,368 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:58,368 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:58,368 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:58,368 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:58,369 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:58,376 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14c5423005d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:58,387 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:58,655 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:58,774 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:58,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:42961. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,806 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43210 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:58,810 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:41223'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:58,811 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:58,812 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:58,812 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:58,812 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:58,812 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:58,819 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x148bd2d6ced0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:58,828 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:58,991 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:58,993 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:46109. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,014 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,017 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:32927. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:59,029 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43164 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,034 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:39615'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,035 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,035 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,035 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,035 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,035 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,040 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,041 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:37443. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,044 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14e52f2b6010>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:59,051 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43180 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43180 remote=tcp://10.6.103.37:8707>: Stream is closed
2025-09-04 12:11:59,051 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43044 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,054 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,059 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:35041'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,060 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,060 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:36519'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,060 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,060 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,060 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,060 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,060 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,060 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,061 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,061 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,061 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,067 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14b736ea0c90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,069 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x152f4aff8e90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,076 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,078 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,103 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,105 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:39577. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:59,139 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43288 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,158 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:34285'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,159 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,159 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,159 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,159 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,159 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,166 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14b1260e87d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,178 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,251 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,254 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:40659. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,285 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43108 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,290 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:41103'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,290 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,291 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,291 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,291 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,291 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,296 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1510b037a490>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,305 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,345 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,518 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,521 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:41489. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,523 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,524 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:41577. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,552 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43314 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,554 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.103.46:37489
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.103.56:42584 remote=tcp://10.6.103.46:37489>: Stream is closed
2025-09-04 12:11:59,557 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:34711'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,558 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,559 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,559 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,559 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,559 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,559 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43002 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,562 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:35315'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,563 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 5591, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:59,563 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,564 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,564 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,564 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,564 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,564 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14d5dd42de90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,570 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x151c8992ee10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,573 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,603 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,605 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:44871. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,609 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,636 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43138 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,655 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:36445'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,656 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,656 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,656 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,656 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,656 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,664 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x152b35088050>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,675 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,806 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,807 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,811 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,812 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,813 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,813 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,813 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,813 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,814 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,815 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,815 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,818 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,825 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,838 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,840 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:11:59,890 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,891 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,946 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:11:59,948 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:34335. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,954 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,955 - distributed.nanny - INFO - Worker closed
2025-09-04 12:11:59,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:11:59,982 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43408 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:11:59,985 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:44027'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:11:59,986 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.56:33191, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:11:59,986 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:11:59,987 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:11:59,987 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:11:59,987 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:11:59,987 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:11:59,991 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1516c6da2990>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:11:59,998 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,114 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:00,116 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:34737. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,139 - distributed.worker - ERROR - failed during get data with tcp://10.6.103.56:34737 -> tcp://10.6.103.41:42667
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.103.56:34737 remote=tcp://10.6.103.41:44566>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-04 12:12:00,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:00,151 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43294 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:00,159 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:39019'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,160 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:00,160 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:00,160 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:00,160 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:00,160 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:00,165 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1470cf757410>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:00,173 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,235 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,319 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,346 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:00,348 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:33191. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,357 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,373 - distributed.worker - ERROR - failed during get data with tcp://10.6.103.56:33191 -> tcp://10.6.103.56:34335
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.103.56:33191 remote=tcp://10.6.103.56:37162>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-04 12:12:00,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:00,385 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43240 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:00,388 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:34799'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,389 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:00,389 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:00,389 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:00,389 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:00,389 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:00,390 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,393 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14b6f34ed090>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:00,399 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,463 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,532 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:43007'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,543 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:38167'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,544 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:36025'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,546 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:33013'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,546 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:33295'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,547 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:37097'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,558 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:33397'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,559 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:42553'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,560 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:43007' closed.
2025-09-04 12:12:00,560 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:39187'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,560 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:43395'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,562 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:45901'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,562 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:41459'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,563 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:45679'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,563 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:43781'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,563 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:32801'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,563 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:38345'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,564 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:36083'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,564 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:38167' closed.
2025-09-04 12:12:00,564 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:36025' closed.
2025-09-04 12:12:00,564 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:33013' closed.
2025-09-04 12:12:00,565 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:33295' closed.
2025-09-04 12:12:00,565 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:37097' closed.
2025-09-04 12:12:00,566 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:33397' closed.
2025-09-04 12:12:00,566 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:42553' closed.
2025-09-04 12:12:00,567 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:39187' closed.
2025-09-04 12:12:00,567 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:43395' closed.
2025-09-04 12:12:00,569 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:45901' closed.
2025-09-04 12:12:00,570 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:41459' closed.
2025-09-04 12:12:00,570 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:45679' closed.
2025-09-04 12:12:00,570 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:43781' closed.
2025-09-04 12:12:00,570 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:32801' closed.
2025-09-04 12:12:00,570 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:38345' closed.
2025-09-04 12:12:00,571 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:36083' closed.
2025-09-04 12:12:00,655 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:38805'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,656 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:38805' closed.
2025-09-04 12:12:00,658 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,658 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:00,660 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:36265. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,690 - distributed.worker - ERROR - failed during get data with tcp://10.6.103.56:36265 -> tcp://10.6.103.61:46493
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.103.56:36265 remote=tcp://10.6.103.61:44752>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-04 12:12:00,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:00,697 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43374 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:00,701 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:46369'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,702 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:00,702 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:00,702 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:00,702 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:00,702 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:00,706 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14bc372bb250>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:00,712 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:00,752 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:34985'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,753 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:34985' closed.
2025-09-04 12:12:00,831 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:00,910 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:37395'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,911 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:37395' closed.
2025-09-04 12:12:00,929 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:34317'. Reason: nanny-close-gracefully
2025-09-04 12:12:00,930 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:34317' closed.
2025-09-04 12:12:00,929 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:00,931 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:33089. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:00,963 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43188 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:00,966 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:39217'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:00,966 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:00,967 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:00,967 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:00,967 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:00,967 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:00,970 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ddd29eee10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:00,975 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,030 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,058 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,079 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,081 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,181 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,198 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:40763'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,201 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:40763' closed.
2025-09-04 12:12:01,248 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,309 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,349 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,358 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:41223'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,360 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:41223' closed.
2025-09-04 12:12:01,539 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,541 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:38819. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,574 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,575 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43276 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,576 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:34533. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,576 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,578 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:46703'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,579 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 4902, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,579 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,579 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,579 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,579 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,579 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,582 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1458a9fdba90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,596 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,608 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:36519'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,610 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:36519' closed.
2025-09-04 12:12:01,609 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.103.41:43081
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 231, in read
    buffer = await read_bytes_rw(stream, buffer_nbytes)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 367, in read_bytes_rw
    actual = await stream.read_into(chunk)  # type: ignore[arg-type]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.103.56:44516 remote=tcp://10.6.103.41:43081>: Stream is closed
2025-09-04 12:12:01,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,614 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,614 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43184 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,617 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:37993'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,618 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.103.39:39701, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,618 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,618 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,618 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,618 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,618 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,620 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ba0060f810>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,625 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,678 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,688 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,689 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:45717. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:34285'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,699 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:39615'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,699 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:34285' closed.
2025-09-04 12:12:01,699 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43036 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43036 remote=tcp://10.6.103.37:8707>: Stream is closed
2025-09-04 12:12:01,704 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:39615' closed.
2025-09-04 12:12:01,706 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:35041'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,707 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:38259'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,708 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-5cd6123c5d9192c6e2d1320e23cf5d4c', 7028, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-04 12:12:01,708 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,708 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:35041' closed.
2025-09-04 12:12:01,708 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,708 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,708 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,708 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,710 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1527b445d650>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,746 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,777 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,779 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:41095. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,815 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43124 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,818 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:36073'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,818 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,819 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,819 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,819 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,819 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,821 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x15003336d3d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,826 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,893 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,894 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,918 - distributed.core - INFO - Connection to tcp://10.6.103.37:8707 has been closed.
2025-09-04 12:12:01,920 - distributed.worker - INFO - Stopping worker at tcp://10.6.103.56:43307. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,924 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:01,952 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:41103'. Reason: nanny-close-gracefully
2025-09-04 12:12:01,953 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:41103' closed.
2025-09-04 12:12:01,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-04 12:12:01,956 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.103.56:43056 remote=tcp://10.6.103.37:8707>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-04 12:12:01,959 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,959 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:01,960 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.103.56:46883'. Reason: worker-handle-scheduler-connection-broken
2025-09-04 12:12:01,960 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-04 12:12:01,960 - distributed.worker - INFO - Removing Worker plugin qme_utils.py4c5203b9-f3a6-44e4-b7ca-511d376fb4b1
2025-09-04 12:12:01,960 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye825f24f-ef9d-4667-9b17-2b9362bd7315
2025-09-04 12:12:01,961 - distributed.worker - INFO - Removing Worker plugin qme_train.py665f9f05-bfe9-4a90-b236-24bd51083828
2025-09-04 12:12:01,961 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyfc76e6ee-c280-4578-8449-ebf0f087edc9
2025-09-04 12:12:01,962 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14db948f1310>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-04 12:12:01,968 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,001 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,024 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:45895'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,025 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:45895' closed.
2025-09-04 12:12:02,155 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:35567'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,156 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:35567' closed.
2025-09-04 12:12:02,157 - distributed.nanny - INFO - Worker closed
2025-09-04 12:12:02,176 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,206 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:34711'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,207 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:34711' closed.
2025-09-04 12:12:02,353 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:36445'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,354 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:36445' closed.
2025-09-04 12:12:02,402 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,467 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,486 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:34501'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,487 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:41289'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,488 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:34501' closed.
2025-09-04 12:12:02,488 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:41289' closed.
2025-09-04 12:12:02,490 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:38783'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,491 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:38783' closed.
2025-09-04 12:12:02,594 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:44027'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,595 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:44027' closed.
2025-09-04 12:12:02,633 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:43481'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,634 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:43481' closed.
2025-09-04 12:12:02,715 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:02,794 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:39019'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,795 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:39019' closed.
2025-09-04 12:12:02,885 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:38485'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,886 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:38485' closed.
2025-09-04 12:12:02,906 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:34799'. Reason: nanny-close-gracefully
2025-09-04 12:12:02,907 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:34799' closed.
2025-09-04 12:12:02,978 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,034 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,055 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:46775'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,055 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:46775' closed.
2025-09-04 12:12:03,252 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,264 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:46369'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,265 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:46369' closed.
2025-09-04 12:12:03,541 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:44323'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,543 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:44323' closed.
2025-09-04 12:12:03,548 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:39217'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,549 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:39217' closed.
2025-09-04 12:12:03,600 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,628 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,750 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,775 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:35315'. Reason: nanny-close-gracefully
2025-09-04 12:12:03,776 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:35315' closed.
2025-09-04 12:12:03,829 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:03,970 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,145 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:46605'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,146 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:46605' closed.
2025-09-04 12:12:04,153 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:37993'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,154 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:37993' closed.
2025-09-04 12:12:04,160 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-04 12:12:04,264 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:38259'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,265 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:38259' closed.
2025-09-04 12:12:04,354 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:36073'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,355 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:36073' closed.
2025-09-04 12:12:04,545 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:38183'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,545 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:38183' closed.
2025-09-04 12:12:04,593 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:46883'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,594 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:46883' closed.
2025-09-04 12:12:04,670 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.103.56:46703'. Reason: nanny-close-gracefully
2025-09-04 12:12:04,671 - distributed.nanny - INFO - Nanny at 'tcp://10.6.103.56:46703' closed.
2025-09-04 12:12:04,673 - distributed.dask_worker - INFO - End worker
