Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 16:27:20,430 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:44329'
2025-09-03 16:27:20,440 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:33225'
2025-09-03 16:27:20,443 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:36883'
2025-09-03 16:27:20,447 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:33051'
2025-09-03 16:27:20,452 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:37045'
2025-09-03 16:27:20,457 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:42273'
2025-09-03 16:27:20,461 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:37553'
2025-09-03 16:27:20,465 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:45285'
2025-09-03 16:27:20,470 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:41249'
2025-09-03 16:27:20,475 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:44087'
2025-09-03 16:27:20,480 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:38125'
2025-09-03 16:27:20,485 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:45293'
2025-09-03 16:27:20,489 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:39457'
2025-09-03 16:27:20,493 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:39773'
2025-09-03 16:27:20,498 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:45903'
2025-09-03 16:27:20,502 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:45433'
2025-09-03 16:27:20,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:45627'
2025-09-03 16:27:20,511 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:41633'
2025-09-03 16:27:20,516 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:35291'
2025-09-03 16:27:20,626 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:43451'
2025-09-03 16:27:20,630 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:46721'
2025-09-03 16:27:20,634 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:43969'
2025-09-03 16:27:20,639 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:36487'
2025-09-03 16:27:20,643 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:39731'
2025-09-03 16:27:20,648 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:39475'
2025-09-03 16:27:20,652 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:36595'
2025-09-03 16:27:20,657 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:34835'
2025-09-03 16:27:20,662 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:38099'
2025-09-03 16:27:20,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:43025'
2025-09-03 16:27:20,671 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:46587'
2025-09-03 16:27:20,675 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:39403'
2025-09-03 16:27:20,681 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:34879'
2025-09-03 16:27:20,685 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:33135'
2025-09-03 16:27:20,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:41797'
2025-09-03 16:27:20,695 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:35633'
2025-09-03 16:27:20,700 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:36251'
2025-09-03 16:27:20,704 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:35289'
2025-09-03 16:27:20,709 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:40123'
2025-09-03 16:27:20,713 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:35033'
2025-09-03 16:27:20,717 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:40511'
2025-09-03 16:27:20,722 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:42517'
2025-09-03 16:27:20,725 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:35685'
2025-09-03 16:27:20,730 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:41235'
2025-09-03 16:27:20,734 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:36777'
2025-09-03 16:27:20,739 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:36373'
2025-09-03 16:27:20,747 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:35147'
2025-09-03 16:27:20,750 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:41045'
2025-09-03 16:27:20,753 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:41393'
2025-09-03 16:27:20,757 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:37223'
2025-09-03 16:27:20,761 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:41825'
2025-09-03 16:27:20,766 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:33885'
2025-09-03 16:27:20,770 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.25:33837'
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:43597
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:40841
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:34995
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:33423
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:41799
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:36477
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:43597
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:40059
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:42437
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:43807
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:40841
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:35301
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:45267
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:34995
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:36387
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:33423
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:41799
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:36477
2025-09-03 16:27:21,817 - distributed.worker - INFO -          dashboard at:          10.6.102.25:34857
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:40059
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:36387
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:41563
2025-09-03 16:27:21,817 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:43941
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:42437
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:43807
2025-09-03 16:27:21,817 - distributed.worker - INFO -          dashboard at:          10.6.102.25:45839
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:35301
2025-09-03 16:27:21,817 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:45267
2025-09-03 16:27:21,817 - distributed.worker - INFO -          dashboard at:          10.6.102.25:41157
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:36489
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:41623
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:41949
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:39551
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:40035
2025-09-03 16:27:21,818 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:41563
2025-09-03 16:27:21,818 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:43941
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:35133
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:38541
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:38905
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:46011
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:46301
2025-09-03 16:27:21,818 - distributed.worker - INFO -          dashboard at:          10.6.102.25:44463
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-e5l9ub0z
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-emk6zs3z
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-bbhcxbau
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-oqjuaebb
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-v237x9_8
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-0nb528p1
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-79jzyt3y
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-34m8upv_
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-b2jvslbs
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-x3j6l_zv
2025-09-03 16:27:21,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-p_8ymrum
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-oguxnhup
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-u3bjdkuf
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-upclccc_
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,820 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:38731
2025-09-03 16:27:21,820 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:38731
2025-09-03 16:27:21,820 - distributed.worker - INFO -          dashboard at:          10.6.102.25:36641
2025-09-03 16:27:21,820 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,820 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,820 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,820 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-opw9h1oy
2025-09-03 16:27:21,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,821 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:39963
2025-09-03 16:27:21,821 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:39963
2025-09-03 16:27:21,821 - distributed.worker - INFO -          dashboard at:          10.6.102.25:36573
2025-09-03 16:27:21,821 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,821 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,821 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,821 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,821 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-cvk2v7kx
2025-09-03 16:27:21,821 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,821 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:37413
2025-09-03 16:27:21,821 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:37413
2025-09-03 16:27:21,821 - distributed.worker - INFO -          dashboard at:          10.6.102.25:35415
2025-09-03 16:27:21,821 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,821 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,821 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,821 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,821 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-ybstpgps
2025-09-03 16:27:21,821 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,821 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:38323
2025-09-03 16:27:21,822 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:38323
2025-09-03 16:27:21,822 - distributed.worker - INFO -          dashboard at:          10.6.102.25:33973
2025-09-03 16:27:21,822 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,822 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,822 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,822 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,822 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-_61uhe6l
2025-09-03 16:27:21,822 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,823 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:41715
2025-09-03 16:27:21,823 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:41715
2025-09-03 16:27:21,824 - distributed.worker - INFO -          dashboard at:          10.6.102.25:34485
2025-09-03 16:27:21,824 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,824 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,824 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,824 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-j7gulttb
2025-09-03 16:27:21,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,825 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:40795
2025-09-03 16:27:21,825 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:40795
2025-09-03 16:27:21,825 - distributed.worker - INFO -          dashboard at:          10.6.102.25:45959
2025-09-03 16:27:21,825 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,825 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,826 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,826 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,826 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-_uaf62sf
2025-09-03 16:27:21,826 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,827 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:34899
2025-09-03 16:27:21,827 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:34899
2025-09-03 16:27:21,827 - distributed.worker - INFO -          dashboard at:          10.6.102.25:41079
2025-09-03 16:27:21,827 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,827 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,828 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,828 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,828 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-drd422uv
2025-09-03 16:27:21,828 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,840 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,840 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,841 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,846 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,846 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,847 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,851 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,852 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,852 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,853 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,856 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,857 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,857 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,859 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,860 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,861 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,861 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,863 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,864 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,865 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,865 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,866 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,867 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,867 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,867 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,868 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:37059
2025-09-03 16:27:21,868 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:37059
2025-09-03 16:27:21,868 - distributed.worker - INFO -          dashboard at:          10.6.102.25:40447
2025-09-03 16:27:21,868 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,868 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,868 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,868 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,868 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-0x3er4yg
2025-09-03 16:27:21,869 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,869 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,869 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,870 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,870 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,871 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,872 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,872 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,872 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,873 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,874 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,875 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,875 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,877 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,877 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,878 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,878 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,879 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,880 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,881 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,881 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,882 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,882 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,883 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,883 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,884 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,885 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,885 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,885 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,886 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,887 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,887 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,887 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,888 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,888 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,889 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,889 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,890 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,890 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,891 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,892 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,892 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,893 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,893 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,894 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,894 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,894 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,895 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,896 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,896 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,896 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,897 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,898 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,898 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,898 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,900 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,919 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,919 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,920 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,940 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:38489
2025-09-03 16:27:21,940 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:38489
2025-09-03 16:27:21,940 - distributed.worker - INFO -          dashboard at:          10.6.102.25:34035
2025-09-03 16:27:21,940 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:44029
2025-09-03 16:27:21,940 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,940 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:44029
2025-09-03 16:27:21,940 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,940 - distributed.worker - INFO -          dashboard at:          10.6.102.25:36239
2025-09-03 16:27:21,940 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,940 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,940 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-72axju7j
2025-09-03 16:27:21,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,940 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:21,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,940 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:21,940 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-8va744rf
2025-09-03 16:27:21,941 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,967 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,968 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,968 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,969 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:21,973 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:21,974 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:21,975 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:21,976 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,019 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:45363
2025-09-03 16:27:22,019 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:45363
2025-09-03 16:27:22,019 - distributed.worker - INFO -          dashboard at:          10.6.102.25:45143
2025-09-03 16:27:22,019 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,019 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,019 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,019 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,019 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-0hidh5j2
2025-09-03 16:27:22,019 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,034 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:38865
2025-09-03 16:27:22,034 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:38865
2025-09-03 16:27:22,034 - distributed.worker - INFO -          dashboard at:          10.6.102.25:39153
2025-09-03 16:27:22,034 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,034 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,034 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,034 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,034 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-x6dv2p0p
2025-09-03 16:27:22,034 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,045 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,046 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,046 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,047 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,056 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:40561
2025-09-03 16:27:22,056 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:40561
2025-09-03 16:27:22,056 - distributed.worker - INFO -          dashboard at:          10.6.102.25:40247
2025-09-03 16:27:22,056 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,056 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,056 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,056 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,056 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-6xaqpzu_
2025-09-03 16:27:22,056 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,056 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:41175
2025-09-03 16:27:22,057 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:41175
2025-09-03 16:27:22,057 - distributed.worker - INFO -          dashboard at:          10.6.102.25:43419
2025-09-03 16:27:22,057 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,057 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,057 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,057 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-lqh89hyu
2025-09-03 16:27:22,057 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,069 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:32773
2025-09-03 16:27:22,069 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:32773
2025-09-03 16:27:22,069 - distributed.worker - INFO -          dashboard at:          10.6.102.25:35227
2025-09-03 16:27:22,070 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,070 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,070 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,070 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-q54_jki5
2025-09-03 16:27:22,070 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,073 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:39535
2025-09-03 16:27:22,073 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:43403
2025-09-03 16:27:22,073 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:39535
2025-09-03 16:27:22,073 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:43403
2025-09-03 16:27:22,073 - distributed.worker - INFO -          dashboard at:          10.6.102.25:42259
2025-09-03 16:27:22,073 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,073 - distributed.worker - INFO -          dashboard at:          10.6.102.25:38949
2025-09-03 16:27:22,073 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,073 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,073 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,073 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,073 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,073 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,073 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,073 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-2ezz4e1y
2025-09-03 16:27:22,073 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-hztrai7a
2025-09-03 16:27:22,073 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,073 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,096 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,097 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,097 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,099 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,106 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,106 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,106 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,107 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,125 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,126 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,126 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,127 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,130 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,131 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,131 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,131 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,132 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,133 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,133 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,134 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,135 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,136 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,136 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,138 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,232 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:45395
2025-09-03 16:27:22,232 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:45395
2025-09-03 16:27:22,232 - distributed.worker - INFO -          dashboard at:          10.6.102.25:35467
2025-09-03 16:27:22,232 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,232 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,232 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,232 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,232 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-wku5mqux
2025-09-03 16:27:22,232 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,248 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,248 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,248 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,249 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,263 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:35417
2025-09-03 16:27:22,263 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:35417
2025-09-03 16:27:22,263 - distributed.worker - INFO -          dashboard at:          10.6.102.25:41585
2025-09-03 16:27:22,263 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,263 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,263 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,263 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,263 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-p6r2a01k
2025-09-03 16:27:22,263 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,278 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:35455
2025-09-03 16:27:22,278 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:35455
2025-09-03 16:27:22,278 - distributed.worker - INFO -          dashboard at:          10.6.102.25:41077
2025-09-03 16:27:22,278 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,278 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,278 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,278 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-qj24xa5s
2025-09-03 16:27:22,278 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,278 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,279 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,281 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:36813
2025-09-03 16:27:22,281 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:36813
2025-09-03 16:27:22,281 - distributed.worker - INFO -          dashboard at:          10.6.102.25:43375
2025-09-03 16:27:22,281 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,281 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,281 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,281 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,281 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-ea7c0evm
2025-09-03 16:27:22,281 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,281 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:37715
2025-09-03 16:27:22,282 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:37715
2025-09-03 16:27:22,282 - distributed.worker - INFO -          dashboard at:          10.6.102.25:36327
2025-09-03 16:27:22,282 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,282 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,282 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,282 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-onv3ruye
2025-09-03 16:27:22,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,284 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:39221
2025-09-03 16:27:22,284 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:39221
2025-09-03 16:27:22,284 - distributed.worker - INFO -          dashboard at:          10.6.102.25:39239
2025-09-03 16:27:22,284 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,285 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,285 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,285 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,285 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-imyetc2y
2025-09-03 16:27:22,285 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,285 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:40797
2025-09-03 16:27:22,285 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:40797
2025-09-03 16:27:22,285 - distributed.worker - INFO -          dashboard at:          10.6.102.25:34139
2025-09-03 16:27:22,285 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,285 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,285 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,285 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,285 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-k2t1vke1
2025-09-03 16:27:22,285 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,285 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:38299
2025-09-03 16:27:22,285 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:38299
2025-09-03 16:27:22,285 - distributed.worker - INFO -          dashboard at:          10.6.102.25:43537
2025-09-03 16:27:22,285 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,285 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,285 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,285 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,285 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-vktqd807
2025-09-03 16:27:22,285 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,286 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:38979
2025-09-03 16:27:22,286 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:38979
2025-09-03 16:27:22,286 - distributed.worker - INFO -          dashboard at:          10.6.102.25:34715
2025-09-03 16:27:22,286 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,286 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,286 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,286 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,286 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-u2vufxhu
2025-09-03 16:27:22,286 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,292 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:41939
2025-09-03 16:27:22,292 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:41939
2025-09-03 16:27:22,292 - distributed.worker - INFO -          dashboard at:          10.6.102.25:37917
2025-09-03 16:27:22,292 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,292 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,293 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,293 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,293 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-dckdmfh9
2025-09-03 16:27:22,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,293 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:37079
2025-09-03 16:27:22,293 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:37079
2025-09-03 16:27:22,293 - distributed.worker - INFO -          dashboard at:          10.6.102.25:39917
2025-09-03 16:27:22,293 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,293 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,293 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,293 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-ska8jdm3
2025-09-03 16:27:22,294 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,297 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:34605
2025-09-03 16:27:22,297 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:34605
2025-09-03 16:27:22,297 - distributed.worker - INFO -          dashboard at:          10.6.102.25:36231
2025-09-03 16:27:22,298 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,298 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,298 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,298 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,298 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-4acbm08_
2025-09-03 16:27:22,298 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,298 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:40177
2025-09-03 16:27:22,298 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:40177
2025-09-03 16:27:22,298 - distributed.worker - INFO -          dashboard at:          10.6.102.25:41289
2025-09-03 16:27:22,298 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,298 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,299 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,299 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,299 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-1w7j12h3
2025-09-03 16:27:22,299 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,299 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:40625
2025-09-03 16:27:22,300 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:40625
2025-09-03 16:27:22,300 - distributed.worker - INFO -          dashboard at:          10.6.102.25:45085
2025-09-03 16:27:22,300 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,300 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,300 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,300 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,300 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-cfllju82
2025-09-03 16:27:22,300 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,301 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:40469
2025-09-03 16:27:22,301 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:40469
2025-09-03 16:27:22,301 - distributed.worker - INFO -          dashboard at:          10.6.102.25:46415
2025-09-03 16:27:22,301 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,301 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,301 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,301 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,301 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-duqp543u
2025-09-03 16:27:22,301 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,303 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,304 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,304 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,305 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:37593
2025-09-03 16:27:22,305 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:37593
2025-09-03 16:27:22,305 - distributed.worker - INFO -          dashboard at:          10.6.102.25:41879
2025-09-03 16:27:22,305 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,305 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,305 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,305 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-znhy_3ma
2025-09-03 16:27:22,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,305 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,310 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:35507
2025-09-03 16:27:22,310 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:35507
2025-09-03 16:27:22,310 - distributed.worker - INFO -          dashboard at:          10.6.102.25:46725
2025-09-03 16:27:22,310 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,310 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,311 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,311 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,311 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-gs15q61f
2025-09-03 16:27:22,311 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,311 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,312 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,312 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,312 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:35571
2025-09-03 16:27:22,312 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:35571
2025-09-03 16:27:22,312 - distributed.worker - INFO -          dashboard at:          10.6.102.25:43919
2025-09-03 16:27:22,312 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,312 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,312 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,312 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,312 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-10j5059o
2025-09-03 16:27:22,312 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,313 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,318 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,319 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:40747
2025-09-03 16:27:22,319 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:40747
2025-09-03 16:27:22,319 - distributed.worker - INFO -          dashboard at:          10.6.102.25:33733
2025-09-03 16:27:22,319 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,319 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,319 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,319 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,319 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,319 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,319 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-num3q851
2025-09-03 16:27:22,319 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,321 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,322 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:41113
2025-09-03 16:27:22,322 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:41113
2025-09-03 16:27:22,322 - distributed.worker - INFO -          dashboard at:          10.6.102.25:46693
2025-09-03 16:27:22,322 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,322 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,322 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,322 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-4q5hx6xh
2025-09-03 16:27:22,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,322 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,323 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,323 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,325 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,326 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,327 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,329 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,329 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.25:45923
2025-09-03 16:27:22,329 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,329 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.25:45923
2025-09-03 16:27:22,330 - distributed.worker - INFO -          dashboard at:          10.6.102.25:38199
2025-09-03 16:27:22,330 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,330 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:27:22,330 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:27:22,330 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-4foovuso
2025-09-03 16:27:22,330 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,330 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,332 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,333 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,333 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,334 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,335 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,335 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,336 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,337 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,338 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,339 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,339 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,340 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,341 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,341 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,343 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,343 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,344 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,344 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,345 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,346 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,346 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,346 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,348 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,352 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,354 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,355 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,366 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,367 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,367 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,368 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,369 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,370 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,370 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,371 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,371 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,372 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,373 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,374 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,374 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,374 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,376 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,376 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,377 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,378 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,378 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:27:22,379 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:22,380 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:27:22,380 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:27:22,381 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:35,651 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,651 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,651 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,651 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,652 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,652 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,652 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,652 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,652 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,652 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,652 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,653 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,653 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,653 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,653 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,653 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,653 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,653 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,654 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,654 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,654 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,654 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,654 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,654 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,654 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,654 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,654 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,655 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,656 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,656 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,657 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,657 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,657 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,657 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,655 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,657 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,658 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,658 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,658 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,658 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,657 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,657 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,658 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,658 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,658 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,658 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,659 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,659 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,659 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,659 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,665 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,666 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,668 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,668 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,670 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,668 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,671 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,677 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:38,327 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,327 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,327 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,327 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,327 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,327 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,328 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,327 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,328 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,328 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,328 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,328 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,327 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,328 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,328 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,328 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,329 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,329 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,329 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,329 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,329 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,329 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,330 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,329 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,329 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,331 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,330 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,332 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,333 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,333 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,333 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,333 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,333 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,333 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,333 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,334 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,334 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,334 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,334 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,334 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,334 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,335 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,335 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,335 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,335 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,337 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,724 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,724 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,724 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,725 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,725 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,725 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,725 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,725 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,725 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,725 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,725 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,725 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,726 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,726 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,726 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,726 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,726 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,726 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,726 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,727 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,727 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,727 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,727 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,727 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,727 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,727 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,727 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,727 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,728 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,728 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,728 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,728 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,728 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,728 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,728 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,728 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,728 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,729 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,729 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,729 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,729 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,729 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,729 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,729 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,729 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,729 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,729 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,729 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,730 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,730 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,730 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,730 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,730 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,730 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,730 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,730 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,731 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,731 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,731 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,731 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,731 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,731 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,731 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,731 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,731 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,732 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,732 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,732 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,732 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,732 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,732 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,732 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,733 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,734 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,735 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:39,166 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,166 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,166 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,170 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,169 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,170 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,170 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,172 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,172 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,172 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,172 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,172 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,172 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,172 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,172 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,173 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,173 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,173 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,173 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,174 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,174 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,176 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,176 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,176 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,185 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,184 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:30:58,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:58,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,437 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:44,774 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:44,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:44,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:44,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:44,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:47,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:47,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:47,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:47,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:47,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:49,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:49,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:49,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:49,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:49,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:50,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:50,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:50,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:50,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:50,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:50,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:50,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:51,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:51,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:51,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:52,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:52,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:53,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:53,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:54,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:54,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:58,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:59,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:00,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:04,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:05,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:05,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:07,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:08,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:10,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:11,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:12,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:12,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,903 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,910 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:14,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:14,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:14,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:14,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:14,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:14,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:15,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:16,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:16,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:19,107 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:19,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:19,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:20,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:20,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:20,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:21,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:25,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:28,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:30,259 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:30,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:30,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:32,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:34,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:34,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:34,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:35,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,306 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:37,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:37,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:37,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:37,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:37,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:37,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:38,005 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:38,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:38,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:38,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,947 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:41,001 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:41,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:41,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:42,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:44,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:44,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:45,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:48,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:51,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:52,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:01,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:01,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:01,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:01,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:01,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:02,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:02,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:02,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:02,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:02,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:03,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:03,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:04,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:06,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:06,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:07,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:07,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:07,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:07,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:08,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:08,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:08,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:08,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:08,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:09,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:09,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:09,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:15,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:16,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:16,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:17,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:18,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:18,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:18,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:18,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:19,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:19,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:19,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,191 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:24,936 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:25,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:55,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:55,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:55,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:57,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:57,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:57,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:57,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:58,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:04,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:08,556 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:09,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:09,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:09,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:09,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:10,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:10,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:11,227 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:12,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:12,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:12,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,442 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,943 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:14,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:14,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:14,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:14,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:14,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:16,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:16,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:16,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:16,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:20,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:22,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:23,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:23,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:23,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:23,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:23,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:23,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:30,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:30,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:31,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:31,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:31,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:31,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:31,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:31,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:32,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:32,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:32,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:32,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:32,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:33,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:33,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:33,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:33,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:35,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:35,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:41,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:42,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:42,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:43,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:47,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:48,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:50,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:50,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:50,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:50,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:51,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:51,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:52,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:54,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:54,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:55,482 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:55,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:55,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:55,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:56,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:56,263 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:56,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:56,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:57,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:57,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:57,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:57,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:58,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:58,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:59,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:59,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:00,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:00,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:02,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:04,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:06,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:08,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:11,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:11,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:11,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:13,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:13,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:13,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:13,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:13,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:13,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:14,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:14,139 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:14,144 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:14,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:14,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:14,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:14,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:17,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:17,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:18,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:18,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:18,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:19,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:19,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:19,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:23,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:23,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:23,519 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:23,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:23,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:27,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:34,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:34,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:34,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:34,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:34,642 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:35,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:35,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:35,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:35,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:35,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:35,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:35,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:35,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:36,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:36,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:36,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:36,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:36,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:36,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:37,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:37,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:37,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:38,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:38,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:38,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:38,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:40,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:41,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:41,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:41,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:45,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:45,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:45,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:48,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:48,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:48,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:49,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:50,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:50,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:50,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:52,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:52,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:52,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:52,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:52,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:52,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,422 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:54,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:54,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:54,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:54,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:54,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,589 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,592 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:56,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:56,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:56,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:56,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:57,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:57,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:57,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:57,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:57,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:57,947 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:58,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:58,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:59,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:59,223 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:59,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:59,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:00,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:01,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:01,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:13,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:13,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:13,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:14,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:14,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:14,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:14,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:15,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:16,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:16,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:16,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:16,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:19,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:20,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:21,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:21,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:22,155 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:23,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:23,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:24,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:24,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:24,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:24,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:26,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:27,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:27,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:27,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:27,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:27,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:29,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:29,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:32,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:33,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:34,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:34,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:34,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:34,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:36,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:38,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:39,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:39,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:39,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:40,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:40,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:41,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:44,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:44,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:44,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:44,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:44,589 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:44,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:44,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:44,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:47,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:47,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:56,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:57,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:58,108 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:58,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:58,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:58,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:59,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:59,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:59,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:59,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:00,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:00,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:00,713 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:00,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,846 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:03,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:03,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:04,422 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:04,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:04,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:04,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:05,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:07,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:08,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:10,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:10,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:12,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:14,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:22,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:22,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:22,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:29,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:32,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:32,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:34,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:36,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:37,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:37,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:38,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:39,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:39,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:39,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:39,161 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:39,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:39,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:39,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:39,642 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:39,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:40,011 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:40,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:41,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:41,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:42,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:42,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:42,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:43,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:43,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:43,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:43,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:43,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:43,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:44,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:44,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:46,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:46,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:46,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:46,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:47,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:50,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:50,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:50,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:50,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:50,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:51,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,161 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:53,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:53,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:54,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:54,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:55,150 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,078 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:02,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:03,945 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:03,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:05,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:05,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:05,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:05,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:05,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:06,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:06,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:06,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:06,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:08,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:08,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:08,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:08,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:11,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:11,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:12,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:14,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:21,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:23,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:37,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:37,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:37,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:37,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:41,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:41,083 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:46,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:52,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:53,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:53,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:54,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:54,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:57,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:57,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:57,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,422 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:59,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:59,556 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:59,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:59,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:00,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:00,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:01,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:01,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:01,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:06,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:07,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:07,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:08,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:09,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:09,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:09,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:12,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:29,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:29,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:29,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:29,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:30,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:30,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:30,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:30,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:32,196 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:32,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:32,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:32,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:32,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:34,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:35,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:35,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,314 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,314 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:37,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:37,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:37,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:37,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:37,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:37,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:37,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:47,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:47,909 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:51,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:51,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:53,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:53,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:53,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:54,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:54,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:54,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:54,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:54,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:54,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:54,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:59,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:59,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:59,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:00,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:03,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:12,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:12,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:13,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:13,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:13,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:13,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:13,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:13,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:14,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:14,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:14,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:14,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,255 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:16,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:16,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:16,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:16,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:17,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:17,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:18,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:18,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:18,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:20,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:20,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:21,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:21,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:21,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:22,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:25,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:25,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:26,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:26,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:26,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,101 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,101 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,316 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:28,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:28,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:28,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:28,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:28,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:29,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:29,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:29,944 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:30,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:30,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:30,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:30,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:30,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:34,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:36,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:36,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:36,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:37,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:38,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:42,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:42,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:46,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:46,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:46,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:47,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:47,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:48,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:48,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:48,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:48,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,005 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:50,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:50,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:50,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:52,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:52,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:53,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:53,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:53,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:54,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:54,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:54,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:55,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:55,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:57,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:58,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:59,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:02,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:02,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:03,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:03,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:04,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:04,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:04,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:04,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:04,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:04,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:04,805 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:05,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:05,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:05,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:05,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:05,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:06,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:06,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:07,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:10,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:10,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:22,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:22,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:23,263 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:23,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:23,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:23,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:23,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:25,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:26,484 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:26,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:27,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:29,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:29,589 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:31,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 32.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:35,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:35,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:39,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:39,075 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:39,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:39,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,161 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:41,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:41,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:41,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:44,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:44,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:44,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:44,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:48,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:49,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:56,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:56,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:00,604 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:00,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:01,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:01,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:02,023 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:02,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:02,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:02,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:02,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:04,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:05,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:06,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:06,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:07,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:07,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:07,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:07,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:07,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:07,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:08,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:09,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:11,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,599 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:16,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:16,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:16,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:16,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:17,113 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:17,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:17,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:17,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,779 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:18,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:19,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:19,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:19,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:20,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:20,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:20,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:21,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:22,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:23,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:23,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:23,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:26,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:26,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:28,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:28,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:29,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:29,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:29,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:30,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:31,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:31,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:37059. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:36477. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:34899. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:40841. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,816 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:35507. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,817 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:40747. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,817 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:40625. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,817 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:35417. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,817 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:35455. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,817 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:39221. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,817 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:38299. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,817 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:37079. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,818 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:43807. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,818 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:40795. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,818 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:43597. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,818 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:37715. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,818 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:41799. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,818 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:33423. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,818 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:45267. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,815 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,818 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:42437. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,818 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:45923. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,819 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:41563. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,819 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:34605. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,819 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:43403. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,819 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:41939. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,819 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:35571. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,819 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:40469. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,819 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:45395. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,819 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:41113. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,820 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:40797. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,820 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:38865. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,820 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:40561. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,820 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:41715. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,820 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:40177. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,820 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:45363. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,820 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:38489. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,820 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:34995. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,816 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,822 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:35301. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,821 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.102.25:50018 remote=tcp://10.6.102.1:8786>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:34,829 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:36595'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,831 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:45903'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,832 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 5746, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,832 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8773, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,832 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,832 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1426, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,832 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,832 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2548, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,833 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,833 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,833 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,833 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,833 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,833 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,833 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,833 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,837 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:46721'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,838 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:40511'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,838 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:42273'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,838 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2042, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,839 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3828, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,839 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:36487'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,839 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:35033'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,839 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,839 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.6:38037, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,839 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,839 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2517, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,839 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,839 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:35633'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,839 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2514, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,839 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,840 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,840 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 5132, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,840 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:41797'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,840 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2245, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,840 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,840 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2550, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,840 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:36373'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,840 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1953, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,840 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,840 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,840 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:39475'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,840 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2303, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,841 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1362, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,841 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3322, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,841 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:35289'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,841 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.34:34733, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,841 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8574, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,841 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1857, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,841 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:39773'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,841 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8558, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,841 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:45285'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,841 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.3:43743, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,841 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,842 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1650, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,842 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:37223'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,842 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,842 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1756, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,842 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,842 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.17:33353, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,842 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1758, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,842 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,842 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:45433'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,842 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,842 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,842 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,842 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,842 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2835, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,842 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1418, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,842 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,842 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,842 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2837, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,843 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 7169, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,843 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3184, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,843 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2487, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,843 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3660, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,843 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3664, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,843 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8578, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,843 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,843 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 5864, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,844 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,845 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,845 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,845 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,845 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,845 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,845 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,845 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,845 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,846 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,862 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:33225'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,862 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:37553'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,863 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.25:38979, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,863 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:44329'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,864 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:33051'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,864 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:35685'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,864 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:45627'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,864 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:41235'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,864 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,865 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:41045'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,865 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3680, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,865 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:33885'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,865 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.21:43175, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,865 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 4041, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,865 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2043, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,865 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:43451'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,865 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2044, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:46587'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,865 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.21:34219, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.24:36583, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2840, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:40123'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,866 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3528, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8361, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3676, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:43025'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,866 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2444, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:35147'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,866 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3530, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2959, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,866 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1120, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,867 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1818, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,867 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:34879'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,867 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2518, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,867 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1424, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,867 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.3:39291, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,867 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1997, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,867 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:42517'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,867 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3942, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,867 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1996, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,867 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:33135'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,867 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.21:40345, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,867 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:43969'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,867 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1479, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8287, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2911, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1652, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8759, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:38099'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.7:36125, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3861, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3162, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8278, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:34835'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2653, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:45293'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,868 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1854, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,869 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:37045'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1853, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2198, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,869 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2199, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2166, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.14:33567, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2165, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2484, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1416, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.35:44357, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.8:39213, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1360, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.22:33179, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1554, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.1:43151, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,872 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.25:37593, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1826, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,875 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1916, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,895 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,895 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,895 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,895 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,895 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,899 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:34,907 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,328 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,493 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:35,495 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:39535. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:35,505 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:35,506 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:36813. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,506 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49718 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49718 remote=tcp://10.6.102.1:8786>: Stream is closed
2025-09-03 16:42:35,514 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:36777'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,515 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:35,515 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:35,515 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:35,515 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:35,515 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:35,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:35,523 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x153a7532c250>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:35,530 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49752 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:35,532 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,533 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:41393'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,534 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:35,535 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:35,535 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:35,535 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:35,535 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:35,541 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:35,550 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,569 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,854 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:35,855 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:37413. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:35,867 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49612 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49612 remote=tcp://10.6.102.1:8786>: Stream is closed
2025-09-03 16:42:35,885 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:38125'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,886 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:35,886 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:35,886 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:35,886 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:35,886 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:35,893 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14c3f1be1d90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:35,903 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,982 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:35,984 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:38323. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,004 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49616 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:36,012 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:35291'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,013 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 7111, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:36,014 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,014 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,014 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,014 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,014 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,021 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x148e47cbc050>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,102 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,106 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,201 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:36,199 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:36,201 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:43941. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,201 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:40059. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,212 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49574 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49574 remote=tcp://10.6.102.1:8786>: Stream is closed
2025-09-03 16:42:36,213 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49554 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49554 remote=tcp://10.6.102.1:8786>: Stream is closed
2025-09-03 16:42:36,216 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:39457'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,221 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.20:37133, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:36,221 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2610, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:36,221 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,221 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,221 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,221 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,221 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,222 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:36883'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,224 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3194, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:36,224 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.11:39461, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:36,224 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.15:35551, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:36,224 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,224 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,224 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,224 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,224 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,227 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ffed448110>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,231 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ebdcf38d50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,363 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:36,364 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:36387. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,374 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49522 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49522 remote=tcp://10.6.102.1:8786>: Stream is closed
2025-09-03 16:42:36,385 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:41633'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,386 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,386 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,386 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,386 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,386 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,393 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x153068b40710>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,404 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,647 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,647 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,646 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.25:40747 -> tcp://10.6.102.14:39263
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.25:40747 remote=tcp://10.6.102.14:53840>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:36,686 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,688 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,758 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,821 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:36,823 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:39963. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,830 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.102.20:34835
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.102.25:41952 remote=tcp://10.6.102.20:34835>: Stream is closed
2025-09-03 16:42:36,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,839 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49606 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49606 remote=tcp://10.6.102.1:8786>: Stream is closed
2025-09-03 16:42:36,843 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:44087'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,845 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.7:44085, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:36,845 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,845 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,845 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,845 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,845 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,853 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x149450bdc890>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,861 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,902 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:36,911 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:36,927 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,929 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,931 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,001 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,077 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:37,080 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:37593. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,083 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,084 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,084 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,090 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:37,092 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:38731. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,092 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:37,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:37,102 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49604 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49604 remote=tcp://10.6.102.1:8786>: Stream is closed
2025-09-03 16:42:37,105 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,108 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49858 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:37,109 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:41249'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,110 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:37,110 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:37,110 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:37,110 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:37,110 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:37,112 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:41825'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,113 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:37,113 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:37,113 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:37,113 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:37,113 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:37,115 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14caac221c50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:37,118 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14f92fdeb1d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:37,122 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,124 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,155 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:37,155 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:44029. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,157 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:37,157 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:38979. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,162 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,162 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,172 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.25:38979 -> tcp://10.6.102.25:41799
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.25:38979 remote=tcp://10.6.102.25:51504>: Stream is closed
2025-09-03 16:42:37,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:37,181 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49668 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:37,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:37,186 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:33837'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,187 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:37,187 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:37,187 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:37,187 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:37,187 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:37,188 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49800 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:37,191 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:36251'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,192 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:37,192 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:37,192 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:37,192 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:37,192 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:37,191 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x146619fb32d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:37,195 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x147abc335b90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:37,200 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,201 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,333 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,372 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,375 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,376 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,377 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,476 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:33225'. Reason: nanny-close-gracefully
2025-09-03 16:42:37,480 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:33225' closed.
2025-09-03 16:42:37,484 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:34835'. Reason: nanny-close-gracefully
2025-09-03 16:42:37,485 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:34835' closed.
2025-09-03 16:42:37,486 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,536 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,541 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,552 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,572 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,790 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:37223'. Reason: nanny-close-gracefully
2025-09-03 16:42:37,791 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:37223' closed.
2025-09-03 16:42:37,906 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:37,924 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:37,925 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:41175. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,947 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49696 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:37,950 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:39731'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,951 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:37,951 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:37,951 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:37,951 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:37,951 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:37,955 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14b9333cdad0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:37,961 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,984 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:39475'. Reason: nanny-close-gracefully
2025-09-03 16:42:37,985 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:39475' closed.
2025-09-03 16:42:37,987 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:41393'. Reason: nanny-close-gracefully
2025-09-03 16:42:37,988 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:41393' closed.
2025-09-03 16:42:37,990 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:36777'. Reason: nanny-close-gracefully
2025-09-03 16:42:37,991 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:36777' closed.
2025-09-03 16:42:38,107 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,112 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,155 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,232 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:38,233 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.25:32773. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,239 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.25:32773 -> tcp://10.6.102.9:35641
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.25:32773 remote=tcp://10.6.102.9:51762>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-03 16:42:38,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:38,246 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.25:49708 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:38,248 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.25:39403'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,248 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2106, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:38,248 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:38,248 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:38,249 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:38,249 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:38,249 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:38,251 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14cee08bc290>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:38,305 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,364 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,393 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:38125'. Reason: nanny-close-gracefully
2025-09-03 16:42:38,394 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:38125' closed.
2025-09-03 16:42:38,406 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,600 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,623 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.25:38489 -> tcp://10.6.102.3:44205
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.25:38489 remote=tcp://10.6.102.3:54986>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:38,651 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,651 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,665 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:37553'. Reason: nanny-close-gracefully
2025-09-03 16:42:38,666 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:37553' closed.
2025-09-03 16:42:38,668 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:43969'. Reason: nanny-close-gracefully
2025-09-03 16:42:38,669 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:43969' closed.
2025-09-03 16:42:38,672 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,691 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,692 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,730 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,762 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,832 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,833 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,837 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:41633'. Reason: nanny-close-gracefully
2025-09-03 16:42:38,838 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:41633' closed.
2025-09-03 16:42:38,850 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,865 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,920 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,930 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,933 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,937 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,958 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,005 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,081 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,087 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,087 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,096 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:36883'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,097 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,098 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:36883' closed.
2025-09-03 16:42:39,102 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:45285'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,103 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:45285' closed.
2025-09-03 16:42:39,111 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,125 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,127 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,165 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,166 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,203 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,204 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,230 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:44329'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,231 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:44329' closed.
2025-09-03 16:42:39,267 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:40511'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,268 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:40511' closed.
2025-09-03 16:42:39,305 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:45433'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,307 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:45433' closed.
2025-09-03 16:42:39,326 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,345 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,375 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,378 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,380 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,381 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,441 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:41797'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,445 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:41797' closed.
2025-09-03 16:42:39,460 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:35291'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,460 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:35291' closed.
2025-09-03 16:42:39,490 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,540 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:43025'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,541 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:43025' closed.
2025-09-03 16:42:39,544 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,562 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:41235'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,563 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:41235' closed.
2025-09-03 16:42:39,575 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:38099'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,576 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:38099' closed.
2025-09-03 16:42:39,582 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:36373'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,583 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:36373' closed.
2025-09-03 16:42:39,638 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:36251'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,644 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:36251' closed.
2025-09-03 16:42:39,690 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:34879'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,690 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:44087'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:35147'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,692 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:34879' closed.
2025-09-03 16:42:39,692 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:44087' closed.
2025-09-03 16:42:39,692 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:35147' closed.
2025-09-03 16:42:39,716 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:39457'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,718 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:39457' closed.
2025-09-03 16:42:39,740 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:41249'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,741 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:41249' closed.
2025-09-03 16:42:39,743 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:42273'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,744 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:42273' closed.
2025-09-03 16:42:39,763 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:33051'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,764 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:33051' closed.
2025-09-03 16:42:39,777 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:33837'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,778 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:33837' closed.
2025-09-03 16:42:39,795 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:41825'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,796 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:41825' closed.
2025-09-03 16:42:39,905 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:35033'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,906 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:35033' closed.
2025-09-03 16:42:39,909 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:35289'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,910 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:35289' closed.
2025-09-03 16:42:39,911 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:43451'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,915 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:43451' closed.
2025-09-03 16:42:39,963 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,971 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:45903'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,972 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:45903' closed.
2025-09-03 16:42:39,983 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:45293'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,984 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:45293' closed.
2025-09-03 16:42:39,987 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:46587'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,988 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:46587' closed.
2025-09-03 16:42:40,159 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,307 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,368 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,380 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:39731'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,383 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:39731' closed.
2025-09-03 16:42:40,601 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:37045'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,602 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:37045' closed.
2025-09-03 16:42:40,676 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,723 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:39403'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,724 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:39403' closed.
2025-09-03 16:42:40,733 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,808 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:41045'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,809 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:41045' closed.
2025-09-03 16:42:40,836 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,836 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,854 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,925 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,962 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,058 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:39773'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,059 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:39773' closed.
2025-09-03 16:42:41,084 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,256 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:33135'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,257 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:33135' closed.
2025-09-03 16:42:41,271 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:46721'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,272 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:46721' closed.
2025-09-03 16:42:41,291 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:40123'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,292 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:40123' closed.
2025-09-03 16:42:41,330 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,348 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,390 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:36595'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,391 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:36595' closed.
2025-09-03 16:42:41,422 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:33885'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,423 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:33885' closed.
2025-09-03 16:42:41,454 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:45627'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,455 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:45627' closed.
2025-09-03 16:42:41,476 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:35685'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,476 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:35685' closed.
2025-09-03 16:42:41,494 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:36487'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,495 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:36487' closed.
2025-09-03 16:42:41,873 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:35633'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,874 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:35633' closed.
2025-09-03 16:42:41,882 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.25:42517'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,883 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.25:42517' closed.
2025-09-03 16:42:41,885 - distributed.dask_worker - INFO - End worker
