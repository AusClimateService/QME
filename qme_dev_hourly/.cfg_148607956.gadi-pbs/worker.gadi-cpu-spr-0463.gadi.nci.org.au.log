Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:52:26,088 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:44131'
2025-09-03 10:52:26,096 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:41393'
2025-09-03 10:52:26,101 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40475'
2025-09-03 10:52:26,105 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34545'
2025-09-03 10:52:26,110 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:41907'
2025-09-03 10:52:26,177 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:39685'
2025-09-03 10:52:26,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:33379'
2025-09-03 10:52:26,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:33683'
2025-09-03 10:52:26,192 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:44957'
2025-09-03 10:52:26,197 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:41771'
2025-09-03 10:52:26,201 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:33347'
2025-09-03 10:52:26,205 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40147'
2025-09-03 10:52:26,209 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:46537'
2025-09-03 10:52:26,214 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:38763'
2025-09-03 10:52:26,218 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:42665'
2025-09-03 10:52:26,222 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:45285'
2025-09-03 10:52:26,226 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40633'
2025-09-03 10:52:26,231 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:46033'
2025-09-03 10:52:26,236 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:46329'
2025-09-03 10:52:26,241 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:33087'
2025-09-03 10:52:26,246 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:36737'
2025-09-03 10:52:26,249 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:43917'
2025-09-03 10:52:26,254 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:33917'
2025-09-03 10:52:26,257 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:41347'
2025-09-03 10:52:26,261 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34507'
2025-09-03 10:52:26,266 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:38609'
2025-09-03 10:52:26,270 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:38051'
2025-09-03 10:52:26,277 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:42333'
2025-09-03 10:52:26,281 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:45001'
2025-09-03 10:52:26,286 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34253'
2025-09-03 10:52:26,290 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:36767'
2025-09-03 10:52:26,293 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34353'
2025-09-03 10:52:26,298 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40307'
2025-09-03 10:52:26,302 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:39001'
2025-09-03 10:52:26,307 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:44853'
2025-09-03 10:52:26,312 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:36347'
2025-09-03 10:52:26,317 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34137'
2025-09-03 10:52:26,322 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:43977'
2025-09-03 10:52:26,325 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40881'
2025-09-03 10:52:26,330 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:46131'
2025-09-03 10:52:26,335 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:35153'
2025-09-03 10:52:26,340 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40609'
2025-09-03 10:52:26,437 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:46517'
2025-09-03 10:52:26,442 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:45907'
2025-09-03 10:52:26,447 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34975'
2025-09-03 10:52:26,452 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:33311'
2025-09-03 10:52:26,458 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:36187'
2025-09-03 10:52:26,463 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:46785'
2025-09-03 10:52:26,469 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:37603'
2025-09-03 10:52:26,472 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:35233'
2025-09-03 10:52:26,476 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:39751'
2025-09-03 10:52:26,480 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:39109'
2025-09-03 10:52:26,483 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40827'
2025-09-03 10:52:26,488 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:42849'
2025-09-03 10:52:26,491 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:44573'
2025-09-03 10:52:26,494 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:36325'
2025-09-03 10:52:26,499 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:42253'
2025-09-03 10:52:26,502 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:39627'
2025-09-03 10:52:26,507 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:39161'
2025-09-03 10:52:26,511 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:46787'
2025-09-03 10:52:26,516 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:43793'
2025-09-03 10:52:26,519 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34417'
2025-09-03 10:52:26,525 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:38667'
2025-09-03 10:52:26,529 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:41425'
2025-09-03 10:52:26,534 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:44691'
2025-09-03 10:52:26,538 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:35753'
2025-09-03 10:52:26,543 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:38189'
2025-09-03 10:52:26,548 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40409'
2025-09-03 10:52:26,554 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:33597'
2025-09-03 10:52:26,559 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:42331'
2025-09-03 10:52:26,565 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:44147'
2025-09-03 10:52:26,569 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40767'
2025-09-03 10:52:26,573 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:42689'
2025-09-03 10:52:26,578 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40615'
2025-09-03 10:52:26,584 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:36861'
2025-09-03 10:52:26,589 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:45013'
2025-09-03 10:52:26,962 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40559'
2025-09-03 10:52:27,144 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:39767'
2025-09-03 10:52:27,148 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:33771'
2025-09-03 10:52:27,151 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:35873'
2025-09-03 10:52:27,156 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:42521'
2025-09-03 10:52:27,160 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:43199'
2025-09-03 10:52:27,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:33701'
2025-09-03 10:52:27,169 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:35539'
2025-09-03 10:52:27,173 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:42041'
2025-09-03 10:52:27,178 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:36119'
2025-09-03 10:52:27,182 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:38967'
2025-09-03 10:52:27,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:42841'
2025-09-03 10:52:27,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:38475'
2025-09-03 10:52:27,191 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34679'
2025-09-03 10:52:27,196 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:39517'
2025-09-03 10:52:27,202 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34043'
2025-09-03 10:52:27,207 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:34763'
2025-09-03 10:52:27,211 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40461'
2025-09-03 10:52:27,216 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:46293'
2025-09-03 10:52:27,219 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:39183'
2025-09-03 10:52:27,222 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:41513'
2025-09-03 10:52:27,227 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:40555'
2025-09-03 10:52:27,234 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:41651'
2025-09-03 10:52:27,237 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:44979'
2025-09-03 10:52:27,240 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:43083'
2025-09-03 10:52:27,243 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:45189'
2025-09-03 10:52:27,247 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:38177'
2025-09-03 10:52:27,251 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.31:36327'
2025-09-03 10:52:27,802 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:35981
2025-09-03 10:52:27,803 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:42733
2025-09-03 10:52:27,803 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:35981
2025-09-03 10:52:27,803 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:37429
2025-09-03 10:52:27,803 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:42733
2025-09-03 10:52:27,803 - distributed.worker - INFO -          dashboard at:          10.6.102.31:35869
2025-09-03 10:52:27,803 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:37429
2025-09-03 10:52:27,803 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43665
2025-09-03 10:52:27,803 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,803 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:44375
2025-09-03 10:52:27,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,803 - distributed.worker - INFO -          dashboard at:          10.6.102.31:44823
2025-09-03 10:52:27,803 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,803 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:44375
2025-09-03 10:52:27,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,803 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,803 - distributed.worker - INFO -          dashboard at:          10.6.102.31:42501
2025-09-03 10:52:27,803 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,803 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,803 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,803 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,803 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,803 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-sdpy_v49
2025-09-03 10:52:27,803 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,803 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-za2iqlgd
2025-09-03 10:52:27,803 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,803 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-l4i2sv5s
2025-09-03 10:52:27,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,803 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,804 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,804 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4m_9xkob
2025-09-03 10:52:27,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,871 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34941
2025-09-03 10:52:27,871 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34941
2025-09-03 10:52:27,871 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43521
2025-09-03 10:52:27,871 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,871 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,871 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,871 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,871 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-npnehtcz
2025-09-03 10:52:27,871 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,875 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:38161
2025-09-03 10:52:27,875 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:38161
2025-09-03 10:52:27,875 - distributed.worker - INFO -          dashboard at:          10.6.102.31:44861
2025-09-03 10:52:27,875 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,875 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,875 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,875 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,875 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ai8s_6i0
2025-09-03 10:52:27,875 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,877 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33729
2025-09-03 10:52:27,877 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33729
2025-09-03 10:52:27,877 - distributed.worker - INFO -          dashboard at:          10.6.102.31:36847
2025-09-03 10:52:27,877 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,877 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,877 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,877 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,877 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2m51ekf3
2025-09-03 10:52:27,877 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,882 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33931
2025-09-03 10:52:27,882 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33931
2025-09-03 10:52:27,882 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45511
2025-09-03 10:52:27,882 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,882 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,882 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,882 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,882 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-zf8vgbqk
2025-09-03 10:52:27,882 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,899 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34463
2025-09-03 10:52:27,899 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34463
2025-09-03 10:52:27,899 - distributed.worker - INFO -          dashboard at:          10.6.102.31:44115
2025-09-03 10:52:27,899 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,899 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,899 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,899 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ba26e6d1
2025-09-03 10:52:27,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,912 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39287
2025-09-03 10:52:27,912 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39287
2025-09-03 10:52:27,912 - distributed.worker - INFO -          dashboard at:          10.6.102.31:39113
2025-09-03 10:52:27,912 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,912 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,912 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,912 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,912 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-xfnz7a57
2025-09-03 10:52:27,912 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,927 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34913
2025-09-03 10:52:27,927 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34913
2025-09-03 10:52:27,927 - distributed.worker - INFO -          dashboard at:          10.6.102.31:46515
2025-09-03 10:52:27,927 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,927 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,927 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,927 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,927 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-eh_otqz5
2025-09-03 10:52:27,927 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,940 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:46395
2025-09-03 10:52:27,940 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:46395
2025-09-03 10:52:27,940 - distributed.worker - INFO -          dashboard at:          10.6.102.31:46725
2025-09-03 10:52:27,940 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,940 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,940 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,940 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-c0fek2lh
2025-09-03 10:52:27,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,959 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39633
2025-09-03 10:52:27,959 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39633
2025-09-03 10:52:27,959 - distributed.worker - INFO -          dashboard at:          10.6.102.31:38749
2025-09-03 10:52:27,959 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:27,959 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:27,959 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:27,959 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:27,959 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-da37wc_8
2025-09-03 10:52:27,959 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,019 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34443
2025-09-03 10:52:28,019 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34443
2025-09-03 10:52:28,019 - distributed.worker - INFO -          dashboard at:          10.6.102.31:39365
2025-09-03 10:52:28,019 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,019 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,019 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,019 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,019 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-34fh49jj
2025-09-03 10:52:28,019 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,040 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:40837
2025-09-03 10:52:28,040 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:40837
2025-09-03 10:52:28,040 - distributed.worker - INFO -          dashboard at:          10.6.102.31:41489
2025-09-03 10:52:28,040 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,040 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,040 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,040 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,040 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6xhee7wl
2025-09-03 10:52:28,040 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,063 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,064 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,065 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,066 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,071 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:43465
2025-09-03 10:52:28,071 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:43465
2025-09-03 10:52:28,071 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43447
2025-09-03 10:52:28,072 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,072 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,072 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,072 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,072 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2l53mwdf
2025-09-03 10:52:28,072 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,075 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,076 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,076 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,078 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,087 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,088 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,089 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,090 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,102 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,105 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,105 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,110 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,175 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:43189
2025-09-03 10:52:28,175 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:43189
2025-09-03 10:52:28,175 - distributed.worker - INFO -          dashboard at:          10.6.102.31:38657
2025-09-03 10:52:28,176 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,176 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,176 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,176 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,176 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-gu0gxhgf
2025-09-03 10:52:28,176 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,192 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:42259
2025-09-03 10:52:28,192 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:42259
2025-09-03 10:52:28,193 - distributed.worker - INFO -          dashboard at:          10.6.102.31:42341
2025-09-03 10:52:28,193 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,193 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,193 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,193 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,193 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-qpwned8z
2025-09-03 10:52:28,193 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,218 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:45909
2025-09-03 10:52:28,218 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:45909
2025-09-03 10:52:28,218 - distributed.worker - INFO -          dashboard at:          10.6.102.31:33519
2025-09-03 10:52:28,218 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,218 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,218 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,218 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,218 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-17kd0if1
2025-09-03 10:52:28,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,219 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,219 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,221 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,229 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:35257
2025-09-03 10:52:28,229 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:35257
2025-09-03 10:52:28,229 - distributed.worker - INFO -          dashboard at:          10.6.102.31:42531
2025-09-03 10:52:28,229 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,229 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,229 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,229 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,229 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-bi3xwq42
2025-09-03 10:52:28,229 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,230 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,231 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,231 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,233 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,243 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,244 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,244 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,246 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,252 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39205
2025-09-03 10:52:28,252 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39205
2025-09-03 10:52:28,252 - distributed.worker - INFO -          dashboard at:          10.6.102.31:32923
2025-09-03 10:52:28,252 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,252 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,252 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,252 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,252 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6i5__yk7
2025-09-03 10:52:28,252 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,255 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,257 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,257 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,259 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,260 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:38849
2025-09-03 10:52:28,260 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:38849
2025-09-03 10:52:28,260 - distributed.worker - INFO -          dashboard at:          10.6.102.31:34635
2025-09-03 10:52:28,260 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,260 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,260 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,260 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-zejcsyxy
2025-09-03 10:52:28,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,270 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33795
2025-09-03 10:52:28,270 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33795
2025-09-03 10:52:28,270 - distributed.worker - INFO -          dashboard at:          10.6.102.31:34879
2025-09-03 10:52:28,270 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,270 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,270 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,270 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-nqr01upn
2025-09-03 10:52:28,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,276 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34413
2025-09-03 10:52:28,276 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34413
2025-09-03 10:52:28,276 - distributed.worker - INFO -          dashboard at:          10.6.102.31:39543
2025-09-03 10:52:28,276 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,276 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,277 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,277 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,277 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_d2h_h7u
2025-09-03 10:52:28,277 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,280 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33973
2025-09-03 10:52:28,280 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33973
2025-09-03 10:52:28,280 - distributed.worker - INFO -          dashboard at:          10.6.102.31:38799
2025-09-03 10:52:28,280 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,280 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,280 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,280 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-uc_k3yzy
2025-09-03 10:52:28,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,288 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:42019
2025-09-03 10:52:28,288 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:42019
2025-09-03 10:52:28,288 - distributed.worker - INFO -          dashboard at:          10.6.102.31:41627
2025-09-03 10:52:28,288 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,288 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,288 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,288 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wcadjuhk
2025-09-03 10:52:28,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,294 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33009
2025-09-03 10:52:28,294 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33009
2025-09-03 10:52:28,294 - distributed.worker - INFO -          dashboard at:          10.6.102.31:38513
2025-09-03 10:52:28,294 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,294 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,294 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,294 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,294 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kz3wr7x4
2025-09-03 10:52:28,294 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,297 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:38551
2025-09-03 10:52:28,297 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:38551
2025-09-03 10:52:28,297 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45109
2025-09-03 10:52:28,297 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,297 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,297 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,297 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8cgu45py
2025-09-03 10:52:28,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,304 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:40639
2025-09-03 10:52:28,304 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:40639
2025-09-03 10:52:28,304 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45419
2025-09-03 10:52:28,304 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,304 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,304 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,305 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,305 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-li9bjsdt
2025-09-03 10:52:28,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,305 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,306 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,306 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,307 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,317 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:41661
2025-09-03 10:52:28,317 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:41661
2025-09-03 10:52:28,317 - distributed.worker - INFO -          dashboard at:          10.6.102.31:35451
2025-09-03 10:52:28,317 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,317 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,317 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,317 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,317 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-d40a8imz
2025-09-03 10:52:28,317 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,330 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,331 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,332 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,336 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34101
2025-09-03 10:52:28,336 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34101
2025-09-03 10:52:28,336 - distributed.worker - INFO -          dashboard at:          10.6.102.31:35557
2025-09-03 10:52:28,336 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,337 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,337 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,337 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,337 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8h1_q23j
2025-09-03 10:52:28,337 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,342 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,343 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,343 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,345 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,354 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,356 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,356 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,357 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,367 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,368 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,368 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,370 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,379 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,380 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,382 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,391 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,392 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,392 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,394 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,400 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33785
2025-09-03 10:52:28,401 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33785
2025-09-03 10:52:28,401 - distributed.worker - INFO -          dashboard at:          10.6.102.31:34125
2025-09-03 10:52:28,401 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,401 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,401 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,401 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,401 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kh5npqlx
2025-09-03 10:52:28,401 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,429 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,430 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,430 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,432 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,536 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:46455
2025-09-03 10:52:28,536 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:46455
2025-09-03 10:52:28,536 - distributed.worker - INFO -          dashboard at:          10.6.102.31:36567
2025-09-03 10:52:28,536 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,536 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,536 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,536 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,536 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7fcc4tat
2025-09-03 10:52:28,536 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,551 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:46213
2025-09-03 10:52:28,551 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:46213
2025-09-03 10:52:28,551 - distributed.worker - INFO -          dashboard at:          10.6.102.31:38375
2025-09-03 10:52:28,551 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,551 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,551 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,551 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,551 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-fgyu73l1
2025-09-03 10:52:28,551 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,602 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:35965
2025-09-03 10:52:28,602 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:35965
2025-09-03 10:52:28,602 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43945
2025-09-03 10:52:28,602 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,602 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,602 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,602 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-hnlxyzlm
2025-09-03 10:52:28,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,656 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33615
2025-09-03 10:52:28,657 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33615
2025-09-03 10:52:28,657 - distributed.worker - INFO -          dashboard at:          10.6.102.31:44771
2025-09-03 10:52:28,657 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,657 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,657 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,657 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,657 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-bciqxzgs
2025-09-03 10:52:28,657 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,676 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39991
2025-09-03 10:52:28,676 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39991
2025-09-03 10:52:28,676 - distributed.worker - INFO -          dashboard at:          10.6.102.31:37485
2025-09-03 10:52:28,676 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,676 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,676 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,676 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,676 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-zb9k_u_x
2025-09-03 10:52:28,676 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,692 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:45295
2025-09-03 10:52:28,693 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:45295
2025-09-03 10:52:28,693 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45323
2025-09-03 10:52:28,693 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,693 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,693 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,693 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,693 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-byaro0nx
2025-09-03 10:52:28,693 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,695 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34045
2025-09-03 10:52:28,695 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34045
2025-09-03 10:52:28,695 - distributed.worker - INFO -          dashboard at:          10.6.102.31:38293
2025-09-03 10:52:28,695 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,695 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,695 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,695 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,695 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-d3rxopr2
2025-09-03 10:52:28,695 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,702 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:38545
2025-09-03 10:52:28,702 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:38545
2025-09-03 10:52:28,702 - distributed.worker - INFO -          dashboard at:          10.6.102.31:39383
2025-09-03 10:52:28,702 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,702 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,702 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,702 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-a37bm4hg
2025-09-03 10:52:28,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,714 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,715 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,715 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,717 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,738 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,740 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,740 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,742 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,787 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:42697
2025-09-03 10:52:28,787 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:42697
2025-09-03 10:52:28,787 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43107
2025-09-03 10:52:28,787 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,787 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,787 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,788 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-l2v3_1xm
2025-09-03 10:52:28,788 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,886 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,887 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,888 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33171
2025-09-03 10:52:28,889 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33171
2025-09-03 10:52:28,889 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40809
2025-09-03 10:52:28,889 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,889 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,889 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,889 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-f45loe35
2025-09-03 10:52:28,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,889 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,936 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,938 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,938 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,939 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,947 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:40535
2025-09-03 10:52:28,947 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:40535
2025-09-03 10:52:28,947 - distributed.worker - INFO -          dashboard at:          10.6.102.31:41057
2025-09-03 10:52:28,947 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,947 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,947 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,947 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,947 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-zu__xr62
2025-09-03 10:52:28,947 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,952 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:44553
2025-09-03 10:52:28,952 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:44553
2025-09-03 10:52:28,952 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45069
2025-09-03 10:52:28,952 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,952 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,952 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,952 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,952 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-v_hni6es
2025-09-03 10:52:28,953 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,958 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34601
2025-09-03 10:52:28,958 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34601
2025-09-03 10:52:28,958 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45147
2025-09-03 10:52:28,958 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,958 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,958 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,958 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,958 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-hy3xn9pv
2025-09-03 10:52:28,958 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,961 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,963 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,963 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,964 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:28,966 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:43151
2025-09-03 10:52:28,966 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:43151
2025-09-03 10:52:28,966 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45421
2025-09-03 10:52:28,966 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,966 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,966 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,966 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,966 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-fl2tt4tg
2025-09-03 10:52:28,966 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,973 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:46177
2025-09-03 10:52:28,973 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:46177
2025-09-03 10:52:28,973 - distributed.worker - INFO -          dashboard at:          10.6.102.31:44203
2025-09-03 10:52:28,973 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,973 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,973 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,973 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,973 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ji6yn1t9
2025-09-03 10:52:28,973 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,975 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:36099
2025-09-03 10:52:28,975 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:36099
2025-09-03 10:52:28,975 - distributed.worker - INFO -          dashboard at:          10.6.102.31:34479
2025-09-03 10:52:28,975 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,975 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,976 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,976 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,976 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-60_z7nm8
2025-09-03 10:52:28,976 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,976 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:44587
2025-09-03 10:52:28,977 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:44587
2025-09-03 10:52:28,977 - distributed.worker - INFO -          dashboard at:          10.6.102.31:34267
2025-09-03 10:52:28,977 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,977 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,977 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,977 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,977 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6fibwur6
2025-09-03 10:52:28,977 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,981 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:45459
2025-09-03 10:52:28,982 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:45459
2025-09-03 10:52:28,982 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40741
2025-09-03 10:52:28,982 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,982 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,982 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:28,982 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:28,982 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-it7i1ca9
2025-09-03 10:52:28,982 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,986 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:28,987 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:28,987 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:28,989 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,010 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,011 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,012 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,013 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,017 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:46105
2025-09-03 10:52:29,017 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:46105
2025-09-03 10:52:29,017 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40101
2025-09-03 10:52:29,017 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,017 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,017 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,017 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-qqc_gsck
2025-09-03 10:52:29,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,023 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,024 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,026 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,035 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,036 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,036 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,038 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,048 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,049 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,049 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,051 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,060 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,061 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,061 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,063 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,072 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,074 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,074 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,075 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,085 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,086 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,086 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,088 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,097 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,099 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,099 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,100 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,110 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,111 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,111 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,113 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,135 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:38431
2025-09-03 10:52:29,135 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:38431
2025-09-03 10:52:29,135 - distributed.worker - INFO -          dashboard at:          10.6.102.31:36473
2025-09-03 10:52:29,135 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,135 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,135 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,135 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,135 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-i3u5y4vd
2025-09-03 10:52:29,135 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,147 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,148 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,149 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,150 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,198 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:36999
2025-09-03 10:52:29,198 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:36999
2025-09-03 10:52:29,198 - distributed.worker - INFO -          dashboard at:          10.6.102.31:33631
2025-09-03 10:52:29,198 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,198 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,198 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,198 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,198 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-d_rsu1sc
2025-09-03 10:52:29,198 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,225 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:44231
2025-09-03 10:52:29,225 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:44231
2025-09-03 10:52:29,225 - distributed.worker - INFO -          dashboard at:          10.6.102.31:46101
2025-09-03 10:52:29,225 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,225 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,225 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,225 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,226 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_lw27v0u
2025-09-03 10:52:29,226 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,371 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:43375
2025-09-03 10:52:29,407 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:42553
2025-09-03 10:52:29,593 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:43375
2025-09-03 10:52:29,421 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34127
2025-09-03 10:52:29,593 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:42553
2025-09-03 10:52:29,594 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45947
2025-09-03 10:52:29,436 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,594 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,594 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43449
2025-09-03 10:52:29,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,444 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:36361
2025-09-03 10:52:29,594 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34127
2025-09-03 10:52:29,594 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,594 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,450 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:44785
2025-09-03 10:52:29,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,594 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,594 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43415
2025-09-03 10:52:29,594 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,450 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:41811
2025-09-03 10:52:29,594 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:36361
2025-09-03 10:52:29,594 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-irb5ulh0
2025-09-03 10:52:29,594 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,594 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,594 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:44785
2025-09-03 10:52:29,468 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:43085
2025-09-03 10:52:29,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,595 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40383
2025-09-03 10:52:29,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,595 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wwfclg_s
2025-09-03 10:52:29,595 - distributed.worker - INFO -          dashboard at:          10.6.102.31:37039
2025-09-03 10:52:29,595 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,595 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:41811
2025-09-03 10:52:29,471 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33203
2025-09-03 10:52:29,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,595 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,595 - distributed.worker - INFO -          dashboard at:          10.6.102.31:33595
2025-09-03 10:52:29,595 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:43085
2025-09-03 10:52:29,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,595 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ipjjrgu6
2025-09-03 10:52:29,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,595 - distributed.worker - INFO -          dashboard at:          10.6.102.31:37045
2025-09-03 10:52:29,595 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,487 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:32893
2025-09-03 10:52:29,595 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,595 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33203
2025-09-03 10:52:29,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,595 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,492 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:40679
2025-09-03 10:52:29,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,596 - distributed.worker - INFO -          dashboard at:          10.6.102.31:36479
2025-09-03 10:52:29,596 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-b8vx_8ro
2025-09-03 10:52:29,497 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:36653
2025-09-03 10:52:29,596 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:32893
2025-09-03 10:52:29,576 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:43023
2025-09-03 10:52:29,596 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,596 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-m0c02asw
2025-09-03 10:52:29,596 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,596 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:40679
2025-09-03 10:52:29,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,596 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40425
2025-09-03 10:52:29,596 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:43023
2025-09-03 10:52:29,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,596 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-8jimvjai
2025-09-03 10:52:29,596 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:36653
2025-09-03 10:52:29,596 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40401
2025-09-03 10:52:29,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,596 - distributed.worker - INFO -          dashboard at:          10.6.102.31:34203
2025-09-03 10:52:29,596 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,596 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,596 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-5zjyczm6
2025-09-03 10:52:29,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,596 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40435
2025-09-03 10:52:29,596 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,597 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wtva7t8z
2025-09-03 10:52:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,597 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,597 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,597 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,597 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-pnrxlchz
2025-09-03 10:52:29,597 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,597 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-uoj386qr
2025-09-03 10:52:29,597 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,597 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,597 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,597 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-p2ib9hpo
2025-09-03 10:52:29,597 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-39zoewr3
2025-09-03 10:52:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,598 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,598 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,609 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:40621
2025-09-03 10:52:29,609 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:40621
2025-09-03 10:52:29,609 - distributed.worker - INFO -          dashboard at:          10.6.102.31:35691
2025-09-03 10:52:29,609 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,609 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,609 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,610 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,610 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-r6u_0ueo
2025-09-03 10:52:29,610 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,624 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,625 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,625 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,627 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,627 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:38459
2025-09-03 10:52:29,627 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:38459
2025-09-03 10:52:29,627 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40673
2025-09-03 10:52:29,627 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,628 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,628 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,628 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-r5szq3s4
2025-09-03 10:52:29,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,653 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:46121
2025-09-03 10:52:29,653 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:46121
2025-09-03 10:52:29,653 - distributed.worker - INFO -          dashboard at:          10.6.102.31:32813
2025-09-03 10:52:29,653 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,653 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,653 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,653 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-s2zk4r9h
2025-09-03 10:52:29,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,655 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:42889
2025-09-03 10:52:29,655 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:42889
2025-09-03 10:52:29,655 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43169
2025-09-03 10:52:29,655 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,655 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,655 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,655 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,655 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ilcd6597
2025-09-03 10:52:29,655 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,658 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:42865
2025-09-03 10:52:29,658 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:42865
2025-09-03 10:52:29,658 - distributed.worker - INFO -          dashboard at:          10.6.102.31:35603
2025-09-03 10:52:29,658 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,658 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,658 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,658 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,658 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-kvdzx7dk
2025-09-03 10:52:29,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,662 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39275
2025-09-03 10:52:29,662 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39275
2025-09-03 10:52:29,662 - distributed.worker - INFO -          dashboard at:          10.6.102.31:44575
2025-09-03 10:52:29,662 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,662 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,662 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,662 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-968rqkzn
2025-09-03 10:52:29,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,670 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:43985
2025-09-03 10:52:29,670 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:43985
2025-09-03 10:52:29,670 - distributed.worker - INFO -          dashboard at:          10.6.102.31:41041
2025-09-03 10:52:29,670 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,671 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,671 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,671 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,671 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-skcnqj5y
2025-09-03 10:52:29,671 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,679 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:45413
2025-09-03 10:52:29,679 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:45413
2025-09-03 10:52:29,679 - distributed.worker - INFO -          dashboard at:          10.6.102.31:35905
2025-09-03 10:52:29,679 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,679 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,679 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,679 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,679 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-jrloiz23
2025-09-03 10:52:29,679 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,681 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:41055
2025-09-03 10:52:29,681 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:41055
2025-09-03 10:52:29,681 - distributed.worker - INFO -          dashboard at:          10.6.102.31:35585
2025-09-03 10:52:29,681 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,681 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,681 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,681 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,681 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-7106rf_d
2025-09-03 10:52:29,681 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,687 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:37223
2025-09-03 10:52:29,687 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:37223
2025-09-03 10:52:29,687 - distributed.worker - INFO -          dashboard at:          10.6.102.31:36991
2025-09-03 10:52:29,687 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,687 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,687 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,687 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,687 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-3fiqbblo
2025-09-03 10:52:29,687 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,693 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:38687
2025-09-03 10:52:29,693 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:38687
2025-09-03 10:52:29,693 - distributed.worker - INFO -          dashboard at:          10.6.102.31:46117
2025-09-03 10:52:29,693 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,693 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,693 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,693 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,693 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-wehipy8f
2025-09-03 10:52:29,693 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,708 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:37041
2025-09-03 10:52:29,708 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:37041
2025-09-03 10:52:29,708 - distributed.worker - INFO -          dashboard at:          10.6.102.31:34741
2025-09-03 10:52:29,709 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,709 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,709 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,709 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,709 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-c8xlmc2u
2025-09-03 10:52:29,709 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,725 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,727 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,727 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,728 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,750 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,751 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33623
2025-09-03 10:52:29,751 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,751 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33623
2025-09-03 10:52:29,751 - distributed.worker - INFO -          dashboard at:          10.6.102.31:44269
2025-09-03 10:52:29,751 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,751 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,751 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,751 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,751 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,751 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-dp3nbh8b
2025-09-03 10:52:29,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,753 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,788 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,789 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,789 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,791 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,801 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,802 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,803 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,813 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:29,814 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,816 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:29,841 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:38533
2025-09-03 10:52:29,841 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:38533
2025-09-03 10:52:29,841 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40943
2025-09-03 10:52:29,841 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,842 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,842 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,842 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6gd7zgpo
2025-09-03 10:52:29,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,843 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:41801
2025-09-03 10:52:29,843 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:41801
2025-09-03 10:52:29,843 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43675
2025-09-03 10:52:29,843 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,843 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,843 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,843 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,843 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-403vkow2
2025-09-03 10:52:29,843 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,882 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:41817
2025-09-03 10:52:29,883 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:41817
2025-09-03 10:52:29,883 - distributed.worker - INFO -          dashboard at:          10.6.102.31:39029
2025-09-03 10:52:29,883 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,883 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:44955
2025-09-03 10:52:29,883 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,883 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,883 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:44955
2025-09-03 10:52:29,883 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,883 - distributed.worker - INFO -          dashboard at:          10.6.102.31:40539
2025-09-03 10:52:29,883 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-fjycm8sv
2025-09-03 10:52:29,883 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,883 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,883 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,883 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,883 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,883 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ib8nw5b5
2025-09-03 10:52:29,883 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,909 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39403
2025-09-03 10:52:29,909 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39403
2025-09-03 10:52:29,909 - distributed.worker - INFO -          dashboard at:          10.6.102.31:39957
2025-09-03 10:52:29,909 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,909 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,909 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,909 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,909 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-1f3cjyfk
2025-09-03 10:52:29,909 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,913 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:42359
2025-09-03 10:52:29,913 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:42359
2025-09-03 10:52:29,913 - distributed.worker - INFO -          dashboard at:          10.6.102.31:35989
2025-09-03 10:52:29,913 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:29,913 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:29,913 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:29,913 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:29,913 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-brozyihx
2025-09-03 10:52:29,913 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,028 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:41847
2025-09-03 10:52:30,028 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:41847
2025-09-03 10:52:30,028 - distributed.worker - INFO -          dashboard at:          10.6.102.31:39123
2025-09-03 10:52:30,028 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,028 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,028 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,028 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2vxjaem1
2025-09-03 10:52:30,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,035 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33775
2025-09-03 10:52:30,035 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33775
2025-09-03 10:52:30,035 - distributed.worker - INFO -          dashboard at:          10.6.102.31:38231
2025-09-03 10:52:30,035 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,035 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,035 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,035 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,035 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-u03i6t9i
2025-09-03 10:52:30,035 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,038 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:34521
2025-09-03 10:52:30,038 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:34521
2025-09-03 10:52:30,038 - distributed.worker - INFO -          dashboard at:          10.6.102.31:38857
2025-09-03 10:52:30,038 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,038 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,038 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,038 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,038 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-pxppapue
2025-09-03 10:52:30,038 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,038 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:33313
2025-09-03 10:52:30,038 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:33313
2025-09-03 10:52:30,038 - distributed.worker - INFO -          dashboard at:          10.6.102.31:39355
2025-09-03 10:52:30,038 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,038 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,038 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,038 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,038 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-_dt4op1j
2025-09-03 10:52:30,039 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,046 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:37121
2025-09-03 10:52:30,046 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:37121
2025-09-03 10:52:30,046 - distributed.worker - INFO -          dashboard at:          10.6.102.31:33417
2025-09-03 10:52:30,046 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,046 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,046 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,046 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,046 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-tcunid16
2025-09-03 10:52:30,046 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,051 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:43561
2025-09-03 10:52:30,051 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:43561
2025-09-03 10:52:30,051 - distributed.worker - INFO -          dashboard at:          10.6.102.31:37415
2025-09-03 10:52:30,051 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,051 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,051 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,051 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4dron75s
2025-09-03 10:52:30,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,076 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:36471
2025-09-03 10:52:30,076 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:36471
2025-09-03 10:52:30,076 - distributed.worker - INFO -          dashboard at:          10.6.102.31:42711
2025-09-03 10:52:30,076 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,076 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,076 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,076 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,076 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-v3dyg8_m
2025-09-03 10:52:30,076 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,090 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:40277
2025-09-03 10:52:30,090 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:40277
2025-09-03 10:52:30,090 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45223
2025-09-03 10:52:30,090 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,090 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,090 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,090 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,090 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-9oduuzrs
2025-09-03 10:52:30,090 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,129 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39899
2025-09-03 10:52:30,129 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39899
2025-09-03 10:52:30,129 - distributed.worker - INFO -          dashboard at:          10.6.102.31:38165
2025-09-03 10:52:30,129 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,129 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,129 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,129 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,129 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-2ox9r8kf
2025-09-03 10:52:30,129 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,161 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:45649
2025-09-03 10:52:30,162 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:45649
2025-09-03 10:52:30,162 - distributed.worker - INFO -          dashboard at:          10.6.102.31:37529
2025-09-03 10:52:30,162 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,162 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,162 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,162 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,162 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-gex1zkzn
2025-09-03 10:52:30,162 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,228 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:30,229 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,229 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,231 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:30,247 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:46463
2025-09-03 10:52:30,247 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:46463
2025-09-03 10:52:30,247 - distributed.worker - INFO -          dashboard at:          10.6.102.31:41157
2025-09-03 10:52:30,247 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,247 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,247 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,247 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4ntksp0v
2025-09-03 10:52:30,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,247 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39417
2025-09-03 10:52:30,247 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39417
2025-09-03 10:52:30,247 - distributed.worker - INFO -          dashboard at:          10.6.102.31:44801
2025-09-03 10:52:30,247 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,247 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,247 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,247 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-4h9rr1l6
2025-09-03 10:52:30,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,261 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39367
2025-09-03 10:52:30,261 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39367
2025-09-03 10:52:30,261 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45251
2025-09-03 10:52:30,261 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,261 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,261 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,261 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,261 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-3bmfhux6
2025-09-03 10:52:30,261 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,262 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:46593
2025-09-03 10:52:30,262 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:46593
2025-09-03 10:52:30,262 - distributed.worker - INFO -          dashboard at:          10.6.102.31:45439
2025-09-03 10:52:30,262 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,262 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,262 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,262 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,262 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-0imtcec5
2025-09-03 10:52:30,262 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,264 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:44227
2025-09-03 10:52:30,264 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:44227
2025-09-03 10:52:30,264 - distributed.worker - INFO -          dashboard at:          10.6.102.31:33011
2025-09-03 10:52:30,264 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,264 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,264 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,264 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,264 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ipp9n5hi
2025-09-03 10:52:30,264 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,265 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:37341
2025-09-03 10:52:30,265 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:37341
2025-09-03 10:52:30,265 - distributed.worker - INFO -          dashboard at:          10.6.102.31:36887
2025-09-03 10:52:30,265 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,265 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,265 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,265 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,265 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-6kzss30f
2025-09-03 10:52:30,265 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,275 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:41773
2025-09-03 10:52:30,275 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:41773
2025-09-03 10:52:30,275 - distributed.worker - INFO -          dashboard at:          10.6.102.31:41165
2025-09-03 10:52:30,275 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,275 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,275 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,275 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,276 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-farskj4m
2025-09-03 10:52:30,276 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,280 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:39335
2025-09-03 10:52:30,280 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:39335
2025-09-03 10:52:30,280 - distributed.worker - INFO -          dashboard at:          10.6.102.31:43873
2025-09-03 10:52:30,280 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,280 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,280 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,280 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-ah6f09sl
2025-09-03 10:52:30,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,286 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.31:44547
2025-09-03 10:52:30,286 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.31:44547
2025-09-03 10:52:30,286 - distributed.worker - INFO -          dashboard at:          10.6.102.31:46373
2025-09-03 10:52:30,286 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,286 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,287 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:52:30,287 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:52:30,287 - distributed.worker - INFO -       Local Directory: /jobfs/148607956.gadi-pbs/dask-scratch-space/worker-hb5lry63
2025-09-03 10:52:30,287 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,292 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:30,293 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,294 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:30,330 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:30,331 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,333 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:30,342 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:30,343 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:30,343 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:30,345 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,461 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,463 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,463 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,465 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,474 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,475 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,475 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,477 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,487 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,488 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,489 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,490 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,500 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,501 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,502 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,504 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,512 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,513 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,518 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,526 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,528 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,528 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,530 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,532 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,539 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,540 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,541 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,543 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,552 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,553 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,555 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,564 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,565 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,568 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,577 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,578 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,578 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,580 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,590 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,592 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,594 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,603 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,605 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,605 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,607 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,616 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,617 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,617 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,620 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:31,628 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:31,630 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:31,630 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:31,631 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,185 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,187 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,187 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,188 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,199 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,200 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,200 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,202 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,212 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,213 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,213 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,215 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,225 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,227 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,227 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,229 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,238 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,239 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,239 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,241 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,251 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,252 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,253 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,254 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,264 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,266 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,266 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,268 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,329 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,330 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,332 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,343 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,344 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,344 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,346 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,447 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,448 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,448 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,450 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,459 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,461 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,461 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,463 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,472 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,473 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,473 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,475 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,485 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,486 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,486 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,488 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,498 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,499 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,501 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,511 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,512 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,512 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,514 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,654 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,655 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,656 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,658 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,667 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,669 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,669 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,671 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:32,680 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:32,681 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:32,681 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:32,683 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,166 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,167 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,167 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,169 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,246 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,247 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,249 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,260 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,261 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,261 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,263 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,507 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,508 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,508 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,510 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,959 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,960 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,961 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,963 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:33,973 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:33,974 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:33,974 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:33,976 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,238 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,239 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,240 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,242 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,251 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,253 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,253 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,255 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,265 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,266 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,266 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,268 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,278 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,279 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,282 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:34,772 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:34,773 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:34,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:34,775 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,031 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,032 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,034 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,044 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,046 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,046 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,048 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,071 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,072 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,073 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,074 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,084 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,086 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,086 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,088 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,098 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,099 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,099 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,101 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:36,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:36,112 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:36,112 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:36,114 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:37,247 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:37,249 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:37,249 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:37,250 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:39,213 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:52:39,215 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:52:39,215 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:52:39,217 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:52:59,655 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:59,656 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:59,660 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:59,663 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:59,672 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:59,680 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:59,683 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:59,688 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:52:59,695 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.101.5:8785
2025-09-03 10:53:02,492 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:02,518 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:03,465 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:03,478 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:03,490 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:03,503 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:03,518 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:04,588 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:04,590 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:04,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:04,592 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:04,605 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:04,606 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:04,606 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:04,608 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:04,621 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:04,623 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:04,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:04,625 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:04,638 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:04,640 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:04,640 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:04,641 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:04,654 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:04,656 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:04,656 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:04,658 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:04,671 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:04,673 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:04,673 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:04,675 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:04,688 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:04,689 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:04,690 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:04,691 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:04,704 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:04,706 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:04,706 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:04,708 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:23,339 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:53:23,342 - distributed.worker - INFO -         Registered to:      tcp://10.6.101.5:8785
2025-09-03 10:53:23,342 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:53:23,347 - distributed.core - INFO - Starting established connection to tcp://10.6.101.5:8785
2025-09-03 10:53:33,492 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:33,507 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:35,596 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:53:35,610 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.101.5:8785 after 30 s
2025-09-03 10:56:37,884 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:37,890 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,212 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,218 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:38,699 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:38,707 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,439 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,445 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,515 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,520 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,681 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,683 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:39,684 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:39,688 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,256 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,261 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,287 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,292 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,302 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,305 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,500 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,505 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,806 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,808 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:40,858 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:40,865 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,082 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,086 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,112 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,119 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,351 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,352 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,439 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,446 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,476 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,479 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,555 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,561 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:41,989 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:41,994 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,075 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,081 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,143 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,148 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,446 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,452 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,525 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,527 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,546 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,548 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:42,631 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:42,633 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,237 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,242 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,333 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,336 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,422 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,425 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,430 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,433 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:43,822 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:43,827 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,062 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,065 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:44,133 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:44,139 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,054 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,060 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,179 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,186 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,496 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,502 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,746 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,751 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,922 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,926 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,928 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,934 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:45,994 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:45,996 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,172 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,173 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,178 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,179 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,595 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,599 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,628 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,634 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,758 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,763 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:46,868 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:46,875 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,091 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,096 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,269 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,275 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,348 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,358 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,429 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,436 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,456 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,461 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:47,594 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:47,599 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,267 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,272 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,381 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,386 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,392 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,539 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,544 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:48,607 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:48,615 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,087 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,095 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,385 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,483 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,489 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:49,775 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:49,780 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,189 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,198 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,263 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,268 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,367 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,368 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,529 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,535 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,578 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,581 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,581 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,586 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,654 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,659 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,766 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,768 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:50,997 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:50,999 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,124 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,126 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,255 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,260 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,267 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,272 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:51,997 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:51,999 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,004 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,010 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,177 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,182 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,200 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,201 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,263 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,268 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,760 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,767 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:52,781 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:52,787 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,035 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,040 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,061 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,066 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,206 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,211 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,318 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,320 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,379 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,388 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:53,544 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:53,550 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,158 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,164 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:54,905 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:54,910 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:55,407 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:55,413 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,665 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,666 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:56,697 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:56,705 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,167 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,169 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,429 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,436 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,694 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,700 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:57,891 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:57,898 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:58,112 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:58,117 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:58,335 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:58,341 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:58,916 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:58,920 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:56:59,420 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:56:59,425 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:01,011 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:01,016 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:01,036 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:01,042 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:02,258 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:02,265 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:02,769 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:02,774 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:03,637 - distributed.worker - INFO - Starting Worker plugin qme_utils.py99b60261-15ef-4b08-86b6-cf8026baba29
2025-09-03 10:57:03,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:57:09,474 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:09,476 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:09,994 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:09,996 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:09,997 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,000 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,002 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,002 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,002 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,004 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,001 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,009 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,027 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,027 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,073 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,076 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,333 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,333 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,335 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,336 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,348 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,350 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,350 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,352 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,355 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,357 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,494 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,510 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,513 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,512 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,514 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,523 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,526 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,618 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,620 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,621 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,622 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,641 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,750 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,755 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,761 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,768 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,878 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,880 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,885 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,890 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,916 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,918 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:10,934 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:10,938 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,119 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,121 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,131 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,133 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,271 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,273 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,275 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,273 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,277 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,279 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,280 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,282 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,296 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,298 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,314 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,316 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,367 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,370 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,370 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,370 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,372 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,372 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,372 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,374 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,392 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,395 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,408 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,409 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,410 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,411 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,415 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,416 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,417 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,418 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,464 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,466 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,491 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,546 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,548 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,549 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,551 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,708 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,710 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,744 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,746 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,750 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,756 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,762 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,763 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,764 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,765 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,784 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,786 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,797 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,800 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,856 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,859 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,866 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,867 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,903 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,905 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,931 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,937 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,946 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,948 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:11,961 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:11,964 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,007 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,006 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,009 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,011 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,040 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,042 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,056 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,058 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,067 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,069 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,242 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,250 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,298 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,303 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,307 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,309 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,352 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,354 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,375 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,377 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,387 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,388 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,402 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,404 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,499 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,512 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,514 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,524 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,527 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,563 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,565 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,584 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,603 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,605 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,686 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,688 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,726 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,728 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,746 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,748 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,755 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,757 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,767 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,769 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,912 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,914 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,951 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,952 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:12,967 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:12,969 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,121 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,129 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,237 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,239 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,239 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,241 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,256 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,258 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,298 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,300 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,385 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,387 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,519 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,521 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,535 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,537 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:13,544 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:13,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:14,005 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:14,007 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:14,471 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:14,479 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:15,033 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:15,036 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:16,196 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:16,198 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:16,203 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:16,205 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:57:17,689 - distributed.worker - INFO - Starting Worker plugin qme_vars.py123e1e1e-9078-49f9-9dd8-5d7f7279a79c
2025-09-03 10:57:17,691 - distributed.utils - INFO - Reload module qme_vars from .py file
