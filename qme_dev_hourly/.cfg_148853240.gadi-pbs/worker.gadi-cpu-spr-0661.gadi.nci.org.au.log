Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-05 09:25:18,728 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:34557'
2025-09-05 09:25:18,737 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:37571'
2025-09-05 09:25:18,741 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:44563'
2025-09-05 09:25:18,745 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:35813'
2025-09-05 09:25:18,749 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:42703'
2025-09-05 09:25:18,754 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:38351'
2025-09-05 09:25:18,757 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:34033'
2025-09-05 09:25:18,761 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:45557'
2025-09-05 09:25:18,766 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:46519'
2025-09-05 09:25:18,771 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:43189'
2025-09-05 09:25:18,776 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:34281'
2025-09-05 09:25:18,780 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:44071'
2025-09-05 09:25:18,784 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:37167'
2025-09-05 09:25:18,790 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:38827'
2025-09-05 09:25:18,794 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:36297'
2025-09-05 09:25:18,798 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:39857'
2025-09-05 09:25:18,803 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:37617'
2025-09-05 09:25:18,809 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:45477'
2025-09-05 09:25:18,813 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:33201'
2025-09-05 09:25:18,929 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:41371'
2025-09-05 09:25:18,934 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:39547'
2025-09-05 09:25:18,939 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:43171'
2025-09-05 09:25:18,944 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:33915'
2025-09-05 09:25:18,948 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:46079'
2025-09-05 09:25:18,952 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:40857'
2025-09-05 09:25:18,957 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:36699'
2025-09-05 09:25:18,963 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:38605'
2025-09-05 09:25:18,966 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:35945'
2025-09-05 09:25:18,970 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:43831'
2025-09-05 09:25:18,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:36591'
2025-09-05 09:25:18,976 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:45467'
2025-09-05 09:25:18,980 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:46051'
2025-09-05 09:25:18,984 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:45497'
2025-09-05 09:25:18,987 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:43779'
2025-09-05 09:25:18,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:37751'
2025-09-05 09:25:18,998 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:36467'
2025-09-05 09:25:19,003 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:34979'
2025-09-05 09:25:19,008 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:44255'
2025-09-05 09:25:19,012 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:42555'
2025-09-05 09:25:19,016 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:34921'
2025-09-05 09:25:19,021 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:37995'
2025-09-05 09:25:19,024 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:37355'
2025-09-05 09:25:19,030 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:38371'
2025-09-05 09:25:19,035 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:38491'
2025-09-05 09:25:19,039 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:41325'
2025-09-05 09:25:19,042 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:45697'
2025-09-05 09:25:19,046 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:46037'
2025-09-05 09:25:19,049 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:41185'
2025-09-05 09:25:19,052 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:35045'
2025-09-05 09:25:19,055 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:40631'
2025-09-05 09:25:19,058 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:36379'
2025-09-05 09:25:19,065 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.13:42837'
2025-09-05 09:25:20,078 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:42377
2025-09-05 09:25:20,078 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:46225
2025-09-05 09:25:20,078 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:36235
2025-09-05 09:25:20,078 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:33231
2025-09-05 09:25:20,078 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:46537
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:42377
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:42835
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:34453
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:43659
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:38407
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:39383
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:38895
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:46225
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:42233
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:43653
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:36235
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:33231
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:37985
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:46537
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:37963
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:42835
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:46707
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:34453
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:43659
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:38407
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:39383
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:38895
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:34721
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:42233
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:38535
2025-09-05 09:25:20,079 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:46453
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:43653
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:43421
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:41327
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:37985
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:37987
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:38145
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:46707
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:34331
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:41585
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:32973
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:33621
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:40381
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:41315
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:38535
2025-09-05 09:25:20,079 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:46453
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:33089
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:37219
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:42163
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:32857
2025-09-05 09:25:20,079 - distributed.worker - INFO -          dashboard at:          10.6.105.13:37027
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,079 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,079 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,079 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-7tbu6tkj
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-8c9w7k8x
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-c9kizvha
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-aw0ibfp8
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-0iena63z
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-nka4ql76
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-hwe_bmrd
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-0ms8lrsc
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-1ctt07mh
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-wogq4_ee
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-xcxh6rh1
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-po0glyse
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-cweuyokp
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-wdafwcrj
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-hzftw7nr
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-fm7ko3km
2025-09-05 09:25:20,080 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-nlxnuwow
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,080 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,089 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:46609
2025-09-05 09:25:20,089 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:46609
2025-09-05 09:25:20,090 - distributed.worker - INFO -          dashboard at:          10.6.105.13:34549
2025-09-05 09:25:20,090 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,090 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,090 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,090 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,090 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-qkk7ns7n
2025-09-05 09:25:20,090 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,102 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,102 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,102 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,103 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,104 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,104 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,104 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,105 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,108 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,108 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,108 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,109 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,110 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,111 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,111 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,112 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,113 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,114 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,114 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,115 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,115 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,116 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,117 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:32867
2025-09-05 09:25:20,117 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:32867
2025-09-05 09:25:20,117 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,117 - distributed.worker - INFO -          dashboard at:          10.6.105.13:35475
2025-09-05 09:25:20,117 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,117 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,117 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,117 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,117 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-v2a465ef
2025-09-05 09:25:20,117 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,117 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,117 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,117 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,119 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,119 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,119 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,119 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,120 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,120 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,120 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,121 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,121 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,122 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,122 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,123 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,123 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,124 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,124 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,124 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,125 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,125 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,126 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,126 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,127 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,127 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,127 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,127 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,128 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,128 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,129 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,129 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,130 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,130 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,130 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,130 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,130 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,131 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,131 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,132 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,132 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,132 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,133 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,135 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,136 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,136 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,138 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,150 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,151 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,151 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,153 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,196 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:35003
2025-09-05 09:25:20,196 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:35003
2025-09-05 09:25:20,196 - distributed.worker - INFO -          dashboard at:          10.6.105.13:43157
2025-09-05 09:25:20,196 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,196 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,196 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,196 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-bofsh_ut
2025-09-05 09:25:20,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,209 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,209 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,209 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,210 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,214 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:41403
2025-09-05 09:25:20,214 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:41403
2025-09-05 09:25:20,214 - distributed.worker - INFO -          dashboard at:          10.6.105.13:33937
2025-09-05 09:25:20,214 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,214 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,214 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,214 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,214 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-rq7rsxjc
2025-09-05 09:25:20,215 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,216 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:45439
2025-09-05 09:25:20,217 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:45439
2025-09-05 09:25:20,217 - distributed.worker - INFO -          dashboard at:          10.6.105.13:40025
2025-09-05 09:25:20,217 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,217 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,217 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,217 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-89pfq9e2
2025-09-05 09:25:20,217 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,237 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,238 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,238 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,239 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,240 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,241 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,241 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,243 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,247 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:41733
2025-09-05 09:25:20,247 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:41733
2025-09-05 09:25:20,247 - distributed.worker - INFO -          dashboard at:          10.6.105.13:40859
2025-09-05 09:25:20,247 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,247 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,247 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,247 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-xwolarr3
2025-09-05 09:25:20,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,256 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:45727
2025-09-05 09:25:20,256 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:45727
2025-09-05 09:25:20,257 - distributed.worker - INFO -          dashboard at:          10.6.105.13:45809
2025-09-05 09:25:20,257 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,257 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,257 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,257 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,257 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-9877z13r
2025-09-05 09:25:20,257 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,269 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,270 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,272 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,275 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,276 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,276 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,277 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,280 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:34003
2025-09-05 09:25:20,280 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:34003
2025-09-05 09:25:20,280 - distributed.worker - INFO -          dashboard at:          10.6.105.13:40029
2025-09-05 09:25:20,280 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,280 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,280 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,280 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-mtduj9bu
2025-09-05 09:25:20,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,291 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:36291
2025-09-05 09:25:20,291 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:36291
2025-09-05 09:25:20,291 - distributed.worker - INFO -          dashboard at:          10.6.105.13:42203
2025-09-05 09:25:20,291 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:43225
2025-09-05 09:25:20,291 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,291 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:43225
2025-09-05 09:25:20,291 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,291 - distributed.worker - INFO -          dashboard at:          10.6.105.13:46101
2025-09-05 09:25:20,291 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,291 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,291 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-suko2fyy
2025-09-05 09:25:20,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,291 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,291 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,291 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-qedn7uqp
2025-09-05 09:25:20,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,298 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,299 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,299 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,299 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,301 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:40727
2025-09-05 09:25:20,301 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:40727
2025-09-05 09:25:20,301 - distributed.worker - INFO -          dashboard at:          10.6.105.13:46571
2025-09-05 09:25:20,301 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,301 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,301 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,301 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,301 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-4gdrzcls
2025-09-05 09:25:20,301 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,303 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,303 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,303 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,304 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,305 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:33045
2025-09-05 09:25:20,305 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:33045
2025-09-05 09:25:20,305 - distributed.worker - INFO -          dashboard at:          10.6.105.13:33307
2025-09-05 09:25:20,305 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,305 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,305 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,305 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-zrfhqccq
2025-09-05 09:25:20,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,311 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,311 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,311 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,312 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,314 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,315 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,315 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,315 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,323 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,324 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,324 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,326 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,353 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:39613
2025-09-05 09:25:20,354 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:39613
2025-09-05 09:25:20,354 - distributed.worker - INFO -          dashboard at:          10.6.105.13:36781
2025-09-05 09:25:20,354 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,354 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,354 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,354 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-_2_re8ps
2025-09-05 09:25:20,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,376 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,377 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,377 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,379 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,508 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:35273
2025-09-05 09:25:20,508 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:35273
2025-09-05 09:25:20,508 - distributed.worker - INFO -          dashboard at:          10.6.105.13:35351
2025-09-05 09:25:20,508 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,508 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,508 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,508 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,508 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-6wukn8s0
2025-09-05 09:25:20,508 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,508 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:40577
2025-09-05 09:25:20,508 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:40577
2025-09-05 09:25:20,508 - distributed.worker - INFO -          dashboard at:          10.6.105.13:42885
2025-09-05 09:25:20,508 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,508 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,508 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,508 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,509 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-1e21zs_p
2025-09-05 09:25:20,509 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,511 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:36719
2025-09-05 09:25:20,511 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:36719
2025-09-05 09:25:20,511 - distributed.worker - INFO -          dashboard at:          10.6.105.13:43571
2025-09-05 09:25:20,511 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,511 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,511 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,511 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-9gprvksi
2025-09-05 09:25:20,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,521 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:45279
2025-09-05 09:25:20,521 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:45279
2025-09-05 09:25:20,521 - distributed.worker - INFO -          dashboard at:          10.6.105.13:36913
2025-09-05 09:25:20,521 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,521 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,521 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,521 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,521 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-3izohw5a
2025-09-05 09:25:20,521 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,526 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:45287
2025-09-05 09:25:20,527 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:45287
2025-09-05 09:25:20,527 - distributed.worker - INFO -          dashboard at:          10.6.105.13:36659
2025-09-05 09:25:20,527 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,527 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,527 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,527 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,527 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-z62v6i9g
2025-09-05 09:25:20,527 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,530 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,531 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,531 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,531 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:32827
2025-09-05 09:25:20,532 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:32827
2025-09-05 09:25:20,532 - distributed.worker - INFO -          dashboard at:          10.6.105.13:45731
2025-09-05 09:25:20,532 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,532 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,532 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,532 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,532 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-1l5oknu3
2025-09-05 09:25:20,532 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,532 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,535 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,536 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,536 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,538 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,538 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:41125
2025-09-05 09:25:20,538 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,538 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:41125
2025-09-05 09:25:20,538 - distributed.worker - INFO -          dashboard at:          10.6.105.13:42677
2025-09-05 09:25:20,538 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,538 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,538 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,538 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,538 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-p7u_z5j3
2025-09-05 09:25:20,538 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,539 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,540 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,541 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,542 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,542 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,543 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,544 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:40861
2025-09-05 09:25:20,544 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:40861
2025-09-05 09:25:20,544 - distributed.worker - INFO -          dashboard at:          10.6.105.13:43493
2025-09-05 09:25:20,544 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,544 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,544 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,544 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,544 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-xc5yu0j_
2025-09-05 09:25:20,544 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,546 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:44467
2025-09-05 09:25:20,546 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:44467
2025-09-05 09:25:20,546 - distributed.worker - INFO -          dashboard at:          10.6.105.13:33769
2025-09-05 09:25:20,546 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,546 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,546 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,546 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,546 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-wd6at40j
2025-09-05 09:25:20,546 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,547 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:34861
2025-09-05 09:25:20,547 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:34861
2025-09-05 09:25:20,547 - distributed.worker - INFO -          dashboard at:          10.6.105.13:35927
2025-09-05 09:25:20,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,547 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:43675
2025-09-05 09:25:20,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,548 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,548 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:43675
2025-09-05 09:25:20,548 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,548 - distributed.worker - INFO -          dashboard at:          10.6.105.13:40215
2025-09-05 09:25:20,548 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-2lpu2lnr
2025-09-05 09:25:20,548 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,548 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,548 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,548 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-kf7p20eo
2025-09-05 09:25:20,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,552 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:36039
2025-09-05 09:25:20,552 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:36039
2025-09-05 09:25:20,552 - distributed.worker - INFO -          dashboard at:          10.6.105.13:41999
2025-09-05 09:25:20,552 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,553 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,553 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,553 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-agq5r4he
2025-09-05 09:25:20,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,555 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:38873
2025-09-05 09:25:20,555 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:38873
2025-09-05 09:25:20,555 - distributed.worker - INFO -          dashboard at:          10.6.105.13:46461
2025-09-05 09:25:20,555 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,555 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,555 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,555 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-3z_wyw_v
2025-09-05 09:25:20,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,556 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:35337
2025-09-05 09:25:20,556 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:35337
2025-09-05 09:25:20,556 - distributed.worker - INFO -          dashboard at:          10.6.105.13:44717
2025-09-05 09:25:20,556 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,556 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,556 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,556 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:40691
2025-09-05 09:25:20,556 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-dp6_azaa
2025-09-05 09:25:20,556 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:40691
2025-09-05 09:25:20,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,556 - distributed.worker - INFO -          dashboard at:          10.6.105.13:37727
2025-09-05 09:25:20,556 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,556 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,556 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,556 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-2afpb0bu
2025-09-05 09:25:20,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,556 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,556 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:46107
2025-09-05 09:25:20,556 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:46107
2025-09-05 09:25:20,556 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:34473
2025-09-05 09:25:20,556 - distributed.worker - INFO -          dashboard at:          10.6.105.13:41513
2025-09-05 09:25:20,556 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:34473
2025-09-05 09:25:20,556 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,556 - distributed.worker - INFO -          dashboard at:          10.6.105.13:39913
2025-09-05 09:25:20,557 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,557 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,557 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,557 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,557 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,557 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,557 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,557 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-xw91f7pu
2025-09-05 09:25:20,557 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,557 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,557 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-zcxwv7s4
2025-09-05 09:25:20,557 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,557 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,558 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:42439
2025-09-05 09:25:20,558 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:42439
2025-09-05 09:25:20,558 - distributed.worker - INFO -          dashboard at:          10.6.105.13:42707
2025-09-05 09:25:20,558 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,558 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,558 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,558 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,558 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-n8_sk6lg
2025-09-05 09:25:20,558 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,558 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:34191
2025-09-05 09:25:20,558 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:34191
2025-09-05 09:25:20,558 - distributed.worker - INFO -          dashboard at:          10.6.105.13:37423
2025-09-05 09:25:20,558 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,558 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,558 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,558 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,558 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-2ew1qvug
2025-09-05 09:25:20,558 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,559 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:39685
2025-09-05 09:25:20,560 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:39685
2025-09-05 09:25:20,560 - distributed.worker - INFO -          dashboard at:          10.6.105.13:33583
2025-09-05 09:25:20,560 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,560 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,560 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,560 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,560 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-dd060pzl
2025-09-05 09:25:20,560 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,563 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,564 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,565 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,566 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:44637
2025-09-05 09:25:20,566 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:44637
2025-09-05 09:25:20,566 - distributed.worker - INFO -          dashboard at:          10.6.105.13:42943
2025-09-05 09:25:20,566 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,566 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,566 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,566 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-3czmt_ko
2025-09-05 09:25:20,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,567 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,582 - distributed.worker - INFO -       Start worker at:    tcp://10.6.105.13:38397
2025-09-05 09:25:20,582 - distributed.worker - INFO -          Listening to:    tcp://10.6.105.13:38397
2025-09-05 09:25:20,582 - distributed.worker - INFO -          dashboard at:          10.6.105.13:38155
2025-09-05 09:25:20,582 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,582 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:20,582 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:20,582 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-4ibpudhx
2025-09-05 09:25:20,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,584 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,585 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,585 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,586 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,587 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,587 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,587 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,588 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,589 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,589 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,589 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,590 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,591 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,591 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,591 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,592 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,592 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,593 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,593 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,593 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,593 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,593 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,594 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,594 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,595 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,595 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,596 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,597 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,598 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,599 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,599 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,600 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,601 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,601 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,602 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,602 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,602 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,602 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,603 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,603 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,603 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,603 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,604 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,604 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,605 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,605 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,606 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,618 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,618 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,619 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,619 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:20,619 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:20,620 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:20,620 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:20,621 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:50,827 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,829 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,830 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,830 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,830 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,830 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,830 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,830 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,830 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,830 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,830 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,830 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,831 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,832 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,830 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,832 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,832 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,832 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,832 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,832 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,833 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,833 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,831 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,833 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,833 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,833 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,833 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,833 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,833 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,834 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,834 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,834 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,834 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,835 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,833 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,835 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,835 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,835 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,835 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,835 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,833 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,835 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,836 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,834 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,836 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,837 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,837 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,836 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,836 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,836 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,837 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,840 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,839 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,839 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,842 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,843 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,843 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,845 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,846 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,846 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,849 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,850 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,848 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,851 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:53,574 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,574 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,574 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,574 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,575 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,575 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,575 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,575 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,575 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,575 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,575 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,575 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,575 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,576 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,576 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,576 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,576 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,576 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,576 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,576 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,576 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,576 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,577 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,577 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,577 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,577 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,577 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,577 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,577 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,577 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,577 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,578 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,578 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,578 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,578 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,578 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,578 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,580 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,580 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,580 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,580 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,580 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,580 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,579 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,580 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,580 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,581 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,580 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,580 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,581 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,581 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,581 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,581 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,581 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,581 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,582 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,583 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,583 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,583 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,583 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,583 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,583 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,584 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,584 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,957 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,957 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,957 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,958 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,959 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,960 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,960 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,960 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,960 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,960 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,960 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,961 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,962 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,962 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,962 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,962 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,962 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,962 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,962 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,962 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,962 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,962 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,963 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,963 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,963 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,963 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,963 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,963 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,963 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,963 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,963 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,963 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,963 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,963 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,963 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,963 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,964 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,965 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,965 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,965 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,965 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,965 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,966 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,967 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:53,968 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,338 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,338 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,338 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,338 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,338 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,338 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,338 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,339 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,339 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,339 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,339 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,339 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,339 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,339 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,339 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,339 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,340 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,340 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,340 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,340 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,340 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,340 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,340 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,340 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,340 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,340 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,340 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,341 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,341 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,342 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,342 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,342 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,342 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,342 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,343 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,344 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,344 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,344 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,344 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,344 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,344 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,344 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,345 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,349 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:33:47,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:48,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:48,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:50,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:50,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:51,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:51,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:52,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:52,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:52,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:53,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:53,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:54,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:54,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:54,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:54,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:54,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:54,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:54,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:54,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:54,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:55,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:55,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:58,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:58,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:00,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:00,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:05,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:05,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:05,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:05,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:07,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:10,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:28,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:28,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:29,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:29,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:30,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:31,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:31,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:31,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:32,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:32,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:33,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:33,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:33,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:33,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:34,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:34,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:35,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:35,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:35,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:35,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:36,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:37,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:37,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:37,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:37,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:38,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:38,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:38,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:38,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:38,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:39,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:40,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:40,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:40,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:40,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:45,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:45,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:45,984 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:46,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:46,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:46,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:46,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:46,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:46,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:47,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:47,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:47,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:47,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:51,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:51,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:51,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:52,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:53,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:55,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:56,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:56,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:56,146 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:56,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:56,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:56,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:57,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,472 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:59,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:59,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:59,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:59,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:59,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:00,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:00,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:00,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:00,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:01,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:01,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:02,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:02,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:02,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:02,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:04,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:04,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:05,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:05,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:09,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:10,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:10,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:11,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:12,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:14,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:14,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:15,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:16,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:16,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:18,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:18,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:18,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:21,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:21,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:21,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:21,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:21,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:22,011 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:23,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:23,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:23,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:24,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:25,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:25,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:25,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:26,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:26,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:26,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:26,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:26,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:26,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:27,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:28,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:28,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:28,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:31,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:31,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:33,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:33,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:34,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:34,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:36,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:36,029 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:36,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:36,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:37,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:44,805 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:48,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:51,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:54,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:05,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:05,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:05,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:05,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:06,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:06,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:06,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:06,668 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:09,107 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:10,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:10,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:10,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:11,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:11,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:11,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:14,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:14,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:14,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:17,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:17,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:19,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:19,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:21,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:23,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:23,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:23,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:23,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:23,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:24,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:24,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:24,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:25,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:26,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:26,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:26,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:26,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:26,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:28,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:28,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:29,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:30,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:30,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:30,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:30,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:30,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:30,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:30,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:30,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:31,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:34,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:34,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:34,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:37,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:41,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:41,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:43,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:45,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:45,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:47,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:47,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:51,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:51,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:51,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:51,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:13,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:13,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:13,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:14,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:14,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:14,878 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:14,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:15,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:15,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:16,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:16,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:16,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:16,232 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:16,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:16,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:17,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:17,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:19,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:21,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:21,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:21,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:25,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:25,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:25,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:27,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:29,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:31,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:31,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:32,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:32,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:32,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:32,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:35,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:39,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 29.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:40,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:40,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:40,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:40,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 30.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:41,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 31.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:44,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:44,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 35.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:45,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:47,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 37.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:48,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:49,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:51,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:52,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:53,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:53,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:53,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:54,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:55,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:55,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:55,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:57,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:57,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:58,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:58,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:58,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:59,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:00,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:02,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:02,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:03,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:03,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:03,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:03,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:03,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:05,447 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:05,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:07,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:07,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:07,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:07,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:08,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:11,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:11,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:12,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:12,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:12,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:13,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:13,654 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:15,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:15,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:15,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:16,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:16,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:17,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:18,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:18,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:19,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:19,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:19,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:19,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:19,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:20,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:22,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:25,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:25,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:25,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:27,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:29,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:29,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:30,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:33,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:35,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:36,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:41,100 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:49,258 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:49,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:49,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:50,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:50,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,472 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:51,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:52,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:52,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:54,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:54,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:54,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:54,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:54,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:55,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:55,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,011 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:57,142 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:57,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:57,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:57,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:01,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:01,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:04,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:04,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:05,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:05,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:07,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:07,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:07,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:07,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:07,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:07,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:08,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:08,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:08,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:10,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:10,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:11,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:12,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:13,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:13,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:13,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:13,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:14,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:14,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:14,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:16,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:16,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:16,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:16,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:18,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:19,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:20,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:27,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:27,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:28,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:29,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:29,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:29,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:30,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:30,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:30,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:31,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:31,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:31,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:31,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:32,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:32,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:32,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:33,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:33,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:35,945 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:36,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:37,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:37,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:37,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:37,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:40,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:41,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:41,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:43,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:49,083 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:49,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:49,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:50,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:50,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:51,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:51,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:51,747 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:51,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:51,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:53,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:53,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:53,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:54,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:54,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:54,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:54,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:55,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:55,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:55,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:55,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:58,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:58,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:58,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:59,484 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:59,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:00,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:00,651 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:00,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:00,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:00,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:01,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:04,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:05,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:10,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:11,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:11,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:11,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:12,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:12,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:12,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:12,824 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:12,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:13,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:13,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:13,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:13,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:13,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:13,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:15,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:15,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:15,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:18,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:18,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:18,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:18,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:18,938 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:19,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:19,247 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:19,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:20,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:21,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:21,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:23,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:25,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:26,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:29,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:29,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,139 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:31,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:31,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:31,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:31,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:32,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:32,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:32,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:32,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:33,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:34,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:35,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:35,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:39,088 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:39,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:39,570 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:40,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:40,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:40,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:43,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:43,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:43,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:43,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:43,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:43,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:44,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:44,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:44,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:45,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:45,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:46,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:46,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:46,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:46,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:46,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:46,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:46,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:49,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:52,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:52,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:52,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:52,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:53,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:54,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:54,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:54,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:06,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:10,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:10,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:11,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:11,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:11,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:11,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:12,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:12,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:12,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:12,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:13,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:14,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:15,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:15,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:15,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:16,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:16,467 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:17,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:20,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:20,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:23,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:23,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:23,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:24,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:25,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:27,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:27,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:27,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:27,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:28,903 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:30,260 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:30,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:30,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:30,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:33,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:33,592 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:35,314 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:36,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:36,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:36,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:36,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:36,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:36,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:37,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:37,668 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:39,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:40,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:40,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:40,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:42,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:45,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:46,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:46,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:46,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:46,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:48,306 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:48,556 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:48,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:49,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:50,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:50,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:50,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:50,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:50,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:54,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:55,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:56,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:57,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:57,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:00,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:00,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:03,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:03,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:03,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:03,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:05,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:07,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:07,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:08,191 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:08,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:09,223 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:09,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:09,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:10,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:10,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:10,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:10,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:10,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:10,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:12,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:12,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:12,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:12,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:15,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:15,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:15,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:17,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:17,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:20,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:20,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:23,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:23,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:23,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:23,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:23,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:23,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:24,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:25,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:26,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:27,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:27,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:28,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:32,805 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:34,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:34,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:34,864 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:34,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:34,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:34,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:34,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:34,974 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:38,438 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:40,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:41,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:41,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:41,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:45,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:46,146 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:46,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:46,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:46,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:46,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:47,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:47,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:48,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:49,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:49,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:49,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:51,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:51,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:51,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:53,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:54,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:54,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:54,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:54,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:54,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:54,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:55,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:59,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:59,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:59,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:59,519 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:59,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:59,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:59,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:59,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:59,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:00,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:00,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:00,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:00,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:00,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:00,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:00,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:01,108 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:01,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:01,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:01,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:01,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:03,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:03,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:03,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:04,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:04,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:04,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:04,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:04,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:04,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:04,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:06,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:08,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:09,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:09,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:12,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:12,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:17,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:17,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:18,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:18,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:19,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:19,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:19,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:22,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:22,026 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:22,029 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:22,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:22,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:22,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:56,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:56,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:57,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:57,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:58,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:58,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:58,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:58,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:58,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:58,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:59,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:59,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:00,642 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:01,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:01,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:01,604 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:03,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:03,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:03,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:03,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:03,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:03,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:05,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:05,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:05,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:05,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:10,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:11,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:12,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:14,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:17,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:17,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:18,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:21,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:21,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:22,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:22,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:22,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:22,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:22,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:23,207 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:23,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:23,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:23,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:23,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:24,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:24,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:24,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:24,954 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:25,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:25,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:25,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:25,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:25,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:26,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:26,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:26,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:26,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:26,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:26,469 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:26,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:26,472 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:26,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:27,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:27,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:27,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:34,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:40,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:41,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:42,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:42,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:42,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:43,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:43,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:44,370 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:44,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:44,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:44,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:44,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:44,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:46,029 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:46,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:46,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:46,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:47,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:48,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:48,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:50,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:50,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:50,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:51,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:59,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:59,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:59,242 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:00,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:00,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:00,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:01,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:01,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:01,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:01,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:02,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:02,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:02,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:03,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:03,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:03,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:03,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:06,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:08,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,582 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:13,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:19,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:19,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:26,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:26,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:27,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:27,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:27,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:29,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:29,442 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:32,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:32,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:32,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:32,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:34,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:34,368 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:34,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:34,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,050 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,428 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,428 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:38,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:41,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:42,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:43,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:44,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:44,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:44,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:46,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:46,447 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:46,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:46,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:47,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:47,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:48,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:48,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:48,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:17,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:18,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:18,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:18,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:19,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:19,604 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:19,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:19,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:20,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:23,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:23,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:24,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:27,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:27,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:27,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:28,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:28,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:32,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:32,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:32,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:32,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:37,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:38,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:49,774 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:50,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:50,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:50,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:50,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:50,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:51,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:51,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:51,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:51,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:51,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:51,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:52,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:52,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:52,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:52,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:53,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:53,513 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:53,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:53,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:54,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:54,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:54,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:54,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:55,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:55,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:56,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:57,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:57,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,083 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,803 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:59,072 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:59,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:59,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:00,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:00,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:05,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:05,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:09,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:10,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,187 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,224 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:13,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:13,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:13,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:13,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:14,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:14,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:15,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:15,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:15,479 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:15,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:15,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:16,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:16,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:17,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:17,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:17,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:18,306 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:23,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:25,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:26,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:27,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:27,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:29,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:29,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:29,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:30,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:30,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:30,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:30,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:30,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:30,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:32,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:32,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:32,484 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:32,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:32,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:32,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:32,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:33,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:33,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:33,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:33,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:33,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:33,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:35,423 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:35,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:38,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:38,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:40,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:40,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:43,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:54,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:56,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:56,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:02,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:03,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:07,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:17,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:18,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:19,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:19,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:19,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:19,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:21,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:21,422 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:22,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:22,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:22,779 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:23,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:23,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:23,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:27,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:28,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:28,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:28,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:28,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:28,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:28,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:29,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:29,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:30,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:30,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:31,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:39,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:39,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:42,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:42,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:43,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:43,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:44,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:44,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:44,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:44,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:44,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:44,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:44,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:44,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:45,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:45,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:45,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:46,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:46,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:46,484 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:46,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:46,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:46,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:48,200 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:48,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:48,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:48,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:48,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:48,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:48,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:49,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:49,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:49,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:49,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:49,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:50,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:54,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:01,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:01,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:01,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:03,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:10,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:10,984 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:11,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:11,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:12,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:14,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:14,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:18,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:18,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,482 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:22,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:22,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:22,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:23,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:23,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:24,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:26,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:30,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:30,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:30,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:31,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:31,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:32,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:34,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:34,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:35,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:36,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:36,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:37,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:40,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:41,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:43,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:43,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:43,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:43,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:44,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:46,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:46,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:46,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:47,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:48,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:49,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:51,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:51,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:51,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:51,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:51,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:51,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:51,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:51,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:52,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:52,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,772 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:34473. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:44467. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:46107. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:43675. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:39685. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:45287. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:45279. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:34191. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:34861. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:40691. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:44637. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:35337. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:32867. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:36039. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:45727. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:45439. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:36291. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:38873. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:41125. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:36719. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:32827. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,772 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:34003. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:35003. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:43225. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,771 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:38397. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:40577. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:41403. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:40861. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49226 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,772 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49176 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49268 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,775 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49216 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49272 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,779 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49282 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,772 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49190 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49196 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,780 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:43659. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49218 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,780 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:41733. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,771 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49198 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,772 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49162 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,772 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.13:49180 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,780 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,781 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,781 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,781 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,783 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:46537. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,783 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:42233. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,783 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:43653. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,783 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:46453. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,781 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,781 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,782 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,784 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:42377. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,784 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:38895. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,785 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:34453. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,782 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,781 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,785 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:39383. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,783 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,785 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:36235. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,786 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:38407. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,785 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:43779'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,784 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,787 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:37985. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,788 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763817, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,788 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,788 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,789 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,789 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,789 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,791 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:42555'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,791 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:36379'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,792 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:40857'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,792 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764765, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,793 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 767504, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,793 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,793 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765189, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,793 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.32:37309, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,793 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,794 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764826, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,794 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765825, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,794 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763411, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,795 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,795 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,795 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,795 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,795 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,795 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,796 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,796 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,801 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:34979'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,802 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:38605'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,802 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:43171'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,803 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:46037'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,803 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:36467'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,803 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:37355'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,803 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:45497'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,804 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:36699'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763223, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765073, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.6:46633, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:41185'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763228, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765683, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765356, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:33201'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.31:43145, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764170, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:45467'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.11:37467, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765701, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.16:36625, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:34921'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.22:34733, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.10:40293, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:40631'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 767393, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764998, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763441, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:42837'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.25:37179, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763839, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763341, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763176, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:41371'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,806 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:41325'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,806 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:44255'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763125, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,806 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:37995'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.10:41393, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764859, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766133, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:35045'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.8:40835, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764860, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765971, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763133, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:38371'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763114, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764861, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763235, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765578, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763138, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763115, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:38491'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763227, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766447, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765582, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764855, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,808 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:35945'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764846, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764858, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,808 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:36591'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.24:46413, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,809 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:45697'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,809 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763440, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,809 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:33915'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,809 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763339, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,809 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:37617'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,809 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763832, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763230, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763231, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765375, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.1:37369, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.25:45579, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.17:35845, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765670, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764461, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.26:40283, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764588, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764989, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766053, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763241, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766200, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,813 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:44563'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,814 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:34557'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,814 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:46519'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,814 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:43189'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,815 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:37167'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,815 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.10:35747, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,815 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:38351'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,815 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763232, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,815 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:34033'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,815 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763234, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,815 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:34281'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,815 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:39857'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,815 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763380, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,815 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763155, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,816 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:38827'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,815 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766684, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,816 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765612, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,816 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763237, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,817 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,817 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,816 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:37571'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,817 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,816 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765597, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,816 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763247, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,816 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764666, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,817 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,817 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763119, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,817 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765105, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,817 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,817 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764686, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,817 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763118, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,817 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,817 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765112, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,818 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765794, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,818 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765530, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,818 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763214, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,819 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763524, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,819 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.11:45295, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,818 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763236, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,819 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 767028, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,819 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766087, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,819 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,819 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764868, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,819 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,821 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,821 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,821 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,821 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,821 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,821 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,821 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,822 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,822 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,822 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,822 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,824 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,825 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,825 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,825 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,825 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,826 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,826 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,826 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,826 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,854 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,854 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,854 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,854 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,854 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,855 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,855 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,855 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,855 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,855 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,858 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763135, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,859 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765472, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,859 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.17:36089, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,862 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:52,864 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,864 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,864 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,864 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,864 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,968 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,970 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:46225. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:52,993 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48650 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:52,997 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:45477'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,998 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765680, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,998 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.31:34693, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,999 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,999 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,999 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,999 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,999 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:53,001 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:53,007 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14c0fb656e90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:53,855 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:53,859 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:38535. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:53,874 - distributed.worker - ERROR - failed during get data with tcp://10.6.105.13:38535 -> tcp://10.6.105.6:35859
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.105.13:38535 remote=tcp://10.6.105.6:54736>: Stream is closed
2025-09-05 09:49:53,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:53,887 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48760 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:53,891 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:35813'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:53,892 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:53,892 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:53,892 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:53,892 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:53,892 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:53,900 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14e6999ab7d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:53,944 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,017 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,851 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,865 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:54,894 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,897 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:42835. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,924 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48686 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:54,928 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:45557'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,929 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,929 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,929 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,930 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,930 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,938 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:54,989 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:55,006 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:55,162 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:55,491 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:37617'. Reason: nanny-close-gracefully
2025-09-05 09:49:55,495 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:37617' closed.
2025-09-05 09:49:56,006 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:46037'. Reason: nanny-close-gracefully
2025-09-05 09:49:56,007 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:46037' closed.
2025-09-05 09:49:56,021 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:56,855 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:56,862 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:35813'. Reason: nanny-close-gracefully
2025-09-05 09:49:56,863 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:35813' closed.
2025-09-05 09:49:56,974 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:35045'. Reason: nanny-close-gracefully
2025-09-05 09:49:56,975 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:35045' closed.
2025-09-05 09:49:56,995 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:57,079 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:57,166 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:57,327 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:34557'. Reason: nanny-close-gracefully
2025-09-05 09:49:57,329 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:34557' closed.
2025-09-05 09:49:57,638 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:45477'. Reason: nanny-close-gracefully
2025-09-05 09:49:57,639 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:45477' closed.
2025-09-05 09:49:58,003 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:45557'. Reason: nanny-close-gracefully
2025-09-05 09:49:58,004 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:45557' closed.
2025-09-05 09:49:58,051 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:58,053 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:46609. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:58,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:58,085 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48792 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:58,089 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:44071'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:58,090 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:58,090 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:58,090 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:58,090 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:58,090 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:58,094 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x149056f2e590>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:58,100 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:58,362 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:58,365 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:40727. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:58,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:58,394 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48894 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:58,398 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:43831'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:58,399 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:58,399 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:58,399 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:58,399 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:58,399 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:58,404 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14a609f91250>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:58,450 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:58,756 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:58,759 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:35273. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:58,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:58,787 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48926 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:58,792 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:37751'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:58,793 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:58,793 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:58,793 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:58,793 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:58,793 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:58,799 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x153b5abc9610>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:58,838 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:59,085 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:59,300 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,030 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:38491'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,031 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:38491' closed.
2025-09-05 09:50:00,103 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:00,166 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,171 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:00,174 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:39613. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,183 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,193 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.105.7:46559
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.105.13:41142 remote=tcp://10.6.105.7:46559>: Stream is closed
2025-09-05 09:50:00,200 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.105.22:37217
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.105.13:44126 remote=tcp://10.6.105.22:37217>: Stream is closed
2025-09-05 09:50:00,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:00,205 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48918 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:00,208 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:46051'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,209 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:00,209 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:00,209 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,209 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:00,209 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:00,209 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:00,209 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,212 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14e28c94c590>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:00,245 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,330 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,455 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:00,518 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,519 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,584 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:44071'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,585 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:44071' closed.
2025-09-05 09:50:00,838 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:00,840 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:33231. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,864 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:00,867 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48672 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:00,870 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:36297'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,871 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:00,871 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:00,872 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:00,872 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:00,872 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:00,874 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14f35fec6e90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:00,877 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,888 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,895 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,919 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,968 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,028 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,030 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,031 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,070 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:01,073 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:42439. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:01,084 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,091 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,092 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,094 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:01,101 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:49108 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:01,106 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:39547'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:01,107 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:01,107 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,107 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:01,107 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:01,107 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:01,107 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:01,110 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:01,124 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,144 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,168 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,175 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,304 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:01,314 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,320 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,343 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,344 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,345 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,348 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,358 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,358 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,360 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,365 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,444 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,447 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:43831'. Reason: nanny-close-gracefully
2025-09-05 09:50:01,448 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:43831' closed.
2025-09-05 09:50:01,572 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,588 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:01,591 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:33045. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:01,595 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,604 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:01,606 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.13:46707. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:01,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:01,623 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48910 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:01,627 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:46079'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:01,628 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:01,628 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:01,628 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:01,628 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:01,628 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:01,627 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.105.30:39195
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.105.13:52804 remote=tcp://10.6.105.30:39195>: Stream is closed
2025-09-05 09:50:01,630 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14b21a3bcb10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:01,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:01,637 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.13:48780 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:01,639 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.13:42703'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:01,640 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:01,640 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:01,640 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:01,640 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:01,640 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:01,641 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1548bba82150>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:01,646 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,665 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,810 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:37751'. Reason: nanny-close-gracefully
2025-09-05 09:50:01,812 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:37751' closed.
2025-09-05 09:50:02,170 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,188 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,213 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,213 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,231 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:43779'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,233 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:43779' closed.
2025-09-05 09:50:02,249 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,523 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,524 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:43171'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,692 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:43171' closed.
2025-09-05 09:50:02,705 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:46519'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,706 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:46519' closed.
2025-09-05 09:50:02,881 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,894 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,901 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,924 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,973 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,032 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,034 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,036 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,091 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,095 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,096 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,099 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,112 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,128 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,149 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,174 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,179 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,223 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:46051'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,224 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:46051' closed.
2025-09-05 09:50:03,238 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:34921'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,239 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:34921' closed.
2025-09-05 09:50:03,263 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:40631'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,265 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:40631' closed.
2025-09-05 09:50:03,319 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,325 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,347 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,348 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,349 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,352 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,363 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,363 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,365 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,370 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,399 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:34281'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,400 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:34281' closed.
2025-09-05 09:50:03,449 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,546 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:37167'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,547 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:37167' closed.
2025-09-05 09:50:03,576 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,601 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,625 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:34979'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,626 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:34979' closed.
2025-09-05 09:50:03,649 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,659 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:42555'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,663 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:42555' closed.
2025-09-05 09:50:03,670 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,703 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:41371'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,704 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:41371' closed.
2025-09-05 09:50:03,725 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:45497'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,726 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:45497' closed.
2025-09-05 09:50:03,756 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:36379'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,757 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:36379' closed.
2025-09-05 09:50:03,814 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:33201'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,815 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:33201' closed.
2025-09-05 09:50:04,012 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:40857'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,014 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:40857' closed.
2025-09-05 09:50:04,073 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:38605'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,075 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:38605' closed.
2025-09-05 09:50:04,102 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:41325'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,104 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:36297'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,105 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:41325' closed.
2025-09-05 09:50:04,107 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:36297' closed.
2025-09-05 09:50:04,120 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:35945'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,120 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:35945' closed.
2025-09-05 09:50:04,208 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:38371'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,210 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:43189'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,211 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:38371' closed.
2025-09-05 09:50:04,211 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:43189' closed.
2025-09-05 09:50:04,261 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:44563'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,261 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:44563' closed.
2025-09-05 09:50:04,272 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:45467'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,273 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:45467' closed.
2025-09-05 09:50:04,280 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:34033'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,281 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:34033' closed.
2025-09-05 09:50:04,284 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:42703'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,284 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:42703' closed.
2025-09-05 09:50:04,337 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:36591'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,339 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:36591' closed.
2025-09-05 09:50:04,347 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:39547'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,347 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:39547' closed.
2025-09-05 09:50:04,421 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:38351'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,422 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:38351' closed.
2025-09-05 09:50:04,459 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:33915'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,460 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:33915' closed.
2025-09-05 09:50:04,465 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:36699'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,466 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:36699' closed.
2025-09-05 09:50:04,477 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:41185'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,477 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:41185' closed.
2025-09-05 09:50:04,519 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:36467'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,521 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:37995'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,521 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:36467' closed.
2025-09-05 09:50:04,522 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:37995' closed.
2025-09-05 09:50:04,530 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:37571'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,531 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:37571' closed.
2025-09-05 09:50:04,550 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:38827'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,551 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:38827' closed.
2025-09-05 09:50:04,553 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:37355'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,554 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:37355' closed.
2025-09-05 09:50:04,560 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:42837'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,563 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:42837' closed.
2025-09-05 09:50:04,579 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:45697'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,580 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:45697' closed.
2025-09-05 09:50:04,586 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:44255'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,587 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:44255' closed.
2025-09-05 09:50:04,715 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:39857'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,716 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:39857' closed.
2025-09-05 09:50:04,798 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.13:46079'. Reason: nanny-close-gracefully
2025-09-05 09:50:04,799 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.13:46079' closed.
2025-09-05 09:50:04,801 - distributed.dask_worker - INFO - End worker
