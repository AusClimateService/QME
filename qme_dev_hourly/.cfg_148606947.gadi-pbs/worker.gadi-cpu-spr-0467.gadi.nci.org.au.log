Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:31:59,553 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:45673'
2025-09-03 10:31:59,564 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41843'
2025-09-03 10:31:59,569 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:40521'
2025-09-03 10:31:59,574 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:46013'
2025-09-03 10:31:59,579 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:40449'
2025-09-03 10:31:59,583 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:37755'
2025-09-03 10:31:59,588 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:46713'
2025-09-03 10:31:59,593 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:46637'
2025-09-03 10:31:59,602 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:44361'
2025-09-03 10:31:59,608 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41637'
2025-09-03 10:31:59,612 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:36421'
2025-09-03 10:31:59,617 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:46481'
2025-09-03 10:31:59,621 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:35087'
2025-09-03 10:31:59,629 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:45045'
2025-09-03 10:31:59,634 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38465'
2025-09-03 10:31:59,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:37397'
2025-09-03 10:31:59,644 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41653'
2025-09-03 10:31:59,648 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:42261'
2025-09-03 10:31:59,653 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:39619'
2025-09-03 10:31:59,657 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38737'
2025-09-03 10:31:59,661 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:35289'
2025-09-03 10:31:59,665 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34209'
2025-09-03 10:31:59,669 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:44375'
2025-09-03 10:31:59,673 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:45415'
2025-09-03 10:31:59,678 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38237'
2025-09-03 10:31:59,684 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:45367'
2025-09-03 10:31:59,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38303'
2025-09-03 10:31:59,775 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:42399'
2025-09-03 10:31:59,780 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:42233'
2025-09-03 10:31:59,784 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:42231'
2025-09-03 10:31:59,788 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:36149'
2025-09-03 10:31:59,793 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:37447'
2025-09-03 10:31:59,798 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34033'
2025-09-03 10:31:59,804 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38019'
2025-09-03 10:31:59,808 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38547'
2025-09-03 10:32:00,574 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42339
2025-09-03 10:32:00,574 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42339
2025-09-03 10:32:00,574 - distributed.worker - INFO -          dashboard at:          10.6.102.35:35767
2025-09-03 10:32:00,574 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,574 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,574 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,574 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xwf0i3k8
2025-09-03 10:32:00,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,582 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:39439
2025-09-03 10:32:00,582 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:39439
2025-09-03 10:32:00,582 - distributed.worker - INFO -          dashboard at:          10.6.102.35:40681
2025-09-03 10:32:00,582 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,582 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,582 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,582 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4t7gh2d9
2025-09-03 10:32:00,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,677 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:45295
2025-09-03 10:32:00,677 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:45295
2025-09-03 10:32:00,677 - distributed.worker - INFO -          dashboard at:          10.6.102.35:36369
2025-09-03 10:32:00,677 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,677 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,677 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,677 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,677 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-999nwfio
2025-09-03 10:32:00,677 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,686 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42733
2025-09-03 10:32:00,686 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42733
2025-09-03 10:32:00,686 - distributed.worker - INFO -          dashboard at:          10.6.102.35:34779
2025-09-03 10:32:00,686 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,687 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,687 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,687 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,687 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ruj3ldyt
2025-09-03 10:32:00,687 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,716 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:41121
2025-09-03 10:32:00,716 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:41121
2025-09-03 10:32:00,716 - distributed.worker - INFO -          dashboard at:          10.6.102.35:35131
2025-09-03 10:32:00,716 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,716 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,716 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,716 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,716 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-09d9diq0
2025-09-03 10:32:00,716 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,732 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:33841
2025-09-03 10:32:00,732 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:33841
2025-09-03 10:32:00,732 - distributed.worker - INFO -          dashboard at:          10.6.102.35:38023
2025-09-03 10:32:00,732 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,732 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,732 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,732 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,732 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g7zw8806
2025-09-03 10:32:00,732 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,742 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:34773
2025-09-03 10:32:00,742 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:33349
2025-09-03 10:32:00,742 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:34773
2025-09-03 10:32:00,742 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:33349
2025-09-03 10:32:00,742 - distributed.worker - INFO -          dashboard at:          10.6.102.35:36631
2025-09-03 10:32:00,742 - distributed.worker - INFO -          dashboard at:          10.6.102.35:39929
2025-09-03 10:32:00,742 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,742 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,742 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,742 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,742 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,742 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,742 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tud7xlc4
2025-09-03 10:32:00,742 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nj1xncuo
2025-09-03 10:32:00,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,744 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:41757
2025-09-03 10:32:00,744 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:41757
2025-09-03 10:32:00,744 - distributed.worker - INFO -          dashboard at:          10.6.102.35:39145
2025-09-03 10:32:00,744 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,744 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,744 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,744 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,744 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-m3u_r1_7
2025-09-03 10:32:00,744 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,745 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:43847
2025-09-03 10:32:00,745 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:43847
2025-09-03 10:32:00,745 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44779
2025-09-03 10:32:00,745 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,745 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,745 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,745 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gp8tc00p
2025-09-03 10:32:00,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,750 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:38773
2025-09-03 10:32:00,750 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:38773
2025-09-03 10:32:00,750 - distributed.worker - INFO -          dashboard at:          10.6.102.35:37473
2025-09-03 10:32:00,750 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,750 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,750 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,750 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,750 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-26qlymol
2025-09-03 10:32:00,751 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,751 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44961
2025-09-03 10:32:00,751 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44961
2025-09-03 10:32:00,751 - distributed.worker - INFO -          dashboard at:          10.6.102.35:42089
2025-09-03 10:32:00,751 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,751 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,751 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,752 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,752 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-r8cqejun
2025-09-03 10:32:00,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,753 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:37653
2025-09-03 10:32:00,754 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:37653
2025-09-03 10:32:00,754 - distributed.worker - INFO -          dashboard at:          10.6.102.35:41127
2025-09-03 10:32:00,754 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,754 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,754 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,754 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9j6ybte_
2025-09-03 10:32:00,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,755 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:43381
2025-09-03 10:32:00,755 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:43381
2025-09-03 10:32:00,755 - distributed.worker - INFO -          dashboard at:          10.6.102.35:35173
2025-09-03 10:32:00,755 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,755 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,755 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,755 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-owj36il3
2025-09-03 10:32:00,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,755 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:35369
2025-09-03 10:32:00,755 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:35369
2025-09-03 10:32:00,755 - distributed.worker - INFO -          dashboard at:          10.6.102.35:46263
2025-09-03 10:32:00,755 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,755 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,755 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,755 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-znio6pd2
2025-09-03 10:32:00,756 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,758 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:37587
2025-09-03 10:32:00,758 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:37587
2025-09-03 10:32:00,758 - distributed.worker - INFO -          dashboard at:          10.6.102.35:45573
2025-09-03 10:32:00,758 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,758 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,758 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,758 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,758 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9j5ya__o
2025-09-03 10:32:00,758 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,769 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:37589
2025-09-03 10:32:00,769 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:37589
2025-09-03 10:32:00,769 - distributed.worker - INFO -          dashboard at:          10.6.102.35:41635
2025-09-03 10:32:00,769 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,769 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,769 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,769 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,769 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-i8ekbai2
2025-09-03 10:32:00,769 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,775 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:43669
2025-09-03 10:32:00,775 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:43669
2025-09-03 10:32:00,775 - distributed.worker - INFO -          dashboard at:          10.6.102.35:39925
2025-09-03 10:32:00,775 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,775 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,775 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,775 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fuwh6eo4
2025-09-03 10:32:00,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,779 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:45283
2025-09-03 10:32:00,779 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:45283
2025-09-03 10:32:00,779 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44775
2025-09-03 10:32:00,779 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,779 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,779 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,780 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ugpq2zov
2025-09-03 10:32:00,780 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,781 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:34957
2025-09-03 10:32:00,781 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:34957
2025-09-03 10:32:00,781 - distributed.worker - INFO -          dashboard at:          10.6.102.35:43491
2025-09-03 10:32:00,781 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,781 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,782 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,782 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,782 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-sxoncuiv
2025-09-03 10:32:00,782 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,789 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:33643
2025-09-03 10:32:00,789 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:33643
2025-09-03 10:32:00,789 - distributed.worker - INFO -          dashboard at:          10.6.102.35:42799
2025-09-03 10:32:00,789 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,789 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,789 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,789 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,789 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zn_jn72d
2025-09-03 10:32:00,789 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,792 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:40857
2025-09-03 10:32:00,792 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:40857
2025-09-03 10:32:00,792 - distributed.worker - INFO -          dashboard at:          10.6.102.35:33881
2025-09-03 10:32:00,792 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,792 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,792 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,792 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,792 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-stf91ndj
2025-09-03 10:32:00,792 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,793 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:34071
2025-09-03 10:32:00,793 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:34071
2025-09-03 10:32:00,793 - distributed.worker - INFO -          dashboard at:          10.6.102.35:40159
2025-09-03 10:32:00,793 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,793 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,793 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,793 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,793 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dwyyq67l
2025-09-03 10:32:00,793 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,802 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:38709
2025-09-03 10:32:00,803 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:38709
2025-09-03 10:32:00,803 - distributed.worker - INFO -          dashboard at:          10.6.102.35:39309
2025-09-03 10:32:00,803 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,803 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,803 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,803 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1zouizeu
2025-09-03 10:32:00,803 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,804 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:35727
2025-09-03 10:32:00,804 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:35727
2025-09-03 10:32:00,804 - distributed.worker - INFO -          dashboard at:          10.6.102.35:42377
2025-09-03 10:32:00,804 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,804 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,804 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,804 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xg9bv6uk
2025-09-03 10:32:00,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,881 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:46035
2025-09-03 10:32:00,882 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:46035
2025-09-03 10:32:00,882 - distributed.worker - INFO -          dashboard at:          10.6.102.35:37463
2025-09-03 10:32:00,882 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,882 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,882 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,882 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,882 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4onl1uri
2025-09-03 10:32:00,882 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,911 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:33105
2025-09-03 10:32:00,911 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:33105
2025-09-03 10:32:00,911 - distributed.worker - INFO -          dashboard at:          10.6.102.35:32881
2025-09-03 10:32:00,911 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,911 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,911 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,911 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,911 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nn8doglb
2025-09-03 10:32:00,911 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,914 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:35991
2025-09-03 10:32:00,914 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:35991
2025-09-03 10:32:00,914 - distributed.worker - INFO -          dashboard at:          10.6.102.35:46747
2025-09-03 10:32:00,914 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,914 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,914 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,914 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,914 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-r_g27ux3
2025-09-03 10:32:00,914 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,924 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:43795
2025-09-03 10:32:00,925 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:43795
2025-09-03 10:32:00,925 - distributed.worker - INFO -          dashboard at:          10.6.102.35:35499
2025-09-03 10:32:00,925 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,925 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,925 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,925 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,925 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7cz8pb92
2025-09-03 10:32:00,925 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,939 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44353
2025-09-03 10:32:00,939 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44353
2025-09-03 10:32:00,939 - distributed.worker - INFO -          dashboard at:          10.6.102.35:34411
2025-09-03 10:32:00,939 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,939 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,939 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,939 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,939 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4wkrwtxc
2025-09-03 10:32:00,939 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,941 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:38837
2025-09-03 10:32:00,941 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:38837
2025-09-03 10:32:00,941 - distributed.worker - INFO -          dashboard at:          10.6.102.35:35889
2025-09-03 10:32:00,941 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,941 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,941 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,941 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,941 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kxryt4tx
2025-09-03 10:32:00,941 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,943 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:46213
2025-09-03 10:32:00,943 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:46213
2025-09-03 10:32:00,943 - distributed.worker - INFO -          dashboard at:          10.6.102.35:39243
2025-09-03 10:32:00,943 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,943 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,943 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,943 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,943 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vjkfelgx
2025-09-03 10:32:00,943 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,944 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:33667
2025-09-03 10:32:00,944 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:33667
2025-09-03 10:32:00,944 - distributed.worker - INFO -          dashboard at:          10.6.102.35:42997
2025-09-03 10:32:00,944 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,944 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,944 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,944 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,944 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-39fcu6if
2025-09-03 10:32:00,944 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,958 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:40391
2025-09-03 10:32:00,958 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:40391
2025-09-03 10:32:00,958 - distributed.worker - INFO -          dashboard at:          10.6.102.35:35903
2025-09-03 10:32:00,958 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,958 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,958 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,958 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,958 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:35615
2025-09-03 10:32:00,958 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4idv78a7
2025-09-03 10:32:00,958 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:35615
2025-09-03 10:32:00,958 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,958 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44843
2025-09-03 10:32:00,958 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:00,958 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:00,958 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:00,958 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:00,958 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cuedgr8q
2025-09-03 10:32:00,959 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,805 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:37193'
2025-09-03 10:32:02,809 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:43227'
2025-09-03 10:32:02,813 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34899'
2025-09-03 10:32:02,822 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,824 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,826 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,835 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38967'
2025-09-03 10:32:02,839 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,842 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,847 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,850 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41619'
2025-09-03 10:32:02,854 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:36775'
2025-09-03 10:32:02,853 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,857 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,857 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,857 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41959'
2025-09-03 10:32:02,862 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,863 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:45377'
2025-09-03 10:32:02,868 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,868 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38827'
2025-09-03 10:32:02,869 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,870 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,872 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:33555'
2025-09-03 10:32:02,873 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,877 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:46631'
2025-09-03 10:32:02,882 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,884 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,884 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,884 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:35981'
2025-09-03 10:32:02,885 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:40525'
2025-09-03 10:32:02,893 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:36409'
2025-09-03 10:32:02,898 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:02,899 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:02,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:02,901 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:02,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41937'
2025-09-03 10:32:02,911 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38243'
2025-09-03 10:32:02,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:35533'
2025-09-03 10:32:02,921 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:40377'
2025-09-03 10:32:02,923 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:39329'
2025-09-03 10:32:02,929 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:39997'
2025-09-03 10:32:02,934 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:39339'
2025-09-03 10:32:02,938 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41061'
2025-09-03 10:32:02,942 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38047'
2025-09-03 10:32:02,947 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41613'
2025-09-03 10:32:03,739 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:43883
2025-09-03 10:32:03,739 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:43883
2025-09-03 10:32:03,739 - distributed.worker - INFO -          dashboard at:          10.6.102.35:41527
2025-09-03 10:32:03,739 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,739 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,739 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,739 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4wns06ba
2025-09-03 10:32:03,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,739 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:37157
2025-09-03 10:32:03,739 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:37157
2025-09-03 10:32:03,739 - distributed.worker - INFO -          dashboard at:          10.6.102.35:33891
2025-09-03 10:32:03,739 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,739 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,739 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,739 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bxher_vf
2025-09-03 10:32:03,739 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,743 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:38211
2025-09-03 10:32:03,743 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:38211
2025-09-03 10:32:03,743 - distributed.worker - INFO -          dashboard at:          10.6.102.35:34979
2025-09-03 10:32:03,743 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,743 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,743 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,743 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6nfgxrbw
2025-09-03 10:32:03,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,744 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:37977
2025-09-03 10:32:03,744 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:37977
2025-09-03 10:32:03,744 - distributed.worker - INFO -          dashboard at:          10.6.102.35:39607
2025-09-03 10:32:03,744 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,744 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,744 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,744 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,744 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-15n_9pn6
2025-09-03 10:32:03,744 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,746 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:41939
2025-09-03 10:32:03,746 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:41939
2025-09-03 10:32:03,746 - distributed.worker - INFO -          dashboard at:          10.6.102.35:40551
2025-09-03 10:32:03,746 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,746 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,746 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,746 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,746 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vbkjuuw2
2025-09-03 10:32:03,746 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,759 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:38473
2025-09-03 10:32:03,759 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:38473
2025-09-03 10:32:03,759 - distributed.worker - INFO -          dashboard at:          10.6.102.35:40261
2025-09-03 10:32:03,759 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,759 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,759 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,759 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,759 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bxb474vt
2025-09-03 10:32:03,759 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,760 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44729
2025-09-03 10:32:03,760 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44729
2025-09-03 10:32:03,760 - distributed.worker - INFO -          dashboard at:          10.6.102.35:45461
2025-09-03 10:32:03,760 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,760 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,761 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,761 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,761 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7chl10ns
2025-09-03 10:32:03,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,767 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42045
2025-09-03 10:32:03,767 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42045
2025-09-03 10:32:03,767 - distributed.worker - INFO -          dashboard at:          10.6.102.35:33585
2025-09-03 10:32:03,767 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,767 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,767 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,767 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nc2rgu7l
2025-09-03 10:32:03,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,787 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:37295
2025-09-03 10:32:03,787 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:37295
2025-09-03 10:32:03,787 - distributed.worker - INFO -          dashboard at:          10.6.102.35:45893
2025-09-03 10:32:03,787 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,787 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,787 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,787 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:33099
2025-09-03 10:32:03,787 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z73z7xta
2025-09-03 10:32:03,787 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:33099
2025-09-03 10:32:03,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,787 - distributed.worker - INFO -          dashboard at:          10.6.102.35:43497
2025-09-03 10:32:03,787 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,787 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,787 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,787 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-19uw0lgg
2025-09-03 10:32:03,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,805 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:33341
2025-09-03 10:32:03,805 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:33341
2025-09-03 10:32:03,805 - distributed.worker - INFO -          dashboard at:          10.6.102.35:42801
2025-09-03 10:32:03,805 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,805 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,805 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,805 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-p_hbbh9h
2025-09-03 10:32:03,806 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,808 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42583
2025-09-03 10:32:03,808 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42583
2025-09-03 10:32:03,808 - distributed.worker - INFO -          dashboard at:          10.6.102.35:40105
2025-09-03 10:32:03,808 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,808 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,808 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,808 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,808 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bafrdsf_
2025-09-03 10:32:03,808 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,827 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:39731
2025-09-03 10:32:03,827 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:39731
2025-09-03 10:32:03,827 - distributed.worker - INFO -          dashboard at:          10.6.102.35:42131
2025-09-03 10:32:03,827 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,827 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,827 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,827 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,827 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7ynmshzl
2025-09-03 10:32:03,827 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,847 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:38987
2025-09-03 10:32:03,847 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:38987
2025-09-03 10:32:03,847 - distributed.worker - INFO -          dashboard at:          10.6.102.35:41055
2025-09-03 10:32:03,847 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,847 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,847 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,847 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,847 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cacbr5uu
2025-09-03 10:32:03,847 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,853 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42323
2025-09-03 10:32:03,853 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42323
2025-09-03 10:32:03,854 - distributed.worker - INFO -          dashboard at:          10.6.102.35:41193
2025-09-03 10:32:03,854 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,854 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,854 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,854 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,854 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-j380bv7_
2025-09-03 10:32:03,854 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,891 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:40393
2025-09-03 10:32:03,891 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:40393
2025-09-03 10:32:03,891 - distributed.worker - INFO -          dashboard at:          10.6.102.35:45915
2025-09-03 10:32:03,891 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,891 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,891 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,891 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pm2n1hrf
2025-09-03 10:32:03,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,895 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:45379
2025-09-03 10:32:03,895 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:45379
2025-09-03 10:32:03,895 - distributed.worker - INFO -          dashboard at:          10.6.102.35:32783
2025-09-03 10:32:03,895 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,895 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,895 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,895 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,895 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-37wut_b7
2025-09-03 10:32:03,895 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,897 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:39623
2025-09-03 10:32:03,897 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:39623
2025-09-03 10:32:03,897 - distributed.worker - INFO -          dashboard at:          10.6.102.35:37605
2025-09-03 10:32:03,897 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,897 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,897 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,897 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,897 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-c_afx37u
2025-09-03 10:32:03,897 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,904 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42493
2025-09-03 10:32:03,904 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42493
2025-09-03 10:32:03,904 - distributed.worker - INFO -          dashboard at:          10.6.102.35:40851
2025-09-03 10:32:03,904 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,904 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,904 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,904 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,904 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:39223
2025-09-03 10:32:03,904 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rmxv434w
2025-09-03 10:32:03,904 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:39223
2025-09-03 10:32:03,904 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,904 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44395
2025-09-03 10:32:03,904 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,904 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,904 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,904 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,904 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u27n6vri
2025-09-03 10:32:03,904 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,915 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:40875
2025-09-03 10:32:03,915 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:40875
2025-09-03 10:32:03,915 - distributed.worker - INFO -          dashboard at:          10.6.102.35:45529
2025-09-03 10:32:03,916 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,916 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,916 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,916 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,916 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n6g8fu5n
2025-09-03 10:32:03,916 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,919 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:37437
2025-09-03 10:32:03,919 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:37437
2025-09-03 10:32:03,919 - distributed.worker - INFO -          dashboard at:          10.6.102.35:36335
2025-09-03 10:32:03,919 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,919 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,919 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,919 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,919 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-w5q7vqha
2025-09-03 10:32:03,919 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,926 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:36879
2025-09-03 10:32:03,926 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:36879
2025-09-03 10:32:03,926 - distributed.worker - INFO -          dashboard at:          10.6.102.35:40879
2025-09-03 10:32:03,926 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,926 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,926 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,926 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,926 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u9o3gagn
2025-09-03 10:32:03,926 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,938 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:39451
2025-09-03 10:32:03,938 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:39451
2025-09-03 10:32:03,938 - distributed.worker - INFO -          dashboard at:          10.6.102.35:39147
2025-09-03 10:32:03,938 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:03,938 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:03,938 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:03,938 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:03,938 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-jmb8t6g3
2025-09-03 10:32:03,938 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:09,197 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:42563'
2025-09-03 10:32:09,200 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:43027'
2025-09-03 10:32:09,205 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34409'
2025-09-03 10:32:09,210 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:40987'
2025-09-03 10:32:09,215 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:46519'
2025-09-03 10:32:09,223 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:33375'
2025-09-03 10:32:09,228 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:42685'
2025-09-03 10:32:09,233 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:33347'
2025-09-03 10:32:09,239 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:40983'
2025-09-03 10:32:09,246 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41475'
2025-09-03 10:32:09,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:39169'
2025-09-03 10:32:09,258 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38621'
2025-09-03 10:32:09,263 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34329'
2025-09-03 10:32:09,268 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34413'
2025-09-03 10:32:09,272 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:40785'
2025-09-03 10:32:09,277 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:33195'
2025-09-03 10:32:09,283 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:42737'
2025-09-03 10:32:09,289 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:40787'
2025-09-03 10:32:09,296 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34211'
2025-09-03 10:32:09,301 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34397'
2025-09-03 10:32:09,307 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:35857'
2025-09-03 10:32:09,312 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:38085'
2025-09-03 10:32:09,315 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:43761'
2025-09-03 10:32:09,320 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34379'
2025-09-03 10:32:09,324 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:43929'
2025-09-03 10:32:09,329 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:39979'
2025-09-03 10:32:09,335 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:44895'
2025-09-03 10:32:09,341 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:39895'
2025-09-03 10:32:09,346 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41433'
2025-09-03 10:32:09,350 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:45015'
2025-09-03 10:32:09,584 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:37611'
2025-09-03 10:32:09,588 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41047'
2025-09-03 10:32:10,092 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:33791
2025-09-03 10:32:10,092 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:33791
2025-09-03 10:32:10,092 - distributed.worker - INFO -          dashboard at:          10.6.102.35:38787
2025-09-03 10:32:10,092 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,092 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,092 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,092 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,092 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wuzgt9qp
2025-09-03 10:32:10,093 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,120 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44075
2025-09-03 10:32:10,120 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44075
2025-09-03 10:32:10,120 - distributed.worker - INFO -          dashboard at:          10.6.102.35:33429
2025-09-03 10:32:10,120 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,120 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,120 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,120 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,120 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qug3uk32
2025-09-03 10:32:10,120 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,150 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:45587
2025-09-03 10:32:10,150 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:45587
2025-09-03 10:32:10,150 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44931
2025-09-03 10:32:10,150 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,150 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,150 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,150 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,150 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ppa_ywwh
2025-09-03 10:32:10,150 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,153 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44123
2025-09-03 10:32:10,153 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44123
2025-09-03 10:32:10,153 - distributed.worker - INFO -          dashboard at:          10.6.102.35:40713
2025-09-03 10:32:10,153 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:37045
2025-09-03 10:32:10,153 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,153 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,153 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:37045
2025-09-03 10:32:10,153 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,153 - distributed.worker - INFO -          dashboard at:          10.6.102.35:35159
2025-09-03 10:32:10,153 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,153 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,153 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-b0_u40mk
2025-09-03 10:32:10,153 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,153 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,153 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,153 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,153 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4_l0_2ei
2025-09-03 10:32:10,153 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,193 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:34437
2025-09-03 10:32:10,193 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:34437
2025-09-03 10:32:10,193 - distributed.worker - INFO -          dashboard at:          10.6.102.35:40135
2025-09-03 10:32:10,193 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,193 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,193 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,193 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,193 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-en1wrsru
2025-09-03 10:32:10,193 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,197 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:34503
2025-09-03 10:32:10,197 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:34503
2025-09-03 10:32:10,197 - distributed.worker - INFO -          dashboard at:          10.6.102.35:45927
2025-09-03 10:32:10,197 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,197 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,197 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,197 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6lpzqgpq
2025-09-03 10:32:10,198 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,209 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:35047
2025-09-03 10:32:10,209 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:35047
2025-09-03 10:32:10,209 - distributed.worker - INFO -          dashboard at:          10.6.102.35:38775
2025-09-03 10:32:10,209 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,209 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,209 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,209 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,209 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x0ggx769
2025-09-03 10:32:10,209 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,244 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42571
2025-09-03 10:32:10,244 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42571
2025-09-03 10:32:10,244 - distributed.worker - INFO -          dashboard at:          10.6.102.35:36665
2025-09-03 10:32:10,244 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,244 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,244 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,244 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,244 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rvoyzz8u
2025-09-03 10:32:10,245 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,250 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:46139
2025-09-03 10:32:10,250 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:46139
2025-09-03 10:32:10,250 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44397
2025-09-03 10:32:10,250 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,250 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,250 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,251 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,251 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3y3jg1x9
2025-09-03 10:32:10,251 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,256 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44095
2025-09-03 10:32:10,256 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44095
2025-09-03 10:32:10,256 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44105
2025-09-03 10:32:10,256 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,256 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,256 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,256 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_2k7jqzn
2025-09-03 10:32:10,256 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42189
2025-09-03 10:32:10,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,256 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42189
2025-09-03 10:32:10,256 - distributed.worker - INFO -          dashboard at:          10.6.102.35:45363
2025-09-03 10:32:10,256 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,256 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,256 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,257 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1_lbi5q8
2025-09-03 10:32:10,257 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,277 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:36609
2025-09-03 10:32:10,277 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:36609
2025-09-03 10:32:10,277 - distributed.worker - INFO -          dashboard at:          10.6.102.35:36797
2025-09-03 10:32:10,277 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,277 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,277 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,277 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,277 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-yqocxm5d
2025-09-03 10:32:10,277 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,344 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:43763'
2025-09-03 10:32:10,347 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:41361
2025-09-03 10:32:10,347 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:41361
2025-09-03 10:32:10,347 - distributed.worker - INFO -          dashboard at:          10.6.102.35:41929
2025-09-03 10:32:10,347 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,347 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,347 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,347 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-k9u8t36n
2025-09-03 10:32:10,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,347 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:33645'
2025-09-03 10:32:10,350 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:46627
2025-09-03 10:32:10,350 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:46627
2025-09-03 10:32:10,350 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44013
2025-09-03 10:32:10,350 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,351 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,351 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,351 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-e1y890vp
2025-09-03 10:32:10,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,352 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:37871'
2025-09-03 10:32:10,354 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:35597
2025-09-03 10:32:10,354 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:35597
2025-09-03 10:32:10,354 - distributed.worker - INFO -          dashboard at:          10.6.102.35:38347
2025-09-03 10:32:10,354 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,354 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,354 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,354 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g6ltc4vg
2025-09-03 10:32:10,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,354 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44367
2025-09-03 10:32:10,354 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:39639
2025-09-03 10:32:10,354 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44367
2025-09-03 10:32:10,355 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:39639
2025-09-03 10:32:10,355 - distributed.worker - INFO -          dashboard at:          10.6.102.35:45059
2025-09-03 10:32:10,355 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44803
2025-09-03 10:32:10,355 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,355 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,355 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,355 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,355 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,355 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-olz14yon
2025-09-03 10:32:10,355 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,355 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-437othp6
2025-09-03 10:32:10,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,357 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:41411'
2025-09-03 10:32:10,361 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,361 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:40395'
2025-09-03 10:32:10,362 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,362 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,364 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,365 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:43093
2025-09-03 10:32:10,365 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:43797
2025-09-03 10:32:10,365 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:43093
2025-09-03 10:32:10,365 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:43797
2025-09-03 10:32:10,365 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44941
2025-09-03 10:32:10,365 - distributed.worker - INFO -          dashboard at:          10.6.102.35:39735
2025-09-03 10:32:10,365 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,365 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,365 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,365 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,365 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,365 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,365 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,365 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,365 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dlw2q_2j
2025-09-03 10:32:10,365 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ogzhxlj2
2025-09-03 10:32:10,365 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,366 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,366 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:46447
2025-09-03 10:32:10,366 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:46447
2025-09-03 10:32:10,366 - distributed.worker - INFO -          dashboard at:          10.6.102.35:32971
2025-09-03 10:32:10,366 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,366 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,366 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,366 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,366 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-go67wu5b
2025-09-03 10:32:10,367 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,367 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:36403'
2025-09-03 10:32:10,370 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:43469
2025-09-03 10:32:10,370 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:43469
2025-09-03 10:32:10,370 - distributed.worker - INFO -          dashboard at:          10.6.102.35:34545
2025-09-03 10:32:10,370 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,370 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,370 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,370 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,370 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-r8jrxwny
2025-09-03 10:32:10,370 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,371 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:34507
2025-09-03 10:32:10,371 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:34507
2025-09-03 10:32:10,371 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:46795
2025-09-03 10:32:10,371 - distributed.worker - INFO -          dashboard at:          10.6.102.35:43315
2025-09-03 10:32:10,371 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:46795
2025-09-03 10:32:10,371 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,371 - distributed.worker - INFO -          dashboard at:          10.6.102.35:37813
2025-09-03 10:32:10,371 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,371 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,371 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:39371
2025-09-03 10:32:10,371 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,371 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,371 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:39371
2025-09-03 10:32:10,371 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rquvuu_x
2025-09-03 10:32:10,371 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,371 - distributed.worker - INFO -          dashboard at:          10.6.102.35:46127
2025-09-03 10:32:10,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,371 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1353n4ra
2025-09-03 10:32:10,371 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,371 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,371 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,371 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-veljygww
2025-09-03 10:32:10,372 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,371 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:37347'
2025-09-03 10:32:10,377 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:36153'
2025-09-03 10:32:10,377 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:10,379 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,379 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,380 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:36415'
2025-09-03 10:32:10,380 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:10,381 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42467
2025-09-03 10:32:10,381 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42467
2025-09-03 10:32:10,381 - distributed.worker - INFO -          dashboard at:          10.6.102.35:33895
2025-09-03 10:32:10,381 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,381 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,381 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,381 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9d8xu9cf
2025-09-03 10:32:10,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,384 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:35495'
2025-09-03 10:32:10,388 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:43113
2025-09-03 10:32:10,388 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:43113
2025-09-03 10:32:10,388 - distributed.worker - INFO -          dashboard at:          10.6.102.35:34763
2025-09-03 10:32:10,388 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,388 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,388 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,388 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-s3i3kvbf
2025-09-03 10:32:10,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,393 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:36133
2025-09-03 10:32:10,393 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:38653
2025-09-03 10:32:10,393 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:36133
2025-09-03 10:32:10,393 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:38653
2025-09-03 10:32:10,393 - distributed.worker - INFO -          dashboard at:          10.6.102.35:46467
2025-09-03 10:32:10,393 - distributed.worker - INFO -          dashboard at:          10.6.102.35:38679
2025-09-03 10:32:10,393 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,393 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,393 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,393 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,393 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,393 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,393 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2zgkw4ch
2025-09-03 10:32:10,393 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-86xdmt5_
2025-09-03 10:32:10,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,395 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44925
2025-09-03 10:32:10,395 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44925
2025-09-03 10:32:10,395 - distributed.worker - INFO -          dashboard at:          10.6.102.35:33615
2025-09-03 10:32:10,395 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,395 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,395 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,395 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,395 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-i6ye4zh7
2025-09-03 10:32:10,395 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,423 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44699
2025-09-03 10:32:10,423 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44699
2025-09-03 10:32:10,423 - distributed.worker - INFO -          dashboard at:          10.6.102.35:42507
2025-09-03 10:32:10,423 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,423 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,423 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,423 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,423 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4z2fva84
2025-09-03 10:32:10,423 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,425 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:39533
2025-09-03 10:32:10,426 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:39533
2025-09-03 10:32:10,426 - distributed.worker - INFO -          dashboard at:          10.6.102.35:35913
2025-09-03 10:32:10,426 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:10,426 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,426 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:10,426 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:10,426 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g18v5jdc
2025-09-03 10:32:10,426 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:10,435 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:37775'
2025-09-03 10:32:10,442 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:45147'
2025-09-03 10:32:10,448 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.35:34513'
2025-09-03 10:32:11,101 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:46057
2025-09-03 10:32:11,101 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:46057
2025-09-03 10:32:11,101 - distributed.worker - INFO -          dashboard at:          10.6.102.35:42621
2025-09-03 10:32:11,101 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,101 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,101 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,101 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,101 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9ztldegb
2025-09-03 10:32:11,101 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,155 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:44197
2025-09-03 10:32:11,155 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:44197
2025-09-03 10:32:11,155 - distributed.worker - INFO -          dashboard at:          10.6.102.35:38731
2025-09-03 10:32:11,155 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,155 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,155 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,155 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4y6nvq23
2025-09-03 10:32:11,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,158 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:41801
2025-09-03 10:32:11,158 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:41801
2025-09-03 10:32:11,158 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44701
2025-09-03 10:32:11,158 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,158 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,158 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,158 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,158 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pnufq0c7
2025-09-03 10:32:11,158 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,164 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42671
2025-09-03 10:32:11,164 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42671
2025-09-03 10:32:11,164 - distributed.worker - INFO -          dashboard at:          10.6.102.35:41855
2025-09-03 10:32:11,164 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,164 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,164 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,164 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,164 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-p24crclg
2025-09-03 10:32:11,165 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,184 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:46569
2025-09-03 10:32:11,184 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:46569
2025-09-03 10:32:11,184 - distributed.worker - INFO -          dashboard at:          10.6.102.35:36333
2025-09-03 10:32:11,184 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,184 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,184 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,184 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,184 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pz_j43q5
2025-09-03 10:32:11,184 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,196 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:40211
2025-09-03 10:32:11,196 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:40211
2025-09-03 10:32:11,196 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44743
2025-09-03 10:32:11,196 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,196 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,196 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,196 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ilwawh_s
2025-09-03 10:32:11,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,209 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:38255
2025-09-03 10:32:11,210 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:38255
2025-09-03 10:32:11,210 - distributed.worker - INFO -          dashboard at:          10.6.102.35:34213
2025-09-03 10:32:11,210 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,210 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,210 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,210 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,210 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-j3ogij_c
2025-09-03 10:32:11,210 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,212 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:42469
2025-09-03 10:32:11,212 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:42469
2025-09-03 10:32:11,212 - distributed.worker - INFO -          dashboard at:          10.6.102.35:37923
2025-09-03 10:32:11,212 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,212 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,212 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,212 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,212 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qv9bejr2
2025-09-03 10:32:11,212 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,220 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:36479
2025-09-03 10:32:11,220 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:36479
2025-09-03 10:32:11,220 - distributed.worker - INFO -          dashboard at:          10.6.102.35:43955
2025-09-03 10:32:11,220 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,220 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,220 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,220 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,220 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kxh_hv62
2025-09-03 10:32:11,221 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,221 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:35051
2025-09-03 10:32:11,221 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:35051
2025-09-03 10:32:11,221 - distributed.worker - INFO -          dashboard at:          10.6.102.35:42037
2025-09-03 10:32:11,221 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,221 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,221 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,221 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,221 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2_63f719
2025-09-03 10:32:11,221 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,233 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:35883
2025-09-03 10:32:11,233 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:35883
2025-09-03 10:32:11,233 - distributed.worker - INFO -          dashboard at:          10.6.102.35:44475
2025-09-03 10:32:11,233 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,233 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,233 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,233 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,233 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x1ti48wi
2025-09-03 10:32:11,233 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,242 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:41793
2025-09-03 10:32:11,242 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:41793
2025-09-03 10:32:11,242 - distributed.worker - INFO -          dashboard at:          10.6.102.35:39077
2025-09-03 10:32:11,242 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,242 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,242 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,242 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,242 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-51f5y76e
2025-09-03 10:32:11,242 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,264 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.35:39537
2025-09-03 10:32:11,264 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.35:39537
2025-09-03 10:32:11,264 - distributed.worker - INFO -          dashboard at:          10.6.102.35:36701
2025-09-03 10:32:11,264 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:11,264 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:11,264 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:32:11,264 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:32:11,264 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-w3bbwwwe
2025-09-03 10:32:11,264 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:15,031 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:15,032 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:15,032 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:15,034 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:16,342 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:16,343 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:16,343 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:16,345 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:16,358 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:16,359 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:16,359 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:16,361 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:16,374 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:16,375 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:16,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:16,377 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:16,814 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:16,815 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:16,815 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:16,817 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,492 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,494 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,494 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,496 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,509 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,510 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,512 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,525 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,526 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,526 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,528 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,542 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,543 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,543 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,545 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,557 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,559 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,559 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,561 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,760 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,761 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,762 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,763 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,776 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,777 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,779 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,796 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,800 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,806 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,808 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,810 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,810 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,812 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,824 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,826 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,826 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,828 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,841 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,842 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,844 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,856 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,857 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,857 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,859 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,872 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,874 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,874 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,875 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,889 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,891 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,893 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,905 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,906 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,908 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,922 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:18,923 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,923 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:18,925 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,551 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,553 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,555 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,570 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,572 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,572 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,574 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,587 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,588 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,589 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,590 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,602 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,604 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,605 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,619 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,620 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,621 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,622 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,635 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,636 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,637 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,638 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,651 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,653 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,655 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,668 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,669 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,669 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,671 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:24,617 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:24,618 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:24,619 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:24,620 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:24,634 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:24,636 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:24,636 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:24,638 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:24,750 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:24,752 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:24,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:24,754 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:24,767 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:24,769 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:24,769 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:24,771 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:24,784 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:24,786 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:24,786 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:24,788 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:24,801 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:24,802 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:24,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:24,804 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:24,817 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:24,819 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:24,819 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:24,821 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:24,834 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:24,835 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:24,835 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:24,837 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,345 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:27,347 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:27,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:27,348 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,362 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:27,364 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:27,364 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:27,365 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,379 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:27,381 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:27,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:27,383 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,396 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:27,397 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:27,398 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:27,399 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,413 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:27,414 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:27,415 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:27,416 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,430 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:27,432 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:27,432 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:27,433 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,447 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:27,449 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:27,449 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:27,450 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,464 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:27,466 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:27,466 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:27,467 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:30,576 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,584 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,717 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,733 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,743 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,743 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,745 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,746 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,752 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,753 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,755 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,756 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,756 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,759 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,771 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,777 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,781 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,883 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,912 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,915 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,926 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,941 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,942 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,945 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,945 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,960 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:30,960 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,741 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,741 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,744 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,746 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,748 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,760 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,762 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,769 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,788 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,789 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,807 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,810 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,828 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,829 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:33,848 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,845 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:33,855 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,862 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:33,875 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:33,893 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:33,888 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:37,740 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:37,741 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,741 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:37,743 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:37,757 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:37,758 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:37,759 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:37,760 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,437 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,438 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,439 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,440 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,455 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,456 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,457 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,458 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,472 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,473 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,474 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,475 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,490 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,491 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,492 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,493 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,507 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,509 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,509 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,511 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,523 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,525 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,525 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,526 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,541 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,543 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,543 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,544 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,558 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,559 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,560 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,561 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,575 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,577 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,579 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,592 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,594 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,596 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,609 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,611 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,613 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:38,626 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:38,628 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:38,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:38,630 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:39,467 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:39,469 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:39,469 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:39,471 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:40,372 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:40,383 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:40,390 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:40,395 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:40,395 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:40,397 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:40,425 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:40,427 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:42,864 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:42,865 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:42,865 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:42,867 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:42,881 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:42,882 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:42,883 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:42,884 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:42,899 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:42,901 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:42,901 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:42,903 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:42,917 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:42,918 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:42,918 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:42,919 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:42,934 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:42,936 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:42,936 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:42,938 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:42,952 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:42,953 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:42,954 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:42,955 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:42,970 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:42,971 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:42,971 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:42,973 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,111 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,113 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,113 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,115 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,131 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,132 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,132 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,134 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,149 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,150 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,150 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,152 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,448 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,449 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,450 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,452 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,466 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,467 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,467 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,469 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,483 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,485 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,485 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,487 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,501 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,502 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,502 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,503 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:43,519 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:43,520 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:43,520 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:43,522 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:46,488 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:46,489 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:46,489 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:46,491 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:46,506 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:46,507 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:46,507 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:46,509 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:46,523 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:46,524 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:46,525 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:46,526 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:48,581 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:48,583 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:48,583 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:48,585 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:48,600 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:48,602 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:48,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:48,604 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:48,618 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:48,619 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:48,619 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:48,621 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:48,635 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:48,636 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:48,636 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:48,638 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:48,652 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:48,653 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:48,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:48,655 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:48,669 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:48,670 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:48,671 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:48,672 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:48,686 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:48,688 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:48,688 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:48,690 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:48,703 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:48,705 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:48,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:48,707 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:49,847 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,860 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,879 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,896 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,911 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,927 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:53,655 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,657 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,657 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,659 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:53,674 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,675 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,676 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,677 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:53,692 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,694 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,694 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,695 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:53,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,711 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,711 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,712 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:53,727 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,728 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,728 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,730 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:53,745 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,746 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,747 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,748 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:53,762 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,764 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,764 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,766 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:53,783 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,786 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,786 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,791 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:53,797 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,799 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,799 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,801 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:53,815 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:53,816 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:53,816 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:53,818 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:58,454 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:58,470 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:35:51,374 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,376 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,496 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,500 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,604 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,605 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,810 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,815 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,892 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,891 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,894 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,897 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,947 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,949 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,950 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,954 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,960 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,961 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,976 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,979 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,037 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,036 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,038 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,039 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,100 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,107 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,111 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,112 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,243 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,245 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,044 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,050 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,089 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,096 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,100 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,101 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,101 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,105 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,115 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,117 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,117 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,124 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,137 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,138 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,351 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,352 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,409 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,419 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,457 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,464 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,501 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,502 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,503 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,503 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,563 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,569 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,618 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,624 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,969 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,970 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,983 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,985 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,010 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,016 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,052 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,053 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,063 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,065 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,261 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,264 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,286 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,292 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,304 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,307 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,320 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,321 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,383 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,384 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,385 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,385 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,411 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,412 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,815 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,816 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,824 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,826 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,857 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,863 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,952 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,957 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,076 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,077 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,233 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,239 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,335 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,340 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,467 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,468 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,696 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,698 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,756 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,946 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,949 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,038 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,040 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,074 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,076 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,081 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,084 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,104 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,110 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,110 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,115 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,141 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,142 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,229 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,230 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,295 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,300 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,361 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,366 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,617 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,619 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,720 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,723 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,725 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,730 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,994 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,996 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,065 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,067 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,224 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,226 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,226 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,229 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,449 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,450 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,570 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,572 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,759 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,761 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,828 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,829 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,902 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,903 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,130 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,132 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,153 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,154 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,735 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,740 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,778 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,781 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,989 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,994 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,120 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,125 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,179 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,185 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,467 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,474 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,559 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,568 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,751 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,753 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,758 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,759 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,870 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,872 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,011 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,013 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,530 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,532 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,915 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,916 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,247 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,253 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,407 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,409 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,605 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,607 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,016 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,018 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,530 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,535 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,834 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,839 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,881 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,887 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,716 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,718 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,135 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,138 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,230 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,237 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:05,520 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:05,524 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:05,910 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:05,916 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:07,867 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:07,872 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:10,765 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:10,770 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:14,998 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:14,999 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:22,883 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,886 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,889 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,892 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,900 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,902 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,904 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,906 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,906 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,908 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,924 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,927 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,927 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,929 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,929 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,930 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,932 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,933 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,934 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,935 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,941 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,942 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,943 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,944 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,957 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,959 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,394 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,394 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,395 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,396 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,397 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,398 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,401 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,403 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,501 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,503 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,507 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,509 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,511 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,513 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,514 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,516 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,520 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,522 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,543 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,548 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,549 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,551 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,551 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,553 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,554 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,558 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,560 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,559 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,561 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,562 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,567 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,566 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,569 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,782 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,784 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,784 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,788 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,790 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,798 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,800 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,840 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,842 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,860 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,861 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,862 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,863 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,865 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,867 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,869 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,870 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,871 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,872 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,873 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,872 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,873 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,874 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,876 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,878 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,883 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,885 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,893 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,893 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,895 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,895 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,897 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,913 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,915 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,027 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,075 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,077 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,091 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,094 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,096 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,098 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,099 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,101 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,114 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,115 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,116 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,118 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,241 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,244 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,335 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,337 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,339 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,341 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,342 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,346 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,389 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,397 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,401 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,403 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,404 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,406 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,499 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,501 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,514 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,516 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,587 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,589 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,627 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,629 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,632 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,634 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,638 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,640 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,641 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,643 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,663 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,669 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,667 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,670 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,672 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,672 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,681 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,686 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,691 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,696 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,746 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,748 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,752 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,754 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,851 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,853 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,854 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,855 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,857 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,857 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,893 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,894 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,895 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,893 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,898 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,897 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,902 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,919 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,927 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,929 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,931 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,936 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,938 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,941 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,944 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,945 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,947 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,962 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,964 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,969 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,971 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,051 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,053 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,057 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,059 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,081 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,083 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,396 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,398 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,474 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,479 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,561 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,563 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,569 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,574 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,598 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,600 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,617 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,619 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,838 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,840 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,517 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,519 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,617 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,619 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:27,510 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:27,514 - distributed.utils - INFO - Reload module qme_vars from .py file
