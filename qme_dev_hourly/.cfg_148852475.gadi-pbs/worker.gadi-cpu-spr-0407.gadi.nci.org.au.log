Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-05 09:11:34,973 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:38473'
2025-09-05 09:11:34,981 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:33041'
2025-09-05 09:11:34,987 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:33157'
2025-09-05 09:11:34,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:39883'
2025-09-05 09:11:34,996 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:33201'
2025-09-05 09:11:35,000 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:36117'
2025-09-05 09:11:35,005 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:33905'
2025-09-05 09:11:35,009 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:36713'
2025-09-05 09:11:35,013 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:38975'
2025-09-05 09:11:35,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:40515'
2025-09-05 09:11:35,022 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:38615'
2025-09-05 09:11:35,026 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:42769'
2025-09-05 09:11:35,031 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:33969'
2025-09-05 09:11:35,035 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:39463'
2025-09-05 09:11:35,039 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:37167'
2025-09-05 09:11:35,042 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:43107'
2025-09-05 09:11:35,046 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:41923'
2025-09-05 09:11:35,051 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:46185'
2025-09-05 09:11:35,055 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:34439'
2025-09-05 09:11:35,060 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:45185'
2025-09-05 09:11:35,143 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:36303'
2025-09-05 09:11:35,148 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:44987'
2025-09-05 09:11:35,153 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:40335'
2025-09-05 09:11:35,157 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:37559'
2025-09-05 09:11:35,161 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:36671'
2025-09-05 09:11:35,166 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:37707'
2025-09-05 09:11:35,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:42171'
2025-09-05 09:11:35,176 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:43035'
2025-09-05 09:11:35,180 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:46031'
2025-09-05 09:11:35,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:39833'
2025-09-05 09:11:35,190 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:38981'
2025-09-05 09:11:35,195 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:40509'
2025-09-05 09:11:35,199 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:35579'
2025-09-05 09:11:35,204 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:46175'
2025-09-05 09:11:35,209 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:43095'
2025-09-05 09:11:35,213 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:34851'
2025-09-05 09:11:35,218 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:45423'
2025-09-05 09:11:35,222 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:34903'
2025-09-05 09:11:35,227 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:44457'
2025-09-05 09:11:35,230 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:46311'
2025-09-05 09:11:35,236 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:33017'
2025-09-05 09:11:35,241 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:45031'
2025-09-05 09:11:35,243 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:44171'
2025-09-05 09:11:35,247 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:46855'
2025-09-05 09:11:35,251 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:43865'
2025-09-05 09:11:35,256 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:33971'
2025-09-05 09:11:35,258 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:42527'
2025-09-05 09:11:35,262 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:43793'
2025-09-05 09:11:35,266 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:46521'
2025-09-05 09:11:35,270 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:40425'
2025-09-05 09:11:35,273 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:34065'
2025-09-05 09:11:35,279 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.47:41963'
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:37089
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:34915
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:33785
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:44529
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:34011
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:33143
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:43309
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:42143
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:40289
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:37089
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:33665
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:43303
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:35317
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:34915
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:33511
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:39323
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:39645
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:33785
2025-09-05 09:11:36,470 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:38275
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:44529
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:34011
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:33143
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:43309
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:42143
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:40289
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:45089
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:33665
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:43303
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:35317
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:44361
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:33511
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:39323
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:39645
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:43657
2025-09-05 09:11:36,470 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:38275
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:33537
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:35625
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:44901
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:35635
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:34231
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:41235
2025-09-05 09:11:36,470 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:36785
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:43743
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:37143
2025-09-05 09:11:36,470 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:46607
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:34323
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:37153
2025-09-05 09:11:36,470 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,470 - distributed.worker - INFO -          dashboard at:          10.6.101.47:42855
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,470 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-kf2miwtp
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-_bpxwawi
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-r1gwjrzu
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-_f7gzi9f
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ein6b434
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-zfc5l9mw
2025-09-05 09:11:36,471 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-smswxcxi
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-c19ssb92
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-3hxrkxjn
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-k45ld3st
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-mn1saogv
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8oujwfog
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-w3pfulh0
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8qareuld
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-c98a3e0n
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-bjg5d0f0
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,471 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,479 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:44913
2025-09-05 09:11:36,479 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:44913
2025-09-05 09:11:36,479 - distributed.worker - INFO -          dashboard at:          10.6.101.47:44091
2025-09-05 09:11:36,479 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,479 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,479 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,479 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,479 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ae641oe4
2025-09-05 09:11:36,479 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,479 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:36653
2025-09-05 09:11:36,479 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:36653
2025-09-05 09:11:36,479 - distributed.worker - INFO -          dashboard at:          10.6.101.47:39835
2025-09-05 09:11:36,480 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,480 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,480 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,480 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,480 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-2fe11c8q
2025-09-05 09:11:36,480 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,481 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:38553
2025-09-05 09:11:36,481 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:38553
2025-09-05 09:11:36,481 - distributed.worker - INFO -          dashboard at:          10.6.101.47:33171
2025-09-05 09:11:36,481 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,481 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,481 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,481 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,481 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-qedwy4d_
2025-09-05 09:11:36,482 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,493 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,493 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,493 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,494 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,494 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:37525
2025-09-05 09:11:36,495 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:37525
2025-09-05 09:11:36,495 - distributed.worker - INFO -          dashboard at:          10.6.101.47:40177
2025-09-05 09:11:36,495 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,495 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,495 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,495 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,495 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-o40toh2e
2025-09-05 09:11:36,495 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,496 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,497 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,497 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,497 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,498 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,499 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,500 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,501 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,502 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,502 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,503 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,503 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:43011
2025-09-05 09:11:36,503 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:43011
2025-09-05 09:11:36,503 - distributed.worker - INFO -          dashboard at:          10.6.101.47:42627
2025-09-05 09:11:36,503 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,503 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,503 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,504 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,504 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-bcf2rw72
2025-09-05 09:11:36,504 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,504 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,505 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,507 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,507 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,508 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,508 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,508 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:45271
2025-09-05 09:11:36,508 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:45271
2025-09-05 09:11:36,508 - distributed.worker - INFO -          dashboard at:          10.6.101.47:44123
2025-09-05 09:11:36,508 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,508 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,508 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,508 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,508 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-z1yz7clm
2025-09-05 09:11:36,508 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,509 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,509 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,510 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,510 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,511 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,511 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,512 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,512 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,513 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,513 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,513 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,513 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,515 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,515 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,515 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,515 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,516 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,516 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,516 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,517 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,518 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,518 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,518 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,519 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,520 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,520 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,520 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,520 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,521 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,521 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,521 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,522 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,522 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,522 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,523 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,523 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,524 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,524 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,524 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,524 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,525 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,525 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,525 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,525 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,526 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,526 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,526 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,526 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:36611
2025-09-05 09:11:36,527 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:36611
2025-09-05 09:11:36,527 - distributed.worker - INFO -          dashboard at:          10.6.101.47:43753
2025-09-05 09:11:36,527 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,527 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,527 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,527 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,527 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-cnthcoxb
2025-09-05 09:11:36,527 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,527 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,527 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,527 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,528 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,529 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,532 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:45649
2025-09-05 09:11:36,532 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:45649
2025-09-05 09:11:36,532 - distributed.worker - INFO -          dashboard at:          10.6.101.47:41037
2025-09-05 09:11:36,532 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,532 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,532 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,532 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,532 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-su9x6tyv
2025-09-05 09:11:36,532 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,539 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:34271
2025-09-05 09:11:36,539 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:34271
2025-09-05 09:11:36,539 - distributed.worker - INFO -          dashboard at:          10.6.101.47:40213
2025-09-05 09:11:36,539 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,539 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,539 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,539 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-w2nulp13
2025-09-05 09:11:36,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,544 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,545 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,545 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,545 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,546 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,547 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,547 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,547 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,548 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,549 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,549 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,549 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,549 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,549 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,549 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,549 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,550 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,551 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,552 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,552 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:41507
2025-09-05 09:11:36,553 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:41507
2025-09-05 09:11:36,553 - distributed.worker - INFO -          dashboard at:          10.6.101.47:40111
2025-09-05 09:11:36,553 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,553 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,553 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,553 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,553 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-r9n6zkes
2025-09-05 09:11:36,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,554 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,575 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,576 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,578 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,579 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:37477
2025-09-05 09:11:36,579 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:37477
2025-09-05 09:11:36,579 - distributed.worker - INFO -          dashboard at:          10.6.101.47:39473
2025-09-05 09:11:36,579 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,579 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,579 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,579 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,579 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-dg708fol
2025-09-05 09:11:36,579 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,599 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:39319
2025-09-05 09:11:36,599 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:39319
2025-09-05 09:11:36,599 - distributed.worker - INFO -          dashboard at:          10.6.101.47:41303
2025-09-05 09:11:36,599 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,599 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,599 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,599 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-7rkpfljs
2025-09-05 09:11:36,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,602 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,603 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,605 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,607 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:36667
2025-09-05 09:11:36,607 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:36667
2025-09-05 09:11:36,607 - distributed.worker - INFO -          dashboard at:          10.6.101.47:44055
2025-09-05 09:11:36,607 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,607 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,607 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,607 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,607 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-pjet1_u3
2025-09-05 09:11:36,607 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,616 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:34429
2025-09-05 09:11:36,616 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:34429
2025-09-05 09:11:36,616 - distributed.worker - INFO -          dashboard at:          10.6.101.47:33019
2025-09-05 09:11:36,616 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,616 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,616 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,616 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,617 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-rdfp4aau
2025-09-05 09:11:36,617 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,618 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:46259
2025-09-05 09:11:36,618 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:46259
2025-09-05 09:11:36,618 - distributed.worker - INFO -          dashboard at:          10.6.101.47:33521
2025-09-05 09:11:36,618 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,618 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,618 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,618 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,618 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-bbsei52a
2025-09-05 09:11:36,618 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,624 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,625 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,625 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,626 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,633 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,634 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,635 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,636 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,638 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,639 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,640 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,641 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,642 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,643 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,643 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,645 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,716 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:41243
2025-09-05 09:11:36,716 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:41243
2025-09-05 09:11:36,716 - distributed.worker - INFO -          dashboard at:          10.6.101.47:45207
2025-09-05 09:11:36,716 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,716 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,717 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,717 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,717 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-f1ujgzq9
2025-09-05 09:11:36,717 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,724 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:33107
2025-09-05 09:11:36,724 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:33107
2025-09-05 09:11:36,724 - distributed.worker - INFO -          dashboard at:          10.6.101.47:45997
2025-09-05 09:11:36,724 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,724 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,724 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,724 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,724 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-reux9u08
2025-09-05 09:11:36,724 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,735 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:36335
2025-09-05 09:11:36,735 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:36335
2025-09-05 09:11:36,735 - distributed.worker - INFO -          dashboard at:          10.6.101.47:39365
2025-09-05 09:11:36,735 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,735 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,735 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,735 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,735 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-du92nypt
2025-09-05 09:11:36,735 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,741 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,742 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,742 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:43705
2025-09-05 09:11:36,743 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:43705
2025-09-05 09:11:36,743 - distributed.worker - INFO -          dashboard at:          10.6.101.47:42407
2025-09-05 09:11:36,743 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,743 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,743 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,743 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-9xj1uk4j
2025-09-05 09:11:36,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,743 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,746 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,747 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,748 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,749 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,752 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,752 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,753 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,763 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:37615
2025-09-05 09:11:36,763 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:37615
2025-09-05 09:11:36,763 - distributed.worker - INFO -          dashboard at:          10.6.101.47:36409
2025-09-05 09:11:36,763 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,763 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,763 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,763 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,763 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-m_2pmvbc
2025-09-05 09:11:36,763 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,769 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,770 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,770 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,771 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,787 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:37757
2025-09-05 09:11:36,787 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:37757
2025-09-05 09:11:36,787 - distributed.worker - INFO -          dashboard at:          10.6.101.47:42073
2025-09-05 09:11:36,787 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,787 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,787 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,787 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-v3eu90u1
2025-09-05 09:11:36,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,790 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,791 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,791 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,793 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,811 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,812 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,814 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,887 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:44879
2025-09-05 09:11:36,887 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:44879
2025-09-05 09:11:36,887 - distributed.worker - INFO -          dashboard at:          10.6.101.47:34581
2025-09-05 09:11:36,887 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,887 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,887 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,887 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-43oj4603
2025-09-05 09:11:36,887 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,889 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:40143
2025-09-05 09:11:36,889 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:40143
2025-09-05 09:11:36,889 - distributed.worker - INFO -          dashboard at:          10.6.101.47:36411
2025-09-05 09:11:36,889 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,889 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,889 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,889 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-humbqrui
2025-09-05 09:11:36,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,894 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:35233
2025-09-05 09:11:36,894 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:35233
2025-09-05 09:11:36,894 - distributed.worker - INFO -          dashboard at:          10.6.101.47:45745
2025-09-05 09:11:36,894 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,894 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,894 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,894 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,894 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-k9zrakcb
2025-09-05 09:11:36,894 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,897 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:37825
2025-09-05 09:11:36,897 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:37825
2025-09-05 09:11:36,897 - distributed.worker - INFO -          dashboard at:          10.6.101.47:35905
2025-09-05 09:11:36,897 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,897 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,897 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,897 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,897 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-itafipx5
2025-09-05 09:11:36,897 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,898 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:34115
2025-09-05 09:11:36,898 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:34115
2025-09-05 09:11:36,898 - distributed.worker - INFO -          dashboard at:          10.6.101.47:37233
2025-09-05 09:11:36,898 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,898 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:38257
2025-09-05 09:11:36,898 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,898 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,898 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:38257
2025-09-05 09:11:36,898 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,898 - distributed.worker - INFO -          dashboard at:          10.6.101.47:43333
2025-09-05 09:11:36,898 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-gxl_908i
2025-09-05 09:11:36,898 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,898 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,898 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,898 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,898 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,898 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-dwwz3fzf
2025-09-05 09:11:36,898 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,898 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:34951
2025-09-05 09:11:36,898 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:34951
2025-09-05 09:11:36,899 - distributed.worker - INFO -          dashboard at:          10.6.101.47:42213
2025-09-05 09:11:36,899 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,899 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,899 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,899 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-tbwnnt2i
2025-09-05 09:11:36,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,905 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,905 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,905 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,905 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,910 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:37699
2025-09-05 09:11:36,910 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:37699
2025-09-05 09:11:36,910 - distributed.worker - INFO -          dashboard at:          10.6.101.47:34277
2025-09-05 09:11:36,910 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,910 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,910 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,910 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,910 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-l4_lgt64
2025-09-05 09:11:36,910 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,910 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,911 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,911 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,913 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,914 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,915 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:39409
2025-09-05 09:11:36,915 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:39409
2025-09-05 09:11:36,915 - distributed.worker - INFO -          dashboard at:          10.6.101.47:34089
2025-09-05 09:11:36,915 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,915 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,916 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,916 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,916 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,916 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,916 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-kaupee2s
2025-09-05 09:11:36,916 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,917 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:43777
2025-09-05 09:11:36,917 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:43777
2025-09-05 09:11:36,917 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,917 - distributed.worker - INFO -          dashboard at:          10.6.101.47:46575
2025-09-05 09:11:36,917 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,917 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,917 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,917 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,917 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8g1umsym
2025-09-05 09:11:36,917 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,918 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:37651
2025-09-05 09:11:36,918 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:37651
2025-09-05 09:11:36,918 - distributed.worker - INFO -          dashboard at:          10.6.101.47:38021
2025-09-05 09:11:36,918 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,918 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,918 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,918 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,918 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-9q_6w6b_
2025-09-05 09:11:36,918 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,919 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,920 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,920 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,921 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:38141
2025-09-05 09:11:36,921 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:38141
2025-09-05 09:11:36,921 - distributed.worker - INFO -          dashboard at:          10.6.101.47:44515
2025-09-05 09:11:36,921 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,921 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,921 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,921 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,921 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8zgihuai
2025-09-05 09:11:36,921 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,922 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,922 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,923 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,923 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,925 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,926 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,927 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,927 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,927 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:45197
2025-09-05 09:11:36,927 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:45197
2025-09-05 09:11:36,927 - distributed.worker - INFO -          dashboard at:          10.6.101.47:35697
2025-09-05 09:11:36,927 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,927 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,927 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,927 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,927 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-qmimef4g
2025-09-05 09:11:36,927 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,928 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,929 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,930 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,930 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,932 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,932 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:45851
2025-09-05 09:11:36,933 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:45851
2025-09-05 09:11:36,933 - distributed.worker - INFO -          dashboard at:          10.6.101.47:35889
2025-09-05 09:11:36,933 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,933 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,933 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,933 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,933 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-tuvo3d28
2025-09-05 09:11:36,933 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,933 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.47:36519
2025-09-05 09:11:36,933 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.47:36519
2025-09-05 09:11:36,933 - distributed.worker - INFO -          dashboard at:          10.6.101.47:41363
2025-09-05 09:11:36,933 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,933 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,933 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:36,933 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:36,933 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8pqjihpm
2025-09-05 09:11:36,934 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,934 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,935 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,935 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,936 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,944 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,944 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,944 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,945 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,947 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,948 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,948 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,949 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,950 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,950 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,950 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,951 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,952 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,952 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,952 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,953 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,954 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,954 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,954 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,954 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,955 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,956 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,956 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,956 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:36,957 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:36,957 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:36,957 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:36,958 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:12:06,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,629 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,630 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,630 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,630 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,630 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,630 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,630 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,630 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,631 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,631 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,631 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,631 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,631 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,631 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,631 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,631 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,633 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,633 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,633 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,633 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,633 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,633 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,633 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,633 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,633 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,631 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,633 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,634 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,634 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,634 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,634 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,634 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,634 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,634 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,634 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,634 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,633 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,633 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,635 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,636 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,634 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,636 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,636 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,636 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,636 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,635 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,635 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,635 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,636 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,636 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,637 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,637 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,638 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,639 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,641 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,643 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,644 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,646 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,647 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,645 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,647 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,649 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,649 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,654 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:09,429 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,429 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,429 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,429 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,429 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,430 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,430 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,430 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,430 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,430 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,430 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,430 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,430 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,431 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,431 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,431 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,430 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,431 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,431 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,431 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,431 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,432 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,432 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,432 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,431 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,432 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,432 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,432 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,432 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,432 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,433 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,433 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,433 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,433 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,433 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,433 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,433 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,433 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,434 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,433 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,434 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,432 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,435 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,435 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,436 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,436 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,434 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,437 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,435 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,438 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,435 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,438 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,439 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,440 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,440 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,810 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,810 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,810 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,810 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,811 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,811 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,811 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,811 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,811 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,811 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,811 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,811 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,811 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,812 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,812 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,812 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,812 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,812 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,812 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,812 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,812 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,812 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,813 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,813 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,813 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,813 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,813 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,813 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,813 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,813 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,814 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,814 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,814 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,815 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,815 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,815 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,815 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,815 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,815 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,815 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,815 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,815 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,815 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,815 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,815 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,816 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,816 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,816 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,816 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,816 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,816 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,816 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,816 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,816 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,816 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,816 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,817 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,817 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,817 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,817 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,817 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,817 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,817 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,817 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,817 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,818 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,819 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,819 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,819 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,819 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,819 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,819 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,819 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,819 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,820 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,820 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,820 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,820 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,820 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,820 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,820 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,820 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,821 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,821 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,821 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:10,270 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,270 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,270 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,270 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,270 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,271 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,271 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,271 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,271 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,271 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,271 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,271 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,272 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,272 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,273 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,273 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,273 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,273 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,273 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,273 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,273 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,273 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,273 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,273 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,273 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,273 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,273 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,273 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,273 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,273 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,273 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,274 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,275 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,275 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,275 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,275 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,275 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,275 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,275 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,275 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,275 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,275 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,275 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,276 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,276 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,276 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,277 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,277 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,277 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,277 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,278 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,278 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,278 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,278 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,278 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,278 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,278 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,278 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,278 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,279 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,279 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,280 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:16:20,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:20,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:21,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:52,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,015 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:56,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,028 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:00,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:00,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:05,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:05,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:05,196 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:05,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:09,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,954 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:19,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:19,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:21,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:23,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:23,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:28,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:29,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:29,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:29,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,604 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,468 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:32,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:32,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:32,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:33,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:33,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,887 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,604 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:44,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:55,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:55,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:55,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:55,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:02,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:02,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:03,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:03,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:04,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:06,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:07,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:07,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:08,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:13,484 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:13,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:14,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:32,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,954 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:42,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:42,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:43,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:43,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:43,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:43,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:43,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,938 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:51,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:51,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:51,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:51,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:52,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:53,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:58,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:58,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:06,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:06,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,497 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,943 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,978 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,668 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,378 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:15,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:18,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:19,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:19,864 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:19,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:27,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:33,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:33,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,005 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,150 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,582 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:52,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:52,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:54,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:54,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:54,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:54,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:54,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:59,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:59,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:00,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:01,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:04,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:05,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:08,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:08,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:43303. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:33511. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:43011. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:34915. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:36653. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:40289. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:39323. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:44913. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:45271. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:37525. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:39645. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:44529. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:33785. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:35317. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:33143. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:34011. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:34271. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:38275. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:38553. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:45851. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:45197. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:33665. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:34115. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:43705. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:40143. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:39409. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:41243. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:36519. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:37699. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:38257. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,284 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:36335. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:34951. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,284 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,285 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,286 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:33107. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:38141. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:43777. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:36667. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:37651. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,285 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:41507. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:45649. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:36611. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:39319. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,287 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:34429. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,288 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:46259. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,291 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:38473'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,293 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.47:37757, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,294 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,294 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,294 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,294 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,294 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,306 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:36713'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,306 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:34851'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:34439'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:38615'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:33041'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:37167'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1527, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,307 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 572, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:43035'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1712, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1238, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.53:45293, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:40509'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1703, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2913, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 841, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:38975'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1272, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:33905'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7127, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:33969'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.47:42143, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.64:39331, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.50:33413, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3246, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1043, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:39463'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1711, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 843, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2904, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2914, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:42769'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2279, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:33201'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.41:46137, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4200, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:40515'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 919, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 842, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2684, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:41923'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.44:33741, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.51:40773, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1672, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2758, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:44987'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1376, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3323, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1705, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2559, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:36117'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4618, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.44:32953, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:42171'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1375, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:46311'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6259, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:42527'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3040, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:45185'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5402, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3052, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:39883'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.61:34199, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1808, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:34065'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1332, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 769, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1778, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.61:38853, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:41963'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3310, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 789, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6835, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:44171'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 855, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 586, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.50:42645, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:33017'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1554, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.53:43571, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:40425'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 856, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4202, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:43095'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1843, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:46521'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:43793'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:35579'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1357, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:38981'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2625, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:37707'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1373, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3751, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 914, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7865, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:45031'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1491, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1325, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1145, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2487, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:40335'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1139, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1359, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1374, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1377, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.70:38579, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:43865'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.58:42873, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1166, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3870, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:46175'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2719, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1887, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1185, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:36303'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2040, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2716, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:39833'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2583, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:36671'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1183, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:46031'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3852, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.49:33919, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1333, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1840, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1297, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1833, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.51:44417, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.60:44337, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.47:43309, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.53:40339, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.50:40071, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.47:43309, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2015, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3730, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.47:43309, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.50:40279, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.66:38121, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,338 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:11,343 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,063 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:12,065 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:37757. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,081 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.47:54134 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:12,091 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:45423'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,091 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2218, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:12,092 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:12,092 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:12,092 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:12,092 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:12,092 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:12,237 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:12,239 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:35233. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:12,255 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.47:54170 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:12,259 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:44457'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,259 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:12,260 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:12,260 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:12,260 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:12,260 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:12,267 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,370 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,371 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,928 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:12,931 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:37825. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:12,947 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.47:54186 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:12,952 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:37559'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,953 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:12,953 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:12,953 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:12,953 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:12,953 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:12,961 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,219 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,312 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,342 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,346 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,868 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:36671'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,871 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:36671' closed.
2025-09-05 09:20:13,886 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:38473'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,887 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:39833'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,888 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:38473' closed.
2025-09-05 09:20:13,889 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:39833' closed.
2025-09-05 09:20:14,269 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:14,374 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,376 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,488 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:14,489 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:14,658 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:44457'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,659 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:44457' closed.
2025-09-05 09:20:14,768 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:33201'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,769 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:33201' closed.
2025-09-05 09:20:14,786 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:46311'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,787 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:46311' closed.
2025-09-05 09:20:14,964 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,191 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:15,224 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,347 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:37559'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,349 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:37559' closed.
2025-09-05 09:20:15,614 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:36303'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,615 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:36303' closed.
2025-09-05 09:20:16,274 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,492 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,683 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:35579'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,684 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:35579' closed.
2025-09-05 09:20:16,868 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:16,871 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:37089. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,877 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:37167'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,878 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:37167' closed.
2025-09-05 09:20:16,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:16,884 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:45423'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,886 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:45423' closed.
2025-09-05 09:20:16,888 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.47:53852 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:16,892 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:43107'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,893 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:16,893 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:16,893 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:16,893 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:16,893 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:16,896 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:16,904 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,195 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:17,326 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,329 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,474 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,620 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:36117'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,622 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:36117' closed.
2025-09-05 09:20:17,857 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,239 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,491 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,605 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,720 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:18,723 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:37615. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:18,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:18,742 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.47:54130 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:18,746 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:33971'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:18,747 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:18,747 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:18,748 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:18,748 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:18,748 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:18,750 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14fd07880450>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:18,757 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,868 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,907 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,919 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,062 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,065 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,114 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,193 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:19,195 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:43309. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:19,205 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.47:43309 -> tcp://10.6.101.47:41507
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.47:43309 remote=tcp://10.6.101.47:36378>: Stream is closed
2025-09-05 09:20:19,209 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.47:43309 -> tcp://10.6.101.47:34429
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.47:43309 remote=tcp://10.6.101.47:33184>: Stream is closed
2025-09-05 09:20:19,211 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.47:43309 -> tcp://10.6.101.47:36611
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.47:43309 remote=tcp://10.6.101.47:36362>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-05 09:20:19,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:19,220 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.47:53870 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:19,223 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:46185'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:19,223 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:19,224 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:19,224 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:19,224 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:19,224 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:19,226 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x153a56b1dfd0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:19,231 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,326 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:43107'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,327 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:43107' closed.
2025-09-05 09:20:19,330 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,333 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,419 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,478 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,660 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,685 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:39883'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,686 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:39883' closed.
2025-09-05 09:20:19,754 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:33905'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,755 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:33905' closed.
2025-09-05 09:20:19,831 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,861 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,861 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,878 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:44987'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,879 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:44987' closed.
2025-09-05 09:20:19,896 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,982 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,983 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,073 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,099 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:20,100 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:37477. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:20,103 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,103 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:20,117 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.47:54056 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:20,123 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:34903'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:20,124 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:20,124 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:20,124 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:20,124 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:20,124 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:20,125 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14f3f722bad0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:20,131 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,156 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:20,158 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:44879. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:20,158 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:20,169 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,170 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,171 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,173 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.47:54150 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:20,178 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,179 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:46855'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:20,180 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:20,179 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,180 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:20,180 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:20,180 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:20,180 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:20,181 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x148382edc710>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:20,187 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,203 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,225 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,225 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:20,227 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.47:42143. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:20,240 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:40515'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:20,241 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:40515' closed.
2025-09-05 09:20:20,244 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,246 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,246 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.47:53920 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:20,250 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.47:33157'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:20,251 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:20,252 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:20,252 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:20,252 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:20,252 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:20,253 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1528a5882190>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:20,259 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,261 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,270 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,495 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,609 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,631 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:42769'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,633 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:42769' closed.
2025-09-05 09:20:20,760 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,862 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:33017'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,863 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:33017' closed.
2025-09-05 09:20:20,872 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,924 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,992 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:46031'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,993 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:46031' closed.
2025-09-05 09:20:21,066 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,069 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,118 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,143 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:33971'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,144 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:33971' closed.
2025-09-05 09:20:21,234 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,266 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:43095'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,267 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:43095' closed.
2025-09-05 09:20:21,296 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:38975'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,297 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:38975' closed.
2025-09-05 09:20:21,423 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,444 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:33041'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,445 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:33041' closed.
2025-09-05 09:20:21,462 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:36713'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,463 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:36713' closed.
2025-09-05 09:20:21,506 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:38981'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,507 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:38981' closed.
2025-09-05 09:20:21,628 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:46185'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,629 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:46185' closed.
2025-09-05 09:20:21,664 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,813 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:34851'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,814 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:34851' closed.
2025-09-05 09:20:21,835 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,865 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,900 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,986 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,986 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,053 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:42527'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,054 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:42527' closed.
2025-09-05 09:20:22,078 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,107 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,107 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,133 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,163 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,173 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,174 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,175 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,182 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,190 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,207 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,229 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,248 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,250 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,255 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:38615'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,256 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:38615' closed.
2025-09-05 09:20:22,261 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:44171'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,262 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,263 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:44171' closed.
2025-09-05 09:20:22,265 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,275 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,287 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:46175'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,288 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:46175' closed.
2025-09-05 09:20:22,403 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:45185'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,404 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:45185' closed.
2025-09-05 09:20:22,486 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:34065'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,487 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:34065' closed.
2025-09-05 09:20:22,511 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:46521'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,512 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:46521' closed.
2025-09-05 09:20:22,575 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:34903'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,576 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:34903' closed.
2025-09-05 09:20:22,587 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:41923'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,588 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:41923' closed.
2025-09-05 09:20:22,589 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:33969'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,590 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:33969' closed.
2025-09-05 09:20:22,604 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:41963'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,605 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:41963' closed.
2025-09-05 09:20:22,639 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:43793'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,640 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:43793' closed.
2025-09-05 09:20:22,656 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:42171'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,657 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:42171' closed.
2025-09-05 09:20:22,661 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:37707'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,662 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:37707' closed.
2025-09-05 09:20:22,664 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:40425'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,665 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:40425' closed.
2025-09-05 09:20:22,679 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:34439'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,680 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:34439' closed.
2025-09-05 09:20:22,697 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:40335'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,699 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:46855'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,700 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:40335' closed.
2025-09-05 09:20:22,700 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:46855' closed.
2025-09-05 09:20:22,752 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:40509'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,753 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:40509' closed.
2025-09-05 09:20:22,755 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:43035'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,756 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:43035' closed.
2025-09-05 09:20:22,823 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:33157'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,824 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:33157' closed.
2025-09-05 09:20:22,836 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:39463'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,837 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:39463' closed.
2025-09-05 09:20:22,849 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:43865'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,850 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:43865' closed.
2025-09-05 09:20:22,856 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.47:45031'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,857 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.47:45031' closed.
2025-09-05 09:20:22,859 - distributed.dask_worker - INFO - End worker
