Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:31:44,186 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:34157'
2025-09-03 10:31:44,197 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:46439'
2025-09-03 10:31:44,203 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:33123'
2025-09-03 10:31:44,209 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:39527'
2025-09-03 10:31:44,213 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45005'
2025-09-03 10:31:44,220 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:40897'
2025-09-03 10:31:44,224 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:35245'
2025-09-03 10:31:44,229 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:35621'
2025-09-03 10:31:44,234 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:34565'
2025-09-03 10:31:44,240 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44713'
2025-09-03 10:31:44,245 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42329'
2025-09-03 10:31:44,249 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:38565'
2025-09-03 10:31:44,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:36473'
2025-09-03 10:31:44,257 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:32921'
2025-09-03 10:31:44,263 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42249'
2025-09-03 10:31:44,267 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:41571'
2025-09-03 10:31:44,272 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:38965'
2025-09-03 10:31:44,277 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:34973'
2025-09-03 10:31:44,283 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:46135'
2025-09-03 10:31:44,288 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45137'
2025-09-03 10:31:44,292 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:35689'
2025-09-03 10:31:44,297 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:43791'
2025-09-03 10:31:44,301 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44559'
2025-09-03 10:31:44,305 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:41889'
2025-09-03 10:31:44,309 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:33497'
2025-09-03 10:31:44,315 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42705'
2025-09-03 10:31:44,319 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:43801'
2025-09-03 10:31:44,423 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:33219'
2025-09-03 10:31:44,429 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:38163'
2025-09-03 10:31:44,433 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:33525'
2025-09-03 10:31:44,438 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:39033'
2025-09-03 10:31:44,442 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:37781'
2025-09-03 10:31:44,446 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:36613'
2025-09-03 10:31:44,451 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:37671'
2025-09-03 10:31:44,452 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:38213'
2025-09-03 10:31:44,456 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45045'
2025-09-03 10:31:44,462 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:39581'
2025-09-03 10:31:44,465 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:38267'
2025-09-03 10:31:44,469 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44403'
2025-09-03 10:31:44,473 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45789'
2025-09-03 10:31:44,478 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:38867'
2025-09-03 10:31:45,372 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:41297
2025-09-03 10:31:45,372 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:41297
2025-09-03 10:31:45,372 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43495
2025-09-03 10:31:45,372 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34557
2025-09-03 10:31:45,372 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43495
2025-09-03 10:31:45,372 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,372 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,372 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45531
2025-09-03 10:31:45,372 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,372 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,372 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,372 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,372 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,372 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gdbp874d
2025-09-03 10:31:45,372 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,372 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,372 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-q301bc5_
2025-09-03 10:31:45,372 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,381 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:42303
2025-09-03 10:31:45,381 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:42303
2025-09-03 10:31:45,381 - distributed.worker - INFO -          dashboard at:          10.6.102.18:44679
2025-09-03 10:31:45,381 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,381 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,381 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,381 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-p88zigka
2025-09-03 10:31:45,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,387 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43533
2025-09-03 10:31:45,387 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43533
2025-09-03 10:31:45,387 - distributed.worker - INFO -          dashboard at:          10.6.102.18:33731
2025-09-03 10:31:45,387 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,387 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,387 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,388 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,388 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5nxl9i7t
2025-09-03 10:31:45,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,528 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:46697
2025-09-03 10:31:45,528 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:46697
2025-09-03 10:31:45,528 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34163
2025-09-03 10:31:45,528 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,528 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,528 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,528 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,528 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z7ajrbgw
2025-09-03 10:31:45,528 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,532 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:34703
2025-09-03 10:31:45,532 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:34703
2025-09-03 10:31:45,532 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34791
2025-09-03 10:31:45,532 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,532 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,533 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,533 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,532 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:42017
2025-09-03 10:31:45,533 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xs2g551j
2025-09-03 10:31:45,533 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:42017
2025-09-03 10:31:45,533 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,533 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41347
2025-09-03 10:31:45,533 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,533 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,533 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,533 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,533 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-afp6wmel
2025-09-03 10:31:45,533 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,535 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45955
2025-09-03 10:31:45,535 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45955
2025-09-03 10:31:45,535 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36511
2025-09-03 10:31:45,535 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,535 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,535 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,535 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,535 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7t8leyjb
2025-09-03 10:31:45,535 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,536 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:37029
2025-09-03 10:31:45,536 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:37029
2025-09-03 10:31:45,536 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34733
2025-09-03 10:31:45,536 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,536 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,536 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,536 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,536 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nspwkmi2
2025-09-03 10:31:45,537 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,547 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:35673
2025-09-03 10:31:45,548 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:35673
2025-09-03 10:31:45,548 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36591
2025-09-03 10:31:45,548 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,548 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,548 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,548 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-unemtcq4
2025-09-03 10:31:45,548 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,551 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:44659
2025-09-03 10:31:45,551 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:44659
2025-09-03 10:31:45,552 - distributed.worker - INFO -          dashboard at:          10.6.102.18:42857
2025-09-03 10:31:45,552 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,552 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,552 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,552 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zrx4gn8y
2025-09-03 10:31:45,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,552 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:40099
2025-09-03 10:31:45,552 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45403
2025-09-03 10:31:45,552 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:40099
2025-09-03 10:31:45,552 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45403
2025-09-03 10:31:45,552 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41037
2025-09-03 10:31:45,552 - distributed.worker - INFO -          dashboard at:          10.6.102.18:38705
2025-09-03 10:31:45,552 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,552 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,552 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,553 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,553 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,553 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,553 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-otp1lkku
2025-09-03 10:31:45,553 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wxqynd90
2025-09-03 10:31:45,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,553 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:40111
2025-09-03 10:31:45,553 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:40111
2025-09-03 10:31:45,553 - distributed.worker - INFO -          dashboard at:          10.6.102.18:39191
2025-09-03 10:31:45,553 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:38749
2025-09-03 10:31:45,553 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,553 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:38749
2025-09-03 10:31:45,553 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,553 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,553 - distributed.worker - INFO -          dashboard at:          10.6.102.18:39811
2025-09-03 10:31:45,553 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,553 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-80d6oa9n
2025-09-03 10:31:45,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,553 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,553 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,553 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l4jranbc
2025-09-03 10:31:45,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,555 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:35699
2025-09-03 10:31:45,555 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:35699
2025-09-03 10:31:45,555 - distributed.worker - INFO -          dashboard at:          10.6.102.18:43491
2025-09-03 10:31:45,555 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,555 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,555 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,555 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-mr40jw8l
2025-09-03 10:31:45,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,560 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43643
2025-09-03 10:31:45,560 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43643
2025-09-03 10:31:45,560 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45501
2025-09-03 10:31:45,560 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,560 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,560 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,560 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,560 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ifazy9gx
2025-09-03 10:31:45,560 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,567 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:46127
2025-09-03 10:31:45,567 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:46127
2025-09-03 10:31:45,567 - distributed.worker - INFO -          dashboard at:          10.6.102.18:40717
2025-09-03 10:31:45,567 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45583
2025-09-03 10:31:45,567 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,567 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45583
2025-09-03 10:31:45,567 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,568 - distributed.worker - INFO -          dashboard at:          10.6.102.18:35079
2025-09-03 10:31:45,568 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,568 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,568 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ymm0ie7e
2025-09-03 10:31:45,568 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,568 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,568 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,568 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,568 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_3dil1f4
2025-09-03 10:31:45,568 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,574 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43807
2025-09-03 10:31:45,574 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43807
2025-09-03 10:31:45,574 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41349
2025-09-03 10:31:45,574 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,574 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,574 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,574 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4o3oz2qg
2025-09-03 10:31:45,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,581 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:44337
2025-09-03 10:31:45,581 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:44337
2025-09-03 10:31:45,581 - distributed.worker - INFO -          dashboard at:          10.6.102.18:39697
2025-09-03 10:31:45,581 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,581 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,581 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,581 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,581 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-t7z8_9t5
2025-09-03 10:31:45,581 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,582 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:35381
2025-09-03 10:31:45,582 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:35381
2025-09-03 10:31:45,582 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34225
2025-09-03 10:31:45,582 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,582 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,582 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,582 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-aqf2b_f3
2025-09-03 10:31:45,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,590 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:34061
2025-09-03 10:31:45,590 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:34061
2025-09-03 10:31:45,590 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36801
2025-09-03 10:31:45,590 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,590 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,590 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,590 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rte1yq8c
2025-09-03 10:31:45,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,590 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:44427
2025-09-03 10:31:45,590 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:44427
2025-09-03 10:31:45,590 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41457
2025-09-03 10:31:45,590 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,591 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,591 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,591 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_vft58mp
2025-09-03 10:31:45,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,592 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:39667
2025-09-03 10:31:45,592 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:39667
2025-09-03 10:31:45,592 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36649
2025-09-03 10:31:45,592 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,592 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,592 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,592 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fmwy29b6
2025-09-03 10:31:45,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,596 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:36373
2025-09-03 10:31:45,596 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:36373
2025-09-03 10:31:45,596 - distributed.worker - INFO -          dashboard at:          10.6.102.18:46317
2025-09-03 10:31:45,596 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,596 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-o7evgx5x
2025-09-03 10:31:45,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,598 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43227
2025-09-03 10:31:45,598 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43227
2025-09-03 10:31:45,598 - distributed.worker - INFO -          dashboard at:          10.6.102.18:38709
2025-09-03 10:31:45,598 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,598 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,598 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,598 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ywdyw1oo
2025-09-03 10:31:45,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,694 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:35563
2025-09-03 10:31:45,694 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:35563
2025-09-03 10:31:45,694 - distributed.worker - INFO -          dashboard at:          10.6.102.18:42875
2025-09-03 10:31:45,694 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,694 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,694 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,695 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,695 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gi9g5yth
2025-09-03 10:31:45,695 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,705 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:34707
2025-09-03 10:31:45,705 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:34707
2025-09-03 10:31:45,705 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34107
2025-09-03 10:31:45,705 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,705 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,705 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,705 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-msl7vy0d
2025-09-03 10:31:45,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,707 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:39055
2025-09-03 10:31:45,707 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:39055
2025-09-03 10:31:45,707 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34393
2025-09-03 10:31:45,707 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,707 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,707 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,707 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,707 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wmkqdnqb
2025-09-03 10:31:45,707 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,734 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:34865
2025-09-03 10:31:45,734 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:34865
2025-09-03 10:31:45,734 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36635
2025-09-03 10:31:45,734 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,734 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,734 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,734 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,734 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-sq6lw804
2025-09-03 10:31:45,734 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,735 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43839
2025-09-03 10:31:45,735 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43839
2025-09-03 10:31:45,735 - distributed.worker - INFO -          dashboard at:          10.6.102.18:42871
2025-09-03 10:31:45,735 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,735 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,735 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,735 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,735 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-caese253
2025-09-03 10:31:45,735 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,736 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45811
2025-09-03 10:31:45,736 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45811
2025-09-03 10:31:45,736 - distributed.worker - INFO -          dashboard at:          10.6.102.18:38359
2025-09-03 10:31:45,736 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,736 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,736 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,736 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,736 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7hqsh2td
2025-09-03 10:31:45,736 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,742 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:41809
2025-09-03 10:31:45,743 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:41809
2025-09-03 10:31:45,743 - distributed.worker - INFO -          dashboard at:          10.6.102.18:35733
2025-09-03 10:31:45,743 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,743 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,743 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,743 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3tze9pi1
2025-09-03 10:31:45,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,743 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:46021
2025-09-03 10:31:45,743 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:46021
2025-09-03 10:31:45,743 - distributed.worker - INFO -          dashboard at:          10.6.102.18:40627
2025-09-03 10:31:45,743 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,743 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,743 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,743 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lgq2u5un
2025-09-03 10:31:45,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,752 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45603
2025-09-03 10:31:45,752 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45603
2025-09-03 10:31:45,752 - distributed.worker - INFO -          dashboard at:          10.6.102.18:39353
2025-09-03 10:31:45,752 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,752 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,752 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,752 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-efndwzxe
2025-09-03 10:31:45,752 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,761 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:32901
2025-09-03 10:31:45,761 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:32901
2025-09-03 10:31:45,761 - distributed.worker - INFO -          dashboard at:          10.6.102.18:33883
2025-09-03 10:31:45,761 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,761 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,761 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,761 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-w6r8u7gj
2025-09-03 10:31:45,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,773 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:34237
2025-09-03 10:31:45,773 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:34237
2025-09-03 10:31:45,773 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45565
2025-09-03 10:31:45,773 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,773 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,773 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,773 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vlcpo1t2
2025-09-03 10:31:45,773 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,775 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45449
2025-09-03 10:31:45,775 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45449
2025-09-03 10:31:45,775 - distributed.worker - INFO -          dashboard at:          10.6.102.18:38453
2025-09-03 10:31:45,775 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,775 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,775 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,775 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_e6rzsad
2025-09-03 10:31:45,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,779 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:34561
2025-09-03 10:31:45,779 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:34561
2025-09-03 10:31:45,779 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45251
2025-09-03 10:31:45,779 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,779 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,779 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,779 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8kxixe47
2025-09-03 10:31:45,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,787 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:35461
2025-09-03 10:31:45,787 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:35461
2025-09-03 10:31:45,787 - distributed.worker - INFO -          dashboard at:          10.6.102.18:39589
2025-09-03 10:31:45,787 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:45,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:45,787 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:45,787 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:45,787 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-i085yfiy
2025-09-03 10:31:45,787 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,768 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,769 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,769 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,771 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,780 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,781 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,781 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,783 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,793 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,794 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,796 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:46,806 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:46,807 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:46,807 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:46,808 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,355 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:37225'
2025-09-03 10:31:47,359 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44073'
2025-09-03 10:31:47,363 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:43605'
2025-09-03 10:31:47,370 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:33861'
2025-09-03 10:31:47,376 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:43831'
2025-09-03 10:31:47,380 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45351'
2025-09-03 10:31:47,385 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44391'
2025-09-03 10:31:47,390 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:33163'
2025-09-03 10:31:47,395 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:37129'
2025-09-03 10:31:47,401 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45093'
2025-09-03 10:31:47,408 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:43129'
2025-09-03 10:31:47,412 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:43319'
2025-09-03 10:31:47,418 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:34913'
2025-09-03 10:31:47,425 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:39627'
2025-09-03 10:31:47,429 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:39553'
2025-09-03 10:31:47,435 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:46043'
2025-09-03 10:31:47,441 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:36989'
2025-09-03 10:31:47,445 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:43601'
2025-09-03 10:31:47,450 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:46093'
2025-09-03 10:31:47,473 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:39995'
2025-09-03 10:31:47,478 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:35475'
2025-09-03 10:31:47,483 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:41775'
2025-09-03 10:31:47,487 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:39709'
2025-09-03 10:31:47,493 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:43641'
2025-09-03 10:31:47,498 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45395'
2025-09-03 10:31:47,503 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45279'
2025-09-03 10:31:47,508 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44997'
2025-09-03 10:31:47,513 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:34167'
2025-09-03 10:31:47,519 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44775'
2025-09-03 10:31:47,524 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42873'
2025-09-03 10:31:47,529 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42771'
2025-09-03 10:31:47,532 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45673'
2025-09-03 10:31:47,536 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:34889'
2025-09-03 10:31:47,542 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:41987'
2025-09-03 10:31:47,546 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:39281'
2025-09-03 10:31:47,552 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:38871'
2025-09-03 10:31:47,556 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45013'
2025-09-03 10:31:47,561 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45729'
2025-09-03 10:31:47,566 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45671'
2025-09-03 10:31:47,572 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:40789'
2025-09-03 10:31:47,577 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42761'
2025-09-03 10:31:47,583 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:40693'
2025-09-03 10:31:47,588 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42041'
2025-09-03 10:31:47,592 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:38089'
2025-09-03 10:31:47,595 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:36109'
2025-09-03 10:31:47,599 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:41939'
2025-09-03 10:31:47,603 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:34559'
2025-09-03 10:31:47,607 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42009'
2025-09-03 10:31:47,611 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,611 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42725'
2025-09-03 10:31:47,612 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,612 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,613 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,616 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44139'
2025-09-03 10:31:47,620 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45581'
2025-09-03 10:31:47,623 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,624 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,624 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,626 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,627 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:35077'
2025-09-03 10:31:47,632 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:38451'
2025-09-03 10:31:47,636 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,637 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,637 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:35075'
2025-09-03 10:31:47,637 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,639 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,640 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:37691'
2025-09-03 10:31:47,645 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44231'
2025-09-03 10:31:47,648 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,649 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:46417'
2025-09-03 10:31:47,649 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,651 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,652 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:36217'
2025-09-03 10:31:47,658 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42699'
2025-09-03 10:31:47,661 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,662 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,663 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,663 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:42941'
2025-09-03 10:31:47,664 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,674 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,675 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,675 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,676 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,686 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,687 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,687 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,689 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,699 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,700 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,700 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,702 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,711 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,712 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,714 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,724 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,725 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,725 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,726 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,736 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,737 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,737 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,739 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,748 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,750 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,750 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,751 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,754 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45541'
2025-09-03 10:31:47,759 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:44485'
2025-09-03 10:31:47,761 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,762 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,762 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,764 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,766 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.18:45745'
2025-09-03 10:31:47,773 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,775 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,776 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,786 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,787 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,788 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,789 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,798 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,799 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,799 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,801 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,812 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,814 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,817 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,824 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,825 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,825 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,827 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:47,914 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:47,915 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:47,915 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:47,917 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:48,449 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:35897
2025-09-03 10:31:48,449 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:35897
2025-09-03 10:31:48,449 - distributed.worker - INFO -          dashboard at:          10.6.102.18:37079
2025-09-03 10:31:48,449 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,449 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,449 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,449 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,449 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-yx3e7sph
2025-09-03 10:31:48,449 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,460 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:42077
2025-09-03 10:31:48,460 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:42077
2025-09-03 10:31:48,460 - distributed.worker - INFO -          dashboard at:          10.6.102.18:33007
2025-09-03 10:31:48,460 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,461 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,461 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,461 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,461 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5axn6gpo
2025-09-03 10:31:48,461 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,464 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:42231
2025-09-03 10:31:48,464 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:42231
2025-09-03 10:31:48,464 - distributed.worker - INFO -          dashboard at:          10.6.102.18:44397
2025-09-03 10:31:48,464 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,464 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,464 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,464 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,464 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6ssaf4sd
2025-09-03 10:31:48,465 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,467 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:32819
2025-09-03 10:31:48,467 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:32819
2025-09-03 10:31:48,468 - distributed.worker - INFO -          dashboard at:          10.6.102.18:33065
2025-09-03 10:31:48,468 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,468 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,468 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,468 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,468 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2a27loys
2025-09-03 10:31:48,468 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,478 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:44479
2025-09-03 10:31:48,478 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:44479
2025-09-03 10:31:48,478 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45829
2025-09-03 10:31:48,478 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,479 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,479 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,479 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,479 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-t_7q81i9
2025-09-03 10:31:48,479 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,481 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:34499
2025-09-03 10:31:48,481 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:34499
2025-09-03 10:31:48,481 - distributed.worker - INFO -          dashboard at:          10.6.102.18:38431
2025-09-03 10:31:48,481 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,481 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,481 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,481 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,481 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-wlv3x5if
2025-09-03 10:31:48,481 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,794 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45515
2025-09-03 10:31:48,794 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45515
2025-09-03 10:31:48,794 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41721
2025-09-03 10:31:48,794 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,794 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,794 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,794 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zbahb5vy
2025-09-03 10:31:48,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,928 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:38013
2025-09-03 10:31:48,928 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:38013
2025-09-03 10:31:48,928 - distributed.worker - INFO -          dashboard at:          10.6.102.18:42349
2025-09-03 10:31:48,928 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:37573
2025-09-03 10:31:48,928 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,928 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:37573
2025-09-03 10:31:48,928 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,928 - distributed.worker - INFO -          dashboard at:          10.6.102.18:37707
2025-09-03 10:31:48,928 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,928 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,928 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-oeytb579
2025-09-03 10:31:48,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,928 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,928 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,928 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z4_4i8lz
2025-09-03 10:31:48,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,931 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45537
2025-09-03 10:31:48,931 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45537
2025-09-03 10:31:48,931 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34035
2025-09-03 10:31:48,931 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,931 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,931 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,931 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,931 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n1co9hyc
2025-09-03 10:31:48,931 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,935 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:41975
2025-09-03 10:31:48,935 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:41975
2025-09-03 10:31:48,935 - distributed.worker - INFO -          dashboard at:          10.6.102.18:38515
2025-09-03 10:31:48,935 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,935 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,935 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,935 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,935 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dquo9sw4
2025-09-03 10:31:48,935 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,940 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:42679
2025-09-03 10:31:48,940 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:42679
2025-09-03 10:31:48,940 - distributed.worker - INFO -          dashboard at:          10.6.102.18:40815
2025-09-03 10:31:48,940 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,940 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,940 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,940 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kygoz547
2025-09-03 10:31:48,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,951 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:33813
2025-09-03 10:31:48,951 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:33813
2025-09-03 10:31:48,951 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45693
2025-09-03 10:31:48,951 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,951 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,951 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,951 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,951 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uw1kvy2e
2025-09-03 10:31:48,951 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,994 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:37609
2025-09-03 10:31:48,994 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:37609
2025-09-03 10:31:48,994 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36859
2025-09-03 10:31:48,994 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:48,994 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:48,994 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:48,994 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:48,994 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uvlx_liv
2025-09-03 10:31:48,994 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,003 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:35255
2025-09-03 10:31:49,003 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:35255
2025-09-03 10:31:49,003 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36565
2025-09-03 10:31:49,003 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,003 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,003 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,003 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,003 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-suabpn4n
2025-09-03 10:31:49,003 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,004 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:40671
2025-09-03 10:31:49,004 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:40671
2025-09-03 10:31:49,004 - distributed.worker - INFO -          dashboard at:          10.6.102.18:35449
2025-09-03 10:31:49,004 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,004 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,004 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,004 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,004 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nz1iccf_
2025-09-03 10:31:49,004 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,014 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:39883
2025-09-03 10:31:49,014 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:39883
2025-09-03 10:31:49,014 - distributed.worker - INFO -          dashboard at:          10.6.102.18:46261
2025-09-03 10:31:49,014 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,014 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,014 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,014 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,014 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5hqf6qxa
2025-09-03 10:31:49,014 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,033 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45097
2025-09-03 10:31:49,033 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45097
2025-09-03 10:31:49,033 - distributed.worker - INFO -          dashboard at:          10.6.102.18:37523
2025-09-03 10:31:49,033 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,033 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,033 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,033 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,033 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-e6iohb0x
2025-09-03 10:31:49,033 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,046 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:44117
2025-09-03 10:31:49,046 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:44117
2025-09-03 10:31:49,046 - distributed.worker - INFO -          dashboard at:          10.6.102.18:44569
2025-09-03 10:31:49,046 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,046 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,046 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,046 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,046 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8vwhiji4
2025-09-03 10:31:49,046 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,059 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:37111
2025-09-03 10:31:49,059 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:37111
2025-09-03 10:31:49,059 - distributed.worker - INFO -          dashboard at:          10.6.102.18:33213
2025-09-03 10:31:49,059 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,059 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,059 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,059 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-03740jxh
2025-09-03 10:31:49,059 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,135 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,136 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,136 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,138 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,187 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,188 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,188 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,190 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,211 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45111
2025-09-03 10:31:49,211 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45111
2025-09-03 10:31:49,211 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41501
2025-09-03 10:31:49,211 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,211 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,211 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,212 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,212 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3ysttkf5
2025-09-03 10:31:49,212 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,226 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,227 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,227 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,228 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,266 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:40663
2025-09-03 10:31:49,267 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:40663
2025-09-03 10:31:49,267 - distributed.worker - INFO -          dashboard at:          10.6.102.18:37783
2025-09-03 10:31:49,267 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,267 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,267 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,267 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,267 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-1hk7o_vh
2025-09-03 10:31:49,267 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,267 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:40039
2025-09-03 10:31:49,267 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:40039
2025-09-03 10:31:49,267 - distributed.worker - INFO -          dashboard at:          10.6.102.18:43607
2025-09-03 10:31:49,267 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,267 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,267 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,267 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,267 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3wkgmtx_
2025-09-03 10:31:49,268 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,327 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:46083
2025-09-03 10:31:49,327 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:46083
2025-09-03 10:31:49,327 - distributed.worker - INFO -          dashboard at:          10.6.102.18:44029
2025-09-03 10:31:49,327 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,327 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,327 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,327 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kcbgs9xl
2025-09-03 10:31:49,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,332 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:46097
2025-09-03 10:31:49,332 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:46097
2025-09-03 10:31:49,332 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45127
2025-09-03 10:31:49,332 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,332 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,333 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,333 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0jfknwop
2025-09-03 10:31:49,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,349 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:33669
2025-09-03 10:31:49,349 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:33669
2025-09-03 10:31:49,349 - distributed.worker - INFO -          dashboard at:          10.6.102.18:39077
2025-09-03 10:31:49,349 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,349 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,349 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,349 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,349 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fbq25ubv
2025-09-03 10:31:49,349 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,368 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,369 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,369 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,371 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,375 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:37215
2025-09-03 10:31:49,375 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:37215
2025-09-03 10:31:49,375 - distributed.worker - INFO -          dashboard at:          10.6.102.18:33939
2025-09-03 10:31:49,375 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,375 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,375 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,375 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2q3ui80b
2025-09-03 10:31:49,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,382 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:40255
2025-09-03 10:31:49,383 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:40255
2025-09-03 10:31:49,383 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41805
2025-09-03 10:31:49,383 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,383 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:39209
2025-09-03 10:31:49,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,383 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,383 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:39209
2025-09-03 10:31:49,383 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,383 - distributed.worker - INFO -          dashboard at:          10.6.102.18:44727
2025-09-03 10:31:49,383 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gby7gjqs
2025-09-03 10:31:49,383 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,383 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,383 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,383 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-j0gejm0c
2025-09-03 10:31:49,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,427 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:32997
2025-09-03 10:31:49,427 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:32997
2025-09-03 10:31:49,427 - distributed.worker - INFO -          dashboard at:          10.6.102.18:42739
2025-09-03 10:31:49,427 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,427 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,427 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,427 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,427 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2io97nms
2025-09-03 10:31:49,427 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,498 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,499 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,499 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,501 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,511 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,513 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,513 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,514 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,536 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43377
2025-09-03 10:31:49,537 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43377
2025-09-03 10:31:49,537 - distributed.worker - INFO -          dashboard at:          10.6.102.18:39331
2025-09-03 10:31:49,537 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,537 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,537 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,537 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45293
2025-09-03 10:31:49,537 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,537 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45293
2025-09-03 10:31:49,537 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-18w8q696
2025-09-03 10:31:49,537 - distributed.worker - INFO -          dashboard at:          10.6.102.18:38851
2025-09-03 10:31:49,537 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,537 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,537 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,537 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,537 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,537 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3o5lcug5
2025-09-03 10:31:49,537 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,537 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:32889
2025-09-03 10:31:49,537 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:32889
2025-09-03 10:31:49,537 - distributed.worker - INFO -          dashboard at:          10.6.102.18:46173
2025-09-03 10:31:49,537 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,537 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,538 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,538 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,538 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rylg1vkl
2025-09-03 10:31:49,538 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,552 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43957
2025-09-03 10:31:49,552 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43957
2025-09-03 10:31:49,552 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41943
2025-09-03 10:31:49,552 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,552 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,552 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,552 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-h60k01e8
2025-09-03 10:31:49,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,553 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:42093
2025-09-03 10:31:49,553 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:42093
2025-09-03 10:31:49,553 - distributed.worker - INFO -          dashboard at:          10.6.102.18:44127
2025-09-03 10:31:49,553 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,554 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,554 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,554 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-k2ydj4zy
2025-09-03 10:31:49,554 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,555 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:36069
2025-09-03 10:31:49,556 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:36069
2025-09-03 10:31:49,556 - distributed.worker - INFO -          dashboard at:          10.6.102.18:39905
2025-09-03 10:31:49,556 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,556 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,556 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,556 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7q9g_36c
2025-09-03 10:31:49,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,564 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:37693
2025-09-03 10:31:49,564 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:37693
2025-09-03 10:31:49,564 - distributed.worker - INFO -          dashboard at:          10.6.102.18:40463
2025-09-03 10:31:49,564 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,564 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,564 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,564 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l8y78mua
2025-09-03 10:31:49,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,564 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45765
2025-09-03 10:31:49,564 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45765
2025-09-03 10:31:49,564 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34967
2025-09-03 10:31:49,564 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,564 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,564 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,564 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-twjrvmmh
2025-09-03 10:31:49,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,566 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:44843
2025-09-03 10:31:49,566 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:34111
2025-09-03 10:31:49,566 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:44843
2025-09-03 10:31:49,566 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:34111
2025-09-03 10:31:49,566 - distributed.worker - INFO -          dashboard at:          10.6.102.18:46455
2025-09-03 10:31:49,566 - distributed.worker - INFO -          dashboard at:          10.6.102.18:42719
2025-09-03 10:31:49,566 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,566 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,566 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,566 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,566 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,566 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,566 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ac577dbg
2025-09-03 10:31:49,566 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8e71phzg
2025-09-03 10:31:49,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,573 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43711
2025-09-03 10:31:49,573 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:41743
2025-09-03 10:31:49,573 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43711
2025-09-03 10:31:49,573 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:41743
2025-09-03 10:31:49,573 - distributed.worker - INFO -          dashboard at:          10.6.102.18:44509
2025-09-03 10:31:49,573 - distributed.worker - INFO -          dashboard at:          10.6.102.18:35575
2025-09-03 10:31:49,573 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,573 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,573 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,573 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,573 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45965
2025-09-03 10:31:49,573 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,573 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,573 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,573 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45965
2025-09-03 10:31:49,573 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ky763hrq
2025-09-03 10:31:49,573 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,573 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34427
2025-09-03 10:31:49,573 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,573 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4st2ppb9
2025-09-03 10:31:49,573 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,573 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,573 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,573 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,573 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,573 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vt8_qnog
2025-09-03 10:31:49,573 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,579 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:44651
2025-09-03 10:31:49,579 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:44651
2025-09-03 10:31:49,579 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45549
2025-09-03 10:31:49,579 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,579 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,579 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,579 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,579 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-d08b17vs
2025-09-03 10:31:49,579 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,579 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:44193
2025-09-03 10:31:49,579 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:44193
2025-09-03 10:31:49,579 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41639
2025-09-03 10:31:49,579 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,579 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,579 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,579 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,579 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-21t1mhox
2025-09-03 10:31:49,580 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,581 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:36133
2025-09-03 10:31:49,581 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:36133
2025-09-03 10:31:49,581 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36785
2025-09-03 10:31:49,581 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,581 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,581 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,581 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,581 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_6fur4u5
2025-09-03 10:31:49,581 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,582 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:42571
2025-09-03 10:31:49,582 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:42571
2025-09-03 10:31:49,582 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45235
2025-09-03 10:31:49,582 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,582 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,582 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,582 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-s9990_4_
2025-09-03 10:31:49,582 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,589 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45071
2025-09-03 10:31:49,589 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45071
2025-09-03 10:31:49,589 - distributed.worker - INFO -          dashboard at:          10.6.102.18:34689
2025-09-03 10:31:49,589 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,589 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,589 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,589 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,590 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-gmviwa5u
2025-09-03 10:31:49,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,590 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:33479
2025-09-03 10:31:49,590 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:33479
2025-09-03 10:31:49,590 - distributed.worker - INFO -          dashboard at:          10.6.102.18:37327
2025-09-03 10:31:49,590 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,590 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,590 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,590 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-f20029ou
2025-09-03 10:31:49,590 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,595 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:35465
2025-09-03 10:31:49,595 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:35465
2025-09-03 10:31:49,595 - distributed.worker - INFO -          dashboard at:          10.6.102.18:43681
2025-09-03 10:31:49,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,595 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,595 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,595 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ycuicj73
2025-09-03 10:31:49,595 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,595 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:46119
2025-09-03 10:31:49,595 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:46119
2025-09-03 10:31:49,595 - distributed.worker - INFO -          dashboard at:          10.6.102.18:46597
2025-09-03 10:31:49,595 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,596 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-mgias49g
2025-09-03 10:31:49,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,596 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:42491
2025-09-03 10:31:49,596 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:42491
2025-09-03 10:31:49,597 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41691
2025-09-03 10:31:49,597 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,597 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,597 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,597 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-hqo4v86o
2025-09-03 10:31:49,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,597 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:35035
2025-09-03 10:31:49,597 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:35035
2025-09-03 10:31:49,597 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41361
2025-09-03 10:31:49,597 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,597 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,597 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,597 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-yuihvaza
2025-09-03 10:31:49,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,599 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:42673
2025-09-03 10:31:49,599 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:42673
2025-09-03 10:31:49,599 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36411
2025-09-03 10:31:49,599 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,599 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,599 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,599 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3ern5f6x
2025-09-03 10:31:49,599 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,603 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:32857
2025-09-03 10:31:49,603 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:32857
2025-09-03 10:31:49,603 - distributed.worker - INFO -          dashboard at:          10.6.102.18:39305
2025-09-03 10:31:49,603 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,603 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,603 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,603 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,603 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-km30t9qs
2025-09-03 10:31:49,603 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,607 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:38809
2025-09-03 10:31:49,607 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:38809
2025-09-03 10:31:49,607 - distributed.worker - INFO -          dashboard at:          10.6.102.18:41575
2025-09-03 10:31:49,607 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,607 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,607 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,607 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,607 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-nx9dxt9k
2025-09-03 10:31:49,607 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,611 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:32929
2025-09-03 10:31:49,611 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:32929
2025-09-03 10:31:49,611 - distributed.worker - INFO -          dashboard at:          10.6.102.18:33647
2025-09-03 10:31:49,611 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,611 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,611 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,611 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8doy52_8
2025-09-03 10:31:49,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,614 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43323
2025-09-03 10:31:49,614 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43323
2025-09-03 10:31:49,614 - distributed.worker - INFO -          dashboard at:          10.6.102.18:43961
2025-09-03 10:31:49,614 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,614 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,614 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,614 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,614 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pon060oy
2025-09-03 10:31:49,614 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,619 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:45795
2025-09-03 10:31:49,619 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:45795
2025-09-03 10:31:49,619 - distributed.worker - INFO -          dashboard at:          10.6.102.18:45179
2025-09-03 10:31:49,619 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,619 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,619 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,619 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,619 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4d6o0evv
2025-09-03 10:31:49,619 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,622 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:43265
2025-09-03 10:31:49,622 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:43265
2025-09-03 10:31:49,622 - distributed.worker - INFO -          dashboard at:          10.6.102.18:43969
2025-09-03 10:31:49,623 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,623 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,623 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,623 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8dxmf8v8
2025-09-03 10:31:49,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,627 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:39665
2025-09-03 10:31:49,627 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:39665
2025-09-03 10:31:49,627 - distributed.worker - INFO -          dashboard at:          10.6.102.18:44619
2025-09-03 10:31:49,627 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,627 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,627 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,627 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vn2nlip2
2025-09-03 10:31:49,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,629 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:33487
2025-09-03 10:31:49,629 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:33487
2025-09-03 10:31:49,629 - distributed.worker - INFO -          dashboard at:          10.6.102.18:42833
2025-09-03 10:31:49,629 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,630 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,630 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,630 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,630 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-t58xg1yr
2025-09-03 10:31:49,630 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,634 - distributed.worker - INFO -       Start worker at:    tcp://10.6.102.18:32935
2025-09-03 10:31:49,634 - distributed.worker - INFO -          Listening to:    tcp://10.6.102.18:32935
2025-09-03 10:31:49,634 - distributed.worker - INFO -          dashboard at:          10.6.102.18:36477
2025-09-03 10:31:49,634 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,635 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,635 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:49,635 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:49,635 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-urcy5_am
2025-09-03 10:31:49,635 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,892 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,893 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,893 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,895 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,905 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,906 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,907 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,908 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,918 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,919 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,919 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,921 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:49,983 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:49,985 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:49,985 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:49,987 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:50,207 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:50,208 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:50,208 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:50,210 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:50,326 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:50,327 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:50,328 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:50,329 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:50,340 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:50,341 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:50,341 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:50,343 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:50,685 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:50,686 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:50,686 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:50,688 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:55,253 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:55,257 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:55,258 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:55,263 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:55,268 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:55,272 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:55,272 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:55,278 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:55,697 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:55,699 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:55,699 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:55,700 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:55,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:55,712 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:55,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:55,714 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:55,724 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:55,726 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:55,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:55,728 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:56,082 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:56,084 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:56,084 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:56,085 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:56,125 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:56,126 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:56,127 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:56,128 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:56,144 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:56,146 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:56,146 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:56,148 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:56,286 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:56,288 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:56,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:56,289 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,181 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,182 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,183 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,184 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,194 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,196 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,198 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,209 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,210 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,210 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,212 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,223 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,225 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,225 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,227 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,238 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,239 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,239 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,241 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,252 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,254 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,254 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,256 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,266 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,268 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,268 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,270 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,281 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,283 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,283 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,285 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,295 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,296 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,296 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,298 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,309 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,311 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,311 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,313 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,324 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,325 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,325 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,327 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,338 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,339 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,339 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,341 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,352 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,354 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,356 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,366 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,368 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,368 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,370 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,380 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,382 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,382 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,384 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,394 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,396 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,396 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,398 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,408 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,410 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,410 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,411 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,423 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,424 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,424 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,426 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,437 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,438 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,438 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,440 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,451 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,452 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,452 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,454 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,465 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,466 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,467 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,468 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,479 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,480 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,481 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,482 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:57,671 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:57,672 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:57,672 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:57,674 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,816 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,817 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,817 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,819 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,830 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,831 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,832 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,833 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,845 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,846 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,848 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:59,859 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:59,861 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:59,861 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:59,863 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,318 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,320 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,320 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,322 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,334 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,335 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,337 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,349 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,351 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,352 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,380 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,381 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,381 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,383 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,395 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,396 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,397 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,398 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:04,410 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:04,412 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:04,412 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:04,414 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:15,707 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:15,709 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:15,736 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:15,737 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:15,737 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:15,744 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:15,745 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:15,754 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:15,763 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,792 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,793 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,795 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,808 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,810 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,810 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,812 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,824 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,826 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,826 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,828 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,842 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,844 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,856 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,858 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,860 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,873 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,874 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,874 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,876 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,889 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,891 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,892 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:17,908 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:17,911 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:17,912 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:17,917 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:18,795 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,793 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:18,803 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:18,819 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:18,832 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:18,918 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:18,929 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,930 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,932 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,936 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,941 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:18,952 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,268 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,269 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,328 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,334 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,351 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,377 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,384 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,384 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:19,428 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:20,459 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:20,461 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:20,461 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:20,463 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:20,608 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:20,609 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:20,609 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:20,611 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:20,640 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:20,642 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:20,642 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:20,644 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:20,689 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:20,690 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:20,690 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:20,692 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:20,706 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:20,707 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:20,708 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:20,709 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:20,722 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:20,724 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:20,724 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:20,726 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:20,756 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:20,757 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:20,757 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:20,759 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:20,896 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:20,911 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:20,924 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:21,249 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,250 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,250 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,252 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,347 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,349 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,349 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,350 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,396 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,398 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,398 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,399 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,430 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,432 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,432 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,434 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,685 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,686 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,687 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,688 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,700 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,702 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,704 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,832 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,834 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,836 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,849 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,851 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,851 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,853 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:21,865 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:21,866 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:21,866 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:21,868 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:27,087 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:27,291 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,192 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,205 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,214 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,229 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,243 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,262 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,274 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,288 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,302 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,315 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,329 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,343 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,358 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,374 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,390 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,404 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:28,414 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:48,814 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:48,831 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:48,845 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:48,861 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:48,879 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:48,897 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:32:48,894 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:49,919 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:51,465 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:51,647 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:51,694 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:51,712 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:51,728 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:51,761 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:51,898 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:51,909 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:51,924 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:55,294 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:32:55,295 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:32:55,295 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:32:55,297 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:32:58,087 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:59,188 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:59,373 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:35:51,380 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,382 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,609 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,613 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,754 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,761 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,836 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,838 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,882 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,883 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,949 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,950 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,953 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,954 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,957 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,996 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,006 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,069 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,071 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,131 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,136 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,240 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,242 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,010 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,016 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,076 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,078 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,129 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,130 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,130 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,131 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,467 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,468 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,469 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,470 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,507 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,512 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,527 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,533 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,942 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,943 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,985 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,992 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,997 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,999 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,036 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,042 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,057 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,058 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,098 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,104 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,241 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,244 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,257 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,263 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,358 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,363 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,372 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,372 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,373 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,377 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,393 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,396 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,459 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,465 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,806 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,807 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,837 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,842 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,848 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,850 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,919 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,924 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,940 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,942 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,946 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,948 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,974 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,982 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,117 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,125 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,194 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,199 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,344 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,345 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,347 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,349 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,377 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,380 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,397 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,399 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,405 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,412 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,429 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,434 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,436 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,445 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,488 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,490 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,762 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,766 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,767 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,768 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,795 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,798 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,940 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,942 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,953 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,956 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,009 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,014 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,081 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,087 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,099 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,104 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,140 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,144 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,180 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,186 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,253 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,259 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,271 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,272 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,621 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,623 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,637 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,642 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,654 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,655 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,763 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,770 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,793 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,945 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,952 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,024 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,026 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,096 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,099 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,107 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,109 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,143 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,148 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,285 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,288 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,466 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,468 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,596 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,602 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,144 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,150 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,301 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,306 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,346 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,353 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,383 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,385 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,389 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,391 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,422 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,428 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,647 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,653 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,991 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,996 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,124 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,126 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,226 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,227 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,162 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,163 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,415 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,417 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,573 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,578 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,319 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,321 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,381 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,384 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,778 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,781 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,062 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,067 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,306 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,308 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,360 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,361 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,376 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,383 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,416 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,422 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,436 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,442 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,466 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,471 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,535 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,540 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,724 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,727 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,851 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,853 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:06,367 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:06,373 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:13,803 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:13,805 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:22,895 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,897 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,901 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,903 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,906 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,907 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,908 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,909 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,910 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,912 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,915 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,917 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,919 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,919 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,923 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,924 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,928 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,933 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,934 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,935 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,936 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,937 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,936 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,935 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,938 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,937 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,940 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,940 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,949 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,953 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,954 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,955 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,957 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,967 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,396 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,398 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,402 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,406 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,506 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,507 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,509 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,514 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,517 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,519 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,520 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,522 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,526 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,527 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,528 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,529 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,545 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,547 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,548 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,550 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,553 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,551 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,554 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,555 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,556 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,558 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,571 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,573 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,795 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,795 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,797 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,797 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,798 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,801 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,803 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,806 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,847 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,849 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,851 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,853 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,856 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,858 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,870 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,872 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,873 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,873 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,875 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,877 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,892 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,894 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,900 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,902 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,021 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,022 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,022 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,024 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,024 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,026 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,031 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,033 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,062 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,064 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,063 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,065 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,091 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,093 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,097 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,099 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,099 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,101 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,120 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,122 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,230 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,232 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,232 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,234 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,232 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,237 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,333 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,335 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,346 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,348 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,352 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,353 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,388 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,390 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,395 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,396 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,436 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,438 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,445 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,446 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,447 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,453 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,454 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,501 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,503 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,514 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,516 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,583 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,584 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,584 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,586 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,663 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,665 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,687 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,689 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,748 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,754 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,855 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,857 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,858 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,860 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,865 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,867 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,866 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,868 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,890 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,891 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,900 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,902 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,925 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,927 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,933 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,934 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,934 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,939 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,942 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,944 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,969 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,971 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,970 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,975 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,985 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,987 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,014 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,016 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,028 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,030 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,046 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,048 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,052 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,053 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,054 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,102 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,104 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,164 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,166 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,277 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,284 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,332 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,335 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,428 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,430 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,557 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,565 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,639 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,640 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,985 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,987 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,999 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,001 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,074 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,077 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,228 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,230 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,229 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,231 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,343 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,581 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,583 - distributed.utils - INFO - Reload module qme_vars from .py file
