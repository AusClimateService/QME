Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-05 09:25:14,844 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40379'
2025-09-05 09:25:14,853 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40009'
2025-09-05 09:25:14,857 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:44437'
2025-09-05 09:25:14,861 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41561'
2025-09-05 09:25:14,865 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40879'
2025-09-05 09:25:14,869 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:44681'
2025-09-05 09:25:14,873 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:42355'
2025-09-05 09:25:14,877 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46633'
2025-09-05 09:25:14,881 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33607'
2025-09-05 09:25:14,887 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41639'
2025-09-05 09:25:14,892 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46207'
2025-09-05 09:25:14,896 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:39133'
2025-09-05 09:25:14,900 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:41217'
2025-09-05 09:25:14,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45433'
2025-09-05 09:25:14,910 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34789'
2025-09-05 09:25:14,914 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37167'
2025-09-05 09:25:14,917 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38641'
2025-09-05 09:25:14,921 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:42311'
2025-09-05 09:25:14,925 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:42609'
2025-09-05 09:25:14,929 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:32793'
2025-09-05 09:25:15,042 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43773'
2025-09-05 09:25:15,047 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36337'
2025-09-05 09:25:15,052 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:32875'
2025-09-05 09:25:15,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43473'
2025-09-05 09:25:15,060 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36959'
2025-09-05 09:25:15,065 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45469'
2025-09-05 09:25:15,070 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38359'
2025-09-05 09:25:15,075 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:43005'
2025-09-05 09:25:15,080 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:34107'
2025-09-05 09:25:15,084 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:36001'
2025-09-05 09:25:15,088 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40001'
2025-09-05 09:25:15,090 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:44259'
2025-09-05 09:25:15,093 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:39351'
2025-09-05 09:25:15,098 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:46137'
2025-09-05 09:25:15,104 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33321'
2025-09-05 09:25:15,108 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33129'
2025-09-05 09:25:15,112 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35205'
2025-09-05 09:25:15,116 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37761'
2025-09-05 09:25:15,120 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40891'
2025-09-05 09:25:15,124 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40953'
2025-09-05 09:25:15,128 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:35093'
2025-09-05 09:25:15,134 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40395'
2025-09-05 09:25:15,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37969'
2025-09-05 09:25:15,141 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38953'
2025-09-05 09:25:15,147 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:37373'
2025-09-05 09:25:15,151 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:32969'
2025-09-05 09:25:15,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:33939'
2025-09-05 09:25:15,159 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:45683'
2025-09-05 09:25:15,164 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:44143'
2025-09-05 09:25:15,168 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:38469'
2025-09-05 09:25:15,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:44905'
2025-09-05 09:25:15,180 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.105.7:40867'
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45865
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41205
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33027
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41435
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42333
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45865
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45629
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41205
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42801
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33027
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41435
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42333
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36755
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45329
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45629
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:35519
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42801
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41115
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37841
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39659
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39845
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41347
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45329
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43549
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45483
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:46203
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39845
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41347
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41829
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:46203
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41307
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39737
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45779
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-0cqphenk
2025-09-05 09:25:16,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-6fmek76s
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-8kxwvadv
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-kaz4jh1g
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-_26ream3
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-jkbp9i53
2025-09-05 09:25:16,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-jo9xom8u
2025-09-05 09:25:16,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,155 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,155 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-mng8e5n3
2025-09-05 09:25:16,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,155 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-i907mi1b
2025-09-05 09:25:16,155 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,155 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-ksprw09y
2025-09-05 09:25:16,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,155 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-8c191obz
2025-09-05 09:25:16,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,157 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:46117
2025-09-05 09:25:16,157 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:46117
2025-09-05 09:25:16,157 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43433
2025-09-05 09:25:16,157 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,157 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,157 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,157 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,157 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-05vx6_sq
2025-09-05 09:25:16,157 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,163 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33419
2025-09-05 09:25:16,163 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33419
2025-09-05 09:25:16,163 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37251
2025-09-05 09:25:16,164 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,164 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,164 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,164 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,164 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-2i7dwxwf
2025-09-05 09:25:16,164 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,165 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:38117
2025-09-05 09:25:16,165 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:38117
2025-09-05 09:25:16,165 - distributed.worker - INFO -          dashboard at:           10.6.105.7:44777
2025-09-05 09:25:16,165 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,165 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,165 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,165 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,165 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-m3u_op1x
2025-09-05 09:25:16,165 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,166 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39893
2025-09-05 09:25:16,166 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39893
2025-09-05 09:25:16,166 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33371
2025-09-05 09:25:16,166 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,166 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,166 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,166 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,166 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-_a4_i89a
2025-09-05 09:25:16,166 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,172 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42307
2025-09-05 09:25:16,172 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42307
2025-09-05 09:25:16,172 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33535
2025-09-05 09:25:16,172 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,172 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,172 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,172 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-8i6zmje8
2025-09-05 09:25:16,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,175 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,175 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,176 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,178 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,179 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,179 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,180 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,181 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,182 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,182 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,184 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,184 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,185 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,185 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,185 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,186 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,187 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,187 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,187 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,187 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:46559
2025-09-05 09:25:16,187 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:46559
2025-09-05 09:25:16,187 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37811
2025-09-05 09:25:16,187 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,188 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,188 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,188 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,188 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-g_bnf71_
2025-09-05 09:25:16,188 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,188 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,188 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,188 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,188 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,190 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,190 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,190 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,190 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,191 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,191 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,191 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,193 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,193 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,194 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,194 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,195 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,196 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,196 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,197 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,197 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,198 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,198 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,198 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,198 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,199 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,199 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,199 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,200 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,200 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,200 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,200 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,201 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,201 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,201 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,201 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,202 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,203 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,203 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,203 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,204 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,204 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,205 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,205 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,206 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,210 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:43359
2025-09-05 09:25:16,210 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:43359
2025-09-05 09:25:16,210 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34251
2025-09-05 09:25:16,210 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,210 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,210 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,210 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,210 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-6013_6u2
2025-09-05 09:25:16,210 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,218 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,219 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,219 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,221 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,230 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,231 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,231 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,232 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,244 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42065
2025-09-05 09:25:16,244 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42065
2025-09-05 09:25:16,244 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41573
2025-09-05 09:25:16,244 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,244 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,244 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,244 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36267
2025-09-05 09:25:16,244 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,244 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36267
2025-09-05 09:25:16,244 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-yt86vhgp
2025-09-05 09:25:16,244 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34843
2025-09-05 09:25:16,244 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,244 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,245 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,245 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,245 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,245 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-1fh1sz5i
2025-09-05 09:25:16,245 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,247 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37723
2025-09-05 09:25:16,247 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37723
2025-09-05 09:25:16,247 - distributed.worker - INFO -          dashboard at:           10.6.105.7:44513
2025-09-05 09:25:16,247 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,247 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,247 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,247 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-onulsn0x
2025-09-05 09:25:16,247 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,266 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,267 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,267 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,269 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,269 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,270 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,271 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,272 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,272 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,272 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,273 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,297 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:40509
2025-09-05 09:25:16,297 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:40509
2025-09-05 09:25:16,297 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45977
2025-09-05 09:25:16,297 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,298 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,298 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,298 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-f3dsz5ps
2025-09-05 09:25:16,298 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,302 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45655
2025-09-05 09:25:16,302 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45655
2025-09-05 09:25:16,302 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39707
2025-09-05 09:25:16,302 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,302 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,302 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,303 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,303 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-nndk99vl
2025-09-05 09:25:16,303 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,308 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33185
2025-09-05 09:25:16,308 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33185
2025-09-05 09:25:16,308 - distributed.worker - INFO -          dashboard at:           10.6.105.7:44253
2025-09-05 09:25:16,308 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,308 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,308 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,308 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,308 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-3kvv7rvi
2025-09-05 09:25:16,308 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,314 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,314 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,315 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,320 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,321 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,322 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,323 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,327 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,328 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,328 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,329 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,331 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36345
2025-09-05 09:25:16,331 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36345
2025-09-05 09:25:16,331 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37527
2025-09-05 09:25:16,331 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,331 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,331 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,331 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-z068r28a
2025-09-05 09:25:16,331 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,332 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33931
2025-09-05 09:25:16,332 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33931
2025-09-05 09:25:16,332 - distributed.worker - INFO -          dashboard at:           10.6.105.7:35741
2025-09-05 09:25:16,332 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,332 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,332 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,332 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-0gk88o6z
2025-09-05 09:25:16,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,338 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:32943
2025-09-05 09:25:16,338 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:32943
2025-09-05 09:25:16,338 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37139
2025-09-05 09:25:16,338 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,338 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,338 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,338 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,338 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-svjygg_u
2025-09-05 09:25:16,338 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,344 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:40495
2025-09-05 09:25:16,344 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:40495
2025-09-05 09:25:16,345 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33289
2025-09-05 09:25:16,345 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,345 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,345 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,345 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,345 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-9smy2axm
2025-09-05 09:25:16,345 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,351 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,352 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,352 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,353 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,354 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,355 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,356 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,359 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,360 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,360 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,361 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,365 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,365 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,365 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,367 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,368 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:46481
2025-09-05 09:25:16,368 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:46481
2025-09-05 09:25:16,368 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34455
2025-09-05 09:25:16,368 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,368 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,368 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,368 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,368 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-xl48rymu
2025-09-05 09:25:16,368 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,376 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41693
2025-09-05 09:25:16,376 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41693
2025-09-05 09:25:16,376 - distributed.worker - INFO -          dashboard at:           10.6.105.7:44125
2025-09-05 09:25:16,376 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,376 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,376 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,376 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,376 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-3weltbqh
2025-09-05 09:25:16,376 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,387 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41947
2025-09-05 09:25:16,388 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41947
2025-09-05 09:25:16,388 - distributed.worker - INFO -          dashboard at:           10.6.105.7:35227
2025-09-05 09:25:16,388 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,388 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,388 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,388 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-f6hfyg1v
2025-09-05 09:25:16,388 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,389 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,390 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,390 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,391 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,397 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45325
2025-09-05 09:25:16,397 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45325
2025-09-05 09:25:16,397 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39495
2025-09-05 09:25:16,397 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,397 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,397 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,397 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,397 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-8crrokys
2025-09-05 09:25:16,397 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,397 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,398 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,398 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,399 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,401 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39577
2025-09-05 09:25:16,401 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39577
2025-09-05 09:25:16,401 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36819
2025-09-05 09:25:16,401 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,401 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,401 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,401 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,401 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-4r4me51c
2025-09-05 09:25:16,402 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,405 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:46447
2025-09-05 09:25:16,405 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:46447
2025-09-05 09:25:16,405 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45895
2025-09-05 09:25:16,405 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,405 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,405 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,405 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,405 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-o_599hvq
2025-09-05 09:25:16,405 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,410 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,411 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,413 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,418 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,419 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,419 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,421 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,425 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,425 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,425 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,427 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,428 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,429 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,429 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,431 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,496 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:43745
2025-09-05 09:25:16,496 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:43745
2025-09-05 09:25:16,496 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34211
2025-09-05 09:25:16,496 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,496 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,496 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,497 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,497 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-4rbl08yr
2025-09-05 09:25:16,497 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,526 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,527 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,527 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,529 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,584 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:33999
2025-09-05 09:25:16,584 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:33999
2025-09-05 09:25:16,584 - distributed.worker - INFO -          dashboard at:           10.6.105.7:39825
2025-09-05 09:25:16,584 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,584 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,584 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,585 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,585 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-5xwem6sm
2025-09-05 09:25:16,585 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,599 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41137
2025-09-05 09:25:16,600 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41137
2025-09-05 09:25:16,600 - distributed.worker - INFO -          dashboard at:           10.6.105.7:41677
2025-09-05 09:25:16,600 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,600 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,600 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,600 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-qga_llum
2025-09-05 09:25:16,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,600 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42147
2025-09-05 09:25:16,600 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42147
2025-09-05 09:25:16,600 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33237
2025-09-05 09:25:16,600 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,600 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,600 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,600 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-5dzzup57
2025-09-05 09:25:16,600 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,601 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39315
2025-09-05 09:25:16,601 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39315
2025-09-05 09:25:16,601 - distributed.worker - INFO -          dashboard at:           10.6.105.7:46711
2025-09-05 09:25:16,601 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,601 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,601 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,601 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,601 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-3hqpapoy
2025-09-05 09:25:16,601 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,607 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,607 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,608 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,609 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,614 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39979
2025-09-05 09:25:16,614 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39979
2025-09-05 09:25:16,614 - distributed.worker - INFO -          dashboard at:           10.6.105.7:35665
2025-09-05 09:25:16,614 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,614 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,614 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,614 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,614 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-n9ob2gq0
2025-09-05 09:25:16,615 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,617 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45181
2025-09-05 09:25:16,618 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45181
2025-09-05 09:25:16,618 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36595
2025-09-05 09:25:16,618 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,618 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,618 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,618 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,618 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-25akyuem
2025-09-05 09:25:16,618 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,619 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:32961
2025-09-05 09:25:16,619 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:32961
2025-09-05 09:25:16,619 - distributed.worker - INFO -          dashboard at:           10.6.105.7:37221
2025-09-05 09:25:16,619 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,619 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,619 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,619 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,619 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-6xkkyllw
2025-09-05 09:25:16,619 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,620 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:45631
2025-09-05 09:25:16,620 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:45631
2025-09-05 09:25:16,620 - distributed.worker - INFO -          dashboard at:           10.6.105.7:45373
2025-09-05 09:25:16,620 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,620 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,620 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,620 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,620 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-40suxufm
2025-09-05 09:25:16,620 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,621 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:32995
2025-09-05 09:25:16,621 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:32995
2025-09-05 09:25:16,621 - distributed.worker - INFO -          dashboard at:           10.6.105.7:40887
2025-09-05 09:25:16,621 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,621 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,621 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,621 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,621 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,621 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-gb0xg74z
2025-09-05 09:25:16,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,622 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:37757
2025-09-05 09:25:16,622 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:37757
2025-09-05 09:25:16,622 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,622 - distributed.worker - INFO -          dashboard at:           10.6.105.7:32843
2025-09-05 09:25:16,622 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,622 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,622 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,622 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-im65a5hv
2025-09-05 09:25:16,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,622 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:42599
2025-09-05 09:25:16,623 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:42599
2025-09-05 09:25:16,623 - distributed.worker - INFO -          dashboard at:           10.6.105.7:38317
2025-09-05 09:25:16,623 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,623 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,623 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,623 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-dm5537qa
2025-09-05 09:25:16,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,624 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,625 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,625 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:39831
2025-09-05 09:25:16,626 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:39831
2025-09-05 09:25:16,626 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43301
2025-09-05 09:25:16,626 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,626 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,626 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,626 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-1g65zgg_
2025-09-05 09:25:16,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,626 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,628 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,629 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,630 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,630 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,631 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,633 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:46013
2025-09-05 09:25:16,633 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:46013
2025-09-05 09:25:16,633 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43049
2025-09-05 09:25:16,633 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:36427
2025-09-05 09:25:16,634 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,634 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,634 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:36427
2025-09-05 09:25:16,634 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,634 - distributed.worker - INFO -          dashboard at:           10.6.105.7:36791
2025-09-05 09:25:16,634 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,634 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,634 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-u2frmw_4
2025-09-05 09:25:16,634 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,634 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,634 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,634 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,634 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-sk_l53pw
2025-09-05 09:25:16,634 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,636 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,637 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,637 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,637 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:41427
2025-09-05 09:25:16,637 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:41427
2025-09-05 09:25:16,637 - distributed.worker - INFO -          dashboard at:           10.6.105.7:34733
2025-09-05 09:25:16,637 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,637 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,637 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,637 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,637 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,637 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-mxzvg8x6
2025-09-05 09:25:16,637 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,637 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:40619
2025-09-05 09:25:16,637 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:40619
2025-09-05 09:25:16,637 - distributed.worker - INFO -          dashboard at:           10.6.105.7:33539
2025-09-05 09:25:16,638 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,638 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,638 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,638 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,638 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-mn0_vxfz
2025-09-05 09:25:16,638 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,638 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,638 - distributed.worker - INFO -       Start worker at:     tcp://10.6.105.7:34731
2025-09-05 09:25:16,638 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,638 - distributed.worker - INFO -          Listening to:     tcp://10.6.105.7:34731
2025-09-05 09:25:16,638 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,638 - distributed.worker - INFO -          dashboard at:           10.6.105.7:43361
2025-09-05 09:25:16,638 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,638 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,638 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:25:16,638 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:25:16,638 - distributed.worker - INFO -       Local Directory: /jobfs/148853240.gadi-pbs/dask-scratch-space/worker-6mek0pk0
2025-09-05 09:25:16,638 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,639 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,640 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,641 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,641 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,642 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,645 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,645 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,645 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,646 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,648 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,649 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,649 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,649 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,650 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,651 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,651 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,652 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,652 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,652 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,652 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,653 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,653 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,653 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,653 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,654 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,654 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,659 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,660 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,660 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,661 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,662 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,662 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,662 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,663 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,663 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,663 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:25:16,664 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,664 - distributed.worker - INFO -         Registered to:      tcp://10.6.105.1:8749
2025-09-05 09:25:16,664 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:25:16,664 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:16,665 - distributed.core - INFO - Starting established connection to tcp://10.6.105.1:8749
2025-09-05 09:25:50,960 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,962 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,962 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,962 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,962 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,962 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,962 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,962 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,962 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,962 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,963 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,963 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,963 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,963 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,964 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,964 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,964 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,964 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,964 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,964 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,965 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,964 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,965 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,966 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,967 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,966 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,968 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,969 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,969 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,969 - distributed.worker - INFO - Starting Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:25:50,973 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,975 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,975 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,976 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,976 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,976 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,977 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,978 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,980 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,978 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,984 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:50,987 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:25:53,709 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,710 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,710 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,710 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,710 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,710 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,710 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,710 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,712 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,713 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,713 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,713 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,713 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,713 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,713 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,713 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,713 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,713 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,713 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,714 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,714 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,712 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,714 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,714 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,714 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,713 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,714 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,714 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,713 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,714 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,714 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,714 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,715 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,715 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,715 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,715 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,716 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,715 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,715 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,715 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,716 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,716 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,716 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,715 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,716 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,716 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,717 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,717 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,716 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,717 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,717 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,717 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,718 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,718 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,718 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,718 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,718 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,718 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,718 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,719 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,716 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,719 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,715 - distributed.worker - INFO - Starting Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:25:53,719 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,719 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,719 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,719 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,719 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,719 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,721 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:53,721 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:25:54,096 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,097 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,097 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,097 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,097 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,097 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,097 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,097 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,099 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,099 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,099 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,099 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,099 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,099 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,099 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,099 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,099 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,100 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,100 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,100 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,100 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,100 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,100 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,100 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,100 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,101 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,101 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,101 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,101 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,101 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,101 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,101 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,101 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,101 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,101 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,101 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,102 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,102 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,102 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,102 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,102 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,102 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,102 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,102 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,102 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,103 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,104 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,104 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,104 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,102 - distributed.worker - INFO - Starting Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:25:54,104 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,104 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,104 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,104 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,104 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,104 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,105 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,106 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,107 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,108 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,112 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:25:54,469 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,469 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,470 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,471 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,471 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,471 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,471 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,471 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,471 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,471 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,471 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,472 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,472 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,472 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,472 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,472 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,472 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,472 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,472 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,472 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,472 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,472 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,472 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,472 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,472 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,472 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,472 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,472 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,473 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,473 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,473 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,474 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,474 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,474 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,474 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,474 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,474 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,475 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,475 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,475 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,475 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,475 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,475 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,475 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,475 - distributed.worker - INFO - Starting Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:25:54,475 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,475 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,476 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,476 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,476 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,476 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,476 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,477 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,477 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,477 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,477 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,477 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,477 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,477 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,477 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,478 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,478 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,478 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,478 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,478 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,478 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,478 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:25:54,478 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:33:00,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:00,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:00,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:00,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:00,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,072 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,075 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,075 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,078 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,088 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:01,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:49,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:51,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:51,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:51,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:53,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:53,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:53,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:53,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:56,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,666 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:57,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:58,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:58,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:58,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:58,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:58,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:58,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:58,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:33:59,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:04,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:06,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:11,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:11,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:56,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:56,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:34:58,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:01,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:01,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:01,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:01,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:01,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:01,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:02,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:02,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:02,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:03,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:04,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:05,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:05,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:05,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:06,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:06,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:06,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:06,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:06,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:06,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:06,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:06,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:07,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:08,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:08,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:08,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:08,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:09,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:09,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:09,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:10,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:12,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:13,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:13,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:14,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:14,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:16,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:17,101 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:17,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:17,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:17,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:17,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:17,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:17,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:17,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:18,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:18,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:18,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:18,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:19,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:19,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:20,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:22,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:22,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:24,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:24,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:24,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:24,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:24,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:27,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:27,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:28,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:29,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:29,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:29,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:31,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:31,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:31,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:31,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:31,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:31,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:32,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:32,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:32,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:32,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:33,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:33,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:34,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:34,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:34,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,947 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:35,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:36,078 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:36,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:36,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:36,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:38,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:39,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:39,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:39,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:39,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:39,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:39,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:39,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:40,805 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:43,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:43,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:43,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:44,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:44,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:44,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:44,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:44,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:45,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:45,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:45,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:45,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:45,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:46,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:46,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:46,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:46,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:46,592 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:48,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:48,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:48,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:48,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:49,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:49,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:49,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:49,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:49,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:49,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:50,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:51,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:35:51,635 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:00,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:02,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:06,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:07,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:07,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:07,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:07,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:07,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:07,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:08,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:08,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:08,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:08,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:08,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:09,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:09,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:09,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:09,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:09,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:09,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:09,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:10,373 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:13,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:13,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:13,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:13,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:13,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:14,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:14,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:16,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:16,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:18,667 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:20,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:20,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:20,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:21,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:22,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:22,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:25,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:26,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:26,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:26,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:26,678 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:27,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:30,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:31,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:31,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:32,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:32,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:36,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:36,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:37,472 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:38,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:38,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:38,909 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:38,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:38,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:38,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:38,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:39,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:40,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:41,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:44,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:45,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:45,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:45,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:45,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:47,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:47,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:47,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:47,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:47,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:48,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:49,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,011 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:50,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:51,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:51,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:51,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:36:51,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:11,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:13,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:14,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:15,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:15,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:15,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:15,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:15,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:15,938 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:16,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:16,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:18,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:18,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:18,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:18,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:19,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:19,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:19,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:19,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:20,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:20,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:20,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:21,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:22,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:22,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:22,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:23,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:23,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:24,447 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:24,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:26,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:28,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:30,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:31,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:33,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:34,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:34,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:34,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:36,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:36,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:37,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:37,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:37,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:46,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:47,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:48,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 38.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:49,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:50,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:50,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:51,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:52,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:53,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:53,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:54,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:54,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:55,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:55,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:55,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:55,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:55,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:56,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:57,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:37:57,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:00,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:00,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,426 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:01,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:02,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:02,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:02,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:03,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:03,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,259 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,260 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:04,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:05,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:05,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:08,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:09,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:09,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:09,711 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:10,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:11,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:11,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:11,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:11,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:11,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:12,207 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:12,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:12,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:12,909 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:13,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:13,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:13,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:13,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:13,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:14,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:14,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:14,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:14,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:14,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:15,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:16,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:16,104 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:16,106 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:18,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:18,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:18,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:19,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:19,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:21,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:22,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:22,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:22,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:22,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:22,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:27,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:27,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:27,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:27,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:27,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:28,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:28,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:28,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:28,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:29,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:30,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:30,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:30,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:30,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:30,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:30,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:30,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:31,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:31,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:31,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:31,588 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:32,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:32,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:34,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:34,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:39,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:41,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:41,224 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:49,011 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:52,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:52,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:53,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:54,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:54,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:55,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:55,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:55,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:55,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:56,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:57,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:58,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:58,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:58,100 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:38:58,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:00,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:00,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:00,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:01,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:01,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:01,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:01,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:01,945 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:07,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:08,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,263 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,305 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,469 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:09,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:10,011 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:10,737 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:10,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:11,023 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:11,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:11,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:11,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:11,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:12,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:12,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:12,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:16,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:17,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:29,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:29,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:30,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:30,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:30,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:30,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:32,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:33,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:33,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:33,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:33,803 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:34,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:36,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:36,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:36,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:36,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:36,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:38,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:38,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:38,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:38,373 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:39,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:39,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:39,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:39,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:39,878 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:39,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:40,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:40,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:40,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:41,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:41,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:45,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:45,200 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:45,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:45,327 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:50,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:50,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:50,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:50,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:51,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:52,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:53,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:53,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:53,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:53,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:53,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:54,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:54,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:54,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:54,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:54,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:55,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:55,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:55,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:55,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:55,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:57,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:57,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:57,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:57,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:57,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:58,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:58,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:58,300 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:39:58,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:00,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:00,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:00,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:01,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:05,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:05,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:05,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:13,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:13,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:14,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:14,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:14,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:16,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:17,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:18,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:19,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:20,088 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:20,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:20,378 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:20,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:20,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:21,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:21,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:22,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:22,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:22,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:22,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:23,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:23,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:23,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:24,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:24,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:24,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:24,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:24,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:24,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:25,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:25,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:25,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:25,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:25,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:25,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:25,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:25,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:29,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:30,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:31,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:31,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:31,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:32,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:32,144 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:32,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:33,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:33,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:34,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:34,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:37,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:37,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:37,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:37,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:37,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:38,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:39,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:39,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:39,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:39,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:39,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:40,196 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:40,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:40,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:40,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:40,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:41,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:42,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:42,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:42,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:42,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:42,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:42,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:42,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:45,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:46,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:47,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:48,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:48,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:48,259 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:48,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:48,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:48,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:49,191 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:49,191 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:50,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:50,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:50,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:51,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:51,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:52,006 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:52,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:52,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:53,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:55,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:55,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:56,669 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:56,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:56,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:56,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:57,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:40:59,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:02,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:02,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:02,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:03,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:03,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:03,820 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:04,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:06,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:09,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:09,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:11,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:11,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:11,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:12,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:13,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:13,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:13,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:15,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:15,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:15,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:15,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:17,072 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:17,072 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:17,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:17,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:17,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:17,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:17,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:17,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:19,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:19,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:19,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:20,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:21,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:22,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:23,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:27,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:27,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:27,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:28,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:28,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:28,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:28,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:28,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:28,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:28,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:28,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,187 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,237 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:29,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:30,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,468 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:31,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:33,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:33,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:34,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:34,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:34,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:34,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:35,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:36,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:42,927 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:48,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:48,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:49,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:49,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:49,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:50,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:50,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:51,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:51,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:51,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:52,023 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:52,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:52,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:52,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:52,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:57,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:59,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:59,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:59,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:59,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:41:59,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:00,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:01,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:01,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:01,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:01,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:01,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:01,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:01,255 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:01,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:03,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:03,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:03,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:03,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:05,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:05,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:06,139 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:07,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:08,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:08,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:09,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:09,073 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:09,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,847 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,848 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,864 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:11,866 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:12,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:12,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:12,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:12,259 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:12,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:13,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:13,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:15,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:15,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:15,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:16,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:16,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:16,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:17,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:18,174 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:18,475 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:18,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:18,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:21,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:23,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:23,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:27,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:27,367 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:27,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:28,075 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:28,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:28,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:28,572 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:28,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:28,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:28,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:28,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:29,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:30,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:31,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:32,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:33,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:34,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:35,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:35,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:36,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:37,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:39,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:40,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:41,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:45,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:45,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:46,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:46,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:46,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:46,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:47,135 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:47,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:47,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:47,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:48,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:48,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:48,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:48,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:49,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:49,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:49,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,303 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,306 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,465 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:50,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:51,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:51,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:51,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:51,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:51,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,072 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:52,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:54,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:54,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:55,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:55,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:56,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:42:56,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:00,984 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:01,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:01,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:01,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:01,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,259 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:02,954 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:03,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:03,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:03,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:03,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:03,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:05,223 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:05,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:05,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:05,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:05,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:05,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:07,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:07,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:07,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:07,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:07,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:07,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:07,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:07,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:08,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:09,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:09,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:09,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:09,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:11,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:11,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:11,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:11,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:11,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:12,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:12,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:14,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:14,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:14,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:14,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:14,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:15,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:15,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:15,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:15,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:17,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:17,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:17,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:17,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:17,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:17,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:17,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:57,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:57,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:57,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:58,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:58,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:58,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:43:59,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:00,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:00,716 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:00,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:00,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:02,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:02,847 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:03,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:06,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:06,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:07,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:07,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:07,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:07,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:08,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:08,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:08,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:08,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:08,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:08,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:08,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:09,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:11,249 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:11,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:11,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:12,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:12,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:13,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:14,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:14,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:15,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:15,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:19,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:19,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:20,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:21,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:21,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:21,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:21,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:27,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:27,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:27,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:27,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,779 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:28,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:29,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:29,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:29,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:29,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:29,335 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:29,335 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:29,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:30,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:31,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:31,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:32,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:32,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:33,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:33,436 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:33,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:33,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:33,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:34,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:34,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:34,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:35,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:35,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:38,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:40,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:41,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:43,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:43,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:43,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:44,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:45,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:46,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:46,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:46,572 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:46,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:47,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:47,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:47,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:47,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:47,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:47,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:47,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:48,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:48,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:48,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:49,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:49,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:50,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:50,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:50,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:50,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:50,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:51,330 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:52,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:54,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:56,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:56,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:56,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:56,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:58,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:44:58,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:01,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:01,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:02,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:04,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:04,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:04,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:04,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:05,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:05,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:05,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:05,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:05,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:05,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:06,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:07,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:07,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:07,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:07,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:07,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:08,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:08,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:08,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:09,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:10,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:10,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:10,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:11,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:11,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:11,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:11,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:11,397 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:11,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:11,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:12,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:13,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:24,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:25,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:26,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:26,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:27,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:27,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:27,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:27,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:28,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:29,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:29,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:30,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:31,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:31,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:31,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:31,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:31,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:31,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:31,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:31,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:32,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:32,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:32,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:33,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:34,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:34,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:35,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:35,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:35,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:35,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:35,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:36,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:37,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:38,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:38,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:39,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:45:42,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:10,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:20,424 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,187 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:22,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:23,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:23,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:23,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,600 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,600 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:25,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,196 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:26,200 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:27,903 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:28,123 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:28,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:28,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:28,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:29,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:29,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:29,908 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:30,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:31,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:31,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:33,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:33,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:34,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:34,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:34,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:35,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:36,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:37,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:37,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:38,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:38,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:38,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:39,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:42,232 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:42,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:42,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:42,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:43,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:45,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 29.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:48,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 32.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:48,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 32.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:49,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:52,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:52,014 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:53,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:55,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:55,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:55,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:56,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:56,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:56,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:56,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:57,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:57,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:57,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:46:58,514 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:00,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:01,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:01,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:02,629 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:02,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:03,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:03,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:03,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:03,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:03,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:03,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:03,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:04,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:04,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:04,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:04,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:04,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:05,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:07,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:09,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:09,381 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:09,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:10,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:11,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:11,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:11,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:11,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,064 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:12,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:13,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:13,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:13,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:13,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:14,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:14,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:14,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:14,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:15,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:15,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:15,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:16,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:16,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:16,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:17,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:17,458 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:17,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:18,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:18,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:19,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:21,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:27,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:27,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:28,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:29,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:29,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:29,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:30,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:30,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:30,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:31,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:32,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:32,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:33,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:34,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:34,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:34,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:34,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:34,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:35,235 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:36,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:36,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:39,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:39,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:39,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:40,083 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:40,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:40,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:40,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:42,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:42,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:42,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:42,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:42,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:44,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:44,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:45,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:51,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:47:55,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:00,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:03,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:17,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:18,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:18,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:18,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:18,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:19,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:20,996 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:21,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:21,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:21,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:21,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:22,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:22,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:24,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:24,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:25,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:25,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:25,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:25,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:25,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:26,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:27,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:28,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:29,191 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:29,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:29,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:29,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:30,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:30,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:30,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:32,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:35,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:35,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:35,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:35,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:37,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:38,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:38,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:39,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:39,314 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:39,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:42,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:42,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:42,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:43,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:45,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:45,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:45,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:46,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:46,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:47,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:48,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:48,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:49,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:49,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:50,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:51,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:51,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:51,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:52,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:52,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:52,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:52,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:52,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:52,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:53,314 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:53,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:53,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:53,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:53,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:53,572 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:53,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:54,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:54,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:54,467 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:54,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:54,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:55,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:55,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:48:58,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:13,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:13,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:13,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:15,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:15,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:15,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:16,007 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:16,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:16,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:16,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:16,756 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:17,218 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:17,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:17,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:17,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:17,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:17,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:18,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:18,753 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:18,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:18,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:18,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:19,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:20,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,122 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,390 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:21,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,378 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:27,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,170 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:28,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:29,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:30,100 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:31,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:31,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:31,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:32,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:33,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:33,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:33,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:33,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:33,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:33,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:34,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:34,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:35,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:35,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:36,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:36,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:37,193 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:37,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:38,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:38,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:38,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:38,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:38,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:38,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:41,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:41,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:41,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:41,847 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:41,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:41,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:42,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:44,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:44,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:46,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:47,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:48,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:48,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:49,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:49,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:49,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:49,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:49,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:49,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:49,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:49,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:50,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:50,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:50,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:52,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:52,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:52,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:52,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:42147. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,774 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:39979. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:32943. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,773 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:45325. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:37757. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:34731. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:36427. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:32961. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:45631. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:33931. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:45329. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,776 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:41137. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,775 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:46013. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,775 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:46559. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,775 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:39577. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:42599. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,775 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:40495. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:42801. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:46447. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:41947. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,777 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:33419. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,775 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:45865. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:39831. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,776 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,775 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:39845. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:42333. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:33185. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:45629. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,778 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:43359. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,779 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:40509. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,779 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:36267. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,779 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:45655. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,779 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:37723. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,779 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:46481. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,774 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,774 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.7:49002 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,780 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:41693. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,780 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:39893. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,780 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,781 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:46203. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,777 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.7:49220 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,774 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.7:49244 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,783 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:52,785 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:43745. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,779 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.105.7:49254 remote=tcp://10.6.105.1:8749>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:49:52,785 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:33939'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,788 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764719, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,788 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 767694, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,788 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,788 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,789 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,789 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,789 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,791 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:38469'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,792 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:32969'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,792 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:43473'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,793 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763712, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,793 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,793 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763709, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,793 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765185, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,793 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,793 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,793 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765184, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,793 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,793 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,793 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,794 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,802 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:36959'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,802 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:37761'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,802 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:43005'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,803 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:45683'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,803 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:38953'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,803 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:34107'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,803 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:40009'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,803 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764298, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,803 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764431, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:35093'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764297, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763714, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:40953'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763734, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:45433'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766887, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,804 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:44259'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,804 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,805 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:40001'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,804 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.15:35221, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,805 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:46207'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766511, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765737, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765355, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,805 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:44143'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764811, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766859, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.16:46575, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.26:40289, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763789, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,805 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:37373'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,805 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765674, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,805 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766865, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763392, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763786, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766667, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:40891'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764869, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.2:39623, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765689, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764707, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,806 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,806 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:40879'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763885, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765667, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763888, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,807 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:33321'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763530, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.2:45285, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763621, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,807 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,807 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763504, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:44681'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764838, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763618, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,808 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:34789'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764845, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,808 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:44437'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.8:44087, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,808 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763592, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,808 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,809 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:46137'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,809 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765348, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,809 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:32875'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,809 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763591, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,809 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765381, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,809 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:42311'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,809 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.6:42187, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,809 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,809 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:33129'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763334, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764066, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,810 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:40395'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763804, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,810 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:43773'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.32:37309, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765998, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,810 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:41561'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765453, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,810 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763651, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.4:44847, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763787, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,811 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:32793'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765455, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763731, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.22:37217, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763634, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763783, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,811 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:40379'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.17:41979, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765311, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,811 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,811 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764047, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,812 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.7:41205, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,812 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:38359'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,812 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.2:43805, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,812 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765306, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,812 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.11:38219, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,812 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:42355'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,812 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 767402, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,812 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 765525, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,812 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 764844, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,812 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,813 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763876, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,813 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.7:45181, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,813 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763884, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,813 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.31:34693, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,813 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,814 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,814 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:40867'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,815 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763732, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,815 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 763727, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,815 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,816 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.21:44993, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,816 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,817 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 768122, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,817 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,817 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.26:38989, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,817 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.32:35633, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,817 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.105.8:45793, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:52,819 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,819 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,819 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,819 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,820 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,821 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,822 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:52,822 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:52,823 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:52,836 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:52,860 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:52,866 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:52,898 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,004 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,007 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:36345. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,026 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,031 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48718 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:54,036 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:36337'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,037 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,037 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,037 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,037 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,037 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,045 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1516db2ea710>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:54,060 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,250 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,253 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:42065. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,274 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.105.31:34693
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.105.7:38522 remote=tcp://10.6.105.31:34693>: Stream is closed
2025-09-05 09:49:54,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,282 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48672 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:54,285 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:42609'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,286 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,287 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,287 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,287 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,287 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,295 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x154f70381310>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:54,303 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,617 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,619 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:41347. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,622 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,624 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:42307. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,639 - distributed.worker - ERROR - failed during get data with tcp://10.6.105.7:42307 -> tcp://10.6.105.23:33361
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.105.7:42307 remote=tcp://10.6.105.23:49812>: Stream is closed
2025-09-05 09:49:54,643 - distributed.worker - ERROR - failed during get data with tcp://10.6.105.7:42307 -> tcp://10.6.105.8:33487
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.105.7:42307 remote=tcp://10.6.105.8:58756>: Stream is closed
2025-09-05 09:49:54,642 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48602 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:54,647 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:46633'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,647 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,648 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,648 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,648 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,648 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,653 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48646 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:54,656 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:37167'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,657 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,657 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,657 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,657 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,657 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,657 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14e503e11510>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:54,664 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,665 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1511d40e6050>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:54,673 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,739 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,740 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:33027. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,744 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48540 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48540 remote=tcp://10.6.105.1:8749>: Stream is closed
2025-09-05 09:49:54,747 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:41217'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,747 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,747 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,747 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,747 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,747 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,753 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14561e4b4a10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:54,758 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,806 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,808 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:39315. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,829 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48806 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:54,833 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:35205'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,834 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,834 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,834 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,834 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,834 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,840 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:54,841 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14845afea710>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:54,851 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,863 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:54,869 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:54,872 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,874 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:38117. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,877 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,878 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:45181. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,888 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:54,889 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:41435. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:54,899 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48820 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:54,900 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48554 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48554 remote=tcp://10.6.105.1:8749>: Stream is closed
2025-09-05 09:49:54,902 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:44905'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,903 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766688, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:54,904 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,904 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,904 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,904 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,904 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,905 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:41639'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,905 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,905 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,905 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,905 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,905 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,905 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48624 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:54,910 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x152126af3310>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:54,913 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:38641'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:54,914 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('concatenate-getitem-open_dataset-tas-mean_chunk-1c3f3d05e3caff38f115635339059401', 766081, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:49:54,914 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:54,913 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1485d1e4a3d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:54,915 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:54,915 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:54,915 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:54,915 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:54,919 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:54,927 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x150a0852e390>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:55,298 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:55,486 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:43473'. Reason: nanny-close-gracefully
2025-09-05 09:49:55,489 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:43473' closed.
2025-09-05 09:49:55,503 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:41561'. Reason: nanny-close-gracefully
2025-09-05 09:49:55,508 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:35093'. Reason: nanny-close-gracefully
2025-09-05 09:49:55,509 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:41561' closed.
2025-09-05 09:49:55,510 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:40867'. Reason: nanny-close-gracefully
2025-09-05 09:49:55,511 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:35093' closed.
2025-09-05 09:49:55,512 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:40867' closed.
2025-09-05 09:49:55,774 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:56,063 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:56,307 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:56,536 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:36337'. Reason: nanny-close-gracefully
2025-09-05 09:49:56,537 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:36337' closed.
2025-09-05 09:49:56,543 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:56,667 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:56,676 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:56,760 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:56,790 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:42609'. Reason: nanny-close-gracefully
2025-09-05 09:49:56,791 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:42609' closed.
2025-09-05 09:49:56,855 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:56,922 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:56,967 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:57,162 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:37167'. Reason: nanny-close-gracefully
2025-09-05 09:49:57,163 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:37167' closed.
2025-09-05 09:49:57,190 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:46633'. Reason: nanny-close-gracefully
2025-09-05 09:49:57,192 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:46633' closed.
2025-09-05 09:49:57,199 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:41217'. Reason: nanny-close-gracefully
2025-09-05 09:49:57,200 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:41217' closed.
2025-09-05 09:49:57,275 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:57,275 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:57,301 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:57,388 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:35205'. Reason: nanny-close-gracefully
2025-09-05 09:49:57,389 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:35205' closed.
2025-09-05 09:49:57,416 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:41639'. Reason: nanny-close-gracefully
2025-09-05 09:49:57,423 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:41639' closed.
2025-09-05 09:49:57,525 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:57,769 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:57,769 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:57,772 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:57,772 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:32875'. Reason: nanny-close-gracefully
2025-09-05 09:49:57,773 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:32875' closed.
2025-09-05 09:49:57,780 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:57,898 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:58,001 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:58,228 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:58,242 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:58,306 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:42355'. Reason: nanny-close-gracefully
2025-09-05 09:49:58,307 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:42355' closed.
2025-09-05 09:49:58,393 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:58,547 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:58,784 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:58,971 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:59,031 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:40953'. Reason: nanny-close-gracefully
2025-09-05 09:49:59,032 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:40953' closed.
2025-09-05 09:49:59,057 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:59,169 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:59,170 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:59,227 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:59,279 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:59,280 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:59,439 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:44681'. Reason: nanny-close-gracefully
2025-09-05 09:49:59,440 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:44681' closed.
2025-09-05 09:49:59,450 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:49:59,453 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:40619. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:59,471 - distributed.worker - ERROR - failed during get data with tcp://10.6.105.7:40619 -> tcp://10.6.105.8:36987
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.105.7:40619 remote=tcp://10.6.105.8:47094>: Stream is closed
2025-09-05 09:49:59,478 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:49:59,482 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48908 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:49:59,484 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:39351'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:49:59,485 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:49:59,485 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:49:59,485 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:49:59,485 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:49:59,485 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:49:59,489 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1470ea6d2f90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:49:59,494 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:59,529 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:59,611 - distributed.nanny - INFO - Worker closed
2025-09-05 09:49:59,758 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:44437'. Reason: nanny-close-gracefully
2025-09-05 09:49:59,761 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:44437' closed.
2025-09-05 09:49:59,762 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:40395'. Reason: nanny-close-gracefully
2025-09-05 09:49:59,764 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:40395' closed.
2025-09-05 09:49:59,773 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:59,774 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:59,776 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:49:59,902 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:00,006 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:00,041 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:44259'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,042 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:44259' closed.
2025-09-05 09:50:00,232 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:00,242 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:45433'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,243 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:45433' closed.
2025-09-05 09:50:00,245 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:00,254 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,259 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:00,261 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:00,263 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:38953'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,262 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:00,264 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:41205. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,265 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:38953' closed.
2025-09-05 09:50:00,265 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:33999. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,263 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:00,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:41427. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,266 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:00,266 - distributed.core - INFO - Connection to tcp://10.6.105.1:8749 has been closed.
2025-09-05 09:50:00,269 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:46117. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,269 - distributed.worker - INFO - Stopping worker at tcp://10.6.105.7:32995. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:00,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:00,289 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48524 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:00,289 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.105.24:40715
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.105.7:44854 remote=tcp://10.6.105.24:40715>: Stream is closed
2025-09-05 09:50:00,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:00,292 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:33607'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:50:00,293 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:00,293 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:00,292 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48896 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:00,293 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:00,294 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:00,294 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:00,292 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48792 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:00,295 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:32793'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,296 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:32793' closed.
2025-09-05 09:50:00,295 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48616 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:00,297 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:45469'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,297 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:00,297 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.105.7:48844 remote=tcp://10.6.105.1:8749>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:50:00,298 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:00,298 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:00,298 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:00,298 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:00,298 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:37969'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,298 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,298 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,298 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,298 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,298 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:00,299 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:00,299 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:00,299 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:00,299 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:00,297 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14bd7de8fc50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:00,299 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:39133'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,300 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:00,300 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:00,300 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:00,300 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:00,300 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:00,300 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.105.7:36001'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:50:00,301 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:50:00,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.py130ff37b-c346-49a5-a967-7c2c59f09424
2025-09-05 09:50:00,301 - distributed.worker - INFO - Removing Worker plugin qme_vars.py5bee52b1-a7c4-4bda-93e5-efbbdc4f8f76
2025-09-05 09:50:00,301 - distributed.worker - INFO - Removing Worker plugin qme_train.py7afc963c-292d-48e9-887f-e88c60b0ede7
2025-09-05 09:50:00,301 - distributed.worker - INFO - Removing Worker plugin qme_apply.py4ef0170c-f139-4c55-9a27-e4b48cb725a6
2025-09-05 09:50:00,302 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,301 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x153657bb7fd0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:00,302 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:00,303 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14e44182f410>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:00,304 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14e5c3022150>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:50:00,307 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,308 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,309 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,315 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,341 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,398 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:00,405 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,479 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:37373'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,480 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:37373' closed.
2025-09-05 09:50:00,503 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,564 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,587 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:42311'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,588 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:42311' closed.
2025-09-05 09:50:00,636 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,636 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:40379'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,692 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:40379' closed.
2025-09-05 09:50:00,711 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,712 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:40879'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,714 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:40879' closed.
2025-09-05 09:50:00,771 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:00,788 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:00,909 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:38359'. Reason: nanny-close-gracefully
2025-09-05 09:50:00,911 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:38359' closed.
2025-09-05 09:50:01,061 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:01,173 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:01,173 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:01,231 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:01,247 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:44143'. Reason: nanny-close-gracefully
2025-09-05 09:50:01,248 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:44143' closed.
2025-09-05 09:50:01,313 - distributed.nanny - INFO - Worker closed
2025-09-05 09:50:01,497 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:01,528 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:43005'. Reason: nanny-close-gracefully
2025-09-05 09:50:01,530 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:43005' closed.
2025-09-05 09:50:01,615 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:01,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:46207'. Reason: nanny-close-gracefully
2025-09-05 09:50:01,692 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:46207' closed.
2025-09-05 09:50:01,705 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:33939'. Reason: nanny-close-gracefully
2025-09-05 09:50:01,707 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:33939' closed.
2025-09-05 09:50:01,727 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:40001'. Reason: nanny-close-gracefully
2025-09-05 09:50:01,728 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:40001' closed.
2025-09-05 09:50:01,955 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:39351'. Reason: nanny-close-gracefully
2025-09-05 09:50:01,956 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:39351' closed.
2025-09-05 09:50:02,085 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:34789'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,086 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:34789' closed.
2025-09-05 09:50:02,258 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,301 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,302 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,302 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,302 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,305 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,310 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,311 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,312 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,321 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,346 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,410 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,507 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,567 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,640 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,640 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,715 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,775 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:02,778 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:36959'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,779 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:36959' closed.
2025-09-05 09:50:02,815 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:38469'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,816 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:38469' closed.
2025-09-05 09:50:02,862 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:44905'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,863 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:44905' closed.
2025-09-05 09:50:02,878 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:33129'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,879 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:33129' closed.
2025-09-05 09:50:02,898 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:46137'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,898 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:46137' closed.
2025-09-05 09:50:02,904 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:33607'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,905 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:33607' closed.
2025-09-05 09:50:02,931 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:32969'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,932 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:32969' closed.
2025-09-05 09:50:02,935 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:39133'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,936 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:39133' closed.
2025-09-05 09:50:02,941 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:37761'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,941 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:37761' closed.
2025-09-05 09:50:02,952 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:37969'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,953 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:37969' closed.
2025-09-05 09:50:02,954 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:36001'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,955 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:36001' closed.
2025-09-05 09:50:02,959 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:45469'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,960 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:45469' closed.
2025-09-05 09:50:02,991 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:40891'. Reason: nanny-close-gracefully
2025-09-05 09:50:02,991 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:40891' closed.
2025-09-05 09:50:03,130 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:33321'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,131 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:33321' closed.
2025-09-05 09:50:03,145 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:45683'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,146 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:45683' closed.
2025-09-05 09:50:03,192 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:34107'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,193 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:34107' closed.
2025-09-05 09:50:03,267 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:38641'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,268 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:38641' closed.
2025-09-05 09:50:03,284 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:40009'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,285 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:40009' closed.
2025-09-05 09:50:03,317 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:50:03,792 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.105.7:43773'. Reason: nanny-close-gracefully
2025-09-05 09:50:03,793 - distributed.nanny - INFO - Nanny at 'tcp://10.6.105.7:43773' closed.
2025-09-05 09:50:03,795 - distributed.dask_worker - INFO - End worker
