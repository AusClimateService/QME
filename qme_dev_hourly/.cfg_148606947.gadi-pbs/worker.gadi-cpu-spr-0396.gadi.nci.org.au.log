Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 10:31:12,165 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:43157'
2025-09-03 10:31:12,176 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:38065'
2025-09-03 10:31:12,181 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:38669'
2025-09-03 10:31:12,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42175'
2025-09-03 10:31:12,189 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37767'
2025-09-03 10:31:12,238 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:36883'
2025-09-03 10:31:12,242 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34879'
2025-09-03 10:31:12,247 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42757'
2025-09-03 10:31:12,252 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42947'
2025-09-03 10:31:12,255 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:40419'
2025-09-03 10:31:12,259 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42481'
2025-09-03 10:31:12,263 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:39287'
2025-09-03 10:31:12,266 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:36791'
2025-09-03 10:31:12,270 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:38927'
2025-09-03 10:31:12,571 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:33217'
2025-09-03 10:31:12,575 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:45217'
2025-09-03 10:31:12,579 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:35699'
2025-09-03 10:31:12,584 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:38825'
2025-09-03 10:31:12,591 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:40897'
2025-09-03 10:31:12,595 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37425'
2025-09-03 10:31:12,599 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34349'
2025-09-03 10:31:12,604 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37821'
2025-09-03 10:31:12,609 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42737'
2025-09-03 10:31:12,614 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:39619'
2025-09-03 10:31:12,619 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37487'
2025-09-03 10:31:12,624 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42097'
2025-09-03 10:31:12,629 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:36017'
2025-09-03 10:31:13,127 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:39909
2025-09-03 10:31:13,127 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:43387
2025-09-03 10:31:13,127 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:42177
2025-09-03 10:31:13,127 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:42571
2025-09-03 10:31:13,127 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:33435
2025-09-03 10:31:13,127 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:45135
2025-09-03 10:31:13,128 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35061
2025-09-03 10:31:13,128 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:39909
2025-09-03 10:31:13,128 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:43387
2025-09-03 10:31:13,128 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:42177
2025-09-03 10:31:13,128 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:42571
2025-09-03 10:31:13,128 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:33435
2025-09-03 10:31:13,128 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:45135
2025-09-03 10:31:13,128 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35061
2025-09-03 10:31:13,128 - distributed.worker - INFO -          dashboard at:          10.6.101.36:36453
2025-09-03 10:31:13,128 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35977
2025-09-03 10:31:13,128 - distributed.worker - INFO -          dashboard at:          10.6.101.36:43147
2025-09-03 10:31:13,128 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42669
2025-09-03 10:31:13,128 - distributed.worker - INFO -          dashboard at:          10.6.101.36:46611
2025-09-03 10:31:13,128 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35933
2025-09-03 10:31:13,128 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35415
2025-09-03 10:31:13,128 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,128 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,128 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,128 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,128 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,128 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,128 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,128 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,128 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,128 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,128 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,128 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,128 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,128 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,128 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,128 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,128 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,128 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n4yzsd91
2025-09-03 10:31:13,128 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,128 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6gwzdp73
2025-09-03 10:31:13,128 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4i8isibz
2025-09-03 10:31:13,128 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-__uzg1g9
2025-09-03 10:31:13,128 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7krcev0j
2025-09-03 10:31:13,128 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-v3ypc0cj
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pda_kqye
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,128 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,133 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:38955
2025-09-03 10:31:13,133 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:38955
2025-09-03 10:31:13,133 - distributed.worker - INFO -          dashboard at:          10.6.101.36:36337
2025-09-03 10:31:13,133 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,133 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:43313'
2025-09-03 10:31:13,133 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,133 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,133 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,133 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g6vup9a8
2025-09-03 10:31:13,133 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,135 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:45747
2025-09-03 10:31:13,135 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:45747
2025-09-03 10:31:13,135 - distributed.worker - INFO -          dashboard at:          10.6.101.36:46127
2025-09-03 10:31:13,135 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,135 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,135 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,135 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,135 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-f12vxicl
2025-09-03 10:31:13,135 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,136 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:40805
2025-09-03 10:31:13,136 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:40805
2025-09-03 10:31:13,136 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42561
2025-09-03 10:31:13,136 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,136 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,136 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,137 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,137 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-us49xen9
2025-09-03 10:31:13,137 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,140 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35015
2025-09-03 10:31:13,140 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35015
2025-09-03 10:31:13,140 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42395
2025-09-03 10:31:13,140 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,140 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,140 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,140 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,140 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3suhtwim
2025-09-03 10:31:13,140 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,144 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35443
2025-09-03 10:31:13,144 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35443
2025-09-03 10:31:13,144 - distributed.worker - INFO -          dashboard at:          10.6.101.36:33259
2025-09-03 10:31:13,144 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,144 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,144 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,144 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,144 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-yxvjtx3q
2025-09-03 10:31:13,144 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,149 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:39457
2025-09-03 10:31:13,149 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:39457
2025-09-03 10:31:13,149 - distributed.worker - INFO -          dashboard at:          10.6.101.36:37141
2025-09-03 10:31:13,149 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,149 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,149 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,149 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,149 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-apl2ztnm
2025-09-03 10:31:13,149 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,162 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:43211
2025-09-03 10:31:13,163 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:43211
2025-09-03 10:31:13,163 - distributed.worker - INFO -          dashboard at:          10.6.101.36:40937
2025-09-03 10:31:13,163 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,163 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,163 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,163 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,163 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-v1uji0qc
2025-09-03 10:31:13,163 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,390 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:37585
2025-09-03 10:31:13,390 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:37585
2025-09-03 10:31:13,390 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35561
2025-09-03 10:31:13,391 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,391 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,391 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,391 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x4dxx7s6
2025-09-03 10:31:13,391 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,408 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34281
2025-09-03 10:31:13,408 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34281
2025-09-03 10:31:13,408 - distributed.worker - INFO -          dashboard at:          10.6.101.36:34747
2025-09-03 10:31:13,408 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,408 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,408 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,408 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-m6uisqvb
2025-09-03 10:31:13,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,434 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:36153
2025-09-03 10:31:13,434 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:36153
2025-09-03 10:31:13,434 - distributed.worker - INFO -          dashboard at:          10.6.101.36:37293
2025-09-03 10:31:13,434 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,434 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,434 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,434 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,434 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-g1faw7ut
2025-09-03 10:31:13,434 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,438 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:45627
2025-09-03 10:31:13,438 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:45627
2025-09-03 10:31:13,438 - distributed.worker - INFO -          dashboard at:          10.6.101.36:38321
2025-09-03 10:31:13,438 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,438 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,438 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,438 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,438 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7jvdm7ha
2025-09-03 10:31:13,438 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,448 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34669
2025-09-03 10:31:13,449 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34669
2025-09-03 10:31:13,449 - distributed.worker - INFO -          dashboard at:          10.6.101.36:39225
2025-09-03 10:31:13,449 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,449 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,449 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,449 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,449 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8rjg8o13
2025-09-03 10:31:13,449 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,460 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:36005
2025-09-03 10:31:13,460 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:36005
2025-09-03 10:31:13,460 - distributed.worker - INFO -          dashboard at:          10.6.101.36:36965
2025-09-03 10:31:13,460 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,460 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,460 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,460 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,460 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-r_2zjcey
2025-09-03 10:31:13,460 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,472 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:33587
2025-09-03 10:31:13,472 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:33587
2025-09-03 10:31:13,473 - distributed.worker - INFO -          dashboard at:          10.6.101.36:44369
2025-09-03 10:31:13,473 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,473 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,473 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,473 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,473 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lpdfqi2l
2025-09-03 10:31:13,473 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,473 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:37907
2025-09-03 10:31:13,473 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:37907
2025-09-03 10:31:13,473 - distributed.worker - INFO -          dashboard at:          10.6.101.36:44277
2025-09-03 10:31:13,473 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,473 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,473 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,473 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,473 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tgp75ydp
2025-09-03 10:31:13,473 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,484 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35887
2025-09-03 10:31:13,484 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35887
2025-09-03 10:31:13,484 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35361
2025-09-03 10:31:13,485 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,485 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,485 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,485 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,485 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zlehw_qs
2025-09-03 10:31:13,485 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,495 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:36181
2025-09-03 10:31:13,495 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:36181
2025-09-03 10:31:13,495 - distributed.worker - INFO -          dashboard at:          10.6.101.36:43331
2025-09-03 10:31:13,495 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,495 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,495 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,495 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,495 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ek29se3r
2025-09-03 10:31:13,495 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,505 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34183
2025-09-03 10:31:13,505 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34183
2025-09-03 10:31:13,505 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35425
2025-09-03 10:31:13,505 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,505 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,505 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,505 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kyjrvja4
2025-09-03 10:31:13,505 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,507 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35769
2025-09-03 10:31:13,507 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35769
2025-09-03 10:31:13,507 - distributed.worker - INFO -          dashboard at:          10.6.101.36:46847
2025-09-03 10:31:13,507 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,507 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,507 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,508 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,508 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4wm71ng6
2025-09-03 10:31:13,508 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,510 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34587
2025-09-03 10:31:13,510 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34587
2025-09-03 10:31:13,510 - distributed.worker - INFO -          dashboard at:          10.6.101.36:43249
2025-09-03 10:31:13,510 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,510 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,510 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,510 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-djwd3_0b
2025-09-03 10:31:13,510 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,866 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:13,867 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,867 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,868 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:13,871 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:13,872 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,872 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,874 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:13,876 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:13,877 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,877 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,878 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:13,910 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:39413
2025-09-03 10:31:13,910 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:39413
2025-09-03 10:31:13,910 - distributed.worker - INFO -          dashboard at:          10.6.101.36:38141
2025-09-03 10:31:13,910 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,910 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,911 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:13,911 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:13,911 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-sgwoxt34
2025-09-03 10:31:13,911 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,955 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:13,956 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:13,956 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:13,958 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:14,776 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:14,777 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:14,777 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:14,779 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:15,050 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:15,051 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:15,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:15,052 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:15,234 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:15,235 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:15,235 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:15,237 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:15,377 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:15,378 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:15,378 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:15,380 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:15,382 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:15,383 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:15,384 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:15,385 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:15,387 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:15,388 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:15,389 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:15,390 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:15,392 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:15,393 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:15,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:15,395 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:15,397 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:15,398 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:15,398 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:15,400 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:15,403 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:15,404 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:15,404 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:15,406 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,116 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,118 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,120 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,122 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,122 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,124 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,126 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,127 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,127 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,129 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,131 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,132 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,132 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,134 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,137 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,138 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,138 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,140 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,143 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,144 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,144 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,146 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,149 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,150 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,150 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,152 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,154 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,155 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,157 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,160 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,161 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,161 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,163 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,165 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,166 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,167 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,168 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,263 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,264 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,264 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,266 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,269 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,270 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,271 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,272 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,275 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,276 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,277 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,279 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,280 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,281 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,283 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,286 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:17,287 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:17,287 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:17,289 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:17,988 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:33567'
2025-09-03 10:31:18,014 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:46673'
2025-09-03 10:31:18,051 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37617'
2025-09-03 10:31:18,054 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34825'
2025-09-03 10:31:18,058 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:41729'
2025-09-03 10:31:18,062 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:43649'
2025-09-03 10:31:18,117 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34289'
2025-09-03 10:31:18,122 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:43839'
2025-09-03 10:31:18,127 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:45739'
2025-09-03 10:31:18,132 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:43825'
2025-09-03 10:31:18,139 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:41913'
2025-09-03 10:31:18,145 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:38401'
2025-09-03 10:31:18,150 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37287'
2025-09-03 10:31:18,155 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:41695'
2025-09-03 10:31:18,160 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:33177'
2025-09-03 10:31:18,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:41337'
2025-09-03 10:31:18,188 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37983'
2025-09-03 10:31:18,192 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34717'
2025-09-03 10:31:18,196 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:44607'
2025-09-03 10:31:18,200 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:46529'
2025-09-03 10:31:18,204 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:46247'
2025-09-03 10:31:18,218 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37133'
2025-09-03 10:31:18,221 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:46549'
2025-09-03 10:31:18,224 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:40621'
2025-09-03 10:31:18,227 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:43503'
2025-09-03 10:31:18,232 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:35765'
2025-09-03 10:31:18,237 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:43603'
2025-09-03 10:31:18,242 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:39689'
2025-09-03 10:31:18,247 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:33257'
2025-09-03 10:31:18,253 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:44787'
2025-09-03 10:31:18,256 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:44167'
2025-09-03 10:31:18,261 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:36551'
2025-09-03 10:31:18,265 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42179'
2025-09-03 10:31:18,270 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:38501'
2025-09-03 10:31:18,274 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:44421'
2025-09-03 10:31:18,279 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:39537'
2025-09-03 10:31:18,285 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42289'
2025-09-03 10:31:18,290 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:45197'
2025-09-03 10:31:18,317 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:33147'
2025-09-03 10:31:18,321 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:44247'
2025-09-03 10:31:18,325 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42443'
2025-09-03 10:31:18,329 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:41267'
2025-09-03 10:31:18,334 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:32769'
2025-09-03 10:31:18,339 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:45809'
2025-09-03 10:31:18,343 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:45131'
2025-09-03 10:31:18,348 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:39843'
2025-09-03 10:31:18,353 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:36587'
2025-09-03 10:31:18,358 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:38719'
2025-09-03 10:31:18,362 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:33197'
2025-09-03 10:31:18,364 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:40687'
2025-09-03 10:31:18,368 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:41313'
2025-09-03 10:31:18,373 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34709'
2025-09-03 10:31:18,377 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34177'
2025-09-03 10:31:18,380 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34509'
2025-09-03 10:31:18,382 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:38901'
2025-09-03 10:31:18,387 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:42525'
2025-09-03 10:31:18,392 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37279'
2025-09-03 10:31:18,398 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:38907'
2025-09-03 10:31:18,403 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:36369'
2025-09-03 10:31:18,407 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:35949'
2025-09-03 10:31:18,415 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:39899'
2025-09-03 10:31:18,421 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37531'
2025-09-03 10:31:18,426 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:45279'
2025-09-03 10:31:18,432 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:45253'
2025-09-03 10:31:18,619 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:40879'
2025-09-03 10:31:18,623 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:36141'
2025-09-03 10:31:18,627 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:44563'
2025-09-03 10:31:18,632 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:41355'
2025-09-03 10:31:18,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:33607'
2025-09-03 10:31:18,643 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37321'
2025-09-03 10:31:18,646 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:33913'
2025-09-03 10:31:18,652 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34283'
2025-09-03 10:31:18,657 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:39245'
2025-09-03 10:31:18,661 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:37009'
2025-09-03 10:31:18,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:35021'
2025-09-03 10:31:18,671 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.36:34917'
2025-09-03 10:31:18,851 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:44653
2025-09-03 10:31:18,852 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:44653
2025-09-03 10:31:18,852 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42509
2025-09-03 10:31:18,852 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:18,852 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:18,852 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:18,852 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:18,852 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-92soy2wu
2025-09-03 10:31:18,852 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:18,878 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34373
2025-09-03 10:31:18,879 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34373
2025-09-03 10:31:18,879 - distributed.worker - INFO -          dashboard at:          10.6.101.36:38247
2025-09-03 10:31:18,879 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:18,879 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:18,879 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:18,879 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:18,879 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-vxktx9kq
2025-09-03 10:31:18,879 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:18,883 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:18,884 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:18,885 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:18,886 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:18,913 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:18,914 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:18,915 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:18,916 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:19,078 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34391
2025-09-03 10:31:19,078 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34391
2025-09-03 10:31:19,079 - distributed.worker - INFO -          dashboard at:          10.6.101.36:43143
2025-09-03 10:31:19,079 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:19,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,079 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:19,079 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:19,079 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9y61p2jb
2025-09-03 10:31:19,079 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,106 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35169
2025-09-03 10:31:19,106 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35169
2025-09-03 10:31:19,106 - distributed.worker - INFO -          dashboard at:          10.6.101.36:32811
2025-09-03 10:31:19,106 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:19,106 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,106 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:19,106 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:19,106 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lkw0hbw1
2025-09-03 10:31:19,106 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,251 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34409
2025-09-03 10:31:19,251 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34409
2025-09-03 10:31:19,251 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45421
2025-09-03 10:31:19,251 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:19,251 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,251 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:19,251 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:19,251 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-aazd2yym
2025-09-03 10:31:19,251 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,283 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:46531
2025-09-03 10:31:19,283 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:46531
2025-09-03 10:31:19,283 - distributed.worker - INFO -          dashboard at:          10.6.101.36:43431
2025-09-03 10:31:19,283 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:19,283 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,283 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:19,283 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:19,283 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ya939oy8
2025-09-03 10:31:19,283 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,297 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:42941
2025-09-03 10:31:19,297 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:42941
2025-09-03 10:31:19,297 - distributed.worker - INFO -          dashboard at:          10.6.101.36:32815
2025-09-03 10:31:19,297 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:19,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,297 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:19,297 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:19,297 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-xcy9ydse
2025-09-03 10:31:19,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,303 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:39449
2025-09-03 10:31:19,303 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:39449
2025-09-03 10:31:19,303 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45611
2025-09-03 10:31:19,303 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:19,303 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,303 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:19,303 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:19,303 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-7puzawlk
2025-09-03 10:31:19,303 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,304 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:40067
2025-09-03 10:31:19,305 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:40067
2025-09-03 10:31:19,305 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35891
2025-09-03 10:31:19,305 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:19,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,305 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:19,305 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:19,305 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-kb3cnx9k
2025-09-03 10:31:19,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,393 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:19,394 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:19,394 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,395 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:19,399 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:19,400 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:19,400 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:19,402 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:20,324 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:36019
2025-09-03 10:31:20,324 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:36019
2025-09-03 10:31:20,324 - distributed.worker - INFO -          dashboard at:          10.6.101.36:36575
2025-09-03 10:31:20,324 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,324 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,324 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,324 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,324 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-h7njg_pu
2025-09-03 10:31:20,324 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,332 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:39421
2025-09-03 10:31:20,333 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:39421
2025-09-03 10:31:20,333 - distributed.worker - INFO -          dashboard at:          10.6.101.36:38715
2025-09-03 10:31:20,333 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,333 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,333 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,333 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-eufx72x1
2025-09-03 10:31:20,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,371 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35459
2025-09-03 10:31:20,371 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35459
2025-09-03 10:31:20,371 - distributed.worker - INFO -          dashboard at:          10.6.101.36:37053
2025-09-03 10:31:20,371 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,371 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,371 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,371 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-lt_rlpc2
2025-09-03 10:31:20,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,377 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:41339
2025-09-03 10:31:20,377 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:41339
2025-09-03 10:31:20,377 - distributed.worker - INFO -          dashboard at:          10.6.101.36:39653
2025-09-03 10:31:20,377 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,377 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,377 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,377 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,377 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5s2ogn13
2025-09-03 10:31:20,377 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,386 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:41303
2025-09-03 10:31:20,386 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:41303
2025-09-03 10:31:20,386 - distributed.worker - INFO -          dashboard at:          10.6.101.36:44195
2025-09-03 10:31:20,386 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,386 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,386 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,386 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,386 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3cr2unky
2025-09-03 10:31:20,386 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,391 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:37743
2025-09-03 10:31:20,391 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:37743
2025-09-03 10:31:20,391 - distributed.worker - INFO -          dashboard at:          10.6.101.36:44857
2025-09-03 10:31:20,391 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,392 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,392 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,392 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,392 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uyk70mqe
2025-09-03 10:31:20,392 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,396 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:41039
2025-09-03 10:31:20,396 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:41039
2025-09-03 10:31:20,396 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42593
2025-09-03 10:31:20,396 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,396 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,396 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,396 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,396 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-drd2d13u
2025-09-03 10:31:20,396 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,401 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:44647
2025-09-03 10:31:20,401 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:44647
2025-09-03 10:31:20,401 - distributed.worker - INFO -          dashboard at:          10.6.101.36:38601
2025-09-03 10:31:20,401 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,401 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,401 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,401 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,402 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u58tlal2
2025-09-03 10:31:20,402 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,406 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35895
2025-09-03 10:31:20,406 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35895
2025-09-03 10:31:20,406 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42867
2025-09-03 10:31:20,406 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,406 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,406 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,406 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,406 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5ecg1yq5
2025-09-03 10:31:20,406 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,410 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:36173
2025-09-03 10:31:20,410 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:36173
2025-09-03 10:31:20,410 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45201
2025-09-03 10:31:20,411 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,411 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,411 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,411 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-uv_mteze
2025-09-03 10:31:20,411 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,416 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:39213
2025-09-03 10:31:20,416 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:39213
2025-09-03 10:31:20,416 - distributed.worker - INFO -          dashboard at:          10.6.101.36:38111
2025-09-03 10:31:20,416 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,416 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,416 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,416 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,416 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-atkipqpa
2025-09-03 10:31:20,416 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,419 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:42647
2025-09-03 10:31:20,419 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:42647
2025-09-03 10:31:20,419 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35785
2025-09-03 10:31:20,419 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,419 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,419 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,420 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,420 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-a2gvas2l
2025-09-03 10:31:20,420 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,423 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:41117
2025-09-03 10:31:20,423 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:41117
2025-09-03 10:31:20,423 - distributed.worker - INFO -          dashboard at:          10.6.101.36:36101
2025-09-03 10:31:20,423 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,423 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:41175
2025-09-03 10:31:20,423 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,423 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,423 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:41175
2025-09-03 10:31:20,423 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,423 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45125
2025-09-03 10:31:20,423 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2urhrxcs
2025-09-03 10:31:20,423 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,423 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,423 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,423 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,423 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,423 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-i0_1pqe1
2025-09-03 10:31:20,423 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,555 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:42329
2025-09-03 10:31:20,555 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:42329
2025-09-03 10:31:20,555 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42399
2025-09-03 10:31:20,555 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,555 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,555 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,555 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-2r__xwuo
2025-09-03 10:31:20,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,564 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:39185
2025-09-03 10:31:20,564 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:39185
2025-09-03 10:31:20,564 - distributed.worker - INFO -          dashboard at:          10.6.101.36:44753
2025-09-03 10:31:20,564 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,564 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,564 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,564 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bvlw39jp
2025-09-03 10:31:20,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,602 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:46591
2025-09-03 10:31:20,602 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:46591
2025-09-03 10:31:20,602 - distributed.worker - INFO -          dashboard at:          10.6.101.36:40275
2025-09-03 10:31:20,602 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,602 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,602 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,603 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-qedfhmew
2025-09-03 10:31:20,603 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,624 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:46111
2025-09-03 10:31:20,624 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:46111
2025-09-03 10:31:20,624 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45867
2025-09-03 10:31:20,624 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,624 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,624 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,624 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,624 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8oy6x22w
2025-09-03 10:31:20,624 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,628 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:43227
2025-09-03 10:31:20,628 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:43227
2025-09-03 10:31:20,628 - distributed.worker - INFO -          dashboard at:          10.6.101.36:41701
2025-09-03 10:31:20,628 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,628 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,628 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,628 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-evnukwig
2025-09-03 10:31:20,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,628 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:33031
2025-09-03 10:31:20,628 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:33031
2025-09-03 10:31:20,628 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42629
2025-09-03 10:31:20,628 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,628 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,628 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,628 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-y_df_y75
2025-09-03 10:31:20,628 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,630 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:44311
2025-09-03 10:31:20,631 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:44311
2025-09-03 10:31:20,631 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42145
2025-09-03 10:31:20,631 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,631 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,631 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,631 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-n2xpqdxq
2025-09-03 10:31:20,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,662 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:42739
2025-09-03 10:31:20,662 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:42739
2025-09-03 10:31:20,662 - distributed.worker - INFO -          dashboard at:          10.6.101.36:40611
2025-09-03 10:31:20,662 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,662 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,662 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,662 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-4maagv_y
2025-09-03 10:31:20,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,702 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:46457
2025-09-03 10:31:20,702 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:46457
2025-09-03 10:31:20,702 - distributed.worker - INFO -          dashboard at:          10.6.101.36:40627
2025-09-03 10:31:20,702 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,702 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,702 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,702 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-bv_9mm46
2025-09-03 10:31:20,702 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,715 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:45175
2025-09-03 10:31:20,715 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:45175
2025-09-03 10:31:20,715 - distributed.worker - INFO -          dashboard at:          10.6.101.36:38999
2025-09-03 10:31:20,715 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,715 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,715 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,715 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,715 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tmdnfgmz
2025-09-03 10:31:20,715 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,726 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:33811
2025-09-03 10:31:20,726 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:33811
2025-09-03 10:31:20,726 - distributed.worker - INFO -          dashboard at:          10.6.101.36:41249
2025-09-03 10:31:20,726 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,726 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,726 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,726 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0rifzych
2025-09-03 10:31:20,726 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,855 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:20,857 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,857 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,858 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:42225
2025-09-03 10:31:20,858 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:42225
2025-09-03 10:31:20,858 - distributed.worker - INFO -          dashboard at:          10.6.101.36:43843
2025-09-03 10:31:20,858 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:20,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,858 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:20,858 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:20,858 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9_d_ingm
2025-09-03 10:31:20,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:20,859 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:21,114 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:21,115 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,117 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:21,150 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:21,151 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,151 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,153 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:21,157 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:21,158 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,158 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,160 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:21,164 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:21,165 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,165 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,167 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:21,178 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:21,180 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,180 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,181 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:21,491 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:21,492 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,493 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,494 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:21,539 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:46311
2025-09-03 10:31:21,539 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:46311
2025-09-03 10:31:21,539 - distributed.worker - INFO -          dashboard at:          10.6.101.36:39783
2025-09-03 10:31:21,539 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,539 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,539 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,540 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0_u5t8rq
2025-09-03 10:31:21,540 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,544 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:41199
2025-09-03 10:31:21,544 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:41199
2025-09-03 10:31:21,544 - distributed.worker - INFO -          dashboard at:          10.6.101.36:37473
2025-09-03 10:31:21,544 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,544 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,544 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,544 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,544 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-zyhxa49p
2025-09-03 10:31:21,544 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,547 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:44723
2025-09-03 10:31:21,547 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:44723
2025-09-03 10:31:21,547 - distributed.worker - INFO -          dashboard at:          10.6.101.36:43803
2025-09-03 10:31:21,547 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:44577
2025-09-03 10:31:21,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,547 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:38019
2025-09-03 10:31:21,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,547 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:44577
2025-09-03 10:31:21,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,547 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:38019
2025-09-03 10:31:21,547 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42691
2025-09-03 10:31:21,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,547 - distributed.worker - INFO -          dashboard at:          10.6.101.36:44587
2025-09-03 10:31:21,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,547 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-m_labfj1
2025-09-03 10:31:21,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,547 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,547 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,547 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,547 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x67udd8z
2025-09-03 10:31:21,547 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-8zms9so0
2025-09-03 10:31:21,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,547 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,550 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:42987
2025-09-03 10:31:21,550 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:42987
2025-09-03 10:31:21,550 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35177
2025-09-03 10:31:21,550 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,550 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,550 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,550 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,550 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_p0krhea
2025-09-03 10:31:21,550 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,551 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:38761
2025-09-03 10:31:21,551 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:38761
2025-09-03 10:31:21,552 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45585
2025-09-03 10:31:21,552 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,552 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,552 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,552 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-u2r5eooj
2025-09-03 10:31:21,552 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,552 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:37829
2025-09-03 10:31:21,552 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:37829
2025-09-03 10:31:21,552 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45519
2025-09-03 10:31:21,552 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,553 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,553 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,553 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rts3t6dm
2025-09-03 10:31:21,553 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,555 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:44981
2025-09-03 10:31:21,555 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:44981
2025-09-03 10:31:21,555 - distributed.worker - INFO -          dashboard at:          10.6.101.36:34309
2025-09-03 10:31:21,555 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,555 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,555 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,555 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3n3xwwrt
2025-09-03 10:31:21,555 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,556 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:37951
2025-09-03 10:31:21,556 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:37951
2025-09-03 10:31:21,556 - distributed.worker - INFO -          dashboard at:          10.6.101.36:39223
2025-09-03 10:31:21,556 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,556 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,556 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,556 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-473wa12w
2025-09-03 10:31:21,556 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,556 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:42701
2025-09-03 10:31:21,557 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:42701
2025-09-03 10:31:21,557 - distributed.worker - INFO -          dashboard at:          10.6.101.36:44683
2025-09-03 10:31:21,557 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,557 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,557 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,557 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,557 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ixhg55lt
2025-09-03 10:31:21,557 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,563 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:40281
2025-09-03 10:31:21,563 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:40281
2025-09-03 10:31:21,563 - distributed.worker - INFO -          dashboard at:          10.6.101.36:36015
2025-09-03 10:31:21,563 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,563 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,563 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,564 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,564 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-0po18_l_
2025-09-03 10:31:21,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,564 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:38215
2025-09-03 10:31:21,564 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:38215
2025-09-03 10:31:21,564 - distributed.worker - INFO -          dashboard at:          10.6.101.36:34671
2025-09-03 10:31:21,564 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,564 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,564 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,564 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-9yah_bld
2025-09-03 10:31:21,564 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,564 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34479
2025-09-03 10:31:21,564 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34479
2025-09-03 10:31:21,564 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45691
2025-09-03 10:31:21,565 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,565 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,565 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,565 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,565 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-a_unx4x8
2025-09-03 10:31:21,565 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,566 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:40849
2025-09-03 10:31:21,566 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:40849
2025-09-03 10:31:21,566 - distributed.worker - INFO -          dashboard at:          10.6.101.36:37109
2025-09-03 10:31:21,566 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,566 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,566 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,566 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6tko38i9
2025-09-03 10:31:21,566 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,567 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:37471
2025-09-03 10:31:21,567 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:37471
2025-09-03 10:31:21,567 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42497
2025-09-03 10:31:21,567 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,567 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,567 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:37381
2025-09-03 10:31:21,567 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,567 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:37381
2025-09-03 10:31:21,567 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-tywe7yq0
2025-09-03 10:31:21,567 - distributed.worker - INFO -          dashboard at:          10.6.101.36:34801
2025-09-03 10:31:21,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,567 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,567 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,567 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,567 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-avg5yey6
2025-09-03 10:31:21,567 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:43309
2025-09-03 10:31:21,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,567 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:43309
2025-09-03 10:31:21,567 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42085
2025-09-03 10:31:21,567 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,567 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,568 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,568 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,568 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-cuv0j2ws
2025-09-03 10:31:21,568 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,570 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:38221
2025-09-03 10:31:21,570 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:38221
2025-09-03 10:31:21,570 - distributed.worker - INFO -          dashboard at:          10.6.101.36:37217
2025-09-03 10:31:21,570 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,570 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,570 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,570 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,570 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-oo09axxs
2025-09-03 10:31:21,570 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,571 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:37285
2025-09-03 10:31:21,571 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:37285
2025-09-03 10:31:21,571 - distributed.worker - INFO -          dashboard at:          10.6.101.36:44415
2025-09-03 10:31:21,571 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,571 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,571 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,571 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,571 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_db3_bbv
2025-09-03 10:31:21,571 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,574 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34885
2025-09-03 10:31:21,574 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34885
2025-09-03 10:31:21,574 - distributed.worker - INFO -          dashboard at:          10.6.101.36:39965
2025-09-03 10:31:21,574 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,574 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,574 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,574 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:33543
2025-09-03 10:31:21,574 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-pbx8k5s_
2025-09-03 10:31:21,574 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:33543
2025-09-03 10:31:21,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,574 - distributed.worker - INFO -          dashboard at:          10.6.101.36:39067
2025-09-03 10:31:21,574 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,574 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,574 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,574 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-poj_12k2
2025-09-03 10:31:21,574 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,575 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:46593
2025-09-03 10:31:21,575 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:46593
2025-09-03 10:31:21,575 - distributed.worker - INFO -          dashboard at:          10.6.101.36:38041
2025-09-03 10:31:21,575 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,575 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,575 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,575 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,575 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-dzlkbk7f
2025-09-03 10:31:21,575 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,586 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:45073
2025-09-03 10:31:21,586 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:45073
2025-09-03 10:31:21,586 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35997
2025-09-03 10:31:21,586 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,586 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,586 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,586 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,586 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3iignuv0
2025-09-03 10:31:21,586 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,586 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:46429
2025-09-03 10:31:21,586 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:46429
2025-09-03 10:31:21,586 - distributed.worker - INFO -          dashboard at:          10.6.101.36:46409
2025-09-03 10:31:21,586 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,586 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,586 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,586 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,587 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-l8p071rx
2025-09-03 10:31:21,587 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,591 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35359
2025-09-03 10:31:21,591 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35359
2025-09-03 10:31:21,591 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45029
2025-09-03 10:31:21,591 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,591 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,591 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,591 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,592 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-r28gosjn
2025-09-03 10:31:21,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,592 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34175
2025-09-03 10:31:21,592 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34175
2025-09-03 10:31:21,592 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42657
2025-09-03 10:31:21,592 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,592 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,592 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,592 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-rs9mer1y
2025-09-03 10:31:21,592 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,594 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:36981
2025-09-03 10:31:21,594 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:36981
2025-09-03 10:31:21,594 - distributed.worker - INFO -          dashboard at:          10.6.101.36:40075
2025-09-03 10:31:21,594 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,594 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,594 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,594 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-69q0sut7
2025-09-03 10:31:21,594 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,596 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:44817
2025-09-03 10:31:21,596 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:44817
2025-09-03 10:31:21,596 - distributed.worker - INFO -          dashboard at:          10.6.101.36:37443
2025-09-03 10:31:21,596 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,596 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,596 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,596 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-mqbm2008
2025-09-03 10:31:21,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,601 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:44939
2025-09-03 10:31:21,601 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:44939
2025-09-03 10:31:21,601 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42983
2025-09-03 10:31:21,601 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,601 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,601 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,601 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,601 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-z2dh0ohm
2025-09-03 10:31:21,601 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,602 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:43373
2025-09-03 10:31:21,602 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:43373
2025-09-03 10:31:21,602 - distributed.worker - INFO -          dashboard at:          10.6.101.36:36191
2025-09-03 10:31:21,602 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,602 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,602 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,602 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-_xj1nsm4
2025-09-03 10:31:21,602 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,602 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:45167
2025-09-03 10:31:21,603 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:45167
2025-09-03 10:31:21,603 - distributed.worker - INFO -          dashboard at:          10.6.101.36:44279
2025-09-03 10:31:21,603 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,603 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,603 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,603 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,603 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-irg4mnwq
2025-09-03 10:31:21,603 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,604 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:40433
2025-09-03 10:31:21,604 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:40433
2025-09-03 10:31:21,604 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35999
2025-09-03 10:31:21,604 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,604 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,604 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,604 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-6gapo4gs
2025-09-03 10:31:21,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,604 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:36891
2025-09-03 10:31:21,604 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:36891
2025-09-03 10:31:21,604 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35527
2025-09-03 10:31:21,604 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,604 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,604 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,604 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,605 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-x34cqsoq
2025-09-03 10:31:21,605 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,605 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:38875
2025-09-03 10:31:21,605 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:38875
2025-09-03 10:31:21,605 - distributed.worker - INFO -          dashboard at:          10.6.101.36:45409
2025-09-03 10:31:21,605 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,605 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,605 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,605 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,605 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-5gxpzqw8
2025-09-03 10:31:21,605 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,609 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:39755
2025-09-03 10:31:21,609 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:39755
2025-09-03 10:31:21,609 - distributed.worker - INFO -          dashboard at:          10.6.101.36:35297
2025-09-03 10:31:21,609 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,609 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,609 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,609 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,609 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-js7j7l5a
2025-09-03 10:31:21,609 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,612 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34693
2025-09-03 10:31:21,613 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34693
2025-09-03 10:31:21,613 - distributed.worker - INFO -          dashboard at:          10.6.101.36:36633
2025-09-03 10:31:21,613 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,613 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,613 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,613 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,613 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-mjcrys_y
2025-09-03 10:31:21,613 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,616 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:39479
2025-09-03 10:31:21,616 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:39479
2025-09-03 10:31:21,616 - distributed.worker - INFO -          dashboard at:          10.6.101.36:36473
2025-09-03 10:31:21,616 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,616 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,616 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,616 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,616 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-71edt9m4
2025-09-03 10:31:21,616 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,622 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:35735
2025-09-03 10:31:21,622 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:35735
2025-09-03 10:31:21,622 - distributed.worker - INFO -          dashboard at:          10.6.101.36:42993
2025-09-03 10:31:21,622 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,622 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,622 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,622 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-fvb8s460
2025-09-03 10:31:21,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,643 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:38395
2025-09-03 10:31:21,643 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:38395
2025-09-03 10:31:21,643 - distributed.worker - INFO -          dashboard at:          10.6.101.36:41173
2025-09-03 10:31:21,643 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,643 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,643 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,643 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,643 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-3tvrzbf9
2025-09-03 10:31:21,643 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,647 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.36:34021
2025-09-03 10:31:21,647 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.36:34021
2025-09-03 10:31:21,647 - distributed.worker - INFO -          dashboard at:          10.6.101.36:37513
2025-09-03 10:31:21,647 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,647 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,647 - distributed.worker - INFO -               Threads:                          1
2025-09-03 10:31:21,647 - distributed.worker - INFO -                Memory:                   4.81 GiB
2025-09-03 10:31:21,647 - distributed.worker - INFO -       Local Directory: /jobfs/148606947.gadi-pbs/dask-scratch-space/worker-ja9junw9
2025-09-03 10:31:21,647 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,919 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:21,920 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,921 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,922 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:21,956 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:21,957 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,958 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,959 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:21,993 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:21,994 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:21,994 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:21,996 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:22,007 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:22,009 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:22,009 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:22,010 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:22,052 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:22,053 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:22,053 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:22,055 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:26,755 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:26,757 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:26,757 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:26,759 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:26,770 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:26,771 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:26,771 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:26,773 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,229 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,230 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,230 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,232 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,238 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,239 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,239 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,241 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,246 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,247 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,248 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,249 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,254 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,256 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,257 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,279 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,280 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,282 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,287 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,288 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,290 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,295 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,296 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,296 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,298 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,303 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,305 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,305 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,306 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,732 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,733 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,734 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,735 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,740 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,741 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,742 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,743 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,749 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,751 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,751 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,752 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,765 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,767 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,767 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,768 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,773 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,775 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,776 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,782 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,784 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,784 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,786 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,790 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,791 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,791 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,793 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,799 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,800 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,802 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,806 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,808 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,808 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,810 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,814 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,816 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,816 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,818 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,823 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,825 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,825 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,826 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,831 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,833 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,833 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,835 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,841 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,841 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,843 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,848 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,849 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,849 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,851 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,856 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,858 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,858 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,860 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,865 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,866 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,866 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,868 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,873 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,874 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,874 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,876 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,881 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,882 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,883 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,885 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,889 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,891 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,891 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,893 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,898 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,899 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,899 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,901 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,906 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,907 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,907 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,909 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,914 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,915 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,915 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,917 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,922 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,923 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,923 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,925 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,930 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,932 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,932 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,933 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,939 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,940 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,940 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,942 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:28,950 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:28,955 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:28,955 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:28,960 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,161 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,163 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,163 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,165 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,170 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,172 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,173 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,179 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,180 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,180 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,182 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,188 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,189 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,189 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,191 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,197 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,198 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,198 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,200 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,206 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,207 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,207 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,209 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,215 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,216 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,216 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,218 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,224 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,226 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,226 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,227 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,233 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,234 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,235 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,236 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,242 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,243 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,243 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,245 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,250 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,252 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,252 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,254 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,260 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,262 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,262 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,264 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,269 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,271 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,271 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,273 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,278 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,280 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,282 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,287 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,288 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,289 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,290 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,296 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,297 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,299 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,305 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,307 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,307 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,309 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,314 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,316 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,316 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,318 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,323 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,324 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,325 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,326 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,332 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,333 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,333 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,335 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,341 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,342 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,342 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,344 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:31,350 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:31,352 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:31,352 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:31,353 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:35,543 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:35,545 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,545 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,546 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:35,595 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 10:31:35,596 - distributed.worker - INFO -         Registered to:      tcp://10.6.82.69:8735
2025-09-03 10:31:35,596 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 10:31:35,598 - distributed.core - INFO - Starting established connection to tcp://10.6.82.69:8735
2025-09-03 10:31:51,860 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:31:59,234 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:31:59,243 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:31:59,255 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:31:59,263 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:31:59,285 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:31:59,293 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:31:59,301 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:31:59,309 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:06,551 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:22,862 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:32:53,860 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.82.69:8735 after 30 s
2025-09-03 10:35:51,476 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,482 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,609 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,615 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,729 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,733 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,957 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,958 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,967 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:51,968 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:51,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,068 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,069 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,082 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,085 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,091 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,096 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,111 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,112 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,113 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,119 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:52,123 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:52,124 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,114 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,115 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,122 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,124 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,152 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,154 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,163 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,169 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,316 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,318 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,398 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,402 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,404 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,404 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,465 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,467 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,531 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,533 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,560 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,563 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,884 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,885 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:53,926 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:53,929 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,055 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,061 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,065 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,071 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,249 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,252 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,257 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,262 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,267 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,268 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,287 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,291 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,333 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,335 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,356 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,358 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,364 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,368 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,370 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,374 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,440 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,445 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,561 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,563 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,632 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,634 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,800 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,805 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,842 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,846 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,876 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,878 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,891 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,893 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,942 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,947 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:54,976 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:54,982 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,227 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,232 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,264 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,267 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,301 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,303 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,316 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,322 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,340 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,342 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,362 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,367 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,462 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,462 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,464 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,468 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,489 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,490 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,664 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,665 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,755 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,757 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,797 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,804 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,810 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,815 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,843 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,844 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:55,844 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:55,847 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,261 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,262 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,286 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,289 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,369 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,369 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,372 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,374 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,619 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,625 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,660 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,661 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,892 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,894 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,908 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,913 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:56,951 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:56,953 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,069 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,074 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,100 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,106 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,116 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,117 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,224 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,229 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,226 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,231 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,240 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,246 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,278 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,280 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,602 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,604 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,634 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,636 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,645 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,647 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,811 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,816 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:57,961 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:57,969 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,167 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,169 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,178 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,179 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,242 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,244 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:58,800 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:58,805 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,070 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,075 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,539 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,541 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,886 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,887 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:35:59,931 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:35:59,933 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:00,300 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:00,301 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,894 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,899 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:01,941 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:01,947 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,350 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,351 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,675 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:02,713 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:02,718 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,081 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,087 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,234 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,240 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,256 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,261 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,889 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,892 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:03,949 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:03,954 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,228 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,229 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:04,619 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:04,623 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:10,228 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:10,231 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:11,574 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:11,579 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:11,743 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:11,744 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:12,712 - distributed.worker - INFO - Starting Worker plugin qme_utils.pyb42042ae-8929-4a91-b24e-81cc14c9ec9c
2025-09-03 10:36:12,718 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 10:36:22,759 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,757 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,761 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,761 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,762 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,763 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,764 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,764 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,766 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,771 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,771 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,770 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,773 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,774 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,775 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,775 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,777 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,781 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,893 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,895 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,920 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,923 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:22,931 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:22,933 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,405 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,411 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,411 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,413 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,495 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,542 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,542 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,544 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,543 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,548 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,549 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,551 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,555 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,558 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,560 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,563 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,796 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,799 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,830 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,830 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,832 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,832 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,833 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,835 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,840 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,841 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,842 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,844 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,849 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,851 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,863 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,865 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,869 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,871 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,871 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,873 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,878 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,880 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,888 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,890 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,892 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,894 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,894 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,894 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:23,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:23,896 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,035 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,037 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,037 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,038 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,039 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,039 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,068 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,070 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,074 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,077 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,078 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,079 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,091 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,093 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,097 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,099 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,100 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,102 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,113 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,114 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,115 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,117 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,119 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,122 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,125 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,127 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,128 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,130 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,232 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,234 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,235 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,237 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,233 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,246 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,331 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,333 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,336 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,339 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,344 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,346 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,350 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,352 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,387 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,389 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,393 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,395 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,395 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,397 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,398 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,400 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,429 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,431 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,436 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,438 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,444 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,450 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,452 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,452 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,459 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,461 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,496 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,503 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,505 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,505 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,508 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,511 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,513 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,628 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,630 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,638 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,640 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,642 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,644 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,660 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,661 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,684 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,687 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,689 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,691 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,740 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,741 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,755 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,757 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,852 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,854 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,855 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,856 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,931 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,932 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,938 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,943 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,968 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,970 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,972 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,974 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:24,986 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:24,988 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,037 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,039 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,053 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,055 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,398 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,400 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,526 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,528 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,711 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,713 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,724 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,726 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,819 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,821 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,864 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,867 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,869 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,872 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:25,967 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:25,969 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,059 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,060 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,230 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,232 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,320 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,322 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,506 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,508 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,554 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,556 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:26,569 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:26,572 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:27,222 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:27,224 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 10:36:28,160 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyec4441cf-c514-4464-8e81-e2d1e307d220
2025-09-03 10:36:28,165 - distributed.utils - INFO - Reload module qme_vars from .py file
