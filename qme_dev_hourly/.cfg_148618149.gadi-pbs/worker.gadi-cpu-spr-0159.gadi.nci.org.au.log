Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 13:15:17,356 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:41047'
2025-09-03 13:15:17,364 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:36481'
2025-09-03 13:15:17,368 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:41571'
2025-09-03 13:15:17,372 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34015'
2025-09-03 13:15:17,377 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34701'
2025-09-03 13:15:17,381 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34229'
2025-09-03 13:15:17,385 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:37389'
2025-09-03 13:15:17,389 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39593'
2025-09-03 13:15:17,395 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:35691'
2025-09-03 13:15:17,399 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:43325'
2025-09-03 13:15:17,403 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:43543'
2025-09-03 13:15:17,409 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:40307'
2025-09-03 13:15:17,413 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:38819'
2025-09-03 13:15:17,417 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:46243'
2025-09-03 13:15:17,421 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:46129'
2025-09-03 13:15:17,426 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:41247'
2025-09-03 13:15:17,432 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39629'
2025-09-03 13:15:17,436 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:36451'
2025-09-03 13:15:17,440 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:44967'
2025-09-03 13:15:17,445 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:46739'
2025-09-03 13:15:17,593 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34779'
2025-09-03 13:15:17,598 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:37869'
2025-09-03 13:15:17,602 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:45627'
2025-09-03 13:15:17,606 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:45737'
2025-09-03 13:15:17,611 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:42989'
2025-09-03 13:15:17,615 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39983'
2025-09-03 13:15:17,620 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:43373'
2025-09-03 13:15:17,629 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34807'
2025-09-03 13:15:17,633 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39181'
2025-09-03 13:15:17,637 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:35651'
2025-09-03 13:15:17,641 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:38619'
2025-09-03 13:15:17,646 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:42307'
2025-09-03 13:15:17,651 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:45513'
2025-09-03 13:15:17,656 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:45439'
2025-09-03 13:15:17,660 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:45457'
2025-09-03 13:15:17,665 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:40229'
2025-09-03 13:15:17,668 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:40181'
2025-09-03 13:15:17,672 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34731'
2025-09-03 13:15:17,676 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:41597'
2025-09-03 13:15:17,680 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34949'
2025-09-03 13:15:17,684 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34319'
2025-09-03 13:15:17,689 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:32825'
2025-09-03 13:15:17,693 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:46485'
2025-09-03 13:15:17,696 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:34829'
2025-09-03 13:15:17,702 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:43079'
2025-09-03 13:15:17,706 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:38501'
2025-09-03 13:15:17,711 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:41979'
2025-09-03 13:15:17,714 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:37433'
2025-09-03 13:15:17,719 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:36917'
2025-09-03 13:15:17,722 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:39127'
2025-09-03 13:15:17,725 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:46183'
2025-09-03 13:15:17,729 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.83.15:40317'
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:33301
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:45453
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:39277
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:45453
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:40825
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35827
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:40847
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37785
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:34751
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41587
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36523
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:33301
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35589
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:46339
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:39277
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:40919
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:40825
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35827
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:40847
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37785
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:34751
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41587
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36523
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:46073
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35589
2025-09-03 13:15:18,801 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:46339
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:36453
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:40767
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:41805
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:41815
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39669
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37679
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:36465
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:43181
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:33371
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO -          dashboard at:           10.6.83.15:34185
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,801 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,801 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,801 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,801 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-ydllse2l
2025-09-03 13:15:18,802 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,802 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,802 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,802 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,802 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-gy3e9jzo
2025-09-03 13:15:18,802 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-sd4vyqow
2025-09-03 13:15:18,802 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-qinxo2il
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-nx2nu90h
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-6ct2dgyn
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-fqgjg2ct
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-_kkiktga
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-vvnmctvy
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-u5fpse3z
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-kg8pqehj
2025-09-03 13:15:18,802 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-ne_fxym3
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,809 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37719
2025-09-03 13:15:18,809 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37719
2025-09-03 13:15:18,809 - distributed.worker - INFO -          dashboard at:           10.6.83.15:41961
2025-09-03 13:15:18,809 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,809 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,809 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,809 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,809 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-hxa9sa5c
2025-09-03 13:15:18,809 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,810 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41025
2025-09-03 13:15:18,810 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41025
2025-09-03 13:15:18,810 - distributed.worker - INFO -          dashboard at:           10.6.83.15:34537
2025-09-03 13:15:18,810 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,810 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,810 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,810 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,810 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-yavnrd6v
2025-09-03 13:15:18,810 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,811 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41301
2025-09-03 13:15:18,811 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41301
2025-09-03 13:15:18,811 - distributed.worker - INFO -          dashboard at:           10.6.83.15:42805
2025-09-03 13:15:18,811 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:43267
2025-09-03 13:15:18,811 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,811 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,811 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:43267
2025-09-03 13:15:18,811 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,811 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,811 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37403
2025-09-03 13:15:18,811 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,811 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-7lk2ap15
2025-09-03 13:15:18,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,812 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,812 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,812 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-top3n_l4
2025-09-03 13:15:18,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,813 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:39445
2025-09-03 13:15:18,813 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:39445
2025-09-03 13:15:18,813 - distributed.worker - INFO -          dashboard at:           10.6.83.15:38445
2025-09-03 13:15:18,813 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,813 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,813 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,813 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,813 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-u54rrr7w
2025-09-03 13:15:18,813 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,814 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:42291
2025-09-03 13:15:18,814 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:42291
2025-09-03 13:15:18,814 - distributed.worker - INFO -          dashboard at:           10.6.83.15:38179
2025-09-03 13:15:18,814 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,814 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,814 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,814 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-0wu1s5d_
2025-09-03 13:15:18,814 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,828 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,829 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,829 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,830 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,833 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:45427
2025-09-03 13:15:18,833 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:45427
2025-09-03 13:15:18,833 - distributed.worker - INFO -          dashboard at:           10.6.83.15:44565
2025-09-03 13:15:18,833 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,833 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,833 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,833 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,833 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-x64o3cy5
2025-09-03 13:15:18,833 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,839 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,840 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,840 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,842 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,847 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,848 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,848 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,850 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,854 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,855 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,855 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,857 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,861 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,862 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,862 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,864 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,865 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,866 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,867 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,868 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,870 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,871 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,871 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,873 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,875 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,876 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,876 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,878 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,879 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,880 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,880 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,882 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,883 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37957
2025-09-03 13:15:18,883 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37957
2025-09-03 13:15:18,883 - distributed.worker - INFO -          dashboard at:           10.6.83.15:34983
2025-09-03 13:15:18,883 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,883 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,883 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,883 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,883 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-msgm9shn
2025-09-03 13:15:18,883 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,883 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,884 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,885 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,886 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,888 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,889 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,889 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:40839
2025-09-03 13:15:18,889 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:40839
2025-09-03 13:15:18,889 - distributed.worker - INFO -          dashboard at:           10.6.83.15:35805
2025-09-03 13:15:18,889 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,889 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,889 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,889 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-_2kn49w_
2025-09-03 13:15:18,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,891 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,892 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,893 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,893 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,894 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:34115
2025-09-03 13:15:18,894 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:34115
2025-09-03 13:15:18,894 - distributed.worker - INFO -          dashboard at:           10.6.83.15:40169
2025-09-03 13:15:18,894 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,894 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,894 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,894 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,894 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-nrbi39jx
2025-09-03 13:15:18,894 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,895 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,896 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,897 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,897 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,899 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,900 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,901 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,901 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,902 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:42203
2025-09-03 13:15:18,902 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:42203
2025-09-03 13:15:18,902 - distributed.worker - INFO -          dashboard at:           10.6.83.15:42235
2025-09-03 13:15:18,902 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,902 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,902 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,902 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,902 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-8__2p9ca
2025-09-03 13:15:18,902 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,903 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,904 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,905 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,906 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,907 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,908 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,909 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,909 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,911 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,912 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,913 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,914 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,915 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,917 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,918 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,918 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,920 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,921 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,922 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,922 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,924 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,930 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35857
2025-09-03 13:15:18,930 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35857
2025-09-03 13:15:18,930 - distributed.worker - INFO -          dashboard at:           10.6.83.15:43905
2025-09-03 13:15:18,930 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,930 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,930 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,930 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,931 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-cn7yr983
2025-09-03 13:15:18,931 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,944 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,945 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,945 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,946 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,949 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,950 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,950 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,952 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,953 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,954 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,954 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,955 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,957 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,958 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,958 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,960 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,961 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35681
2025-09-03 13:15:18,961 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35681
2025-09-03 13:15:18,961 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39449
2025-09-03 13:15:18,961 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,961 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,961 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,961 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,961 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-z7atl0q9
2025-09-03 13:15:18,961 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,961 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,961 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:43699
2025-09-03 13:15:18,961 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:43699
2025-09-03 13:15:18,961 - distributed.worker - INFO -          dashboard at:           10.6.83.15:46389
2025-09-03 13:15:18,961 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,961 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,961 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,961 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,961 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-1gbemmk3
2025-09-03 13:15:18,961 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,962 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,962 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,964 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,984 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,985 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,985 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,986 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,989 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:18,990 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,990 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,992 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:18,994 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:42365
2025-09-03 13:15:18,994 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:42365
2025-09-03 13:15:18,994 - distributed.worker - INFO -          dashboard at:           10.6.83.15:46369
2025-09-03 13:15:18,994 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:18,994 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:18,994 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:18,994 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:18,994 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-kw6ktszl
2025-09-03 13:15:18,994 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,006 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:34899
2025-09-03 13:15:19,006 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:34899
2025-09-03 13:15:19,006 - distributed.worker - INFO -          dashboard at:           10.6.83.15:44847
2025-09-03 13:15:19,006 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,006 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,006 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,006 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,006 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:33161
2025-09-03 13:15:19,006 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-a1jfyipw
2025-09-03 13:15:19,007 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:33161
2025-09-03 13:15:19,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,007 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45275
2025-09-03 13:15:19,007 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,007 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,007 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,007 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-zanmc24o
2025-09-03 13:15:19,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,020 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,021 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,021 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,023 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,029 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:33213
2025-09-03 13:15:19,029 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:33213
2025-09-03 13:15:19,029 - distributed.worker - INFO -          dashboard at:           10.6.83.15:40605
2025-09-03 13:15:19,030 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,030 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,030 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,030 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-eto0zq74
2025-09-03 13:15:19,030 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,032 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,033 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,034 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,035 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,039 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,040 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,040 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,042 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,062 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,063 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,063 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,065 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,134 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:44593
2025-09-03 13:15:19,134 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:44593
2025-09-03 13:15:19,134 - distributed.worker - INFO -          dashboard at:           10.6.83.15:32845
2025-09-03 13:15:19,134 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,134 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,134 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,134 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,134 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-18vh9cmc
2025-09-03 13:15:19,134 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,170 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,171 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,171 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,173 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,239 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:44053
2025-09-03 13:15:19,239 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:44053
2025-09-03 13:15:19,239 - distributed.worker - INFO -          dashboard at:           10.6.83.15:34605
2025-09-03 13:15:19,239 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,239 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,239 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,239 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,240 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-1dy67ha8
2025-09-03 13:15:19,240 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,241 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37141
2025-09-03 13:15:19,241 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37141
2025-09-03 13:15:19,241 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39059
2025-09-03 13:15:19,241 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,241 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,241 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,241 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,241 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-1ao4cmd9
2025-09-03 13:15:19,241 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,251 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38519
2025-09-03 13:15:19,252 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38519
2025-09-03 13:15:19,252 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37321
2025-09-03 13:15:19,252 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,252 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,252 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,252 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,252 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-oekezt1a
2025-09-03 13:15:19,252 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,255 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:43693
2025-09-03 13:15:19,256 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:43693
2025-09-03 13:15:19,256 - distributed.worker - INFO -          dashboard at:           10.6.83.15:41899
2025-09-03 13:15:19,256 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,256 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,256 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,256 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-gryc0byr
2025-09-03 13:15:19,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,256 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38395
2025-09-03 13:15:19,256 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38395
2025-09-03 13:15:19,256 - distributed.worker - INFO -          dashboard at:           10.6.83.15:34533
2025-09-03 13:15:19,256 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,256 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,256 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,256 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-u5j73v33
2025-09-03 13:15:19,256 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,262 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,262 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,262 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,263 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,266 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:46197
2025-09-03 13:15:19,266 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:46197
2025-09-03 13:15:19,266 - distributed.worker - INFO -          dashboard at:           10.6.83.15:42315
2025-09-03 13:15:19,266 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,266 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,266 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,266 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,266 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-m5msazhc
2025-09-03 13:15:19,266 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,266 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35231
2025-09-03 13:15:19,267 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35231
2025-09-03 13:15:19,267 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37935
2025-09-03 13:15:19,267 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,267 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,267 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,267 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,267 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-xo2p79jw
2025-09-03 13:15:19,267 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,270 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37459
2025-09-03 13:15:19,270 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37459
2025-09-03 13:15:19,270 - distributed.worker - INFO -          dashboard at:           10.6.83.15:41249
2025-09-03 13:15:19,270 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,270 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,270 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,270 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-3crvf4ly
2025-09-03 13:15:19,270 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,274 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37949
2025-09-03 13:15:19,275 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37949
2025-09-03 13:15:19,275 - distributed.worker - INFO -          dashboard at:           10.6.83.15:44647
2025-09-03 13:15:19,275 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,275 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,275 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,275 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,275 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-9_arfbwo
2025-09-03 13:15:19,275 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36945
2025-09-03 13:15:19,275 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,275 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36945
2025-09-03 13:15:19,275 - distributed.worker - INFO -          dashboard at:           10.6.83.15:46583
2025-09-03 13:15:19,275 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,275 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,275 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,275 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,275 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-yb50v3el
2025-09-03 13:15:19,275 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,275 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:42545
2025-09-03 13:15:19,275 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:42545
2025-09-03 13:15:19,275 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39193
2025-09-03 13:15:19,275 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,275 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,276 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,276 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,276 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-qp0l3_sx
2025-09-03 13:15:19,276 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,276 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,276 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36363
2025-09-03 13:15:19,277 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36363
2025-09-03 13:15:19,277 - distributed.worker - INFO -          dashboard at:           10.6.83.15:36663
2025-09-03 13:15:19,277 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,277 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,277 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,277 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,277 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-2kti4mb8
2025-09-03 13:15:19,277 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,277 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,277 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,278 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:41543
2025-09-03 13:15:19,278 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:41543
2025-09-03 13:15:19,278 - distributed.worker - INFO -          dashboard at:           10.6.83.15:33529
2025-09-03 13:15:19,278 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,278 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,278 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,278 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-iryc21ty
2025-09-03 13:15:19,278 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,279 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,280 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:34903
2025-09-03 13:15:19,280 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:34903
2025-09-03 13:15:19,280 - distributed.worker - INFO -          dashboard at:           10.6.83.15:38573
2025-09-03 13:15:19,280 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,280 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,280 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,280 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-_r3y9bgk
2025-09-03 13:15:19,280 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,282 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38207
2025-09-03 13:15:19,282 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38207
2025-09-03 13:15:19,282 - distributed.worker - INFO -          dashboard at:           10.6.83.15:38785
2025-09-03 13:15:19,282 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,282 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,282 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,282 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-e10dx3ed
2025-09-03 13:15:19,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,286 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:44759
2025-09-03 13:15:19,286 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:44759
2025-09-03 13:15:19,286 - distributed.worker - INFO -          dashboard at:           10.6.83.15:39231
2025-09-03 13:15:19,286 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,286 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,286 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,286 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,286 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-rueasq8z
2025-09-03 13:15:19,286 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,288 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:36127
2025-09-03 13:15:19,288 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:36127
2025-09-03 13:15:19,288 - distributed.worker - INFO -          dashboard at:           10.6.83.15:40139
2025-09-03 13:15:19,288 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,288 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,288 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,288 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-g7er94le
2025-09-03 13:15:19,288 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,291 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:35783
2025-09-03 13:15:19,291 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:35783
2025-09-03 13:15:19,291 - distributed.worker - INFO -          dashboard at:           10.6.83.15:45947
2025-09-03 13:15:19,291 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,291 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,291 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,291 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-tbr3eu8d
2025-09-03 13:15:19,291 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,292 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:38517
2025-09-03 13:15:19,292 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:37125
2025-09-03 13:15:19,292 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:38517
2025-09-03 13:15:19,292 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:37125
2025-09-03 13:15:19,292 - distributed.worker - INFO -          dashboard at:           10.6.83.15:37763
2025-09-03 13:15:19,292 - distributed.worker - INFO -          dashboard at:           10.6.83.15:41531
2025-09-03 13:15:19,292 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,292 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,292 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,293 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,293 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,293 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,293 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,293 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-7k2o6pvs
2025-09-03 13:15:19,293 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-0j2pztjy
2025-09-03 13:15:19,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,293 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,297 - distributed.worker - INFO -       Start worker at:     tcp://10.6.83.15:32853
2025-09-03 13:15:19,297 - distributed.worker - INFO -          Listening to:     tcp://10.6.83.15:32853
2025-09-03 13:15:19,297 - distributed.worker - INFO -          dashboard at:           10.6.83.15:32793
2025-09-03 13:15:19,297 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,297 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,297 - distributed.worker - INFO -               Threads:                          2
2025-09-03 13:15:19,297 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 13:15:19,297 - distributed.worker - INFO -       Local Directory: /jobfs/148618149.gadi-pbs/dask-scratch-space/worker-wzczu4fc
2025-09-03 13:15:19,298 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,298 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,299 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,299 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,301 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,303 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,304 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,304 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,306 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,308 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,309 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,309 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,312 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,313 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,314 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,314 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,315 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,317 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,318 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,318 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,319 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,322 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,323 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,323 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,324 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,326 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,327 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,327 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,329 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,330 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,332 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,332 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,333 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,335 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,336 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,336 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,337 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,339 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,340 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,340 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,342 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,345 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,346 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,347 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,348 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,349 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,351 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,351 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,352 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,354 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,355 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,356 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,357 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,359 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,359 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,360 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,361 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,362 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,362 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,364 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,366 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,367 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,367 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,368 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,369 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,371 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,371 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,372 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,373 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,374 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,375 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,376 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:15:19,377 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 13:15:19,378 - distributed.worker - INFO -         Registered to:       tcp://10.6.81.1:8764
2025-09-03 13:15:19,379 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 13:15:19,380 - distributed.core - INFO - Starting established connection to tcp://10.6.81.1:8764
2025-09-03 13:16:21,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,787 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,788 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,789 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,789 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,789 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,789 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,789 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,789 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,789 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,790 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,790 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,790 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,790 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,790 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,791 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,791 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,791 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,791 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,791 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,791 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,791 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,791 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,791 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,792 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,792 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,792 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,790 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,790 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,790 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,792 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,792 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,793 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,791 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,793 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,793 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,793 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,794 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,794 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,794 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,794 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,792 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,794 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,792 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,795 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,795 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,795 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,795 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,795 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,796 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,796 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,794 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,796 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,796 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,794 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,794 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,797 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,795 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,796 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,797 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,801 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,802 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,803 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,803 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,804 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,804 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,804 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,805 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,805 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,805 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,806 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,806 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,803 - distributed.worker - INFO - Starting Worker plugin qme_utils.py04885534-db08-480f-9f19-cf8332e985ae
2025-09-03 13:16:21,805 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,808 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:21,816 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 13:16:25,465 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,466 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,466 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,466 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,466 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,466 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,466 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,466 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,467 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,469 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,469 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,469 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,469 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,469 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,469 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,469 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,469 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,469 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,469 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,469 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,469 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,469 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,469 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,468 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,471 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,471 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,471 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,471 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,470 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,471 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,471 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,471 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,471 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,471 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,471 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,471 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,471 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,472 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,472 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,471 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,471 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,472 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,472 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,472 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,472 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,472 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,472 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,473 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,473 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,473 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,473 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,473 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,474 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,474 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,474 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,474 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,474 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,474 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,474 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,474 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,475 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,475 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,475 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,475 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,475 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,475 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,473 - distributed.worker - INFO - Starting Worker plugin qme_vars.pyb6dc7e9b-31e5-4dec-80e5-d3053119e5b3
2025-09-03 13:16:25,475 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,475 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:25,478 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 13:16:26,907 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,907 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,907 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,907 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,907 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,907 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,908 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,908 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,908 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,908 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,908 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,908 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,909 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,910 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,910 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,910 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,910 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,910 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,910 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,910 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,910 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,911 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,911 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,911 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,911 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,911 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,911 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,911 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,911 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,911 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,911 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,911 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,911 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,911 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,912 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,912 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,912 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,912 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,912 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,912 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,912 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,912 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,912 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,912 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,912 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,912 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,912 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,912 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,912 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,913 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,913 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,913 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,913 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,913 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,913 - distributed.worker - INFO - Starting Worker plugin qme_train.py5a10009d-56a8-4689-a04c-aa3714b9a1e1
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,914 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,916 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,916 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,915 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,916 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,916 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,916 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,917 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,917 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,917 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,917 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,917 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,917 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,917 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,917 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:26,917 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 13:16:28,354 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,355 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,356 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,356 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,356 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,356 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,356 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,356 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,356 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,357 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,357 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,357 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,357 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,357 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,357 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,357 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,357 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,357 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,357 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,357 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,357 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,357 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,358 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,358 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,358 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,357 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,357 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,358 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,358 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,358 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,358 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,358 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,358 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,358 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,358 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,358 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,358 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,358 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,358 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,358 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,358 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,359 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,359 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,359 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,359 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,359 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,359 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,359 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,359 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,359 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,359 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,359 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,359 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,359 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,359 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,359 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,360 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,360 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,360 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,360 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,360 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,360 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,360 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,360 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,361 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,361 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,361 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,361 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,361 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,361 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,361 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,361 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,361 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,362 - distributed.worker - INFO - Starting Worker plugin qme_apply.py3a1d306b-9a77-46f4-8620-bf79068eeac7
2025-09-03 13:16:28,363 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,363 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,363 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,363 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,363 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,363 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,364 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,364 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,364 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,364 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,364 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:16:28,373 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 13:20:05,111 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,456 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,958 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,967 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:06,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:07,001 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:07,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:07,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:25,540 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:30,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:34,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:34,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:35,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:35,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:36,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:36,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:39,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:39,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:39,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:39,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:40,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:40,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:40,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:41,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:43,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:43,907 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:44,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:44,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:46,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:46,582 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:48,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:48,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:51,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:51,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:52,684 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:53,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:53,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:54,281 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:55,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:55,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:56,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:20:57,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:00,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:01,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:01,998 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:02,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:06,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:06,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:07,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:07,439 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:08,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:08,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:09,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:09,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:11,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:14,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:15,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:18,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:19,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:20,139 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:20,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:21,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:21,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:22,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:22,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:22,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:24,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:25,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:25,767 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:25,764 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:25,763 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:25,768 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:25,771 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:25,792 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:26,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:26,763 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:26,762 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:26,767 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:26,764 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:26,769 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:26,768 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.81.21:38481
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 368, in connect
    raise OSError(
OSError: Timed out trying to connect to tcp://10.6.81.21:38481 after 30 s
2025-09-03 13:21:33,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:49,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:51,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:51,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:51,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:52,447 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:53,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:54,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:54,708 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:55,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:55,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:56,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:56,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:56,879 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:56,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:58,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:58,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:21:59,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:00,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:00,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:00,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:00,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:00,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:01,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:02,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:02,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:02,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:02,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:03,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:04,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:04,143 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:04,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:04,336 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:04,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:05,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:05,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:06,216 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:06,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:06,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:07,385 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:08,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:08,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:09,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:09,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:10,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:11,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:12,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:12,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:13,224 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:13,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:14,585 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:14,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:14,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:15,510 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:18,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:18,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:18,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:19,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:20,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:21,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:23,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:26,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:27,224 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:28,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:31,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:32,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:32,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:32,044 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:32,474 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:32,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:32,748 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:32,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:43,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:43,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:44,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:44,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:44,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:45,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:45,724 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:45,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:45,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:45,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:47,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:48,191 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:50,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:52,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:54,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:54,631 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:55,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:55,621 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:55,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:56,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:56,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:56,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:58,126 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:58,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:59,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:22:59,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,198 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:01,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:03,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:04,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:06,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:06,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:07,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:07,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:08,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:08,944 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:09,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:09,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:10,878 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:11,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:11,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:12,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:12,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:14,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:24,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:26,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:26,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:27,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:34,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:34,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:35,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:36,006 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:36,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:36,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:36,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:36,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:37,818 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:37,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:39,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:40,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:40,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:41,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:41,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:42,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:42,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:43,158 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:43,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:46,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:47,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:47,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:47,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:48,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:49,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:50,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:50,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:51,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:51,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:52,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:52,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:52,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:52,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:52,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:53,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:53,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:53,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:53,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:54,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:56,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:56,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:57,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:57,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:58,134 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:58,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:23:59,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:00,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:01,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:03,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:03,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:03,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:03,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:03,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:03,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:04,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:04,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:04,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:04,751 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:04,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:05,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:05,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:06,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:06,256 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:06,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:07,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 13:24:12,777 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
