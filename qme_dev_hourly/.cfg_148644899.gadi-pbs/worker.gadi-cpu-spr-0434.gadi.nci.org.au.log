Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-03 16:26:55,121 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:45109'
2025-09-03 16:26:55,130 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:33949'
2025-09-03 16:26:55,134 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46243'
2025-09-03 16:26:55,139 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:40985'
2025-09-03 16:26:55,142 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46825'
2025-09-03 16:26:55,148 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:45455'
2025-09-03 16:26:55,152 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:42925'
2025-09-03 16:26:55,157 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46579'
2025-09-03 16:26:55,161 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:35415'
2025-09-03 16:26:55,167 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:45757'
2025-09-03 16:26:55,172 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46073'
2025-09-03 16:26:55,176 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:34701'
2025-09-03 16:26:55,179 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:45587'
2025-09-03 16:26:55,182 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46133'
2025-09-03 16:26:55,185 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:37133'
2025-09-03 16:26:55,190 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:41649'
2025-09-03 16:26:55,195 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:32799'
2025-09-03 16:26:55,199 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:40609'
2025-09-03 16:26:55,204 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:35783'
2025-09-03 16:26:55,209 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:40193'
2025-09-03 16:26:55,300 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:40113'
2025-09-03 16:26:55,305 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:33887'
2025-09-03 16:26:55,310 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46781'
2025-09-03 16:26:55,314 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46255'
2025-09-03 16:26:55,319 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:43849'
2025-09-03 16:26:55,323 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:35199'
2025-09-03 16:26:55,328 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46109'
2025-09-03 16:26:55,333 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:39879'
2025-09-03 16:26:55,341 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:35879'
2025-09-03 16:26:55,344 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:41453'
2025-09-03 16:26:55,347 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:40167'
2025-09-03 16:26:55,352 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:41041'
2025-09-03 16:26:55,355 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:35627'
2025-09-03 16:26:55,359 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:35469'
2025-09-03 16:26:55,364 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:40159'
2025-09-03 16:26:55,368 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46129'
2025-09-03 16:26:55,373 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:39099'
2025-09-03 16:26:55,378 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:45457'
2025-09-03 16:26:55,382 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:45613'
2025-09-03 16:26:55,386 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:33083'
2025-09-03 16:26:55,389 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46775'
2025-09-03 16:26:55,393 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:33055'
2025-09-03 16:26:55,398 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:35073'
2025-09-03 16:26:55,403 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:42949'
2025-09-03 16:26:55,406 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:42783'
2025-09-03 16:26:55,411 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:40059'
2025-09-03 16:26:55,414 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:38463'
2025-09-03 16:26:55,419 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:35193'
2025-09-03 16:26:55,422 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:35751'
2025-09-03 16:26:55,427 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:40623'
2025-09-03 16:26:55,433 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:46261'
2025-09-03 16:26:55,436 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.102.2:39543'
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:40289
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:38501
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:43479
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:36691
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:43369
2025-09-03 16:26:56,260 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:40289
2025-09-03 16:26:56,260 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:38501
2025-09-03 16:26:56,260 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:43479
2025-09-03 16:26:56,260 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:36691
2025-09-03 16:26:56,260 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:43369
2025-09-03 16:26:56,260 - distributed.worker - INFO -          dashboard at:           10.6.102.2:43215
2025-09-03 16:26:56,260 - distributed.worker - INFO -          dashboard at:           10.6.102.2:39949
2025-09-03 16:26:56,260 - distributed.worker - INFO -          dashboard at:           10.6.102.2:36683
2025-09-03 16:26:56,260 - distributed.worker - INFO -          dashboard at:           10.6.102.2:45067
2025-09-03 16:26:56,260 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,260 - distributed.worker - INFO -          dashboard at:           10.6.102.2:45425
2025-09-03 16:26:56,260 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,260 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,260 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,260 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,260 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,260 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,260 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,260 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,260 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,260 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,260 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,260 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,260 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,260 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-2fhpw7af
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-6hn_dlvn
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-z8e2lyyz
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-8ggi_c66
2025-09-03 16:26:56,260 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-kwb6egb1
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,260 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,273 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:46853
2025-09-03 16:26:56,273 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:46853
2025-09-03 16:26:56,274 - distributed.worker - INFO -          dashboard at:           10.6.102.2:37687
2025-09-03 16:26:56,274 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,274 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,274 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,274 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,274 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-61wmvjkc
2025-09-03 16:26:56,274 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,275 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,275 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,275 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,276 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,281 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,282 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,282 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,282 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,283 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,283 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,283 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,284 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,284 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,285 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,285 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,286 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,286 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,286 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,287 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,288 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,295 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,296 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,296 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,297 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,345 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:43285
2025-09-03 16:26:56,345 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:43285
2025-09-03 16:26:56,345 - distributed.worker - INFO -          dashboard at:           10.6.102.2:45731
2025-09-03 16:26:56,345 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,345 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,345 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,345 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,345 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-305mnxth
2025-09-03 16:26:56,345 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,346 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:41609
2025-09-03 16:26:56,346 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:41609
2025-09-03 16:26:56,346 - distributed.worker - INFO -          dashboard at:           10.6.102.2:36741
2025-09-03 16:26:56,346 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,346 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,346 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,346 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,346 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-lsu3a9eu
2025-09-03 16:26:56,346 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:43405
2025-09-03 16:26:56,346 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,346 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:43405
2025-09-03 16:26:56,346 - distributed.worker - INFO -          dashboard at:           10.6.102.2:41239
2025-09-03 16:26:56,346 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,346 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,346 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,346 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,346 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-trcj7k4z
2025-09-03 16:26:56,346 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,354 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:38723
2025-09-03 16:26:56,354 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:38723
2025-09-03 16:26:56,354 - distributed.worker - INFO -          dashboard at:           10.6.102.2:34063
2025-09-03 16:26:56,354 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,354 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,355 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,355 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,355 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-8ia7bews
2025-09-03 16:26:56,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,356 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,356 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,356 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,357 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,366 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,367 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,367 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,368 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,368 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,369 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,369 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,369 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:44873
2025-09-03 16:26:56,370 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:44873
2025-09-03 16:26:56,370 - distributed.worker - INFO -          dashboard at:           10.6.102.2:39951
2025-09-03 16:26:56,370 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,370 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,370 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,370 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,370 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-fer8xjkh
2025-09-03 16:26:56,370 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,370 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,376 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,377 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,377 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,379 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,382 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:46247
2025-09-03 16:26:56,382 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:46247
2025-09-03 16:26:56,383 - distributed.worker - INFO -          dashboard at:           10.6.102.2:44315
2025-09-03 16:26:56,383 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,383 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,383 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,383 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-403w9z2q
2025-09-03 16:26:56,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,384 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:45401
2025-09-03 16:26:56,384 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:45401
2025-09-03 16:26:56,384 - distributed.worker - INFO -          dashboard at:           10.6.102.2:37151
2025-09-03 16:26:56,384 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,384 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,384 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,384 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,384 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-etnattw5
2025-09-03 16:26:56,384 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,386 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:45237
2025-09-03 16:26:56,386 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:45237
2025-09-03 16:26:56,386 - distributed.worker - INFO -          dashboard at:           10.6.102.2:46657
2025-09-03 16:26:56,386 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,386 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,386 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,386 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,386 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-c3q4qpnq
2025-09-03 16:26:56,386 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,387 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:33491
2025-09-03 16:26:56,387 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:33491
2025-09-03 16:26:56,387 - distributed.worker - INFO -          dashboard at:           10.6.102.2:44737
2025-09-03 16:26:56,387 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,387 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,387 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,387 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,387 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-jdhu73jl
2025-09-03 16:26:56,387 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,392 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,393 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,393 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,393 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,393 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,394 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,394 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,395 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,396 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,396 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,396 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,403 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,404 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,404 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,405 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,406 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,407 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,407 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,409 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:42557
2025-09-03 16:26:56,409 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:42557
2025-09-03 16:26:56,409 - distributed.worker - INFO -          dashboard at:           10.6.102.2:46539
2025-09-03 16:26:56,409 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,409 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,409 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:45595
2025-09-03 16:26:56,409 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,409 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:45595
2025-09-03 16:26:56,409 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-j3cjbiho
2025-09-03 16:26:56,409 - distributed.worker - INFO -          dashboard at:           10.6.102.2:44637
2025-09-03 16:26:56,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,409 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,409 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,409 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,409 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,409 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-wxd55uxk
2025-09-03 16:26:56,409 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,413 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:34893
2025-09-03 16:26:56,413 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:34893
2025-09-03 16:26:56,414 - distributed.worker - INFO -          dashboard at:           10.6.102.2:34673
2025-09-03 16:26:56,414 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,414 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,414 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,414 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,414 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-g_uaq6m9
2025-09-03 16:26:56,414 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,429 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,430 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,430 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,431 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,431 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,432 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,432 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,433 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,434 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,435 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,435 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,436 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,450 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:37451
2025-09-03 16:26:56,450 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:37451
2025-09-03 16:26:56,450 - distributed.worker - INFO -          dashboard at:           10.6.102.2:43433
2025-09-03 16:26:56,450 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,450 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,450 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,450 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,450 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-8fhf0zri
2025-09-03 16:26:56,450 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,462 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:44915
2025-09-03 16:26:56,462 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:44915
2025-09-03 16:26:56,462 - distributed.worker - INFO -          dashboard at:           10.6.102.2:42619
2025-09-03 16:26:56,462 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,462 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,462 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,462 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,462 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-z8ndspxu
2025-09-03 16:26:56,462 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,472 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,473 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,473 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,474 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,480 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:33471
2025-09-03 16:26:56,480 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:33471
2025-09-03 16:26:56,480 - distributed.worker - INFO -          dashboard at:           10.6.102.2:39881
2025-09-03 16:26:56,480 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,480 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,480 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,480 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,480 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-zcop5a1x
2025-09-03 16:26:56,480 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,483 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,484 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,484 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,486 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,503 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,504 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,504 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,505 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,521 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:42643
2025-09-03 16:26:56,521 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:42643
2025-09-03 16:26:56,521 - distributed.worker - INFO -          dashboard at:           10.6.102.2:38679
2025-09-03 16:26:56,521 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,521 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,521 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,521 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,521 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-4lkz2t36
2025-09-03 16:26:56,521 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,521 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:41515
2025-09-03 16:26:56,521 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:41515
2025-09-03 16:26:56,521 - distributed.worker - INFO -          dashboard at:           10.6.102.2:33343
2025-09-03 16:26:56,521 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,521 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,521 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,521 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,521 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-c5aclbga
2025-09-03 16:26:56,521 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,530 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:46131
2025-09-03 16:26:56,530 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:46131
2025-09-03 16:26:56,531 - distributed.worker - INFO -          dashboard at:           10.6.102.2:36987
2025-09-03 16:26:56,531 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,531 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,531 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,531 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,531 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-3c2tbs3e
2025-09-03 16:26:56,531 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,542 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,543 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,543 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,544 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,544 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,545 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,545 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,547 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,550 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,551 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,551 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,552 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,586 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:33655
2025-09-03 16:26:56,587 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:33655
2025-09-03 16:26:56,587 - distributed.worker - INFO -          dashboard at:           10.6.102.2:44011
2025-09-03 16:26:56,587 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,587 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,587 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,587 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,587 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-p6pw4xq7
2025-09-03 16:26:56,587 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,607 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:46135
2025-09-03 16:26:56,607 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:46135
2025-09-03 16:26:56,607 - distributed.worker - INFO -          dashboard at:           10.6.102.2:39939
2025-09-03 16:26:56,607 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,607 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,607 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,607 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,607 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-1jqo45gw
2025-09-03 16:26:56,607 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,608 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,608 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,609 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,610 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,635 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,636 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,637 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,638 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,760 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:42419
2025-09-03 16:26:56,760 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:42419
2025-09-03 16:26:56,760 - distributed.worker - INFO -          dashboard at:           10.6.102.2:36803
2025-09-03 16:26:56,760 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,760 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,760 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,760 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,760 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-dinkzntt
2025-09-03 16:26:56,760 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,774 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:46407
2025-09-03 16:26:56,775 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:46407
2025-09-03 16:26:56,775 - distributed.worker - INFO -          dashboard at:           10.6.102.2:34705
2025-09-03 16:26:56,775 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,775 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,775 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,775 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-t3rqju99
2025-09-03 16:26:56,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,776 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:41701
2025-09-03 16:26:56,776 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:41701
2025-09-03 16:26:56,776 - distributed.worker - INFO -          dashboard at:           10.6.102.2:33663
2025-09-03 16:26:56,776 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,776 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,776 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:44489
2025-09-03 16:26:56,776 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,776 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,776 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:44489
2025-09-03 16:26:56,776 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-fi6a381t
2025-09-03 16:26:56,776 - distributed.worker - INFO -          dashboard at:           10.6.102.2:33729
2025-09-03 16:26:56,776 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,776 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,776 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,776 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,776 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,776 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-g7s9wud3
2025-09-03 16:26:56,776 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,779 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:44853
2025-09-03 16:26:56,779 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:44853
2025-09-03 16:26:56,779 - distributed.worker - INFO -          dashboard at:           10.6.102.2:46737
2025-09-03 16:26:56,779 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,779 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,779 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,779 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-j_85b3q0
2025-09-03 16:26:56,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,781 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,782 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,782 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,784 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,785 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,785 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,785 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,786 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,789 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,789 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,789 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,790 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,794 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:44583
2025-09-03 16:26:56,794 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:44583
2025-09-03 16:26:56,794 - distributed.worker - INFO -          dashboard at:           10.6.102.2:42689
2025-09-03 16:26:56,794 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,794 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,794 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,794 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-v57v7zea
2025-09-03 16:26:56,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,794 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:39947
2025-09-03 16:26:56,794 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:39947
2025-09-03 16:26:56,795 - distributed.worker - INFO -          dashboard at:           10.6.102.2:45515
2025-09-03 16:26:56,795 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,795 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,795 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,795 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,795 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-50i01f5a
2025-09-03 16:26:56,795 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,795 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,796 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,796 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,797 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,798 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,799 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,799 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,800 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,804 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:37859
2025-09-03 16:26:56,804 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:37859
2025-09-03 16:26:56,804 - distributed.worker - INFO -          dashboard at:           10.6.102.2:39481
2025-09-03 16:26:56,804 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,804 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,804 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,804 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-5ukbgcan
2025-09-03 16:26:56,804 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,805 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:43679
2025-09-03 16:26:56,805 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:43679
2025-09-03 16:26:56,805 - distributed.worker - INFO -          dashboard at:           10.6.102.2:34805
2025-09-03 16:26:56,805 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,805 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,805 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,805 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-fxvv27nb
2025-09-03 16:26:56,805 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,807 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,807 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,807 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,808 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,809 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:43595
2025-09-03 16:26:56,809 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:43595
2025-09-03 16:26:56,809 - distributed.worker - INFO -          dashboard at:           10.6.102.2:42409
2025-09-03 16:26:56,809 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,809 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,809 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,809 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,809 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-f5mm8cy7
2025-09-03 16:26:56,809 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,812 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:35915
2025-09-03 16:26:56,812 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:35915
2025-09-03 16:26:56,812 - distributed.worker - INFO -          dashboard at:           10.6.102.2:42851
2025-09-03 16:26:56,812 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,812 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,812 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,812 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-ru1du8fx
2025-09-03 16:26:56,812 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,812 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:35197
2025-09-03 16:26:56,812 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:35197
2025-09-03 16:26:56,812 - distributed.worker - INFO -          dashboard at:           10.6.102.2:33191
2025-09-03 16:26:56,813 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,813 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,813 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,813 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,813 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-nrq18s4q
2025-09-03 16:26:56,813 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,816 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,817 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,817 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,818 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:35969
2025-09-03 16:26:56,818 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:35969
2025-09-03 16:26:56,818 - distributed.worker - INFO -          dashboard at:           10.6.102.2:35313
2025-09-03 16:26:56,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-nytjbozq
2025-09-03 16:26:56,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,818 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:46289
2025-09-03 16:26:56,818 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,818 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:46289
2025-09-03 16:26:56,818 - distributed.worker - INFO -          dashboard at:           10.6.102.2:41009
2025-09-03 16:26:56,818 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,818 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,818 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,818 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,818 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-k3plfvkq
2025-09-03 16:26:56,819 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,819 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,819 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,819 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,820 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,820 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:46357
2025-09-03 16:26:56,820 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:46357
2025-09-03 16:26:56,820 - distributed.worker - INFO -          dashboard at:           10.6.102.2:45165
2025-09-03 16:26:56,820 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,820 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:44653
2025-09-03 16:26:56,820 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,820 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,820 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:44653
2025-09-03 16:26:56,820 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-ip4ygpf9
2025-09-03 16:26:56,820 - distributed.worker - INFO -          dashboard at:           10.6.102.2:33749
2025-09-03 16:26:56,820 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,820 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,820 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,820 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-5_oksfo2
2025-09-03 16:26:56,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,821 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:34479
2025-09-03 16:26:56,822 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:34479
2025-09-03 16:26:56,822 - distributed.worker - INFO -          dashboard at:           10.6.102.2:35101
2025-09-03 16:26:56,822 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,822 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,822 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,822 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,822 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-t9k45hzt
2025-09-03 16:26:56,822 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,823 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:43029
2025-09-03 16:26:56,823 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:43029
2025-09-03 16:26:56,823 - distributed.worker - INFO -          dashboard at:           10.6.102.2:42661
2025-09-03 16:26:56,823 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,823 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,823 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,823 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,823 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-yor2przq
2025-09-03 16:26:56,823 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,824 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:37137
2025-09-03 16:26:56,824 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:37137
2025-09-03 16:26:56,824 - distributed.worker - INFO -          dashboard at:           10.6.102.2:41487
2025-09-03 16:26:56,824 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,824 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,824 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,824 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-zxx5wyss
2025-09-03 16:26:56,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,824 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:40651
2025-09-03 16:26:56,824 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:40651
2025-09-03 16:26:56,824 - distributed.worker - INFO -          dashboard at:           10.6.102.2:43047
2025-09-03 16:26:56,824 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,824 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,824 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,824 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-o0prjk_x
2025-09-03 16:26:56,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,825 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,826 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,826 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,826 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,826 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,826 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,827 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,828 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,828 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,829 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:40347
2025-09-03 16:26:56,829 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:40347
2025-09-03 16:26:56,829 - distributed.worker - INFO -          dashboard at:           10.6.102.2:46067
2025-09-03 16:26:56,829 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,829 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,829 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,829 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,829 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-m2ogql_9
2025-09-03 16:26:56,829 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,829 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,830 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,830 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:35341
2025-09-03 16:26:56,830 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:35341
2025-09-03 16:26:56,830 - distributed.worker - INFO -          dashboard at:           10.6.102.2:32977
2025-09-03 16:26:56,830 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:38453
2025-09-03 16:26:56,830 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,830 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,830 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:38453
2025-09-03 16:26:56,830 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,830 - distributed.worker - INFO -          dashboard at:           10.6.102.2:45839
2025-09-03 16:26:56,830 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,830 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,830 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-_xz9m4j1
2025-09-03 16:26:56,830 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,830 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,830 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,830 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,830 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-h96bf9gb
2025-09-03 16:26:56,830 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,830 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,830 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,830 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,831 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,831 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,833 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,834 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,834 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,834 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,835 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,835 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,835 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,836 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,837 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,837 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,837 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,837 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,840 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,840 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,841 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,841 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,841 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:35093
2025-09-03 16:26:56,842 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:35093
2025-09-03 16:26:56,842 - distributed.worker - INFO -          dashboard at:           10.6.102.2:44789
2025-09-03 16:26:56,842 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,842 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,842 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,842 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-xa5x5uae
2025-09-03 16:26:56,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,842 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,842 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,842 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,842 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,843 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,843 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,843 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,843 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,843 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,843 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,844 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,845 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,845 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,846 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,846 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:43043
2025-09-03 16:26:56,846 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:43043
2025-09-03 16:26:56,846 - distributed.worker - INFO -       Start worker at:     tcp://10.6.102.2:33161
2025-09-03 16:26:56,846 - distributed.worker - INFO -          dashboard at:           10.6.102.2:37835
2025-09-03 16:26:56,846 - distributed.worker - INFO -          Listening to:     tcp://10.6.102.2:33161
2025-09-03 16:26:56,846 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,846 - distributed.worker - INFO -          dashboard at:           10.6.102.2:40675
2025-09-03 16:26:56,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,846 - distributed.worker - INFO - Waiting to connect to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,846 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,846 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,846 - distributed.worker - INFO -               Threads:                          2
2025-09-03 16:26:56,846 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-03 16:26:56,846 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-yvq8yfcf
2025-09-03 16:26:56,846 - distributed.worker - INFO -       Local Directory: /jobfs/148644899.gadi-pbs/dask-scratch-space/worker-l1m718cr
2025-09-03 16:26:56,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,846 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,847 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,847 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,848 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,848 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,848 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,848 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,849 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,849 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,850 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,852 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,853 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,853 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,854 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,854 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,855 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,855 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,855 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,863 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,864 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,864 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,865 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-03 16:26:56,866 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:26:56,866 - distributed.worker - INFO -         Registered to:      tcp://10.6.102.1:8786
2025-09-03 16:26:56,866 - distributed.worker - INFO - -------------------------------------------------
2025-09-03 16:26:56,867 - distributed.core - INFO - Starting established connection to tcp://10.6.102.1:8786
2025-09-03 16:27:35,663 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,663 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,664 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,664 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,664 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,664 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,664 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,664 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,665 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,665 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,665 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,665 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,666 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,666 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,666 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,666 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,666 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,666 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,666 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,665 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,668 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,668 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,666 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,669 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,670 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,670 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,670 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,670 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,668 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,668 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,668 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,668 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,669 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,669 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,669 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,670 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,670 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,670 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,671 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,671 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,674 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,671 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,672 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,672 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,673 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,675 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,667 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,673 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,673 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,673 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,674 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,674 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,679 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,680 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,681 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,681 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,682 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,683 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,683 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,684 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,684 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,684 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,684 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,685 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,686 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,686 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,687 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,687 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,687 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,687 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,687 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,688 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,690 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,689 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:35,693 - distributed.worker - INFO - Starting Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:27:35,700 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-03 16:27:38,338 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,338 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,339 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,339 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,339 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,339 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,339 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,340 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,339 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,341 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,342 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,342 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,342 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,342 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,342 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,342 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,342 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,343 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,342 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,342 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,342 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,343 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,342 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,343 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,342 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,342 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,343 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,343 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,342 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,343 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,341 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,343 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,344 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,344 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,344 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,344 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,344 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,345 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,344 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,346 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,346 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,346 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,346 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,346 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,345 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,344 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,346 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,346 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,347 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,347 - distributed.worker - INFO - Starting Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:27:38,347 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,347 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,348 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,348 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,348 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,348 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,348 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,348 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,349 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,349 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,349 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,350 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,353 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-03 16:27:38,736 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,736 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,736 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,736 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,737 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,737 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,737 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,737 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,737 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,737 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,738 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,739 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,739 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,739 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,739 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,739 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,739 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,739 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,739 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,740 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,740 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,740 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,740 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,740 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,740 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,740 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,740 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,740 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,740 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,740 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,740 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,741 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,741 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,742 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,742 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,742 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,742 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,742 - distributed.worker - INFO - Starting Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,743 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,744 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,745 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:38,746 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-03 16:27:39,178 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,178 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,178 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,179 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,179 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,179 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,179 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,179 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,179 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,179 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,179 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,179 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,180 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,180 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,180 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,180 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,180 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,180 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,180 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,181 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,181 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,181 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,182 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,182 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,182 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,182 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,182 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,182 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,182 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,182 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,182 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,182 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,182 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,182 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,182 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,182 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,182 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,182 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,183 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,183 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,184 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,184 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,184 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,184 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,184 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,184 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,184 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,184 - distributed.worker - INFO - Starting Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:27:39,185 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,185 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,185 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,185 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,185 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,185 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,185 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,185 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,186 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,186 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,186 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,186 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,187 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,187 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,187 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,187 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,187 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,187 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,187 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,188 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:27:39,189 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-03 16:30:58,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:58,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,445 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,519 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,556 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,617 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:30:59,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:46,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:46,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:47,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:47,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:47,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:47,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:48,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:48,316 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:48,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:48,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:48,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:49,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:51,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:51,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:51,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:52,968 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:52,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:52,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:52,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:53,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:53,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:53,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:53,431 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:53,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:54,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:54,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:54,258 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:54,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:55,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:55,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:56,571 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:56,774 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:31:58,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:00,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:02,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:02,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:03,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:09,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:09,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:10,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:10,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:11,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:11,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:11,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:12,101 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:12,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:12,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:12,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:12,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:12,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:13,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:14,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:15,484 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:15,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:17,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:17,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:19,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:19,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:19,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:19,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:20,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:20,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:20,312 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:20,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:22,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:22,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:22,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:22,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:23,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:24,731 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:24,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:24,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:24,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:32,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:33,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:33,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:33,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:34,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:34,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:34,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:35,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,638 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:36,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:37,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:38,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:38,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:38,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:38,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,482 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:39,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:40,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:41,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:41,599 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:41,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:41,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:41,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:42,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:42,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:42,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:43,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:43,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:43,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:43,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:43,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:44,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:44,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:45,545 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:32:47,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:00,662 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:01,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:02,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:02,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:03,286 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:03,651 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:04,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:04,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:04,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:04,298 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:04,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:05,575 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:05,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:06,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:06,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:06,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:06,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:09,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:09,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:10,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:10,107 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:10,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:10,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:10,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:10,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:10,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:11,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:11,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:11,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:11,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:12,148 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:12,178 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:12,183 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:12,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:12,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:12,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:12,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:17,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:18,161 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:18,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:18,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:18,811 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:19,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:19,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:20,173 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:21,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,605 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:22,944 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,042 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,389 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,412 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,508 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:23,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:24,179 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:25,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:25,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:26,091 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:26,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:26,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:26,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:28,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:32,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:32,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:38,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:43,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:45,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 29.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:56,668 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:33:56,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:04,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:04,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:04,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:06,501 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:06,582 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:06,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,354 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,356 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,693 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:07,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:08,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:08,391 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:09,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:09,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:09,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:09,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:09,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,854 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:13,862 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:14,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:14,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:14,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:15,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:26,623 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:26,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:27,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:27,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:30,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:30,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 27.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:30,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:32,200 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:32,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:32,450 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:33,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:33,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:33,331 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:33,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:33,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:34,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:35,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:35,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:35,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:35,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,110 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,469 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:36,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:37,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:38,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:40,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:40,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:40,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:41,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:48,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:49,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:50,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:50,512 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:50,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:51,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:51,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:52,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:52,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:52,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,038 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:53,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:54,156 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:54,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:54,341 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:54,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:54,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:54,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:54,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:55,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:55,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:55,803 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:56,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:56,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:56,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:56,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:57,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:59,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:59,943 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:34:59,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:00,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:00,671 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:02,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:02,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:03,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:06,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:06,883 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:10,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:11,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:12,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:13,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:13,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:13,865 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,011 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,535 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:15,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:16,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:16,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:16,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:16,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:16,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:16,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:16,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:16,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:16,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:18,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:18,805 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:18,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:19,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:19,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:20,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:20,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:20,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:21,762 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:22,914 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:23,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,251 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,985 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:32,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:33,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:36,684 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:36,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:36,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:40,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:41,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:41,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:43,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:45,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:45,334 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:45,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:45,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:45,674 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:46,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:50,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:50,438 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:50,523 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:50,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:50,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:50,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,375 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:51,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:52,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:52,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:52,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,425 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:53,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:54,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:54,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:54,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,052 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:55,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:56,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:56,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:57,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:57,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:59,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:59,066 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:59,068 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:59,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:35:59,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:02,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:03,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:10,207 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:10,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:12,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:12,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:13,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:14,793 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:15,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:15,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:16,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:16,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,742 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:17,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,568 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,570 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,837 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:18,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:19,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:19,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:20,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:22,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:22,167 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:22,244 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:22,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:22,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:23,070 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:24,706 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:24,839 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:25,118 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:25,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:25,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:25,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:25,727 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:25,729 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:26,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:27,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:33,028 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:33,260 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:33,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:33,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:34,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,847 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:35,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:36,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,207 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,207 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:37,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:39,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:39,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:40,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:40,519 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:41,597 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:42,863 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:43,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:46,265 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:46,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:50,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:52,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:55,843 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:55,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:59,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:59,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:36:59,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:00,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,109 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,115 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:01,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:02,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:02,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:02,768 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:02,780 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:02,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:03,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:04,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:04,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:04,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:04,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:04,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:05,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:06,107 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:06,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:08,010 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:08,011 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:08,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:15,012 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:15,020 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:15,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:15,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:15,526 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:16,961 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:16,966 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:17,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:18,532 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:21,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:28,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:29,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:30,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:30,369 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:30,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:30,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:30,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:30,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:31,153 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:31,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:31,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:31,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:31,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:31,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:31,786 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:31,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:32,032 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:32,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:32,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:32,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:35,430 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:35,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:35,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:40,025 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:42,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:45,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:48,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,474 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,801 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:49,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:51,019 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:51,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:51,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:51,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,060 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,069 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:52,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:53,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:53,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:53,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:54,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:56,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,107 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,119 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:57,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:58,563 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:37:58,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:01,700 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:02,715 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:02,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:02,733 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:02,739 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:03,432 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:03,949 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:04,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:05,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:05,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:05,584 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:06,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:06,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,284 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,604 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:07,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:08,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:08,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:08,838 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:09,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:09,940 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:10,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:11,687 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:11,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:12,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:12,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:12,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:12,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:12,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:13,977 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:17,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:17,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:20,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:35,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:35,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:35,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:35,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:40,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:40,853 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:40,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:44,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:53,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:54,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:54,607 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:54,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:54,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:54,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:54,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,774 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:55,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,226 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,616 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,774 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:56,776 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:57,083 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:57,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:57,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:57,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,696 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:58,994 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:59,151 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:59,213 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:59,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:38:59,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:00,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:01,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:01,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:01,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:01,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:01,493 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:01,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:04,046 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42792 closed before handshake completed
2025-09-03 16:39:04,048 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42790 closed before handshake completed
2025-09-03 16:39:04,048 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42764 closed before handshake completed
2025-09-03 16:39:04,048 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42776 closed before handshake completed
2025-09-03 16:39:04,049 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59548 closed before handshake completed
2025-09-03 16:39:04,050 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50158 closed before handshake completed
2025-09-03 16:39:04,050 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50140 closed before handshake completed
2025-09-03 16:39:04,051 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50154 closed before handshake completed
2025-09-03 16:39:04,051 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50148 closed before handshake completed
2025-09-03 16:39:04,051 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35176 closed before handshake completed
2025-09-03 16:39:04,051 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35174 closed before handshake completed
2025-09-03 16:39:04,054 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39428 closed before handshake completed
2025-09-03 16:39:04,054 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39414 closed before handshake completed
2025-09-03 16:39:04,054 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35838 closed before handshake completed
2025-09-03 16:39:04,055 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35834 closed before handshake completed
2025-09-03 16:39:04,055 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35818 closed before handshake completed
2025-09-03 16:39:04,055 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35814 closed before handshake completed
2025-09-03 16:39:04,056 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60592 closed before handshake completed
2025-09-03 16:39:04,056 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48878 closed before handshake completed
2025-09-03 16:39:04,056 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48880 closed before handshake completed
2025-09-03 16:39:04,056 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48870 closed before handshake completed
2025-09-03 16:39:04,056 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48892 closed before handshake completed
2025-09-03 16:39:04,057 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45464 closed before handshake completed
2025-09-03 16:39:04,059 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33862 closed before handshake completed
2025-09-03 16:39:04,060 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33850 closed before handshake completed
2025-09-03 16:39:04,060 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59560 closed before handshake completed
2025-09-03 16:39:04,060 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59574 closed before handshake completed
2025-09-03 16:39:04,061 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50160 closed before handshake completed
2025-09-03 16:39:04,061 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50176 closed before handshake completed
2025-09-03 16:39:04,061 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35182 closed before handshake completed
2025-09-03 16:39:04,062 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50742 closed before handshake completed
2025-09-03 16:39:04,062 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50722 closed before handshake completed
2025-09-03 16:39:04,062 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50708 closed before handshake completed
2025-09-03 16:39:04,062 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50736 closed before handshake completed
2025-09-03 16:39:04,063 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35852 closed before handshake completed
2025-09-03 16:39:04,072 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33100 closed before handshake completed
2025-09-03 16:39:04,073 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36040 closed before handshake completed
2025-09-03 16:39:04,073 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:39982 closed before handshake completed
2025-09-03 16:39:04,074 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42794 closed before handshake completed
2025-09-03 16:39:04,074 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56140 closed before handshake completed
2025-09-03 16:39:04,075 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33872 closed before handshake completed
2025-09-03 16:39:04,075 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34362 closed before handshake completed
2025-09-03 16:39:04,075 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34350 closed before handshake completed
2025-09-03 16:39:04,075 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:59314 closed before handshake completed
2025-09-03 16:39:04,075 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:59330 closed before handshake completed
2025-09-03 16:39:04,083 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46784 closed before handshake completed
2025-09-03 16:39:04,083 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55230 closed before handshake completed
2025-09-03 16:39:04,085 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50776 closed before handshake completed
2025-09-03 16:39:04,086 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50774 closed before handshake completed
2025-09-03 16:39:04,086 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50766 closed before handshake completed
2025-09-03 16:39:04,089 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49454 closed before handshake completed
2025-09-03 16:39:04,089 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49428 closed before handshake completed
2025-09-03 16:39:04,090 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50758 closed before handshake completed
2025-09-03 16:39:04,093 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49440 closed before handshake completed
2025-09-03 16:39:04,094 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60602 closed before handshake completed
2025-09-03 16:39:04,103 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45478 closed before handshake completed
2025-09-03 16:39:04,109 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56840 closed before handshake completed
2025-09-03 16:39:04,113 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38192 closed before handshake completed
2025-09-03 16:39:04,113 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38182 closed before handshake completed
2025-09-03 16:39:04,128 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42806 closed before handshake completed
2025-09-03 16:39:04,131 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55914 closed before handshake completed
2025-09-03 16:39:04,131 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56148 closed before handshake completed
2025-09-03 16:39:04,142 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59580 closed before handshake completed
2025-09-03 16:39:04,145 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46834 closed before handshake completed
2025-09-03 16:39:04,145 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46850 closed before handshake completed
2025-09-03 16:39:04,146 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34380 closed before handshake completed
2025-09-03 16:39:04,146 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34364 closed before handshake completed
2025-09-03 16:39:04,159 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55240 closed before handshake completed
2025-09-03 16:39:04,160 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55246 closed before handshake completed
2025-09-03 16:39:04,160 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55238 closed before handshake completed
2025-09-03 16:39:04,160 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50788 closed before handshake completed
2025-09-03 16:39:04,179 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33104 closed before handshake completed
2025-09-03 16:39:04,182 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45496 closed before handshake completed
2025-09-03 16:39:04,183 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45512 closed before handshake completed
2025-09-03 16:39:04,183 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45488 closed before handshake completed
2025-09-03 16:39:04,183 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45528 closed before handshake completed
2025-09-03 16:39:04,184 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48910 closed before handshake completed
2025-09-03 16:39:04,184 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48902 closed before handshake completed
2025-09-03 16:39:04,184 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48898 closed before handshake completed
2025-09-03 16:39:04,184 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48922 closed before handshake completed
2025-09-03 16:39:04,184 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43706 closed before handshake completed
2025-09-03 16:39:04,188 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:39992 closed before handshake completed
2025-09-03 16:39:04,188 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:39998 closed before handshake completed
2025-09-03 16:39:04,193 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38202 closed before handshake completed
2025-09-03 16:39:04,197 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40308 closed before handshake completed
2025-09-03 16:39:04,210 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42820 closed before handshake completed
2025-09-03 16:39:04,221 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59592 closed before handshake completed
2025-09-03 16:39:04,222 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59598 closed before handshake completed
2025-09-03 16:39:04,223 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59582 closed before handshake completed
2025-09-03 16:39:04,232 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35190 closed before handshake completed
2025-09-03 16:39:04,233 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35198 closed before handshake completed
2025-09-03 16:39:04,234 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50198 closed before handshake completed
2025-09-03 16:39:04,234 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50184 closed before handshake completed
2025-09-03 16:39:04,243 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39440 closed before handshake completed
2025-09-03 16:39:04,251 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60616 closed before handshake completed
2025-09-03 16:39:04,261 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33116 closed before handshake completed
2025-09-03 16:39:04,261 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33124 closed before handshake completed
2025-09-03 16:39:04,262 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45534 closed before handshake completed
2025-09-03 16:39:04,263 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45544 closed before handshake completed
2025-09-03 16:39:04,265 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43752 closed before handshake completed
2025-09-03 16:39:04,265 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43722 closed before handshake completed
2025-09-03 16:39:04,265 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43730 closed before handshake completed
2025-09-03 16:39:04,266 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43742 closed before handshake completed
2025-09-03 16:39:04,267 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56842 closed before handshake completed
2025-09-03 16:39:04,269 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40006 closed before handshake completed
2025-09-03 16:39:04,278 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40334 closed before handshake completed
2025-09-03 16:39:04,278 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40320 closed before handshake completed
2025-09-03 16:39:04,287 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42832 closed before handshake completed
2025-09-03 16:39:04,287 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42840 closed before handshake completed
2025-09-03 16:39:04,298 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33886 closed before handshake completed
2025-09-03 16:39:04,304 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59608 closed before handshake completed
2025-09-03 16:39:04,313 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35234 closed before handshake completed
2025-09-03 16:39:04,314 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35206 closed before handshake completed
2025-09-03 16:39:04,314 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35222 closed before handshake completed
2025-09-03 16:39:04,335 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35866 closed before handshake completed
2025-09-03 16:39:04,335 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49468 closed before handshake completed
2025-09-03 16:39:04,336 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49480 closed before handshake completed
2025-09-03 16:39:04,485 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56858 closed before handshake completed
2025-09-03 16:39:04,486 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55928 closed before handshake completed
2025-09-03 16:39:04,487 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55926 closed before handshake completed
2025-09-03 16:39:04,487 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33902 closed before handshake completed
2025-09-03 16:39:04,487 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33892 closed before handshake completed
2025-09-03 16:39:04,487 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59650 closed before handshake completed
2025-09-03 16:39:04,487 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59636 closed before handshake completed
2025-09-03 16:39:04,487 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59622 closed before handshake completed
2025-09-03 16:39:04,487 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59666 closed before handshake completed
2025-09-03 16:39:04,488 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59632 closed before handshake completed
2025-09-03 16:39:04,488 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59626 closed before handshake completed
2025-09-03 16:39:04,488 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59670 closed before handshake completed
2025-09-03 16:39:04,488 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:56066 closed before handshake completed
2025-09-03 16:39:04,488 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:56070 closed before handshake completed
2025-09-03 16:39:04,489 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35268 closed before handshake completed
2025-09-03 16:39:04,489 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35246 closed before handshake completed
2025-09-03 16:39:04,489 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35262 closed before handshake completed
2025-09-03 16:39:04,489 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35280 closed before handshake completed
2025-09-03 16:39:04,489 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46788 closed before handshake completed
2025-09-03 16:39:04,489 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50820 closed before handshake completed
2025-09-03 16:39:04,489 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50812 closed before handshake completed
2025-09-03 16:39:04,490 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50794 closed before handshake completed
2025-09-03 16:39:04,490 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50792 closed before handshake completed
2025-09-03 16:39:04,490 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50802 closed before handshake completed
2025-09-03 16:39:04,491 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33148 closed before handshake completed
2025-09-03 16:39:04,491 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33138 closed before handshake completed
2025-09-03 16:39:04,491 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33858 closed before handshake completed
2025-09-03 16:39:04,491 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33848 closed before handshake completed
2025-09-03 16:39:04,492 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40016 closed before handshake completed
2025-09-03 16:39:04,492 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38208 closed before handshake completed
2025-09-03 16:39:04,492 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41590 closed before handshake completed
2025-09-03 16:39:04,492 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57230 closed before handshake completed
2025-09-03 16:39:04,493 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34382 closed before handshake completed
2025-09-03 16:39:04,493 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34384 closed before handshake completed
2025-09-03 16:39:04,493 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50828 closed before handshake completed
2025-09-03 16:39:04,493 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39442 closed before handshake completed
2025-09-03 16:39:04,498 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60624 closed before handshake completed
2025-09-03 16:39:04,499 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60630 closed before handshake completed
2025-09-03 16:39:04,504 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36056 closed before handshake completed
2025-09-03 16:39:04,508 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43792 closed before handshake completed
2025-09-03 16:39:04,508 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43788 closed before handshake completed
2025-09-03 16:39:04,508 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43776 closed before handshake completed
2025-09-03 16:39:04,508 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43754 closed before handshake completed
2025-09-03 16:39:04,508 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43764 closed before handshake completed
2025-09-03 16:39:04,509 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40020 closed before handshake completed
2025-09-03 16:39:04,509 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40026 closed before handshake completed
2025-09-03 16:39:04,513 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38214 closed before handshake completed
2025-09-03 16:39:04,530 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55940 closed before handshake completed
2025-09-03 16:39:04,541 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57232 closed before handshake completed
2025-09-03 16:39:04,542 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57242 closed before handshake completed
2025-09-03 16:39:04,545 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34398 closed before handshake completed
2025-09-03 16:39:04,548 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50210 closed before handshake completed
2025-09-03 16:39:04,569 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35908 closed before handshake completed
2025-09-03 16:39:04,570 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35892 closed before handshake completed
2025-09-03 16:39:04,570 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35890 closed before handshake completed
2025-09-03 16:39:04,571 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35884 closed before handshake completed
2025-09-03 16:39:04,571 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35878 closed before handshake completed
2025-09-03 16:39:04,574 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60646 closed before handshake completed
2025-09-03 16:39:04,587 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56864 closed before handshake completed
2025-09-03 16:39:04,593 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40034 closed before handshake completed
2025-09-03 16:39:04,595 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38228 closed before handshake completed
2025-09-03 16:39:04,618 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33916 closed before handshake completed
2025-09-03 16:39:04,625 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57250 closed before handshake completed
2025-09-03 16:39:04,627 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46866 closed before handshake completed
2025-09-03 16:39:04,628 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46860 closed before handshake completed
2025-09-03 16:39:04,649 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35910 closed before handshake completed
2025-09-03 16:39:04,662 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48936 closed before handshake completed
2025-09-03 16:39:04,663 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48948 closed before handshake completed
2025-09-03 16:39:04,665 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48938 closed before handshake completed
2025-09-03 16:39:04,666 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45564 closed before handshake completed
2025-09-03 16:39:04,666 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45554 closed before handshake completed
2025-09-03 16:39:04,670 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56880 closed before handshake completed
2025-09-03 16:39:04,674 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38244 closed before handshake completed
2025-09-03 16:39:04,687 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42842 closed before handshake completed
2025-09-03 16:39:04,691 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55946 closed before handshake completed
2025-09-03 16:39:04,710 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50214 closed before handshake completed
2025-09-03 16:39:04,713 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35292 closed before handshake completed
2025-09-03 16:39:04,713 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35288 closed before handshake completed
2025-09-03 16:39:04,729 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49506 closed before handshake completed
2025-09-03 16:39:04,729 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49492 closed before handshake completed
2025-09-03 16:39:04,732 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60658 closed before handshake completed
2025-09-03 16:39:04,742 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48958 closed before handshake completed
2025-09-03 16:39:04,742 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48966 closed before handshake completed
2025-09-03 16:39:04,743 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33866 closed before handshake completed
2025-09-03 16:39:04,744 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48972 closed before handshake completed
2025-09-03 16:39:04,746 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48982 closed before handshake completed
2025-09-03 16:39:04,749 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40042 closed before handshake completed
2025-09-03 16:39:04,757 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40340 closed before handshake completed
2025-09-03 16:39:04,768 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42858 closed before handshake completed
2025-09-03 16:39:04,778 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33946 closed before handshake completed
2025-09-03 16:39:04,779 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33932 closed before handshake completed
2025-09-03 16:39:04,779 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33924 closed before handshake completed
2025-09-03 16:39:04,780 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41596 closed before handshake completed
2025-09-03 16:39:04,783 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57254 closed before handshake completed
2025-09-03 16:39:04,788 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46874 closed before handshake completed
2025-09-03 16:39:04,789 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:56084 closed before handshake completed
2025-09-03 16:39:04,802 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39444 closed before handshake completed
2025-09-03 16:39:04,809 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49512 closed before handshake completed
2025-09-03 16:39:04,811 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60672 closed before handshake completed
2025-09-03 16:39:04,822 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45566 closed before handshake completed
2025-09-03 16:39:04,832 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56894 closed before handshake completed
2025-09-03 16:39:04,833 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40058 closed before handshake completed
2025-09-03 16:39:04,850 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55952 closed before handshake completed
2025-09-03 16:39:04,851 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55950 closed before handshake completed
2025-09-03 16:39:04,851 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42866 closed before handshake completed
2025-09-03 16:39:04,859 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59696 closed before handshake completed
2025-09-03 16:39:04,859 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59692 closed before handshake completed
2025-09-03 16:39:04,860 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59680 closed before handshake completed
2025-09-03 16:39:04,862 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41598 closed before handshake completed
2025-09-03 16:39:04,862 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57276 closed before handshake completed
2025-09-03 16:39:04,863 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57278 closed before handshake completed
2025-09-03 16:39:04,864 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57266 closed before handshake completed
2025-09-03 16:39:04,864 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57292 closed before handshake completed
2025-09-03 16:39:04,865 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46880 closed before handshake completed
2025-09-03 16:39:04,870 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35302 closed before handshake completed
2025-09-03 16:39:04,871 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50224 closed before handshake completed
2025-09-03 16:39:04,875 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46804 closed before handshake completed
2025-09-03 16:39:04,876 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46796 closed before handshake completed
2025-09-03 16:39:04,880 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50220 closed before handshake completed
2025-09-03 16:39:04,882 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55278 closed before handshake completed
2025-09-03 16:39:04,882 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55262 closed before handshake completed
2025-09-03 16:39:04,883 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55272 closed before handshake completed
2025-09-03 16:39:04,902 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36062 closed before handshake completed
2025-09-03 16:39:04,902 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33868 closed before handshake completed
2025-09-03 16:39:04,918 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40364 closed before handshake completed
2025-09-03 16:39:04,918 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40350 closed before handshake completed
2025-09-03 16:39:04,927 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42878 closed before handshake completed
2025-09-03 16:39:04,928 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42892 closed before handshake completed
2025-09-03 16:39:04,942 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57304 closed before handshake completed
2025-09-03 16:39:04,943 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41612 closed before handshake completed
2025-09-03 16:39:04,946 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34410 closed before handshake completed
2025-09-03 16:39:04,946 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46896 closed before handshake completed
2025-09-03 16:39:04,948 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50230 closed before handshake completed
2025-09-03 16:39:04,949 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50232 closed before handshake completed
2025-09-03 16:39:04,956 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55280 closed before handshake completed
2025-09-03 16:39:04,957 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55296 closed before handshake completed
2025-09-03 16:39:04,959 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46828 closed before handshake completed
2025-09-03 16:39:04,959 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46814 closed before handshake completed
2025-09-03 16:39:04,969 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49520 closed before handshake completed
2025-09-03 16:39:04,981 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36074 closed before handshake completed
2025-09-03 16:39:04,982 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48992 closed before handshake completed
2025-09-03 16:39:04,983 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45580 closed before handshake completed
2025-09-03 16:39:04,984 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43796 closed before handshake completed
2025-09-03 16:39:04,994 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38320 closed before handshake completed
2025-09-03 16:39:04,994 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38278 closed before handshake completed
2025-09-03 16:39:04,995 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38258 closed before handshake completed
2025-09-03 16:39:04,995 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38294 closed before handshake completed
2025-09-03 16:39:04,996 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38310 closed before handshake completed
2025-09-03 16:39:04,996 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38270 closed before handshake completed
2025-09-03 16:39:05,010 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55968 closed before handshake completed
2025-09-03 16:39:05,018 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33948 closed before handshake completed
2025-09-03 16:39:05,019 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33976 closed before handshake completed
2025-09-03 16:39:05,019 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33960 closed before handshake completed
2025-09-03 16:39:05,035 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46850 closed before handshake completed
2025-09-03 16:39:05,036 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46844 closed before handshake completed
2025-09-03 16:39:05,038 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46840 closed before handshake completed
2025-09-03 16:39:05,053 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49526 closed before handshake completed
2025-09-03 16:39:05,053 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:49524 closed before handshake completed
2025-09-03 16:39:05,055 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60710 closed before handshake completed
2025-09-03 16:39:05,055 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60694 closed before handshake completed
2025-09-03 16:39:05,056 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60708 closed before handshake completed
2025-09-03 16:39:05,056 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60682 closed before handshake completed
2025-09-03 16:39:05,067 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56910 closed before handshake completed
2025-09-03 16:39:05,069 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40064 closed before handshake completed
2025-09-03 16:39:05,078 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40366 closed before handshake completed
2025-09-03 16:39:05,092 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55974 closed before handshake completed
2025-09-03 16:39:05,093 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55972 closed before handshake completed
2025-09-03 16:39:05,095 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55984 closed before handshake completed
2025-09-03 16:39:05,105 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46928 closed before handshake completed
2025-09-03 16:39:05,106 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46932 closed before handshake completed
2025-09-03 16:39:05,106 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46920 closed before handshake completed
2025-09-03 16:39:05,107 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46906 closed before handshake completed
2025-09-03 16:39:05,108 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50246 closed before handshake completed
2025-09-03 16:39:05,109 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50234 closed before handshake completed
2025-09-03 16:39:05,117 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46852 closed before handshake completed
2025-09-03 16:39:05,118 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50844 closed before handshake completed
2025-09-03 16:39:05,119 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50854 closed before handshake completed
2025-09-03 16:39:05,121 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39448 closed before handshake completed
2025-09-03 16:39:05,122 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39456 closed before handshake completed
2025-09-03 16:39:05,123 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50254 closed before handshake completed
2025-09-03 16:39:05,132 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60712 closed before handshake completed
2025-09-03 16:39:05,145 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33884 closed before handshake completed
2025-09-03 16:39:05,146 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45582 closed before handshake completed
2025-09-03 16:39:05,147 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45592 closed before handshake completed
2025-09-03 16:39:05,149 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40078 closed before handshake completed
2025-09-03 16:39:05,149 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40088 closed before handshake completed
2025-09-03 16:39:05,150 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40098 closed before handshake completed
2025-09-03 16:39:05,167 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:59448 closed before handshake completed
2025-09-03 16:39:05,179 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53352 closed before handshake completed
2025-09-03 16:39:05,180 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53358 closed before handshake completed
2025-09-03 16:39:05,185 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34420 closed before handshake completed
2025-09-03 16:39:05,186 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34416 closed before handshake completed
2025-09-03 16:39:05,187 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34422 closed before handshake completed
2025-09-03 16:39:05,188 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:46944 closed before handshake completed
2025-09-03 16:39:05,189 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50258 closed before handshake completed
2025-09-03 16:39:05,211 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41298 closed before handshake completed
2025-09-03 16:39:05,219 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33150 closed before handshake completed
2025-09-03 16:39:05,222 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48998 closed before handshake completed
2025-09-03 16:39:05,222 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:49008 closed before handshake completed
2025-09-03 16:39:05,225 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50380 closed before handshake completed
2025-09-03 16:39:05,226 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56922 closed before handshake completed
2025-09-03 16:39:05,233 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40118 closed before handshake completed
2025-09-03 16:39:05,233 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40104 closed before handshake completed
2025-09-03 16:39:05,259 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:56230 closed before handshake completed
2025-09-03 16:39:05,263 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57312 closed before handshake completed
2025-09-03 16:39:05,292 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60748 closed before handshake completed
2025-09-03 16:39:05,293 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60744 closed before handshake completed
2025-09-03 16:39:05,293 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60714 closed before handshake completed
2025-09-03 16:39:05,294 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60730 closed before handshake completed
2025-09-03 16:39:05,303 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33900 closed before handshake completed
2025-09-03 16:39:05,306 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50396 closed before handshake completed
2025-09-03 16:39:05,306 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50408 closed before handshake completed
2025-09-03 16:39:05,307 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50394 closed before handshake completed
2025-09-03 16:39:05,313 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38324 closed before handshake completed
2025-09-03 16:39:05,340 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53374 closed before handshake completed
2025-09-03 16:39:05,342 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53382 closed before handshake completed
2025-09-03 16:39:05,346 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34454 closed before handshake completed
2025-09-03 16:39:05,346 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34456 closed before handshake completed
2025-09-03 16:39:05,347 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34432 closed before handshake completed
2025-09-03 16:39:05,349 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34444 closed before handshake completed
2025-09-03 16:39:05,357 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55300 closed before handshake completed
2025-09-03 16:39:05,359 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50866 closed before handshake completed
2025-09-03 16:39:05,359 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50858 closed before handshake completed
2025-09-03 16:39:05,360 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50868 closed before handshake completed
2025-09-03 16:39:05,372 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60750 closed before handshake completed
2025-09-03 16:39:05,372 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60766 closed before handshake completed
2025-09-03 16:39:05,373 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60800 closed before handshake completed
2025-09-03 16:39:05,373 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60790 closed before handshake completed
2025-09-03 16:39:05,374 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60774 closed before handshake completed
2025-09-03 16:39:05,382 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:49024 closed before handshake completed
2025-09-03 16:39:05,382 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:49012 closed before handshake completed
2025-09-03 16:39:05,383 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:49010 closed before handshake completed
2025-09-03 16:39:05,383 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33906 closed before handshake completed
2025-09-03 16:39:05,385 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33152 closed before handshake completed
2025-09-03 16:39:05,386 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56942 closed before handshake completed
2025-09-03 16:39:05,387 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56930 closed before handshake completed
2025-09-03 16:39:05,407 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:59456 closed before handshake completed
2025-09-03 16:39:05,408 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:59454 closed before handshake completed
2025-09-03 16:39:05,411 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:55996 closed before handshake completed
2025-09-03 16:39:05,430 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35316 closed before handshake completed
2025-09-03 16:39:05,463 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45614 closed before handshake completed
2025-09-03 16:39:05,464 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45608 closed before handshake completed
2025-09-03 16:39:05,465 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50442 closed before handshake completed
2025-09-03 16:39:05,465 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50414 closed before handshake completed
2025-09-03 16:39:05,466 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50426 closed before handshake completed
2025-09-03 16:39:05,466 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50420 closed before handshake completed
2025-09-03 16:39:05,474 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38338 closed before handshake completed
2025-09-03 16:39:05,477 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40374 closed before handshake completed
2025-09-03 16:39:05,510 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35324 closed before handshake completed
2025-09-03 16:39:05,511 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50290 closed before handshake completed
2025-09-03 16:39:05,512 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50286 closed before handshake completed
2025-09-03 16:39:05,513 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50270 closed before handshake completed
2025-09-03 16:39:05,515 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46864 closed before handshake completed
2025-09-03 16:39:05,519 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55302 closed before handshake completed
2025-09-03 16:39:05,521 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39472 closed before handshake completed
2025-09-03 16:39:05,529 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41308 closed before handshake completed
2025-09-03 16:39:05,530 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41302 closed before handshake completed
2025-09-03 16:39:05,542 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:49048 closed before handshake completed
2025-09-03 16:39:05,542 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:49036 closed before handshake completed
2025-09-03 16:39:05,543 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:49032 closed before handshake completed
2025-09-03 16:39:05,544 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50456 closed before handshake completed
2025-09-03 16:39:05,545 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50448 closed before handshake completed
2025-09-03 16:39:05,548 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40132 closed before handshake completed
2025-09-03 16:39:05,549 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40122 closed before handshake completed
2025-09-03 16:39:05,553 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38352 closed before handshake completed
2025-09-03 16:39:05,554 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38340 closed before handshake completed
2025-09-03 16:39:05,555 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38348 closed before handshake completed
2025-09-03 16:39:05,557 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40392 closed before handshake completed
2025-09-03 16:39:05,558 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40384 closed before handshake completed
2025-09-03 16:39:06,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:06,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:06,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:06,907 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57014 closed before handshake completed
2025-09-03 16:39:06,909 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40262 closed before handshake completed
2025-09-03 16:39:06,910 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40246 closed before handshake completed
2025-09-03 16:39:06,913 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38430 closed before handshake completed
2025-09-03 16:39:06,921 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40566 closed before handshake completed
2025-09-03 16:39:06,939 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53490 closed before handshake completed
2025-09-03 16:39:06,940 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41830 closed before handshake completed
2025-09-03 16:39:06,941 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41826 closed before handshake completed
2025-09-03 16:39:06,942 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57496 closed before handshake completed
2025-09-03 16:39:06,943 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57488 closed before handshake completed
2025-09-03 16:39:06,946 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34548 closed before handshake completed
2025-09-03 16:39:06,947 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:56220 closed before handshake completed
2025-09-03 16:39:06,948 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:56214 closed before handshake completed
2025-09-03 16:39:06,948 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:56208 closed before handshake completed
2025-09-03 16:39:06,949 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:56194 closed before handshake completed
2025-09-03 16:39:06,949 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:56200 closed before handshake completed
2025-09-03 16:39:06,960 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50964 closed before handshake completed
2025-09-03 16:39:06,960 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50952 closed before handshake completed
2025-09-03 16:39:06,961 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50950 closed before handshake completed
2025-09-03 16:39:06,962 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39614 closed before handshake completed
2025-09-03 16:39:06,973 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41420 closed before handshake completed
2025-09-03 16:39:06,979 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33278 closed before handshake completed
2025-09-03 16:39:06,982 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33974 closed before handshake completed
2025-09-03 16:39:06,984 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50618 closed before handshake completed
2025-09-03 16:39:06,986 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57032 closed before handshake completed
2025-09-03 16:39:06,987 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57024 closed before handshake completed
2025-09-03 16:39:07,019 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53504 closed before handshake completed
2025-09-03 16:39:07,025 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57498 closed before handshake completed
2025-09-03 16:39:07,027 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:56228 closed before handshake completed
2025-09-03 16:39:07,028 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50360 closed before handshake completed
2025-09-03 16:39:07,029 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50354 closed before handshake completed
2025-09-03 16:39:07,038 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50990 closed before handshake completed
2025-09-03 16:39:07,039 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50980 closed before handshake completed
2025-09-03 16:39:07,041 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39620 closed before handshake completed
2025-09-03 16:39:07,048 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35978 closed before handshake completed
2025-09-03 16:39:07,065 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36252 closed before handshake completed
2025-09-03 16:39:07,066 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57048 closed before handshake completed
2025-09-03 16:39:07,068 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50634 closed before handshake completed
2025-09-03 16:39:07,068 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50620 closed before handshake completed
2025-09-03 16:39:07,069 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50626 closed before handshake completed
2025-09-03 16:39:07,070 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40292 closed before handshake completed
2025-09-03 16:39:07,071 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40276 closed before handshake completed
2025-09-03 16:39:07,073 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38440 closed before handshake completed
2025-09-03 16:39:07,078 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40576 closed before handshake completed
2025-09-03 16:39:07,090 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56044 closed before handshake completed
2025-09-03 16:39:07,099 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53506 closed before handshake completed
2025-09-03 16:39:07,119 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55374 closed before handshake completed
2025-09-03 16:39:07,121 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39634 closed before handshake completed
2025-09-03 16:39:07,132 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60908 closed before handshake completed
2025-09-03 16:39:07,133 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60912 closed before handshake completed
2025-09-03 16:39:07,134 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60914 closed before handshake completed
2025-09-03 16:39:07,139 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33292 closed before handshake completed
2025-09-03 16:39:07,143 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45774 closed before handshake completed
2025-09-03 16:39:07,143 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45782 closed before handshake completed
2025-09-03 16:39:07,145 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50658 closed before handshake completed
2025-09-03 16:39:07,145 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:50644 closed before handshake completed
2025-09-03 16:39:07,146 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57060 closed before handshake completed
2025-09-03 16:39:07,147 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57064 closed before handshake completed
2025-09-03 16:39:07,152 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40324 closed before handshake completed
2025-09-03 16:39:07,153 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40308 closed before handshake completed
2025-09-03 16:39:07,153 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40302 closed before handshake completed
2025-09-03 16:39:07,157 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40590 closed before handshake completed
2025-09-03 16:39:07,170 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56058 closed before handshake completed
2025-09-03 16:39:07,180 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41854 closed before handshake completed
2025-09-03 16:39:07,181 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41842 closed before handshake completed
2025-09-03 16:39:07,183 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:53974 closed before handshake completed
2025-09-03 16:39:07,190 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35406 closed before handshake completed
2025-09-03 16:39:07,191 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35404 closed before handshake completed
2025-09-03 16:39:07,195 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46968 closed before handshake completed
2025-09-03 16:39:07,196 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46956 closed before handshake completed
2025-09-03 16:39:07,197 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46960 closed before handshake completed
2025-09-03 16:39:07,197 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55378 closed before handshake completed
2025-09-03 16:39:07,220 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33312 closed before handshake completed
2025-09-03 16:39:07,221 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33296 closed before handshake completed
2025-09-03 16:39:07,229 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40340 closed before handshake completed
2025-09-03 16:39:07,229 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40350 closed before handshake completed
2025-09-03 16:39:07,247 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:59562 closed before handshake completed
2025-09-03 16:39:07,247 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:59584 closed before handshake completed
2025-09-03 16:39:07,248 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:59570 closed before handshake completed
2025-09-03 16:39:07,260 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41858 closed before handshake completed
2025-09-03 16:39:07,268 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:50960 closed before handshake completed
2025-09-03 16:39:07,281 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39650 closed before handshake completed
2025-09-03 16:39:07,289 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41430 closed before handshake completed
2025-09-03 16:39:07,306 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57088 closed before handshake completed
2025-09-03 16:39:07,307 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57074 closed before handshake completed
2025-09-03 16:39:07,313 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38454 closed before handshake completed
2025-09-03 16:39:07,314 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38468 closed before handshake completed
2025-09-03 16:39:07,317 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40604 closed before handshake completed
2025-09-03 16:39:07,332 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56068 closed before handshake completed
2025-09-03 16:39:07,333 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56082 closed before handshake completed
2025-09-03 16:39:07,339 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:56348 closed before handshake completed
2025-09-03 16:39:07,339 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:56340 closed before handshake completed
2025-09-03 16:39:07,342 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53520 closed before handshake completed
2025-09-03 16:39:07,356 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46978 closed before handshake completed
2025-09-03 16:39:07,362 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39660 closed before handshake completed
2025-09-03 16:39:07,369 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41468 closed before handshake completed
2025-09-03 16:39:07,370 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41438 closed before handshake completed
2025-09-03 16:39:07,371 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41456 closed before handshake completed
2025-09-03 16:39:07,371 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41442 closed before handshake completed
2025-09-03 16:39:07,381 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36254 closed before handshake completed
2025-09-03 16:39:07,387 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57094 closed before handshake completed
2025-09-03 16:39:07,388 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57106 closed before handshake completed
2025-09-03 16:39:07,389 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:40360 closed before handshake completed
2025-09-03 16:39:07,393 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38550 closed before handshake completed
2025-09-03 16:39:07,394 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38522 closed before handshake completed
2025-09-03 16:39:07,395 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38506 closed before handshake completed
2025-09-03 16:39:07,395 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38490 closed before handshake completed
2025-09-03 16:39:07,396 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38534 closed before handshake completed
2025-09-03 16:39:07,396 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38480 closed before handshake completed
2025-09-03 16:39:07,398 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40618 closed before handshake completed
2025-09-03 16:39:07,398 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40614 closed before handshake completed
2025-09-03 16:39:07,419 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53532 closed before handshake completed
2025-09-03 16:39:07,420 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53528 closed before handshake completed
2025-09-03 16:39:07,420 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:56356 closed before handshake completed
2025-09-03 16:39:07,425 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:47054 closed before handshake completed
2025-09-03 16:39:07,427 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:50966 closed before handshake completed
2025-09-03 16:39:07,431 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50368 closed before handshake completed
2025-09-03 16:39:07,435 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46988 closed before handshake completed
2025-09-03 16:39:07,439 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55382 closed before handshake completed
2025-09-03 16:39:07,449 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41470 closed before handshake completed
2025-09-03 16:39:07,461 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36262 closed before handshake completed
2025-09-03 16:39:07,462 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36272 closed before handshake completed
2025-09-03 16:39:07,463 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:39844 closed before handshake completed
2025-09-03 16:39:07,466 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57118 closed before handshake completed
2025-09-03 16:39:07,474 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38558 closed before handshake completed
2025-09-03 16:39:07,478 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40628 closed before handshake completed
2025-09-03 16:39:07,498 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:56370 closed before handshake completed
2025-09-03 16:39:07,500 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53548 closed before handshake completed
2025-09-03 16:39:07,503 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41868 closed before handshake completed
2025-09-03 16:39:07,504 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41878 closed before handshake completed
2025-09-03 16:39:07,505 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:47074 closed before handshake completed
2025-09-03 16:39:07,506 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:47060 closed before handshake completed
2025-09-03 16:39:07,518 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46998 closed before handshake completed
2025-09-03 16:39:07,529 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41476 closed before handshake completed
2025-09-03 16:39:07,530 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.34:41484 closed before handshake completed
2025-09-03 16:39:07,541 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36278 closed before handshake completed
2025-09-03 16:39:07,546 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57124 closed before handshake completed
2025-09-03 16:39:07,553 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.22:38568 closed before handshake completed
2025-09-03 16:39:07,560 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40638 closed before handshake completed
2025-09-03 16:39:07,579 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:56380 closed before handshake completed
2025-09-03 16:39:07,580 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:56398 closed before handshake completed
2025-09-03 16:39:07,580 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:56382 closed before handshake completed
2025-09-03 16:39:07,581 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:53552 closed before handshake completed
2025-09-03 16:39:07,582 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41886 closed before handshake completed
2025-09-03 16:39:07,586 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.8:47086 closed before handshake completed
2025-09-03 16:39:07,590 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.9:50970 closed before handshake completed
2025-09-03 16:39:07,601 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39676 closed before handshake completed
2025-09-03 16:39:07,627 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:57126 closed before handshake completed
2025-09-03 16:39:07,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:11,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:11,093 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:11,464 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:11,780 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33050 closed before handshake completed
2025-09-03 16:39:11,781 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33064 closed before handshake completed
2025-09-03 16:39:11,782 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33056 closed before handshake completed
2025-09-03 16:39:11,783 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33038 closed before handshake completed
2025-09-03 16:39:11,887 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42704 closed before handshake completed
2025-09-03 16:39:11,888 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42752 closed before handshake completed
2025-09-03 16:39:11,889 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42736 closed before handshake completed
2025-09-03 16:39:11,890 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42746 closed before handshake completed
2025-09-03 16:39:11,890 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.16:42720 closed before handshake completed
2025-09-03 16:39:11,909 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50108 closed before handshake completed
2025-09-03 16:39:11,910 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50088 closed before handshake completed
2025-09-03 16:39:11,911 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50102 closed before handshake completed
2025-09-03 16:39:11,912 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50098 closed before handshake completed
2025-09-03 16:39:11,912 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.1:50124 closed before handshake completed
2025-09-03 16:39:11,918 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50694 closed before handshake completed
2025-09-03 16:39:11,919 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.10:55224 closed before handshake completed
2025-09-03 16:39:11,921 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.4:50686 closed before handshake completed
2025-09-03 16:39:11,934 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35804 closed before handshake completed
2025-09-03 16:39:11,935 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35796 closed before handshake completed
2025-09-03 16:39:11,936 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35744 closed before handshake completed
2025-09-03 16:39:11,936 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35752 closed before handshake completed
2025-09-03 16:39:11,937 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35780 closed before handshake completed
2025-09-03 16:39:11,938 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35768 closed before handshake completed
2025-09-03 16:39:11,938 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35756 closed before handshake completed
2025-09-03 16:39:11,939 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.2:35742 closed before handshake completed
2025-09-03 16:39:11,973 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56096 closed before handshake completed
2025-09-03 16:39:11,974 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56118 closed before handshake completed
2025-09-03 16:39:11,975 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56130 closed before handshake completed
2025-09-03 16:39:11,975 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.23:56106 closed before handshake completed
2025-09-03 16:39:11,980 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41572 closed before handshake completed
2025-09-03 16:39:11,981 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41574 closed before handshake completed
2025-09-03 16:39:11,981 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.18:41586 closed before handshake completed
2025-09-03 16:39:11,993 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35138 closed before handshake completed
2025-09-03 16:39:11,994 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35164 closed before handshake completed
2025-09-03 16:39:11,995 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35160 closed before handshake completed
2025-09-03 16:39:11,995 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.20:35152 closed before handshake completed
2025-09-03 16:39:11,996 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46752 closed before handshake completed
2025-09-03 16:39:11,997 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.19:46768 closed before handshake completed
2025-09-03 16:39:12,041 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40294 closed before handshake completed
2025-09-03 16:39:12,042 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.27:40302 closed before handshake completed
2025-09-03 16:39:12,095 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60588 closed before handshake completed
2025-09-03 16:39:12,096 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60574 closed before handshake completed
2025-09-03 16:39:12,097 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.21:60590 closed before handshake completed
2025-09-03 16:39:12,145 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57216 closed before handshake completed
2025-09-03 16:39:12,146 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57204 closed before handshake completed
2025-09-03 16:39:12,147 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57210 closed before handshake completed
2025-09-03 16:39:12,148 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.36:57198 closed before handshake completed
2025-09-03 16:39:12,185 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:35998 closed before handshake completed
2025-09-03 16:39:12,186 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36012 closed before handshake completed
2025-09-03 16:39:12,187 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:35984 closed before handshake completed
2025-09-03 16:39:12,187 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:36026 closed before handshake completed
2025-09-03 16:39:12,188 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.24:35992 closed before handshake completed
2025-09-03 16:39:12,189 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33792 closed before handshake completed
2025-09-03 16:39:12,190 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33794 closed before handshake completed
2025-09-03 16:39:12,191 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33836 closed before handshake completed
2025-09-03 16:39:12,191 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33820 closed before handshake completed
2025-09-03 16:39:12,192 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.35:33806 closed before handshake completed
2025-09-03 16:39:12,192 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45448 closed before handshake completed
2025-09-03 16:39:12,193 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45408 closed before handshake completed
2025-09-03 16:39:12,193 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45432 closed before handshake completed
2025-09-03 16:39:12,194 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.25:45416 closed before handshake completed
2025-09-03 16:39:12,195 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.7:43694 closed before handshake completed
2025-09-03 16:39:12,221 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.14:33848 closed before handshake completed
2025-09-03 16:39:12,272 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.11:39968 closed before handshake completed
2025-09-03 16:39:12,309 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34322 closed before handshake completed
2025-09-03 16:39:12,310 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.5:34334 closed before handshake completed
2025-09-03 16:39:12,325 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39384 closed before handshake completed
2025-09-03 16:39:12,350 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56808 closed before handshake completed
2025-09-03 16:39:12,350 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56810 closed before handshake completed
2025-09-03 16:39:12,351 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56824 closed before handshake completed
2025-09-03 16:39:12,352 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56806 closed before handshake completed
2025-09-03 16:39:12,353 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56800 closed before handshake completed
2025-09-03 16:39:12,423 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33080 closed before handshake completed
2025-09-03 16:39:12,424 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.6:33094 closed before handshake completed
2025-09-03 16:39:12,462 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.15:59534 closed before handshake completed
2025-09-03 16:39:12,505 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48850 closed before handshake completed
2025-09-03 16:39:12,506 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48846 closed before handshake completed
2025-09-03 16:39:12,506 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48848 closed before handshake completed
2025-09-03 16:39:12,507 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.17:48856 closed before handshake completed
2025-09-03 16:39:16,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:17,989 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.13:56792 closed before handshake completed
2025-09-03 16:39:21,727 - distributed.comm.tcp - INFO - Connection from tcp://10.6.102.3:39398 closed before handshake completed
2025-09-03 16:39:23,714 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:28,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:30,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:30,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:30,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:30,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,504 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:31,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:32,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:32,150 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,337 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,338 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,800 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:33,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:34,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:34,102 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:34,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:34,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:34,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:34,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:34,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:35,758 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:35,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,528 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:36,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:37,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:38,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:38,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:45,467 - distributed.core - INFO - Event loop was unresponsive in Worker for 20.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:49,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:49,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 24.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:50,537 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:53,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:54,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:54,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:55,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,195 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,197 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:56,803 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:57,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:58,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:58,133 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:59,556 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:59,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:39:59,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:00,028 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:00,029 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:00,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:00,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:00,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:00,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:00,916 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:01,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:01,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:02,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:03,454 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:05,858 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:05,860 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:10,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:11,289 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:11,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:12,516 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:14,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:14,582 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:14,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,112 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,232 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,232 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,234 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,419 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,444 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,448 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,670 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:15,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:16,160 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:16,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:16,306 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:16,766 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:16,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:17,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:17,166 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:17,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:17,328 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:17,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:17,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:17,876 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:18,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:18,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:18,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:18,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,418 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:19,547 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:20,071 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:25,267 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:25,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:26,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:26,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:26,518 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:26,816 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:26,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:26,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,738 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,973 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:27,975 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:28,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:28,627 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:28,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:29,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:29,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:29,343 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:29,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:29,947 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:30,463 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:30,721 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:30,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:31,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:31,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:31,211 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:31,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:33,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:34,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:38,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:38,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:38,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:46,302 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:46,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:46,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:46,596 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:46,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:47,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:47,077 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:48,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,090 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,905 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,924 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:49,983 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:50,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:51,009 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:51,016 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:51,017 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:51,062 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:51,117 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:51,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:51,333 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:52,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:52,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:52,384 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:52,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:52,482 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:52,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:52,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:56,105 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:59,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:59,033 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:40:59,043 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:00,685 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:00,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:00,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:01,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:01,141 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:01,282 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:02,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:02,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:02,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:02,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:05,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:05,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:05,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:05,594 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:06,076 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:06,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:06,086 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:06,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:06,719 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:06,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:08,945 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:08,946 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:09,636 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:09,639 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:09,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:22,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:22,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:22,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:22,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 21.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:24,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 22.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:29,546 - distributed.core - INFO - Event loop was unresponsive in Worker for 28.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:34,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:34,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:35,952 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:35,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,583 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,673 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,730 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:36,850 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:37,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:37,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:37,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:38,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:39,436 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,318 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,340 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,506 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:40,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:42,258 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:42,392 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:42,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:42,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:42,856 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:42,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:44,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:45,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:45,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:45,530 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:47,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:47,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:47,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:48,794 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:50,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:50,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:41:51,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:00,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:00,625 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:00,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:00,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:00,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:01,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:01,373 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:01,732 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:01,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:02,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:02,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:03,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:03,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:04,477 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:04,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:04,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:05,026 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:09,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:09,273 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:09,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:09,279 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:09,410 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:11,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:12,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:12,443 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:12,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:13,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:13,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:13,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:13,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,955 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:14,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,005 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,026 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,029 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,567 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,579 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:15,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:16,236 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:16,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:17,398 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:17,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:17,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:17,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:17,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:19,214 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:20,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:22,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:23,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:30,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:30,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:31,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:31,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:31,686 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:31,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,059 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,130 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,132 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,210 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,212 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:32,943 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:33,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:33,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:33,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:33,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:33,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,352 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,353 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,359 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,468 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:34893. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:40289. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,834 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:37451. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,835 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:33471. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,835 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:43405. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,835 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:35341. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,835 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:35093. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,835 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:37137. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,836 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:40651. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,836 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:46853. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,836 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:36691. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,836 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:44653. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,836 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:44583. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,836 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:33655. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,836 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:34479. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,836 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:42557. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,836 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:35969. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,834 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,837 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:43595. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,837 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:33161. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,837 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:42419. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,837 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:42643. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,833 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,837 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:43285. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,837 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:35197. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,837 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:45595. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,837 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:44873. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,836 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,838 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:41701. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,838 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:35915. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,838 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:45237. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,838 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:41609. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,838 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:46407. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,839 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:46289. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,839 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:43479. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,835 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.102.2:40530 remote=tcp://10.6.102.1:8786>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:34,841 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,841 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:37859. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,836 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.102.2:40220 remote=tcp://10.6.102.1:8786>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:34,838 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.102.2:40272 remote=tcp://10.6.102.1:8786>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:34,839 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.102.2:40214 remote=tcp://10.6.102.1:8786>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:34,842 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1259, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://10.6.102.2:40262 remote=tcp://10.6.102.1:8786>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:34,860 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:45587'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,862 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:40193'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,862 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:33949'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,862 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:35783'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,862 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:45757'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,862 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:35751'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,862 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2155, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,862 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:35073'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,863 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2167, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,863 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46109'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,863 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:38463'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,863 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2828, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,863 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1373, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,863 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1389, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,863 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,863 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1740, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,863 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3003, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,863 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8705, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,863 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,863 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1574, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1739, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3581, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.16:36237, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8520, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3557, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1072, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1277, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2292, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.20:39447, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,864 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.6:41721, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1078, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,864 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,864 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,864 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,865 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1054, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,865 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,866 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,867 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,867 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:45109'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,867 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46243'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,867 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:39543'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:40059'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:35199'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46579'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46781'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:40159'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:33055'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,868 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:40623'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,869 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:40113'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 5422, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:42949'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1493, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.14:37235, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:42925'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3788, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1514, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3560, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1075, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:41649'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.24:44825, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.9:43061, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2763, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:41041'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3564, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,869 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1674, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:41453'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1390, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1741, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.2:41515, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 5848, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1216, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:40609'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1736, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8755, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.18:46799, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:39099'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2385, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2208, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.18:37509, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,870 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:35879'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 5134, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,870 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,870 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1858, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8302, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.18:41843, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,871 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:32799'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 6537, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2207, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1226, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,871 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:45457'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3233, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1080, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,871 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46133'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1076, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,871 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8489, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,871 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,872 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.14:33483, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,872 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:45455'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,872 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1060, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,872 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8561, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,872 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:33083'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,872 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.7:40343, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,872 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1261, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,872 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,873 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3376, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,873 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.8:41823, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,873 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.17:34421, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,873 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8746, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,873 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.2:43679, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,873 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.2:45401, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,873 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.3:43743, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,873 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1523, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,873 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.8:43043, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.24:44899, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8589, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1383, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.17:33473, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8592, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.36:35663, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1522, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3612, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.19:46783, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 6041, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,874 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,875 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.22:33179, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,875 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1515, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,875 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.4:37965, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,875 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2406, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,875 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,876 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 2396, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,876 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,876 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3002, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,877 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 1191, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:34,877 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,878 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,878 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,878 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,878 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,878 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,878 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,878 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,879 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,879 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,879 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,879 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,879 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,879 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,879 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,879 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,879 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,880 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,880 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,880 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,880 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,881 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,881 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,881 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,881 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,881 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,881 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,881 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,882 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,882 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,899 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:34,900 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:34,900 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:34,900 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:34,900 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:34,987 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:34,990 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:46247. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,005 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:35,011 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39890 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:35,015 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:37133'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,014 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.2:37859 -> tcp://10.6.102.1:40669
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.2:37859 remote=tcp://10.6.102.1:58990>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:35,016 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 5383, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:35,016 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:35,018 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:35,019 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:35,019 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:35,019 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:35,166 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.2:33471 -> tcp://10.6.102.23:38831
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.2:33471 remote=tcp://10.6.102.23:39728>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:35,281 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:35,285 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:40347. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:35,315 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:40172 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:35,331 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:35469'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,332 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:35,332 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:35,332 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:35,332 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:35,332 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:35,340 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x15173189f450>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:35,351 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,493 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,524 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:35,523 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:35,525 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:43043. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,525 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:33491. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:35,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:35,545 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:40200 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:35,548 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46261'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,549 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:35,547 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39918 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:35,549 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:35,550 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:35,550 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:35,550 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:35,552 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46073'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,558 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3498, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:35,558 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:35,558 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:35,558 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:35,558 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:35,558 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:35,556 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x15386817ec90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:35,565 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,668 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:35,668 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:44915. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,675 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:35,678 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39952 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:35,680 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:33887'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,681 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 8308, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:35,681 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:35,681 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:35,681 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:35,681 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:35,681 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:35,687 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x15546d899f50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:35,692 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,786 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:35,880 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:35,882 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:38453. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:35,904 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:40182 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:35,912 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:43849'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:35,913 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:35,913 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:35,913 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:35,913 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:35,913 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:35,926 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,099 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:36,102 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:46131. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,110 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.2:34479 -> tcp://10.6.102.20:33981
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.2:34479 remote=tcp://10.6.102.20:55236>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:36,120 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,127 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39982 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:36,132 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46129'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,137 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,137 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,137 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,137 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,138 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,145 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14fa2ce36190>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,153 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,598 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:36,599 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:39947. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,609 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,624 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:40062 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:36,632 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:45613'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,633 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,633 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,633 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,633 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,633 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,636 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:36,639 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:46357. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,641 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:36,643 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:41515. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,641 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14823b58b990>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,643 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:36,646 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:43679. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,650 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,663 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,661 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.2:43679 -> tcp://10.6.102.2:42419
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.2:43679 remote=tcp://10.6.102.2:60750>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-03 16:42:36,663 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:40122 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:36,667 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:42783'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,668 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:36,668 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,669 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,669 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,669 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,669 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,669 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39970 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:36,673 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:40068 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:36,674 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:39879'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,675 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,675 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,675 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,675 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,675 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,676 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46255'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:36,677 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:36,677 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:36,677 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:36,677 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:36,677 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:36,676 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14b10a7e6b90>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,684 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,682 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ef5d9513d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,683 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ffda0e3b10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:36,689 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,690 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,799 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:36,807 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.2:35915 -> tcp://10.6.102.14:46509
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.2:35915 remote=tcp://10.6.102.14:57586>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-03 16:42:37,045 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,209 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,355 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,497 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,536 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,539 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:37,541 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:45401. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:37,567 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,566 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39900 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:37,573 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:34701'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,574 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:37,574 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:37,574 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:37,574 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:37,574 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:37,582 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,614 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:37,616 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:38501. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,637 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:37,641 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,642 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,642 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39784 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:37,645 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:40985'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:37,646 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:37,646 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:37,646 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:37,646 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:37,646 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:37,651 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x15107ef5bb10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:37,657 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,694 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,779 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:37,790 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,876 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:35469'. Reason: nanny-close-gracefully
2025-09-03 16:42:37,878 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:35469' closed.
2025-09-03 16:42:37,929 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:37,947 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:33083'. Reason: nanny-close-gracefully
2025-09-03 16:42:37,948 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:33083' closed.
2025-09-03 16:42:37,982 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46261'. Reason: nanny-close-gracefully
2025-09-03 16:42:37,983 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46261' closed.
2025-09-03 16:42:38,027 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:38,030 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:44853. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,046 - distributed.worker - ERROR - failed during get data with tcp://10.6.102.2:44853 -> tcp://10.6.102.3:36333
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.102.2:44853 remote=tcp://10.6.102.3:55916>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-03 16:42:38,053 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:38,057 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:40038 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:38,060 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:35627'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,061 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:38,061 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:38,061 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:38,061 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:38,061 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:38,064 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x147d4617e790>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:38,069 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,126 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:33887'. Reason: nanny-close-gracefully
2025-09-03 16:42:38,127 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:33887' closed.
2025-09-03 16:42:38,156 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,233 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:37133'. Reason: nanny-close-gracefully
2025-09-03 16:42:38,235 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:37133' closed.
2025-09-03 16:42:38,338 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:38,339 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:43369. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,340 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,341 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:38,343 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:43029. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,356 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.102.11:33065
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 226, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2879, in get_data_from_worker
    response = await send_recv(
               ^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1018, in send_recv
    response = await comm.read(deserializers=deserializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Ephemeral Worker->Worker for gather local=tcp://10.6.102.2:46692 remote=tcp://10.6.102.11:33065>: Stream is closed
2025-09-03 16:42:38,360 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:43849'. Reason: nanny-close-gracefully
2025-09-03 16:42:38,360 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:43849' closed.
2025-09-03 16:42:38,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:38,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:38,367 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39814 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:38,369 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46825'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,369 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:40150 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:38,370 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:38,370 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:38,370 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:38,370 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:38,371 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:38,372 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:35193'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,372 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:38,373 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:38,373 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:38,373 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:38,373 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:38,375 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x154447460510>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:38,377 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1480e0b7cf50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:38,380 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,382 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,613 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,642 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:38,642 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:44489. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:38,653 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,653 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:40034 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:38,655 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:40167'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,655 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-664014352b01c2eea80f3f701e468b9a', 3605, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:38,655 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:38,655 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:38,655 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:38,656 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:38,656 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:38,658 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:38,682 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46129'. Reason: nanny-close-gracefully
2025-09-03 16:42:38,684 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46129' closed.
2025-09-03 16:42:38,687 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,692 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,693 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,731 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,788 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,804 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:38,816 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:38,943 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:38,945 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:38723. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,970 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:38,974 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39862 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-03 16:42:38,978 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:35415'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:38,979 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.10:35413, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:38,980 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:38,980 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:38,980 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:38,980 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:38,980 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:38,983 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1538e3213090>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:38,988 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,049 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,096 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,128 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:42783'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,132 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:42783' closed.
2025-09-03 16:42:39,148 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46073'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,149 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46073' closed.
2025-09-03 16:42:39,154 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:45613'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,155 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:45613' closed.
2025-09-03 16:42:39,213 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,241 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46255'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,242 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46255' closed.
2025-09-03 16:42:39,244 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:39879'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,245 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:39879' closed.
2025-09-03 16:42:39,268 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,268 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,310 - distributed.core - INFO - Connection to tcp://10.6.102.1:8786 has been closed.
2025-09-03 16:42:39,311 - distributed.worker - INFO - Stopping worker at tcp://10.6.102.2:46135. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:39,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-03 16:42:39,318 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,321 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39998 remote=tcp://10.6.102.1:8786>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 308, in write
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 137, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Worker->Scheduler local=tcp://10.6.102.2:39998 remote=tcp://10.6.102.1:8786>: Stream is closed
2025-09-03 16:42:39,323 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,323 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,329 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.102.2:46775'. Reason: worker-handle-scheduler-connection-broken
2025-09-03 16:42:39,330 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.23:36763, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:39,330 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.102.3:42657, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-03 16:42:39,330 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-03 16:42:39,330 - distributed.worker - INFO - Removing Worker plugin qme_utils.py1d5c8fe7-a714-4c02-b47d-37cc6d7f0848
2025-09-03 16:42:39,330 - distributed.worker - INFO - Removing Worker plugin qme_vars.pye7f0b07d-9c67-4b5f-926b-4dff9694ebc5
2025-09-03 16:42:39,330 - distributed.worker - INFO - Removing Worker plugin qme_train.pyb56dbd10-95ab-4a3b-9925-4131dd74b838
2025-09-03 16:42:39,331 - distributed.worker - INFO - Removing Worker plugin qme_apply.pyd1c7ce75-6e80-44d8-9cff-2674c5c3b113
2025-09-03 16:42:39,333 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 547, in connect
    stream = await self.client.connect(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/tcpclient.py", line 279, in connect
    af, addr, stream = await connector.start(connect_timeout=timeout)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-03 16:42:39,338 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,366 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:45455'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,367 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:45455' closed.
2025-09-03 16:42:39,407 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,445 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,460 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,493 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,506 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,507 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,514 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:45457'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,515 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:45457' closed.
2025-09-03 16:42:39,519 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,540 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,584 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,603 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,641 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,645 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,646 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,646 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,647 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,647 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,647 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,660 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:39,670 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,670 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,693 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:39543'. Reason: nanny-close-gracefully
2025-09-03 16:42:39,694 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:39543' closed.
2025-09-03 16:42:39,701 - distributed.nanny - INFO - Worker closed
2025-09-03 16:42:39,783 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,072 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,096 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46579'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,097 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46579' closed.
2025-09-03 16:42:40,111 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46133'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,112 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46133' closed.
2025-09-03 16:42:40,134 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:34701'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,135 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:34701' closed.
2025-09-03 16:42:40,197 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:40985'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,198 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:41453'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,199 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:40985' closed.
2025-09-03 16:42:40,199 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:41453' closed.
2025-09-03 16:42:40,328 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:40623'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,329 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:40623' closed.
2025-09-03 16:42:40,344 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,382 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,385 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,518 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:35627'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,520 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:35627' closed.
2025-09-03 16:42:40,735 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,792 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,820 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:40,910 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46825'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,911 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46825' closed.
2025-09-03 16:42:40,924 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:35073'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,929 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:35073' closed.
2025-09-03 16:42:40,933 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:35193'. Reason: nanny-close-gracefully
2025-09-03 16:42:40,934 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:35193' closed.
2025-09-03 16:42:40,991 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,100 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,198 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:35783'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,199 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:35783' closed.
2025-09-03 16:42:41,213 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:42925'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,215 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:42925' closed.
2025-09-03 16:42:41,262 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:33055'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,263 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:33055' closed.
2025-09-03 16:42:41,272 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,273 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,322 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,327 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,327 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,341 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,412 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,437 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:35415'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,438 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:35415' closed.
2025-09-03 16:42:41,449 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,464 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,497 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,510 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,510 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,523 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,584 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:35199'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,585 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:35199' closed.
2025-09-03 16:42:41,606 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,645 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,649 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,650 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,651 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,674 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,674 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,705 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-03 16:42:41,741 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:35751'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,743 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:35751' closed.
2025-09-03 16:42:41,757 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:38463'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,758 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:38463' closed.
2025-09-03 16:42:41,792 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:35879'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,794 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:35879' closed.
2025-09-03 16:42:41,811 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:41649'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,812 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:41649' closed.
2025-09-03 16:42:41,893 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46775'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,894 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46775' closed.
2025-09-03 16:42:41,919 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46243'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,923 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46243' closed.
2025-09-03 16:42:41,945 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46781'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,946 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46781' closed.
2025-09-03 16:42:41,962 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:45587'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,963 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:45587' closed.
2025-09-03 16:42:41,974 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:32799'. Reason: nanny-close-gracefully
2025-09-03 16:42:41,975 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:32799' closed.
2025-09-03 16:42:42,027 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:40193'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,028 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:40193' closed.
2025-09-03 16:42:42,034 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:45757'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,035 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:45757' closed.
2025-09-03 16:42:42,052 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:40159'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,054 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:40159' closed.
2025-09-03 16:42:42,055 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:40113'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,056 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:40113' closed.
2025-09-03 16:42:42,118 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:42949'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,119 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:42949' closed.
2025-09-03 16:42:42,138 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:39099'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,140 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:40059'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,141 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:39099' closed.
2025-09-03 16:42:42,141 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:40059' closed.
2025-09-03 16:42:42,166 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:45109'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,167 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:45109' closed.
2025-09-03 16:42:42,180 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:46109'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,181 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:46109' closed.
2025-09-03 16:42:42,205 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:40609'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,206 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:40609' closed.
2025-09-03 16:42:42,219 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:40167'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,220 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:40167' closed.
2025-09-03 16:42:42,224 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:41041'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,225 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:41041' closed.
2025-09-03 16:42:42,231 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.102.2:33949'. Reason: nanny-close-gracefully
2025-09-03 16:42:42,231 - distributed.nanny - INFO - Nanny at 'tcp://10.6.102.2:33949' closed.
2025-09-03 16:42:42,234 - distributed.dask_worker - INFO - End worker
