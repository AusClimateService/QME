2025-09-12 10:16:27,383 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:33843'
2025-09-12 10:16:27,395 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:38627'
2025-09-12 10:16:27,401 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:38387'
2025-09-12 10:16:27,407 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:41669'
2025-09-12 10:16:27,409 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:42945'
2025-09-12 10:16:27,412 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:33215'
2025-09-12 10:16:27,416 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:36227'
2025-09-12 10:16:27,419 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:33699'
2025-09-12 10:16:27,426 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:33841'
2025-09-12 10:16:27,430 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:42815'
2025-09-12 10:16:27,435 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:32773'
2025-09-12 10:16:27,439 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:44077'
2025-09-12 10:16:27,442 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:45157'
2025-09-12 10:16:27,447 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:36723'
2025-09-12 10:16:27,452 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:39361'
2025-09-12 10:16:27,457 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:44395'
2025-09-12 10:16:27,461 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:36811'
2025-09-12 10:16:27,466 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:39939'
2025-09-12 10:16:27,471 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:37673'
2025-09-12 10:16:27,480 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:35527'
2025-09-12 10:16:27,483 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:42715'
2025-09-12 10:16:27,487 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:42285'
2025-09-12 10:16:27,492 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:43539'
2025-09-12 10:16:27,497 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:39465'
2025-09-12 10:16:27,501 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:40325'
2025-09-12 10:16:27,576 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:45581'
2025-09-12 10:16:27,580 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:34465'
2025-09-12 10:16:27,585 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:38437'
2025-09-12 10:16:27,590 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:45815'
2025-09-12 10:16:27,595 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:41659'
2025-09-12 10:16:27,600 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:35711'
2025-09-12 10:16:27,603 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.5.25:36113'
2025-09-12 10:16:29,534 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:42681
2025-09-12 10:16:29,534 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:42681
2025-09-12 10:16:29,535 - distributed.worker - INFO -          dashboard at:            10.6.5.25:39671
2025-09-12 10:16:29,535 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,535 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,535 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,535 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,535 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-yatrz5ou
2025-09-12 10:16:29,535 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,576 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:41149
2025-09-12 10:16:29,577 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:41149
2025-09-12 10:16:29,577 - distributed.worker - INFO -          dashboard at:            10.6.5.25:45883
2025-09-12 10:16:29,577 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,577 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,577 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,577 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-9kfkux90
2025-09-12 10:16:29,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,596 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:37395
2025-09-12 10:16:29,596 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:37395
2025-09-12 10:16:29,596 - distributed.worker - INFO -          dashboard at:            10.6.5.25:33711
2025-09-12 10:16:29,597 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,597 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,597 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,597 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-cih_l9ec
2025-09-12 10:16:29,597 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,597 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,598 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,598 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,600 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,601 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,601 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,603 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,613 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,614 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,614 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,615 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,621 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:38613
2025-09-12 10:16:29,622 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:38613
2025-09-12 10:16:29,622 - distributed.worker - INFO -          dashboard at:            10.6.5.25:37393
2025-09-12 10:16:29,622 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,622 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,622 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,622 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-7z8moytu
2025-09-12 10:16:29,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,625 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,626 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:34101
2025-09-12 10:16:29,627 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:34101
2025-09-12 10:16:29,627 - distributed.worker - INFO -          dashboard at:            10.6.5.25:40409
2025-09-12 10:16:29,627 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,627 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,627 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,627 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-hfzxlxmo
2025-09-12 10:16:29,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,643 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,643 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,644 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,644 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,645 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,645 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,658 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:39257
2025-09-12 10:16:29,658 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:39257
2025-09-12 10:16:29,658 - distributed.worker - INFO -          dashboard at:            10.6.5.25:37895
2025-09-12 10:16:29,659 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,659 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,659 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,659 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-nh54oaix
2025-09-12 10:16:29,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,662 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:35985
2025-09-12 10:16:29,662 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:35985
2025-09-12 10:16:29,662 - distributed.worker - INFO -          dashboard at:            10.6.5.25:44147
2025-09-12 10:16:29,662 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,662 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,662 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,662 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-7k2bc41x
2025-09-12 10:16:29,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,675 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,676 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,676 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,678 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,680 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:41305
2025-09-12 10:16:29,680 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:41305
2025-09-12 10:16:29,681 - distributed.worker - INFO -          dashboard at:            10.6.5.25:42379
2025-09-12 10:16:29,681 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,681 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,681 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,681 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,681 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-huavm3ou
2025-09-12 10:16:29,681 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,681 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,682 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,682 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,684 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,685 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:43003
2025-09-12 10:16:29,685 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:43003
2025-09-12 10:16:29,685 - distributed.worker - INFO -          dashboard at:            10.6.5.25:43543
2025-09-12 10:16:29,685 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,685 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,685 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,685 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,685 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-v16o6sib
2025-09-12 10:16:29,686 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,686 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:38197
2025-09-12 10:16:29,686 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:38197
2025-09-12 10:16:29,687 - distributed.worker - INFO -          dashboard at:            10.6.5.25:33931
2025-09-12 10:16:29,687 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,687 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,687 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,687 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,687 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-81crrwwv
2025-09-12 10:16:29,687 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,688 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:45613
2025-09-12 10:16:29,688 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:45613
2025-09-12 10:16:29,688 - distributed.worker - INFO -          dashboard at:            10.6.5.25:36115
2025-09-12 10:16:29,688 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,688 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,688 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,688 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,688 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-w4ag9ud3
2025-09-12 10:16:29,688 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,690 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:33143
2025-09-12 10:16:29,691 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:33143
2025-09-12 10:16:29,691 - distributed.worker - INFO -          dashboard at:            10.6.5.25:35577
2025-09-12 10:16:29,691 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,691 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,691 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,691 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,691 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-xpkwb98j
2025-09-12 10:16:29,691 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,701 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,701 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,701 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,702 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,702 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,703 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,703 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,703 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,704 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,704 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,704 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:46253
2025-09-12 10:16:29,704 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:46253
2025-09-12 10:16:29,704 - distributed.worker - INFO -          dashboard at:            10.6.5.25:32903
2025-09-12 10:16:29,705 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,705 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,705 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,705 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-1fqi_wax
2025-09-12 10:16:29,705 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,705 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,705 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,706 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:34429
2025-09-12 10:16:29,706 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:34429
2025-09-12 10:16:29,706 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,706 - distributed.worker - INFO -          dashboard at:            10.6.5.25:36437
2025-09-12 10:16:29,706 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,706 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:36887
2025-09-12 10:16:29,706 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,706 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:36887
2025-09-12 10:16:29,706 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,706 - distributed.worker - INFO -          dashboard at:            10.6.5.25:33093
2025-09-12 10:16:29,706 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,706 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,706 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,706 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-r3axwuhn
2025-09-12 10:16:29,706 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,706 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,707 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,707 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,707 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,707 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-2wtmqf_3
2025-09-12 10:16:29,707 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,707 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,708 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,708 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,708 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,709 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,711 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:33977
2025-09-12 10:16:29,711 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:33977
2025-09-12 10:16:29,711 - distributed.worker - INFO -          dashboard at:            10.6.5.25:46565
2025-09-12 10:16:29,711 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,711 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,711 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,711 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,711 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-o8esego2
2025-09-12 10:16:29,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,714 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:45877
2025-09-12 10:16:29,714 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:45877
2025-09-12 10:16:29,714 - distributed.worker - INFO -          dashboard at:            10.6.5.25:34043
2025-09-12 10:16:29,714 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,714 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,714 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,715 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,715 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-tx3v6n96
2025-09-12 10:16:29,715 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,724 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:43005
2025-09-12 10:16:29,724 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:43005
2025-09-12 10:16:29,724 - distributed.worker - INFO -          dashboard at:            10.6.5.25:40397
2025-09-12 10:16:29,724 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,724 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,724 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,724 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,724 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-86qs_zw0
2025-09-12 10:16:29,725 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,730 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,731 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,731 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,731 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,732 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,732 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,733 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,733 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,735 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,736 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,736 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,737 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,737 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,738 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,738 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,739 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,740 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,740 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,740 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,741 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,742 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:42297
2025-09-12 10:16:29,743 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:36539
2025-09-12 10:16:29,743 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:42297
2025-09-12 10:16:29,743 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:36539
2025-09-12 10:16:29,743 - distributed.worker - INFO -          dashboard at:            10.6.5.25:34145
2025-09-12 10:16:29,743 - distributed.worker - INFO -          dashboard at:            10.6.5.25:42591
2025-09-12 10:16:29,743 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,743 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,743 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,743 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,743 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,743 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,743 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-qjegbr08
2025-09-12 10:16:29,743 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-4g2lev32
2025-09-12 10:16:29,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,743 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,744 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:37937
2025-09-12 10:16:29,745 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:37937
2025-09-12 10:16:29,745 - distributed.worker - INFO -          dashboard at:            10.6.5.25:39889
2025-09-12 10:16:29,745 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,745 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,745 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,745 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-k4kbag6f
2025-09-12 10:16:29,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,752 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,753 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,753 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,753 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:34033
2025-09-12 10:16:29,754 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:34033
2025-09-12 10:16:29,754 - distributed.worker - INFO -          dashboard at:            10.6.5.25:33425
2025-09-12 10:16:29,754 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,754 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,754 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,754 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-7osv3xku
2025-09-12 10:16:29,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,755 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,760 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,761 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,762 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,762 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,763 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:33159
2025-09-12 10:16:29,763 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:33159
2025-09-12 10:16:29,763 - distributed.worker - INFO -          dashboard at:            10.6.5.25:41173
2025-09-12 10:16:29,763 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,763 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,763 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,763 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,763 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,763 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,763 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-4wpzm1ym
2025-09-12 10:16:29,764 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,764 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,764 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,765 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,765 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,766 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,770 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:40009
2025-09-12 10:16:29,770 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:40009
2025-09-12 10:16:29,770 - distributed.worker - INFO -          dashboard at:            10.6.5.25:42217
2025-09-12 10:16:29,770 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,770 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,770 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,770 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,770 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,770 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-91xhtmmb
2025-09-12 10:16:29,770 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,771 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,771 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,772 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,777 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:35999
2025-09-12 10:16:29,777 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:35999
2025-09-12 10:16:29,777 - distributed.worker - INFO -          dashboard at:            10.6.5.25:33907
2025-09-12 10:16:29,777 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,777 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,777 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,777 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,777 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-3cjue6z8
2025-09-12 10:16:29,778 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,779 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,780 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,780 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,781 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:35173
2025-09-12 10:16:29,781 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,781 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:35173
2025-09-12 10:16:29,781 - distributed.worker - INFO -          dashboard at:            10.6.5.25:33991
2025-09-12 10:16:29,782 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,782 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,782 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,782 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,782 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-yrxlbgz9
2025-09-12 10:16:29,782 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,790 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,791 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,791 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,793 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,794 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:37305
2025-09-12 10:16:29,794 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:37305
2025-09-12 10:16:29,794 - distributed.worker - INFO -          dashboard at:            10.6.5.25:41033
2025-09-12 10:16:29,794 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,794 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,794 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,794 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,794 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-ymb568z3
2025-09-12 10:16:29,795 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,795 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,796 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,796 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,797 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,801 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,802 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,802 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,803 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,808 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,809 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,809 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,810 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,889 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:43525
2025-09-12 10:16:29,889 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:43525
2025-09-12 10:16:29,889 - distributed.worker - INFO -          dashboard at:            10.6.5.25:32801
2025-09-12 10:16:29,889 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,889 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,889 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,889 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,889 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-z6xehg2s
2025-09-12 10:16:29,890 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,909 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,910 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,910 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,912 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,931 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:43929
2025-09-12 10:16:29,931 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:43929
2025-09-12 10:16:29,931 - distributed.worker - INFO -          dashboard at:            10.6.5.25:43207
2025-09-12 10:16:29,931 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,931 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,932 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,932 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,932 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-xu3s3qbh
2025-09-12 10:16:29,932 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,947 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,947 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,948 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,948 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:29,960 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:35363
2025-09-12 10:16:29,960 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:35363
2025-09-12 10:16:29,960 - distributed.worker - INFO -          dashboard at:            10.6.5.25:33603
2025-09-12 10:16:29,960 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,960 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,960 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:29,961 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:29,961 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-5t4a9qbs
2025-09-12 10:16:29,961 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,976 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:29,977 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:29,977 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:29,978 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:30,018 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:37007
2025-09-12 10:16:30,019 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:37007
2025-09-12 10:16:30,019 - distributed.worker - INFO -          dashboard at:            10.6.5.25:34657
2025-09-12 10:16:30,019 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:30,019 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:30,019 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:30,019 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:30,019 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-dccrqtpr
2025-09-12 10:16:30,019 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:30,028 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:34571
2025-09-12 10:16:30,028 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:34571
2025-09-12 10:16:30,029 - distributed.worker - INFO -          dashboard at:            10.6.5.25:39159
2025-09-12 10:16:30,029 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:16:30,029 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:30,029 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:16:30,029 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:16:30,029 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-lek97h_q
2025-09-12 10:16:30,029 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:30,035 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:30,035 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:30,035 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:30,036 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:30,046 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:16:30,046 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:16:30,046 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:16:30,047 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:16:42,042 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,043 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,043 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,044 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,044 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,044 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,045 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,045 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,045 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,046 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,046 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,047 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,045 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,047 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,047 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,047 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,048 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,047 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,048 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,047 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,048 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,049 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,049 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,048 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,050 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,049 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,050 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,050 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,049 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,051 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,051 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,051 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,052 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,052 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,052 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,052 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,053 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,053 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,052 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,053 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,053 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,054 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,052 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,054 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,054 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,054 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,054 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,055 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,054 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,055 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,056 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,056 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,056 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,056 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,056 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,055 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:16:42,057 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,057 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,059 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,059 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,060 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,060 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,061 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:42,062 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:16:44,962 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,962 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,963 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,963 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,964 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,964 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,964 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,964 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,965 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,965 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,965 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,966 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,967 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,966 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,967 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,967 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,968 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,968 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,967 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,968 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,970 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,969 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,971 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,969 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,970 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,971 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,971 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,972 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,973 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,973 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,973 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,973 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,973 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,973 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,972 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,975 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,974 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,975 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,975 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,976 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,976 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,976 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,976 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,976 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,977 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,978 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,978 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,978 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,978 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,978 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,978 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,979 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,980 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,980 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,980 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,980 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,980 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,980 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,981 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,982 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:16:44,982 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,983 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,983 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:44,983 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:16:45,075 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,076 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,077 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,078 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,078 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,078 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,079 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,079 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,079 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,080 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,080 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,080 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,082 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,082 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,082 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,082 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,083 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,083 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,083 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,084 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,085 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,085 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,086 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,086 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,087 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,087 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,087 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,087 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,087 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,088 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,088 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,088 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,088 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,089 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,089 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,089 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,090 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,090 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,091 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,091 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,091 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,092 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,092 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,093 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,093 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,094 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,095 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,095 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,095 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,095 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,095 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,096 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,096 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,097 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,097 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,097 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,097 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,097 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,098 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:16:45,099 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,099 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,100 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,100 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,100 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:16:45,156 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,156 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,157 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,157 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,158 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,158 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,158 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,158 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,159 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,160 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,160 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,161 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,161 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,161 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,162 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,162 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,163 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,163 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,163 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,164 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,164 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,164 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,164 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,165 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,165 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,165 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,166 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,166 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,167 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,167 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,167 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,168 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,168 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,169 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,169 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,169 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,170 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,170 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,171 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,171 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,172 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,172 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,172 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,173 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,173 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,174 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,174 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,174 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,174 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,175 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,175 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,175 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,176 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,176 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,177 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,177 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,177 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,177 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,178 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:16:45,178 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,179 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:16:45,179 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:49:56,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:49:59,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:04,254 - distributed.core - INFO - Event loop was unresponsive in Worker for 121.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:06,074 - distributed.core - INFO - Event loop was unresponsive in Worker for 120.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:14,128 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:15,409 - distributed.core - INFO - Event loop was unresponsive in Worker for 121.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:17,487 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:23,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:26,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:33,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:34,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:35,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:37,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:43,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:51,154 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:53,075 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:50:57,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:00,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 121.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:03,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:07,413 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:07,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:10,149 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:11,476 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:18,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:18,773 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:20,783 - distributed.core - INFO - Event loop was unresponsive in Worker for 83.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:28,240 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:30,092 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:32,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 93.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:33,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 132.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:41,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 135.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:45,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:51,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:51:53,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 90.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:52:02,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:52:04,822 - distributed.core - INFO - Event loop was unresponsive in Worker for 91.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:52:09,485 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:52:16,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:52:51,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 145.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:53:41,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 215.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:53:51,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 161.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:53:52,402 - distributed.core - INFO - Event loop was unresponsive in Worker for 218.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:53:53,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 165.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:54:00,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 337.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:54:03,750 - distributed.core - INFO - Event loop was unresponsive in Worker for 228.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:54:11,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 217.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:54:13,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 164.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:54:13,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 174.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:54:13,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 216.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:54:18,651 - distributed.core - INFO - Event loop was unresponsive in Worker for 156.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:54:32,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 219.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:54:37,428 - distributed.core - INFO - Event loop was unresponsive in Worker for 220.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:55:10,223 - distributed.core - INFO - Event loop was unresponsive in Worker for 249.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:55:53,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:55:53,435 - distributed.core - INFO - Event loop was unresponsive in Worker for 289.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:55:58,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:55:59,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 417.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:02,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 295.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:07,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:13,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 429.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:15,129 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:15,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 304.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:19,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 300.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:22,006 - distributed.core - INFO - Event loop was unresponsive in Worker for 128.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:22,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 131.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:23,499 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,504 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,505 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,507 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,507 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,508 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,510 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,511 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,513 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,514 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,515 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,515 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,516 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,530 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,531 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:23,531 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757638583.4436677
2025-09-12 10:56:27,502 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,506 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,507 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,508 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,509 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,510 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,513 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,514 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,515 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,516 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,517 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,517 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,529 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,531 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,532 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:27,533 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 10:56:28,137 - distributed.nanny - INFO - Worker process 2633436 was killed by signal 9
2025-09-12 10:56:28,309 - distributed.nanny - INFO - Worker process 2633379 was killed by signal 9
2025-09-12 10:56:28,312 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:28,332 - distributed.nanny - INFO - Worker process 2633369 was killed by signal 9
2025-09-12 10:56:28,341 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:28,372 - distributed.nanny - INFO - Worker process 2633389 was killed by signal 9
2025-09-12 10:56:29,660 - distributed.diskutils - INFO - Found stale lock file and directory '/jobfs/149515417.gadi-pbs/dask-scratch-space/worker-cih_l9ec', purging
2025-09-12 10:56:29,662 - distributed.diskutils - INFO - Found stale lock file and directory '/jobfs/149515417.gadi-pbs/dask-scratch-space/worker-o8esego2', purging
2025-09-12 10:56:29,662 - distributed.diskutils - INFO - Found stale lock file and directory '/jobfs/149515417.gadi-pbs/dask-scratch-space/worker-v16o6sib', purging
2025-09-12 10:56:29,663 - distributed.diskutils - INFO - Found stale lock file and directory '/jobfs/149515417.gadi-pbs/dask-scratch-space/worker-7osv3xku', purging
2025-09-12 10:56:29,664 - distributed.diskutils - INFO - Found stale lock file and directory '/jobfs/149515417.gadi-pbs/dask-scratch-space/worker-qjegbr08', purging
2025-09-12 10:56:29,665 - distributed.diskutils - INFO - Found stale lock file and directory '/jobfs/149515417.gadi-pbs/dask-scratch-space/worker-4g2lev32', purging
2025-09-12 10:56:29,665 - distributed.diskutils - INFO - Found stale lock file and directory '/jobfs/149515417.gadi-pbs/dask-scratch-space/worker-91xhtmmb', purging
2025-09-12 10:56:29,666 - distributed.diskutils - INFO - Found stale lock file and directory '/jobfs/149515417.gadi-pbs/dask-scratch-space/worker-z6xehg2s', purging
2025-09-12 10:56:29,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 296.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:30,407 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:40345
2025-09-12 10:56:30,407 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:40345
2025-09-12 10:56:30,407 - distributed.worker - INFO -          dashboard at:            10.6.5.25:44579
2025-09-12 10:56:30,408 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:30,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:30,408 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:30,408 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:30,408 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-zkufixsb
2025-09-12 10:56:30,408 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:30,431 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:30,432 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:30,491 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:30,799 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:33267
2025-09-12 10:56:30,799 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:33267
2025-09-12 10:56:30,799 - distributed.worker - INFO -          dashboard at:            10.6.5.25:34885
2025-09-12 10:56:30,799 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:30,800 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:30,800 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:30,800 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:30,800 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-r1qmj0hk
2025-09-12 10:56:30,800 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:30,852 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:30,855 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:30,871 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:32,176 - distributed.core - INFO - Event loop was unresponsive in Nanny for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:32,178 - distributed.nanny - INFO - Worker process 2633373 was killed by signal 9
2025-09-12 10:56:32,179 - distributed.nanny - INFO - Worker process 2633413 was killed by signal 9
2025-09-12 10:56:32,179 - distributed.nanny - INFO - Worker process 2633416 was killed by signal 9
2025-09-12 10:56:32,180 - distributed.nanny - INFO - Worker process 2633447 was killed by signal 9
2025-09-12 10:56:32,181 - distributed.nanny - INFO - Worker process 2633361 was killed by signal 9
2025-09-12 10:56:32,181 - distributed.nanny - INFO - Worker process 2633457 was killed by signal 9
2025-09-12 10:56:32,182 - distributed.nanny - INFO - Worker process 2633344 was killed by signal 9
2025-09-12 10:56:32,182 - distributed.nanny - INFO - Worker process 2633421 was killed by signal 9
2025-09-12 10:56:33,120 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:33,177 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:33,179 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:33,181 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:33,229 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:33,239 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:33,245 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:33,253 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:33,253 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:33,255 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:33,283 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:33,285 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:33,286 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:33,347 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:33,375 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:33,383 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:33,383 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:33,385 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:34,475 - distributed.nanny - INFO - Worker process 2633459 was killed by signal 9
2025-09-12 10:56:36,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:36,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:37,947 - distributed.nanny - INFO - Worker process 2633348 was killed by signal 9
2025-09-12 10:56:40,322 - distributed.nanny - INFO - Worker process 2633429 was killed by signal 9
2025-09-12 10:56:40,323 - distributed.nanny - INFO - Worker process 2633405 was killed by signal 9
2025-09-12 10:56:41,825 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,442 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,447 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,447 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,447 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,447 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,448 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,448 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,448 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,450 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,450 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,450 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,451 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,451 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,451 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,451 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,452 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,452 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,453 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,453 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,453 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,453 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,453 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,454 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,454 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,454 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,454 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,455 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,455 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,455 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,455 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,458 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,458 - distributed.core - INFO - Event loop was unresponsive in Nanny for 15.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,466 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,605 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,608 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,611 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,614 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,619 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,622 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,625 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,628 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,631 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,634 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,637 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,639 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 10:56:43,683 - distributed.core - INFO - Event loop was unresponsive in Nanny for 11.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:43,709 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,712 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,717 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,722 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,726 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,731 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,735 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,740 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,745 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,757 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,771 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,776 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:43,785 - distributed.nanny - WARNING - Restarting worker
2025-09-12 10:56:45,549 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:41617
2025-09-12 10:56:45,549 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:41617
2025-09-12 10:56:45,549 - distributed.worker - INFO -          dashboard at:            10.6.5.25:34693
2025-09-12 10:56:45,549 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,550 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,550 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,550 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,550 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-r8q_0u3h
2025-09-12 10:56:45,550 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,565 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,566 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,587 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,642 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:38383
2025-09-12 10:56:45,642 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:38383
2025-09-12 10:56:45,642 - distributed.worker - INFO -          dashboard at:            10.6.5.25:44137
2025-09-12 10:56:45,642 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,642 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,642 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,642 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,642 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-2eevyy45
2025-09-12 10:56:45,642 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,659 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,660 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,673 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:37897
2025-09-12 10:56:45,673 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:37897
2025-09-12 10:56:45,673 - distributed.worker - INFO -          dashboard at:            10.6.5.25:34123
2025-09-12 10:56:45,673 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,673 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,673 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,674 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,674 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-sz3z8av4
2025-09-12 10:56:45,674 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,693 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,693 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,699 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,728 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:32789
2025-09-12 10:56:45,728 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:32789
2025-09-12 10:56:45,728 - distributed.worker - INFO -          dashboard at:            10.6.5.25:39665
2025-09-12 10:56:45,728 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,729 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,729 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,729 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,729 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-yicb1sbt
2025-09-12 10:56:45,729 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,744 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:35753
2025-09-12 10:56:45,744 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:35753
2025-09-12 10:56:45,744 - distributed.worker - INFO -          dashboard at:            10.6.5.25:40651
2025-09-12 10:56:45,744 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,744 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,744 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,745 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,745 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-ay3o9hmk
2025-09-12 10:56:45,745 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,745 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,746 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,762 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,763 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,763 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:39801
2025-09-12 10:56:45,763 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:39801
2025-09-12 10:56:45,764 - distributed.worker - INFO -          dashboard at:            10.6.5.25:40081
2025-09-12 10:56:45,764 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,764 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,764 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,764 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,764 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-y_ri8bxi
2025-09-12 10:56:45,764 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,785 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,785 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,786 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,787 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:38689
2025-09-12 10:56:45,788 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:38689
2025-09-12 10:56:45,788 - distributed.worker - INFO -          dashboard at:            10.6.5.25:33503
2025-09-12 10:56:45,788 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,788 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,788 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,788 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,788 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-9j1p82x4
2025-09-12 10:56:45,788 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,803 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,803 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,814 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,819 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:46843
2025-09-12 10:56:45,819 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:46843
2025-09-12 10:56:45,819 - distributed.worker - INFO -          dashboard at:            10.6.5.25:46285
2025-09-12 10:56:45,819 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,819 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,820 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,820 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,820 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-wb799wkg
2025-09-12 10:56:45,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,833 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,836 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,837 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,853 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:44447
2025-09-12 10:56:45,853 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:44447
2025-09-12 10:56:45,853 - distributed.worker - INFO -          dashboard at:            10.6.5.25:37005
2025-09-12 10:56:45,853 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,853 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,853 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,854 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,854 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,854 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-9fioh7il
2025-09-12 10:56:45,854 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,877 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,878 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,878 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,893 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:35935
2025-09-12 10:56:45,894 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:35935
2025-09-12 10:56:45,894 - distributed.worker - INFO -          dashboard at:            10.6.5.25:40029
2025-09-12 10:56:45,894 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,894 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,894 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,894 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,894 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-neadz_ud
2025-09-12 10:56:45,894 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,918 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,920 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,921 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,928 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:44477
2025-09-12 10:56:45,928 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:44477
2025-09-12 10:56:45,928 - distributed.worker - INFO -          dashboard at:            10.6.5.25:35937
2025-09-12 10:56:45,928 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,928 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,928 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,929 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,929 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-i8e4rtkt
2025-09-12 10:56:45,929 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,954 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:45,954 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:45,958 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:45,978 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:37741
2025-09-12 10:56:45,979 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:37741
2025-09-12 10:56:45,979 - distributed.worker - INFO -          dashboard at:            10.6.5.25:39357
2025-09-12 10:56:45,979 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:45,979 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:45,979 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:45,979 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:45,979 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-lsugk8j5
2025-09-12 10:56:45,980 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:46,020 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:35471
2025-09-12 10:56:46,020 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:35471
2025-09-12 10:56:46,020 - distributed.worker - INFO -          dashboard at:            10.6.5.25:46541
2025-09-12 10:56:46,020 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:46,020 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:46,020 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:46,021 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:46,021 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-az1eqm9h
2025-09-12 10:56:46,021 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:46,025 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:46,026 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:46,037 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:46,052 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:46,052 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:46,078 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:46,099 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:46,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 234.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:46,276 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:34593
2025-09-12 10:56:46,276 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:34593
2025-09-12 10:56:46,276 - distributed.worker - INFO -          dashboard at:            10.6.5.25:44771
2025-09-12 10:56:46,276 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 10:56:46,276 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:46,277 - distributed.worker - INFO -               Threads:                          1
2025-09-12 10:56:46,277 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 10:56:46,277 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-yl0aik_t
2025-09-12 10:56:46,277 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:46,332 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 10:56:46,333 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 10:56:46,387 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 10:56:47,627 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:47,666 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:47,669 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:47,677 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:47,683 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:47,757 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:47,757 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:47,758 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:47,760 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:47,763 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:47,771 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:47,771 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:47,772 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:47,798 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:47,815 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:47,820 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:47,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:47,828 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:47,892 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:47,933 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:47,935 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:47,937 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:47,938 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:47,950 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:47,960 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:47,981 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:47,983 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:47,984 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,003 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,004 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,005 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,005 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,008 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,010 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,014 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,014 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,022 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,022 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,024 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,025 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,025 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:48,027 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:48,044 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,044 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:48,051 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,052 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,067 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,067 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,071 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,072 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,076 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,077 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,077 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,077 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,078 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,079 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,087 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,089 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,090 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,090 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,092 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,093 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,095 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,096 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,097 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,132 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:48,147 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,148 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,148 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,151 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,151 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,152 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,156 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,156 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,157 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,158 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,158 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,159 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,159 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,159 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,166 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,185 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,187 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,188 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,235 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,240 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,248 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,248 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,250 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,296 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:48,311 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,313 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,317 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,328 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,343 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,348 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,348 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,350 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,391 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:48,399 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,401 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,402 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,438 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,443 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,451 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,451 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,452 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,506 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:48,522 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,523 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,526 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,533 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 10:56:48,551 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,551 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 10:56:48,553 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 10:56:48,563 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,571 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,571 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,573 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:48,580 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 10:56:48,625 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 10:56:48,650 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 10:56:48,662 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 10:56:48,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 10:56:48,683 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 10:56:50,995 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:51,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:51,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:51,292 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:51,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:51,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:51,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:51,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:51,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:51,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:52,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:52,182 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:52,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:56:52,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:57:17,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 344.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:57:26,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 356.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:58:03,308 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:58:20,903 - distributed.core - INFO - Event loop was unresponsive in Worker for 395.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:58:21,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:58:36,309 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:58:50,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:59:23,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:59:33,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 10:59:53,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 340.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:00:04,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 346.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:00:25,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:01:57,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:02:02,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:02:05,688 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:02:11,186 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:02:59,159 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:04:24,045 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:04:54,357 - distributed.core - INFO - Event loop was unresponsive in Worker for 128.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:05:09,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:05:17,661 - distributed.core - INFO - Event loop was unresponsive in Worker for 141.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:05:19,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:05:26,718 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:05:35,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:05:44,039 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:06:02,874 - distributed.nanny.memory - WARNING - Worker tcp://10.6.5.25:45613 (pid=2633400) exceeded 95% memory budget. Restarting...
2025-09-12 11:06:04,024 - distributed.nanny - INFO - Worker process 2633400 was killed by signal 15
2025-09-12 11:06:05,804 - distributed.nanny - WARNING - Restarting worker
2025-09-12 11:06:08,272 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:36855
2025-09-12 11:06:08,273 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:36855
2025-09-12 11:06:08,273 - distributed.worker - INFO -          dashboard at:            10.6.5.25:39407
2025-09-12 11:06:08,273 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 11:06:08,273 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 11:06:08,273 - distributed.worker - INFO -               Threads:                          1
2025-09-12 11:06:08,273 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 11:06:08,273 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-gv63crf9
2025-09-12 11:06:08,273 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 11:06:08,347 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 11:06:08,348 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 11:06:08,371 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 11:06:11,191 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 11:06:11,233 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 11:06:11,236 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 11:06:11,242 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 11:06:11,277 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 11:06:11,301 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 11:06:11,306 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 11:06:11,306 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 11:06:11,323 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 11:06:18,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:06:25,371 - distributed.core - INFO - Event loop was unresponsive in Worker for 130.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:07:15,933 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:07:24,604 - distributed.nanny.memory - WARNING - Worker tcp://10.6.5.25:33159 (pid=2633391) exceeded 95% memory budget. Restarting...
2025-09-12 11:07:25,406 - distributed.nanny - INFO - Worker process 2633391 was killed by signal 15
2025-09-12 11:07:27,721 - distributed.nanny - WARNING - Restarting worker
2025-09-12 11:07:30,023 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:44833
2025-09-12 11:07:30,023 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:44833
2025-09-12 11:07:30,023 - distributed.worker - INFO -          dashboard at:            10.6.5.25:38407
2025-09-12 11:07:30,023 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 11:07:30,023 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 11:07:30,023 - distributed.worker - INFO -               Threads:                          1
2025-09-12 11:07:30,023 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 11:07:30,023 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-vjrcuvco
2025-09-12 11:07:30,024 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 11:07:30,053 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 11:07:30,053 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 11:07:30,064 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 11:07:32,159 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 11:07:32,185 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 11:07:32,187 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 11:07:32,200 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 11:07:32,203 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 11:07:32,216 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 11:07:32,221 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 11:07:32,221 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 11:07:32,245 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
2025-09-12 11:07:38,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:08:01,507 - distributed.core - INFO - Event loop was unresponsive in Worker for 120.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:08:07,095 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:08:08,888 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:08:36,923 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:09:30,802 - distributed.core - INFO - Event loop was unresponsive in Worker for 89.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:09:31,857 - distributed.core - INFO - Event loop was unresponsive in Worker for 130.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:09:35,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 88.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:10:27,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:10:46,150 - distributed.core - INFO - Event loop was unresponsive in Worker for 210.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:10:51,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:10:54,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 334.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:10:58,344 - distributed.core - INFO - Event loop was unresponsive in Worker for 86.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:11:12,078 - distributed.core - INFO - Event loop was unresponsive in Worker for 336.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:11:17,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 333.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:11:17,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 128.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:11:20,268 - distributed.core - INFO - Event loop was unresponsive in Worker for 129.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:11:38,702 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:11:52,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 85.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:12:18,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 86.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:12:37,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 79.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:12:47,840 - distributed.core - INFO - Event loop was unresponsive in Worker for 87.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:12:51,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:12:58,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:13:17,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:13:22,116 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:14:58,841 - distributed.core - INFO - Event loop was unresponsive in Worker for 328.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:15:08,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:15:08,844 - distributed.core - INFO - Event loop was unresponsive in Worker for 210.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:16:32,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 84.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:16:51,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:17:04,342 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:17:14,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:17:44,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:18:12,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:18:33,619 - distributed.core - INFO - Event loop was unresponsive in Worker for 127.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:18:49,100 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:18:50,005 - distributed.core - INFO - Event loop was unresponsive in Worker for 139.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:19:03,595 - distributed.core - INFO - Event loop was unresponsive in Worker for 126.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:19:07,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 142.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:19:49,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 124.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:22:32,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:22:42,807 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:23:12,869 - distributed.core - INFO - Event loop was unresponsive in Worker for 125.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:26:24,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:27:53,740 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:27:54,022 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:28:08,520 - distributed.core - INFO - Event loop was unresponsive in Worker for 25.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:28:19,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 36.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:28:29,741 - distributed.core - INFO - Event loop was unresponsive in Worker for 46.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:28:41,483 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:28:41,723 - distributed.core - INFO - Event loop was unresponsive in Worker for 58.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:28:53,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 121.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:29:00,915 - distributed.core - INFO - Event loop was unresponsive in Worker for 77.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:29:59,481 - distributed.core - INFO - Event loop was unresponsive in Worker for 136.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:30:08,749 - distributed.core - INFO - Event loop was unresponsive in Worker for 130.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:30:20,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 86.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:30:20,769 - distributed.core - INFO - Event loop was unresponsive in Worker for 120.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:30:33,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 121.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:30:44,495 - distributed.core - INFO - Event loop was unresponsive in Worker for 121.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:30:54,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 121.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:31:08,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 122.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:31:10,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:31:23,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 119.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:32:37,164 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:32:37,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 134.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:34:03,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 198.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:34:26,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 197.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:35:42,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 322.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:06,299 - distributed.core - INFO - Event loop was unresponsive in Worker for 123.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:23,449 - distributed.nanny - INFO - Nanny asking worker to close. Reason: check-worker-ttl-1757640983.4416735
2025-09-12 11:36:27,451 - distributed.nanny - WARNING - Worker process still alive after 4.0 seconds, killing
2025-09-12 11:36:28,449 - distributed.core - ERROR - Exception while handling op kill
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 834, in _handle_comm
    result = await result
             ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 400, in kill
    await self.process.kill(reason=reason, timeout=timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/nanny.py", line 883, in kill
    await process.join(max(0, deadline - time()))
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/process.py", line 330, in join
    await wait_for(asyncio.shield(self._exit_future), timeout)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1922, in wait_for
    async with asyncio.timeout(timeout):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError
2025-09-12 11:36:30,330 - distributed.nanny - INFO - Worker process 2634230 was killed by signal 9
2025-09-12 11:36:30,541 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:30,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:30,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:30,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:30,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:31,509 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:31,527 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:31,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:32,447 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:32,515 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:32,622 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:32,637 - distributed.nanny - WARNING - Restarting worker
2025-09-12 11:36:32,803 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:32,900 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:33,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:33,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:34,799 - distributed.worker - INFO -       Start worker at:      tcp://10.6.5.25:33589
2025-09-12 11:36:34,800 - distributed.worker - INFO -          Listening to:      tcp://10.6.5.25:33589
2025-09-12 11:36:34,800 - distributed.worker - INFO -          dashboard at:            10.6.5.25:36159
2025-09-12 11:36:34,800 - distributed.worker - INFO - Waiting to connect to:       tcp://10.6.5.25:8760
2025-09-12 11:36:34,800 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 11:36:34,800 - distributed.worker - INFO -               Threads:                          1
2025-09-12 11:36:34,800 - distributed.worker - INFO -                Memory:                  93.75 GiB
2025-09-12 11:36:34,801 - distributed.worker - INFO -       Local Directory: /jobfs/149515417.gadi-pbs/dask-scratch-space/worker-tqvv7egt
2025-09-12 11:36:34,801 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 11:36:34,820 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-12 11:36:34,820 - distributed.worker - INFO - Starting Worker plugin qme_utils.py6b2993a6-c918-41ec-8865-f0a1b3bbaa72
2025-09-12 11:36:34,848 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-12 11:36:35,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-12 11:36:36,907 - distributed.worker - INFO - Starting Worker plugin qme_vars.py1b2260e4-dbde-463d-91ae-c6dcf1c86510
2025-09-12 11:36:36,909 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-12 11:36:36,915 - distributed.worker - INFO - Starting Worker plugin qme_train.py23f0f3ec-7943-4f0f-b154-49f47250c423
2025-09-12 11:36:36,918 - distributed.worker - INFO - Starting Worker plugin qme_apply.pya27fa5a2-a812-4120-b9bb-c3f40251d1f6
2025-09-12 11:36:36,919 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-12 11:36:36,925 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-12 11:36:36,931 - distributed.worker - INFO -         Registered to:       tcp://10.6.5.25:8760
2025-09-12 11:36:36,931 - distributed.worker - INFO - -------------------------------------------------
2025-09-12 11:36:36,933 - distributed.core - INFO - Starting established connection to tcp://10.6.5.25:8760
