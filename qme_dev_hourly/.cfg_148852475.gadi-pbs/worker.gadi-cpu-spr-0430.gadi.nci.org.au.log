Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-05 09:11:55,832 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:37425'
2025-09-05 09:11:55,839 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:33873'
2025-09-05 09:11:55,842 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:36285'
2025-09-05 09:11:55,856 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:40185'
2025-09-05 09:11:55,859 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:42271'
2025-09-05 09:11:55,863 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:46771'
2025-09-05 09:11:55,866 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:43661'
2025-09-05 09:11:55,870 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:33285'
2025-09-05 09:11:55,875 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:43301'
2025-09-05 09:11:55,880 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:36685'
2025-09-05 09:11:55,886 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:34303'
2025-09-05 09:11:55,891 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:45013'
2025-09-05 09:11:55,895 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:44047'
2025-09-05 09:11:55,900 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:45529'
2025-09-05 09:11:55,904 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:38115'
2025-09-05 09:11:55,907 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:39311'
2025-09-05 09:11:55,912 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:45979'
2025-09-05 09:11:55,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:37937'
2025-09-05 09:11:55,920 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:38169'
2025-09-05 09:11:55,925 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:33645'
2025-09-05 09:11:56,001 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:44173'
2025-09-05 09:11:56,006 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:43891'
2025-09-05 09:11:56,011 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:37879'
2025-09-05 09:11:56,014 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:33933'
2025-09-05 09:11:56,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:33097'
2025-09-05 09:11:56,022 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:45093'
2025-09-05 09:11:56,027 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:44479'
2025-09-05 09:11:56,031 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:39309'
2025-09-05 09:11:56,036 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:42841'
2025-09-05 09:11:56,041 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:37699'
2025-09-05 09:11:56,045 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:36429'
2025-09-05 09:11:56,050 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:45099'
2025-09-05 09:11:56,054 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:45477'
2025-09-05 09:11:56,059 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:43087'
2025-09-05 09:11:56,064 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:33975'
2025-09-05 09:11:56,068 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:36295'
2025-09-05 09:11:56,072 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:35559'
2025-09-05 09:11:56,077 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:33991'
2025-09-05 09:11:56,082 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:46045'
2025-09-05 09:11:56,086 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:42049'
2025-09-05 09:11:56,089 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:33077'
2025-09-05 09:11:56,095 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:41325'
2025-09-05 09:11:56,100 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:45743'
2025-09-05 09:11:56,105 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:37099'
2025-09-05 09:11:56,110 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:33011'
2025-09-05 09:11:56,113 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:38955'
2025-09-05 09:11:56,119 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:39873'
2025-09-05 09:11:56,126 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:43901'
2025-09-05 09:11:56,130 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:34543'
2025-09-05 09:11:56,135 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:46413'
2025-09-05 09:11:56,140 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:39287'
2025-09-05 09:11:56,144 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.70:36011'
2025-09-05 09:11:57,114 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:37513
2025-09-05 09:11:57,114 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:39521
2025-09-05 09:11:57,114 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:32867
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:34837
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:37513
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:39521
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:32867
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:34735
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:36561
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:45295
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:34837
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:42509
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:35545
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:41923
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:34263
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:34749
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:40281
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:46163
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:34735
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:44523
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:36561
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:45295
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:37905
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:43663
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:42509
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:41923
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:40281
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:46163
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:41479
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:44523
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:33471
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:37347
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:37905
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:33551
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:35011
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:39627
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:34307
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:40065
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -          dashboard at:          10.6.101.70:41911
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-5n_f8a2r
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-_ve98i40
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ajrlgxpv
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-crulurwk
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ab3pnb9v
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-pm6z6qpu
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-rya27cb1
2025-09-05 09:11:57,115 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-0tx2_iec
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,116 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-lpy61evg
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,116 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-568sd7bl
2025-09-05 09:11:57,116 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-1qwbfnr6
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,116 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-r4mb7cau
2025-09-05 09:11:57,116 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-d5cy68k_
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,116 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,117 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:41667
2025-09-05 09:11:57,117 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:41667
2025-09-05 09:11:57,117 - distributed.worker - INFO -          dashboard at:          10.6.101.70:43049
2025-09-05 09:11:57,117 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,117 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,117 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,117 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,117 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-_iexxnfd
2025-09-05 09:11:57,118 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,123 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:35441
2025-09-05 09:11:57,123 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:35441
2025-09-05 09:11:57,123 - distributed.worker - INFO -          dashboard at:          10.6.101.70:46543
2025-09-05 09:11:57,123 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,123 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,123 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,123 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,123 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-64yqvflb
2025-09-05 09:11:57,123 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,125 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:39651
2025-09-05 09:11:57,125 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:39651
2025-09-05 09:11:57,125 - distributed.worker - INFO -          dashboard at:          10.6.101.70:32961
2025-09-05 09:11:57,125 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,125 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,125 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,125 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,125 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-t2w_ggtc
2025-09-05 09:11:57,125 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,133 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:40963
2025-09-05 09:11:57,133 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:40963
2025-09-05 09:11:57,133 - distributed.worker - INFO -          dashboard at:          10.6.101.70:37487
2025-09-05 09:11:57,133 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,133 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,133 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,133 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,133 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ublc_lpt
2025-09-05 09:11:57,133 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,136 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:44907
2025-09-05 09:11:57,136 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:44907
2025-09-05 09:11:57,136 - distributed.worker - INFO -          dashboard at:          10.6.101.70:39053
2025-09-05 09:11:57,136 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,136 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,136 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,136 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,136 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-gsqy_xju
2025-09-05 09:11:57,136 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,144 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,145 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,145 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,145 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,147 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:34319
2025-09-05 09:11:57,147 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:34319
2025-09-05 09:11:57,147 - distributed.worker - INFO -          dashboard at:          10.6.101.70:33995
2025-09-05 09:11:57,147 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,147 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,147 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,147 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,147 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-wtqt3ys9
2025-09-05 09:11:57,147 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,153 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,154 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,156 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,160 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,161 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,161 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,163 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,164 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:40897
2025-09-05 09:11:57,164 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:40897
2025-09-05 09:11:57,164 - distributed.worker - INFO -          dashboard at:          10.6.101.70:34441
2025-09-05 09:11:57,164 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,164 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,164 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,164 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,164 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-7filmpjx
2025-09-05 09:11:57,164 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,165 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,166 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,166 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,168 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,171 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,172 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,172 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,174 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,175 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,176 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,176 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,178 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,179 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,180 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,180 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,182 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,183 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,184 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,184 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,186 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,186 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,187 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,187 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,189 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,189 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,190 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,190 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,192 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,192 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,193 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,194 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,195 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,195 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,196 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,196 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,198 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,198 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,199 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,199 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,201 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,201 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,202 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,202 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,203 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,204 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,205 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,205 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,206 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,206 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,207 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,207 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,208 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,209 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,209 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,210 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,211 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,212 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,213 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,214 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,214 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:46289
2025-09-05 09:11:57,214 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:46289
2025-09-05 09:11:57,214 - distributed.worker - INFO -          dashboard at:          10.6.101.70:37921
2025-09-05 09:11:57,214 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,214 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,214 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,214 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,214 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8f7t_pep
2025-09-05 09:11:57,214 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,215 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,215 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,216 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,216 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,217 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,218 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,218 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,220 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,240 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,241 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,241 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,242 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,274 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:41933
2025-09-05 09:11:57,274 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:41933
2025-09-05 09:11:57,274 - distributed.worker - INFO -          dashboard at:          10.6.101.70:36851
2025-09-05 09:11:57,274 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,274 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,274 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,274 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,274 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-5vd6fryw
2025-09-05 09:11:57,274 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,303 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,304 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,304 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,306 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,324 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:33875
2025-09-05 09:11:57,324 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:33875
2025-09-05 09:11:57,325 - distributed.worker - INFO -          dashboard at:          10.6.101.70:45619
2025-09-05 09:11:57,325 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,325 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,325 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,325 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,325 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-mldfq446
2025-09-05 09:11:57,325 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,337 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:40615
2025-09-05 09:11:57,337 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:40615
2025-09-05 09:11:57,338 - distributed.worker - INFO -          dashboard at:          10.6.101.70:42039
2025-09-05 09:11:57,338 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,338 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,338 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,338 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,338 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-xhpce3yy
2025-09-05 09:11:57,338 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,353 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,354 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,355 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,356 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,359 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:33195
2025-09-05 09:11:57,359 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:33195
2025-09-05 09:11:57,359 - distributed.worker - INFO -          dashboard at:          10.6.101.70:39681
2025-09-05 09:11:57,359 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,359 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,359 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,359 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,359 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ee1nqlyf
2025-09-05 09:11:57,359 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,365 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,366 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,366 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,368 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,379 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:39731
2025-09-05 09:11:57,379 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:39731
2025-09-05 09:11:57,379 - distributed.worker - INFO -          dashboard at:          10.6.101.70:38111
2025-09-05 09:11:57,380 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,380 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,380 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,380 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,380 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-jr2htabm
2025-09-05 09:11:57,380 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,391 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,392 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,392 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,394 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,405 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,406 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,407 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,408 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,509 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:38579
2025-09-05 09:11:57,509 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:38579
2025-09-05 09:11:57,509 - distributed.worker - INFO -          dashboard at:          10.6.101.70:46029
2025-09-05 09:11:57,509 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,509 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,509 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,509 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,509 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-k_evbq6g
2025-09-05 09:11:57,509 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,538 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,539 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,539 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,540 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,576 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:39123
2025-09-05 09:11:57,577 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:39123
2025-09-05 09:11:57,577 - distributed.worker - INFO -          dashboard at:          10.6.101.70:41633
2025-09-05 09:11:57,577 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,577 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,577 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,577 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-fu_hwaxy
2025-09-05 09:11:57,577 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,607 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,608 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,609 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,610 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,611 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:42947
2025-09-05 09:11:57,611 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:42947
2025-09-05 09:11:57,611 - distributed.worker - INFO -          dashboard at:          10.6.101.70:46737
2025-09-05 09:11:57,611 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,611 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,611 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,611 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-6fh2zdqv
2025-09-05 09:11:57,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,611 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:33989
2025-09-05 09:11:57,611 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:33989
2025-09-05 09:11:57,611 - distributed.worker - INFO -          dashboard at:          10.6.101.70:37981
2025-09-05 09:11:57,611 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,611 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,611 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,611 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ixpbdzd7
2025-09-05 09:11:57,611 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,613 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:38019
2025-09-05 09:11:57,613 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:38019
2025-09-05 09:11:57,613 - distributed.worker - INFO -          dashboard at:          10.6.101.70:43587
2025-09-05 09:11:57,613 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,613 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,613 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:39009
2025-09-05 09:11:57,613 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,613 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,613 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:39009
2025-09-05 09:11:57,613 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ms0kzce5
2025-09-05 09:11:57,613 - distributed.worker - INFO -          dashboard at:          10.6.101.70:33719
2025-09-05 09:11:57,613 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,613 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,613 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,613 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,613 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,613 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-fsj29be4
2025-09-05 09:11:57,613 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,621 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:42795
2025-09-05 09:11:57,621 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:42795
2025-09-05 09:11:57,621 - distributed.worker - INFO -          dashboard at:          10.6.101.70:37395
2025-09-05 09:11:57,621 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,621 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,621 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,621 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,621 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-p5z2gd7v
2025-09-05 09:11:57,621 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,622 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:42519
2025-09-05 09:11:57,622 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:42519
2025-09-05 09:11:57,622 - distributed.worker - INFO -          dashboard at:          10.6.101.70:39669
2025-09-05 09:11:57,622 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,622 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,622 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,622 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-9ncauqgb
2025-09-05 09:11:57,622 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,623 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:43857
2025-09-05 09:11:57,623 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:43857
2025-09-05 09:11:57,623 - distributed.worker - INFO -          dashboard at:          10.6.101.70:38377
2025-09-05 09:11:57,623 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,623 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,623 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,623 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-udsccklg
2025-09-05 09:11:57,623 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,624 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:43241
2025-09-05 09:11:57,624 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:43241
2025-09-05 09:11:57,624 - distributed.worker - INFO -          dashboard at:          10.6.101.70:41339
2025-09-05 09:11:57,624 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,624 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,624 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,624 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,624 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-fcbdyo6n
2025-09-05 09:11:57,624 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,625 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:35209
2025-09-05 09:11:57,625 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:35209
2025-09-05 09:11:57,625 - distributed.worker - INFO -          dashboard at:          10.6.101.70:41419
2025-09-05 09:11:57,625 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,625 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,625 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,625 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,625 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-_piggrbv
2025-09-05 09:11:57,625 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,626 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:41699
2025-09-05 09:11:57,626 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:41699
2025-09-05 09:11:57,626 - distributed.worker - INFO -          dashboard at:          10.6.101.70:37719
2025-09-05 09:11:57,626 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,626 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,626 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,626 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-en0eusd0
2025-09-05 09:11:57,626 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,627 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:38891
2025-09-05 09:11:57,627 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:38891
2025-09-05 09:11:57,627 - distributed.worker - INFO -          dashboard at:          10.6.101.70:46703
2025-09-05 09:11:57,627 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,627 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,627 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,627 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-fgkayaac
2025-09-05 09:11:57,627 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,631 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,631 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:45109
2025-09-05 09:11:57,631 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:45109
2025-09-05 09:11:57,631 - distributed.worker - INFO -          dashboard at:          10.6.101.70:43413
2025-09-05 09:11:57,631 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,631 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,631 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,631 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,631 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-q97269of
2025-09-05 09:11:57,631 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,632 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,634 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:41683
2025-09-05 09:11:57,634 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:41683
2025-09-05 09:11:57,634 - distributed.worker - INFO -          dashboard at:          10.6.101.70:38647
2025-09-05 09:11:57,634 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,634 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,634 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,634 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,634 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8iunwrdy
2025-09-05 09:11:57,634 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,643 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:46607
2025-09-05 09:11:57,643 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:40495
2025-09-05 09:11:57,643 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:46607
2025-09-05 09:11:57,643 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:40495
2025-09-05 09:11:57,643 - distributed.worker - INFO -          dashboard at:          10.6.101.70:35071
2025-09-05 09:11:57,643 - distributed.worker - INFO -          dashboard at:          10.6.101.70:42829
2025-09-05 09:11:57,643 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,643 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,643 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,643 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,643 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,643 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,643 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,643 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,643 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,643 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-016o260v
2025-09-05 09:11:57,643 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-nxm41m1g
2025-09-05 09:11:57,643 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,643 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:43679
2025-09-05 09:11:57,643 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,644 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:43679
2025-09-05 09:11:57,644 - distributed.worker - INFO -          dashboard at:          10.6.101.70:41043
2025-09-05 09:11:57,644 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,644 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,644 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,644 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-k6qnmc39
2025-09-05 09:11:57,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,644 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,644 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,646 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,649 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,650 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,650 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:43235
2025-09-05 09:11:57,650 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:40201
2025-09-05 09:11:57,650 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:43235
2025-09-05 09:11:57,650 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:40201
2025-09-05 09:11:57,650 - distributed.worker - INFO -          dashboard at:          10.6.101.70:44745
2025-09-05 09:11:57,650 - distributed.worker - INFO -          dashboard at:          10.6.101.70:34385
2025-09-05 09:11:57,650 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,650 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,650 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,650 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,650 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,650 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,650 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-mld466mn
2025-09-05 09:11:57,650 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-_0ocg85i
2025-09-05 09:11:57,650 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,651 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,652 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,653 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:45921
2025-09-05 09:11:57,653 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:45921
2025-09-05 09:11:57,653 - distributed.worker - INFO -          dashboard at:          10.6.101.70:46499
2025-09-05 09:11:57,653 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,653 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,653 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,653 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-34zlsq92
2025-09-05 09:11:57,653 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,654 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,654 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:44457
2025-09-05 09:11:57,654 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:44457
2025-09-05 09:11:57,654 - distributed.worker - INFO -          dashboard at:          10.6.101.70:43553
2025-09-05 09:11:57,654 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,654 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,654 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,654 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,654 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-9ddp715m
2025-09-05 09:11:57,654 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,655 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,655 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,657 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,658 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:37887
2025-09-05 09:11:57,658 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:37887
2025-09-05 09:11:57,658 - distributed.worker - INFO -          dashboard at:          10.6.101.70:36639
2025-09-05 09:11:57,658 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,658 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,658 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,658 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,658 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-jmik6a3w
2025-09-05 09:11:57,658 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,658 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,659 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,659 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,660 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,660 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:41343
2025-09-05 09:11:57,660 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:41343
2025-09-05 09:11:57,660 - distributed.worker - INFO -          dashboard at:          10.6.101.70:44985
2025-09-05 09:11:57,660 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,660 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,660 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,660 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,660 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ldmz5vz5
2025-09-05 09:11:57,660 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,661 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:41035
2025-09-05 09:11:57,661 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:41035
2025-09-05 09:11:57,661 - distributed.worker - INFO -          dashboard at:          10.6.101.70:36481
2025-09-05 09:11:57,661 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,662 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,662 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,662 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-z5yc_ood
2025-09-05 09:11:57,662 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,662 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,663 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,664 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,665 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,666 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,667 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,667 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,668 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,669 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.70:43903
2025-09-05 09:11:57,669 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.70:43903
2025-09-05 09:11:57,669 - distributed.worker - INFO -          dashboard at:          10.6.101.70:43391
2025-09-05 09:11:57,669 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,669 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,669 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:57,669 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:57,669 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-6bgfpwc4
2025-09-05 09:11:57,669 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,669 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,670 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,671 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,672 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,672 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,673 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,674 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,675 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,675 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,676 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,677 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,678 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,678 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,679 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,680 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,681 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,681 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,682 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,683 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,684 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,699 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,699 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,699 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,700 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,703 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,704 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,704 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,706 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,707 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,708 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,709 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,710 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,711 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,711 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,713 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,713 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,714 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,714 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,716 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,716 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,717 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,717 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,718 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,719 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,719 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,720 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,721 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,721 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,722 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,722 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,724 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,724 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,725 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,725 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,726 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,727 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,727 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,727 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,729 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,729 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,730 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,730 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,731 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:57,731 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:57,732 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:57,732 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:57,734 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:12:06,733 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,733 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,733 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,733 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,733 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,733 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,733 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,733 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,734 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,734 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,734 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,734 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,734 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,734 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,735 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,735 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,735 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,735 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,735 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,735 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,735 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,736 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,735 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,736 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,736 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,736 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,736 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,736 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,736 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,736 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,736 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,736 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,736 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,736 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,736 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,736 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,736 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,737 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,737 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,737 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,737 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,737 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,737 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,737 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,737 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,738 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,739 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,739 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,737 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,739 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,739 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,739 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,740 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,739 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,739 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,739 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,739 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,740 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,738 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,740 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,740 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,740 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,741 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,741 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,740 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,739 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,740 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,741 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,741 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,742 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,742 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,742 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,742 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,742 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,745 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,745 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,746 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,746 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,743 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,747 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,748 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,749 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,749 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,752 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,752 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:09,536 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,536 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,536 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,536 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,536 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,536 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,538 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,538 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,538 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,538 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,538 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,539 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,536 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,539 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,538 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,537 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,540 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,541 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,541 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,538 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,538 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,541 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,541 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,541 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,538 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,541 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,541 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,541 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,541 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,542 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,541 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,542 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,541 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,543 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,539 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,543 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,543 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,543 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,543 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,543 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,540 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,543 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,541 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,544 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,541 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,545 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,545 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,545 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,545 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,545 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,542 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,542 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,542 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,546 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,547 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,547 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,547 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,548 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,548 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,923 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,923 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,923 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,924 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,924 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,924 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,924 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,924 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,924 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,924 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,924 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,925 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,925 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,925 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,925 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,925 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,925 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,925 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,925 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,925 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,926 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,926 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,926 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,926 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,926 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,926 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,927 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,928 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,928 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,928 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,928 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,928 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,928 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,928 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,928 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,928 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,928 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,928 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,928 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,928 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,928 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,928 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,928 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,929 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,929 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,929 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,930 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,929 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,929 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,929 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,929 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,930 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,930 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,930 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,930 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,930 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,930 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,930 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,930 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,931 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,931 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,931 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,931 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,931 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,931 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,932 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,932 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,932 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,933 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,933 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,933 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,933 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,933 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,934 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,935 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,935 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,935 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,935 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,935 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,935 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,935 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:10,379 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,379 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,379 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,379 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,380 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,380 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,380 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,380 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,380 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,380 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,380 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,381 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,381 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,381 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,381 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,381 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,381 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,381 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,381 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,381 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,382 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,382 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,382 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,382 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,382 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,382 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,382 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,382 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,382 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,382 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,383 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,383 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,383 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,383 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,383 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,384 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,384 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,384 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,384 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,384 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,384 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,385 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,386 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,386 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,385 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,386 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,386 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,386 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,386 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,386 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,387 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,387 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,388 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,388 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,388 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,388 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,388 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,388 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,388 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,388 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,389 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,390 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:16:17,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,491 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,564 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,572 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,574 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,580 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,593 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,600 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,645 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,684 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,699 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,720 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,804 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,805 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,867 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,870 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,890 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,891 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,892 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,894 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:17,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,650 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,735 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,788 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,864 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,989 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,080 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,406 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,262 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,339 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:51,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:52,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:52,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:52,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:52,901 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:52,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,611 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,833 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,913 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,124 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,556 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:57,868 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:00,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:00,246 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:00,261 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,466 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,019 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:04,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:04,321 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:09,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:09,608 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:10,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:10,799 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,030 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,248 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,250 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,790 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,531 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,539 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,002 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,150 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,152 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,157 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,401 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,569 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,660 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,003 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,502 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,420 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,633 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,634 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,319 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:19,005 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:20,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:22,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:24,087 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:24,088 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:24,089 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:24,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:28,499 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:29,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,664 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,665 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,672 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:33,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,897 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,904 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,717 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,992 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,997 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,171 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,241 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,317 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,320 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,323 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,329 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,726 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:37,379 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,304 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,613 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,614 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,620 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,709 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,710 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:40,199 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:40,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:40,511 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:40,767 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:40,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:41,355 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:42,828 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:42,834 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:43,796 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:45,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,603 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,795 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,849 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:51,471 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:51,713 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:51,784 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,761 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,632 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,659 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:55,624 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:56,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:56,176 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:56,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:57,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,229 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,243 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:06,959 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:10,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:12,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:14,956 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:14,960 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:14,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,462 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,881 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,886 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,191 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,203 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,024 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,382 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:32,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,618 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,646 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.49s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,219 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,480 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,127 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,252 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,269 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,470 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,503 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,845 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,871 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,896 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.75s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:40,145 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,971 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,976 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,184 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,185 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,188 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,407 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,550 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,578 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,722 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,725 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,257 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,258 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,809 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,048 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,049 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,835 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,842 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,988 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,991 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,437 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,438 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,206 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,208 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:52,169 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:53,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:53,990 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:56,125 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:56,647 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:57,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:57,453 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:58,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,962 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,400 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,693 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,695 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,948 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,950 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,964 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,270 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,275 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,276 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,346 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.21s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,018 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,283 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,460 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,652 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,654 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,655 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,449 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,628 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,630 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:15,697 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:15,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:16,100 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:16,345 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:19,189 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:19,836 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:21,746 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:22,500 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:33,313 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:33,587 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:33,590 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,374 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,682 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,103 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,548 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,549 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,116 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,469 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,764 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,939 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,217 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,232 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,253 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,260 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,641 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,079 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.07s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,231 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,239 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,361 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,332 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,451 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,911 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,161 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,215 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,648 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,698 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,898 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,899 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,446 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,041 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,238 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,358 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,366 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,376 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,524 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,372 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,792 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,364 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:55,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:57,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:58,427 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:58,440 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:58,441 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.17s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:01,362 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:01,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:01,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:01,775 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:03,415 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:03,416 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:03,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,265 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:37513. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,265 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:44457. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,265 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:41667. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:44523. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,265 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:35441. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,265 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:43903. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,265 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:36561. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,265 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:45295. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:40963. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:46163. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:42509. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:44907. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,264 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:34837. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,264 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,264 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:34735. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:45921. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,266 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:37905. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,264 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,267 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:40281. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,267 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:43235. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,267 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:40201. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,267 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:35209. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,262 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,267 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:39009. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,267 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:38019. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,268 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:45109. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,268 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:39521. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,268 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:41683. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,268 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:40495. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,268 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:43857. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,268 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:40897. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,268 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:38891. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,268 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:43679. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,263 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,269 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:42519. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,269 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:42947. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,269 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:33875. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,269 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:46607. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,269 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:33195. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,269 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:33989. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,269 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:46289. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,270 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:42795. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,270 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:40615. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,270 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:41933. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,270 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:37887. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,271 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:43241. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,271 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:41699. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:36685'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,278 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:35559'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2285, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,279 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 882, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,279 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6291, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,279 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,280 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6282, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,280 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,280 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,280 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,280 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,280 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,280 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,281 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,281 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,281 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,282 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:36285'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:39311'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:37425'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:37879'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:46771'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2760, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,283 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:33285'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,283 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4530, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,284 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2392, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,284 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4552, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,284 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1418, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,284 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,284 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 219, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,284 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,284 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5131, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,284 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,284 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6467, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,285 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.67:37739, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,285 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1637, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,285 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1252, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,285 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:36081, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,285 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 8142, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,285 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,286 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,286 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,286 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,286 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,286 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,286 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,286 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,286 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,286 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,287 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,287 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,287 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,287 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,292 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:45529'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,292 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:38115'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,292 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:45013'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,293 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:44047'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,293 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:33873'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,293 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:43301'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,293 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 8093, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,293 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:36011'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,293 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:42271'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,293 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3173, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,293 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:33975'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,293 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,294 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3157, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,294 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:33011'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,294 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:33933'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,294 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,294 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:45979'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,294 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1255, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,294 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,294 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3387, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,294 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:36597, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,294 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,294 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:42841'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,294 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2100, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,294 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,294 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3235, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,294 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5719, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3232, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:46045'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,295 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2110, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:32801, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1220, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,295 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:46721, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,295 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:34543'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.53:43003, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 967, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6105, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.44:45639, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1196, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.61:43631, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:45743'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:35021, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.64:38415, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.40:46567, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2175, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1399, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,295 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2749, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:38505, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:40185'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2608, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2360, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2194, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2088, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:37771, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1420, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:45093'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2623, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2367, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6468, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2107, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2759, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,296 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.70:41343, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,297 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:42049'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,296 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6420, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,297 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:37699'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,297 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6429, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,297 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:39287'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,297 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2283, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,297 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.70:39651, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,298 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:36295'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1639, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.37:33007, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:39873'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,298 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3385, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1695, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,299 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:43901'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2055, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,299 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:41325'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.70:32867, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,299 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:44479'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.61:43631, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,299 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:45099'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 8069, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2802, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:42705, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,300 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:43891'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 8141, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1222, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 8064, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,300 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:38169'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 484, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.51:44417, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 301, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3709, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:33991'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1310, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,301 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:45477'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2496, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.67:44175, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,301 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 225, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,301 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 575, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,301 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:38955'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,301 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1025, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,301 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:33645'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,301 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2674, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,301 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:43087'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,301 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:37099'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,301 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:38313, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,301 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:37493, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,301 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1743, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,302 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2090, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,302 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1329, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,302 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 8143, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,302 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6464, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,302 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5139, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,302 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2061, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,302 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3382, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,302 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 106, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,303 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.41:37319, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,303 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,304 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,304 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,304 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,304 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,304 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,304 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,304 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6465, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,304 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3298, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,304 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,304 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 1790, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,304 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,304 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 581, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,305 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,305 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,305 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,305 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,305 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,305 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,305 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,305 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,306 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,305 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2150, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,307 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2164, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,307 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,307 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,307 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,307 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,307 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,308 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,308 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,308 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,308 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,308 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:37493, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-91ba88a1e7a9909410f2cbe9c4a420de', 221, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.70:34319, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,321 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.38:46785, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,328 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,328 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,328 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,328 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,329 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,492 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,373 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:12,375 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:34319. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:12,387 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.70:36598 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:12,392 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:44173'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:12,392 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:12,392 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:12,393 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:12,393 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:12,393 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:12,399 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,416 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,416 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,417 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,418 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,564 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,987 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:12,990 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:32867. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,000 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.70:32867 -> tcp://10.6.101.62:41987
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.70:32867 remote=tcp://10.6.101.62:43436>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-05 09:20:13,006 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:13,009 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.70:36454 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:13,011 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:37937'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,012 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:13,012 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:13,012 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:13,012 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:13,012 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:13,019 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,497 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,931 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:37099'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,934 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:37099' closed.
2025-09-05 09:20:14,402 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,421 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,421 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,422 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,422 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,568 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,794 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:45477'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,796 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:45477' closed.
2025-09-05 09:20:14,816 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:45093'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,817 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:45093' closed.
2025-09-05 09:20:14,824 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:45529'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,826 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:45529' closed.
2025-09-05 09:20:14,877 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:44173'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,877 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:44173' closed.
2025-09-05 09:20:14,899 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:42271'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,899 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:42271' closed.
2025-09-05 09:20:14,942 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:38955'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,943 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:38955' closed.
2025-09-05 09:20:15,021 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,033 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:15,036 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:38579. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:15,046 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:15,051 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.70:36660 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:15,056 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:39309'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:15,058 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2411, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:15,058 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:15,058 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:15,058 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:15,058 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:15,058 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:15,062 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:15,323 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:15,324 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:15,409 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:37937'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,410 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:37937' closed.
2025-09-05 09:20:16,030 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,057 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,294 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,379 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:16,382 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:41923. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,395 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:16,401 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.70:36516 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:16,407 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:43661'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,408 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:16,409 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:16,409 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:16,409 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:16,409 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:16,412 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1503c1bcf490>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:16,424 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,549 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,599 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,017 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,017 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,019 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,066 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:17,328 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:17,476 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:33933'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,477 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:33933' closed.
2025-09-05 09:20:17,635 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,681 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:39873'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,682 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:39873' closed.
2025-09-05 09:20:17,703 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:45979'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,705 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:45979' closed.
2025-09-05 09:20:17,760 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:17,762 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:39731. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:17,763 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:17,777 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.70:36658 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:17,780 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:33097'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:17,781 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:17,781 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:17,782 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:17,782 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:17,782 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:17,784 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14f4185ce6d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:17,790 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,817 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:17,820 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:39651. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:17,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:17,836 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.70:36574 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:17,840 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:34303'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:17,841 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:17,841 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:17,841 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:17,841 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:17,841 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:17,843 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ab19bbac10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:17,848 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,984 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,988 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:17,990 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:39123. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:17,999 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:18,005 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.70:36672 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:18,009 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:36429'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:18,010 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:18,010 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:18,010 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:18,010 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:18,010 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:18,013 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14e9c3e35a10>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:18,019 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,035 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,062 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,096 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,142 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,296 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,301 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,428 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,488 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,489 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,543 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:45099'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,545 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:45099' closed.
2025-09-05 09:20:18,553 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,558 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:39309'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,559 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:39309' closed.
2025-09-05 09:20:18,603 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,684 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:45743'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,686 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:45743' closed.
2025-09-05 09:20:18,728 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,812 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:43661'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,814 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:43661' closed.
2025-09-05 09:20:18,898 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,905 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,906 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,906 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:18,909 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:41035. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:18,921 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:18,925 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.70:36882 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:18,930 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:46413'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:18,931 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:18,931 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:18,931 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:18,931 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:18,931 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:18,933 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14ebb63e9590>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:18,939 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,000 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:37425'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,001 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:37425' closed.
2025-09-05 09:20:19,021 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:43901'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,021 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,022 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:43901' closed.
2025-09-05 09:20:19,022 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,023 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,028 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,131 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,159 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,396 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:19,398 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.70:41343. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:19,401 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,411 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:19,412 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:33285'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,414 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:34543'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,415 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:33991'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,415 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:33285' closed.
2025-09-05 09:20:19,416 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:34543' closed.
2025-09-05 09:20:19,417 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:33991' closed.
2025-09-05 09:20:19,417 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.70:36870 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:19,421 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.70:33077'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:19,422 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:19,422 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:19,422 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:19,422 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:19,422 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:19,424 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14c801749d50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:19,430 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,588 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,639 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,767 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,768 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,793 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,822 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,851 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,862 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,915 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,967 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,988 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,022 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,025 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:33645'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,026 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:33645' closed.
2025-09-05 09:20:20,054 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,100 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,138 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:35559'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,139 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:35559' closed.
2025-09-05 09:20:20,140 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,146 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,159 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,176 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:33097'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,178 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:33097' closed.
2025-09-05 09:20:20,221 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,221 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,224 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:34303'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,227 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:34303' closed.
2025-09-05 09:20:20,300 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,442 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:36295'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,443 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:36295' closed.
2025-09-05 09:20:20,463 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:36429'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,464 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:36429' closed.
2025-09-05 09:20:20,492 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,493 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,581 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:39311'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,581 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:39311' closed.
2025-09-05 09:20:20,606 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:33011'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,607 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:33011' closed.
2025-09-05 09:20:20,732 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,757 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:41325'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,758 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:41325' closed.
2025-09-05 09:20:20,886 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:37879'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,887 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:33975'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,888 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:37879' closed.
2025-09-05 09:20:20,888 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:33975' closed.
2025-09-05 09:20:20,902 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,909 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,909 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,942 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,032 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,135 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,147 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:42841'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,148 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:42841' closed.
2025-09-05 09:20:21,163 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,351 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:44047'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,352 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:44047' closed.
2025-09-05 09:20:21,372 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:46413'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,373 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:46413' closed.
2025-09-05 09:20:21,377 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:43301'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,378 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:43301' closed.
2025-09-05 09:20:21,402 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:43891'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,402 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:43891' closed.
2025-09-05 09:20:21,405 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,430 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:37699'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,431 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:37699' closed.
2025-09-05 09:20:21,433 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,592 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,627 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:43087'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,628 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:43087' closed.
2025-09-05 09:20:21,662 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:38169'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,662 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:38169' closed.
2025-09-05 09:20:21,771 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,804 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:44479'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,805 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:44479' closed.
2025-09-05 09:20:21,826 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,827 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:33077'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,828 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:33077' closed.
2025-09-05 09:20:21,866 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,919 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,970 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,009 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:38115'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,010 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:38115' closed.
2025-09-05 09:20:22,144 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,163 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,219 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:46045'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,220 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:40185'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,221 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:46045' closed.
2025-09-05 09:20:22,221 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:40185' closed.
2025-09-05 09:20:22,225 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,225 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,260 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:33873'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,260 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:33873' closed.
2025-09-05 09:20:22,410 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:36011'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,411 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:36011' closed.
2025-09-05 09:20:22,474 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:36685'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,475 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:36685' closed.
2025-09-05 09:20:22,495 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:45013'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,496 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:45013' closed.
2025-09-05 09:20:22,605 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:36285'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,606 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:36285' closed.
2025-09-05 09:20:22,616 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:42049'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,617 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:42049' closed.
2025-09-05 09:20:22,619 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:39287'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,620 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:39287' closed.
2025-09-05 09:20:22,654 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.70:46771'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,654 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.70:46771' closed.
2025-09-05 09:20:22,656 - distributed.dask_worker - INFO - End worker
