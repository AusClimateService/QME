{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5e4cc-d62a-44ae-ba97-9db1e97bd7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import sys\n",
    "sys.path.append(\"..\") # Set to path of codebase\n",
    "\n",
    "from qme_train import *\n",
    "from qme_apply import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13557d09-7a40-4c43-ae59-d938007e4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.diagnostics\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3325b2-7f5c-4262-9742-c90bd2a7dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data\n",
    "var = \"pr\"\n",
    "\n",
    "st_year_train = 1980\n",
    "en_year_train = 2019\n",
    "\n",
    "# Also can include the training period when applying\n",
    "st_year_apply = 1980 \n",
    "en_year_apply = 2019\n",
    "\n",
    "# Apply bias correction to future data for this model\n",
    "st_year_fut = 2080\n",
    "en_year_fut = 2099\n",
    "\n",
    "obs_path = '/g/data/ia39/npcp/data/{var}/observations/AGCD/raw/task-reference/{var}_NPCP-20i_AGCD_v1-0-1_day_{year}0101-{year}1231.nc'\n",
    "mdl_path = '/g/data/ia39/npcp/data/{var}/CSIRO-ACCESS-ESM1-5/BOM-BARPA-R/raw/task-reference/{var}_NPCP-20i_CSIRO-ACCESS-ESM1-5_{empat}_r6i1p1f1_BOM-BARPA-R_v1_day_{year}0101-{year}1231.nc'\n",
    "\n",
    "obs_file_list = [obs_path.format(var = var, year = y) \n",
    "                 for y in range(st_year_train, en_year_train + 1)]\n",
    "\n",
    "mdl_file_list = [mdl_path.format(var = var, year = y, empat = \"ssp370\" if y > 2014 else \"historical\") \n",
    "                 for y in range(st_year_train, en_year_apply + 1)]\n",
    "\n",
    "fut_file_list = [mdl_path.format(var = var, year = y, empat = \"ssp370\" if y > 2014 else \"historical\") \n",
    "                 for y in range(st_year_fut, en_year_fut + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c71f40-4a1d-413b-b79b-28b86b140dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"xtr\": 3,\n",
    "    \"cal_smth\": 21,\n",
    "    \"mthd\": '_quick',\n",
    "    \"mn_smth\": '_3mn' if var == \"pr\" else '',\n",
    "    \"ssze_lim\": 50,\n",
    "    \"mltp\": False,\n",
    "    \"lmt\": 1.5 if var == \"pr\" else -1,\n",
    "    \"lmt_thresh\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352e5589-4b7b-47e8-8e0d-b59e317d4a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardise_latlon(ds, digits=4):\n",
    "    \"\"\"\n",
    "    This function rounds the latitude / longitude coordinates to the 4th digit, because some dataset\n",
    "    seem to have strange digits (e.g. 50.00000001 instead of 50.0), which prevents merging of data.\n",
    "    \"\"\"\n",
    "    ds = ds.assign_coords({\"lat\": np.round(ds.lat, digits)})\n",
    "    ds = ds.assign_coords({\"lon\": np.round(ds.lon, digits)})\n",
    "    return(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01613af-e22f-4ba6-bfd4-99e1c77cb636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data and chunk (chunk sizes for lat and lon may be adjusted here to help performance)\n",
    "lat_chunk_size = 25\n",
    "lon_chunk_size = 25\n",
    "\n",
    "obs_data = xr.open_mfdataset(obs_file_list, preprocess = standardise_latlon)[var].chunk(time = -1, lat = lat_chunk_size, lon = lon_chunk_size)\n",
    "mdl_data = xr.open_mfdataset(mdl_file_list, preprocess = standardise_latlon)[var].chunk(time = -1, lat = lat_chunk_size, lon = lon_chunk_size)\n",
    "fut_data = xr.open_mfdataset(fut_file_list, preprocess = standardise_latlon)[var].chunk(time = -1, lat = lat_chunk_size, lon = lon_chunk_size)\n",
    "obs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8af23-c49b-4f00-a853-c377486fe77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select training data years\n",
    "mdl_training = mdl_data.sel(time = mdl_data.time.dt.year.isin(range(st_year_train, en_year_train + 1))).chunk({\"time\": -1})\n",
    "obs_training = obs_data.sel(time = obs_data.time.dt.year.isin(range(st_year_train, en_year_train + 1))).chunk({\"time\": -1})\n",
    "\n",
    "# Select model data years for application\n",
    "mdl_apply = mdl_data.sel(time = mdl_data.time.dt.year.isin(range(st_year_apply, en_year_apply + 1))).chunk({\"time\": -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030f2e15-e3b7-41da-a8e4-4649413e500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distributions histograms\n",
    "dist_mdl = make_dist(var, mdl_training).chunk({\"values\": -1, \"month\": -1})\n",
    "dist_obs = make_dist(var, obs_training).chunk({\"values\": -1, \"month\": -1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad4778-be00-45ee-a8bc-655ece9a66f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply QME to create adjustment factors\n",
    "# Using .persist() will start the calculation in the background and keep it in distributed memory\n",
    "# Without using persist, dask may calculate these twice (once for current and once for future data)\n",
    "dist_bc = calc_qme(var, dist_mdl, dist_obs, **params).chunk({\"values\": -1, \"month\": -1}).persist()\n",
    "dist_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8530c3-ee76-46d1-819c-8f7ccef06c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply bias correction factors to model data\n",
    "mdl_bc = apply_bc(var, mdl_apply, dist_bc.biascorr).rename(var)\n",
    "mdl_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8871c0-b8d5-4637-8840-880db7d155f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply bias correction factors to future data\n",
    "fut_bc = apply_bc(var, fut_data, dist_bc.biascorr).rename(var)\n",
    "fut_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84601622-c9db-4d3b-b8ca-28f3534d4f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output directory as appropriate\n",
    "outdir = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d662aa61-f299-4c92-ba99-6d52f04bb9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save bias corrected model data as netCDF\n",
    "mdl_bc.to_netcdf(outdir + f'{var}_sample_out_historical.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5cd1b-2e8f-4617-8c77-8be519c81bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save bias corrected future data as netCDF\n",
    "fut_bc.to_netcdf(outdir + f'{var}_sample_out_future.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
