Loading singularity
Loading conda/analysis3-25.06
Loading gadi_jupyterlab/23.02
2025-09-05 09:11:43,584 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:35217'
2025-09-05 09:11:43,594 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:44943'
2025-09-05 09:11:43,601 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:34047'
2025-09-05 09:11:43,605 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:37719'
2025-09-05 09:11:43,613 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:42489'
2025-09-05 09:11:43,616 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:33383'
2025-09-05 09:11:43,620 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:36867'
2025-09-05 09:11:43,625 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:38863'
2025-09-05 09:11:43,629 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:35139'
2025-09-05 09:11:43,633 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:37395'
2025-09-05 09:11:43,638 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:37851'
2025-09-05 09:11:43,641 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:33875'
2025-09-05 09:11:43,645 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:40171'
2025-09-05 09:11:43,649 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:35687'
2025-09-05 09:11:43,654 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:43341'
2025-09-05 09:11:43,657 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:44259'
2025-09-05 09:11:43,662 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:40015'
2025-09-05 09:11:43,666 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:46755'
2025-09-05 09:11:43,671 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:34929'
2025-09-05 09:11:43,675 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:40959'
2025-09-05 09:11:43,833 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:42749'
2025-09-05 09:11:43,838 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:33509'
2025-09-05 09:11:43,843 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:33253'
2025-09-05 09:11:43,846 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:40217'
2025-09-05 09:11:43,851 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:46089'
2025-09-05 09:11:43,855 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:42499'
2025-09-05 09:11:43,859 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:40207'
2025-09-05 09:11:43,864 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:41235'
2025-09-05 09:11:43,869 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:39741'
2025-09-05 09:11:43,874 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:42693'
2025-09-05 09:11:43,879 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:38053'
2025-09-05 09:11:43,883 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:36715'
2025-09-05 09:11:43,889 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:45515'
2025-09-05 09:11:43,893 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:42483'
2025-09-05 09:11:43,898 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:38651'
2025-09-05 09:11:43,902 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:45877'
2025-09-05 09:11:43,907 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:42791'
2025-09-05 09:11:43,912 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:34191'
2025-09-05 09:11:43,916 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:37283'
2025-09-05 09:11:43,920 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:33431'
2025-09-05 09:11:43,923 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:41579'
2025-09-05 09:11:43,928 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:41875'
2025-09-05 09:11:43,932 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:39923'
2025-09-05 09:11:43,936 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:40705'
2025-09-05 09:11:43,939 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:32917'
2025-09-05 09:11:43,943 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:43157'
2025-09-05 09:11:43,947 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:38227'
2025-09-05 09:11:43,953 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:44135'
2025-09-05 09:11:43,956 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:41517'
2025-09-05 09:11:43,962 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:45019'
2025-09-05 09:11:43,966 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:42581'
2025-09-05 09:11:43,972 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.6.101.60:41389'
2025-09-05 09:11:44,711 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:34323
2025-09-05 09:11:44,711 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:37259
2025-09-05 09:11:44,711 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:36963
2025-09-05 09:11:44,711 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:34265
2025-09-05 09:11:44,711 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:38831
2025-09-05 09:11:44,711 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:34323
2025-09-05 09:11:44,711 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:37259
2025-09-05 09:11:44,711 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:34875
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:36963
2025-09-05 09:11:44,711 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:33545
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:42023
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:34265
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:34085
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:35065
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:35643
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:37087
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:38385
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:38831
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:35125
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:43667
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:37835
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:43795
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:34875
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:43763
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:33545
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:42023
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:37527
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:34085
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:35065
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:35643
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:37087
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:38385
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:38023
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:35125
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:43795
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:34415
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:35149
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:34827
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:43949
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:41911
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:33825
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:42109
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:38097
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:37311
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO -          dashboard at:          10.6.101.60:33517
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-t85w5dil
2025-09-05 09:11:44,712 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,712 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-pkr_2zbe
2025-09-05 09:11:44,712 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,712 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,712 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-i6esl1wc
2025-09-05 09:11:44,713 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,713 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,713 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-1n63zjrk
2025-09-05 09:11:44,713 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,713 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,713 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-w0wk20hd
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-p6rckqad
2025-09-05 09:11:44,713 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-zcja3c7r
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-0ublja9q
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-lj5bkkvt
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-g6le7zss
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ds_5s12q
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-1wru6oju
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-0a3btm80
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-zhmefnuz
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-2qm3_npp
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,713 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,720 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:45361
2025-09-05 09:11:44,720 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:45361
2025-09-05 09:11:44,720 - distributed.worker - INFO -          dashboard at:          10.6.101.60:41047
2025-09-05 09:11:44,720 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,720 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,720 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,721 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,721 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-qtvebbpv
2025-09-05 09:11:44,721 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,721 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:37429
2025-09-05 09:11:44,721 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:37429
2025-09-05 09:11:44,721 - distributed.worker - INFO -          dashboard at:          10.6.101.60:34351
2025-09-05 09:11:44,721 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,721 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,721 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,721 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,721 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-7ilbp8_a
2025-09-05 09:11:44,721 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,723 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:39399
2025-09-05 09:11:44,723 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:39399
2025-09-05 09:11:44,723 - distributed.worker - INFO -          dashboard at:          10.6.101.60:44357
2025-09-05 09:11:44,723 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,723 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,723 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,724 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,724 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-7wqwqrtg
2025-09-05 09:11:44,724 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,748 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,749 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,749 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,750 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,752 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,753 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,754 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,754 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,754 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,755 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,755 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,755 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,757 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,758 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,758 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,760 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,760 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,761 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,761 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,762 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,762 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,764 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,764 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,765 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,765 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,766 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,766 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,766 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,767 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,768 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,768 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,768 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,769 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,769 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,769 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,770 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,770 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,771 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,772 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,772 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,773 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,773 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,774 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,774 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,775 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,775 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,775 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,776 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,777 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,777 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,777 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,778 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,779 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,779 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,779 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,779 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,781 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,781 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,781 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,782 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,819 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,820 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,820 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,822 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,823 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,824 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,824 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,826 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,826 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,827 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,827 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,828 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,831 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:33145
2025-09-05 09:11:44,831 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:33145
2025-09-05 09:11:44,831 - distributed.worker - INFO -          dashboard at:          10.6.101.60:32847
2025-09-05 09:11:44,831 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,831 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,831 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,831 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,831 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-39ycjb16
2025-09-05 09:11:44,831 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,831 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:40627
2025-09-05 09:11:44,831 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:40627
2025-09-05 09:11:44,831 - distributed.worker - INFO -          dashboard at:          10.6.101.60:42541
2025-09-05 09:11:44,831 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,831 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,831 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,831 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,831 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-o9nggdf0
2025-09-05 09:11:44,831 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,857 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,857 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,857 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,859 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,862 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,862 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,863 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,864 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,948 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:33293
2025-09-05 09:11:44,948 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:33293
2025-09-05 09:11:44,948 - distributed.worker - INFO -          dashboard at:          10.6.101.60:45257
2025-09-05 09:11:44,948 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,948 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,948 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,948 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,948 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-gd9halh_
2025-09-05 09:11:44,948 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,975 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:44,975 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:36041
2025-09-05 09:11:44,975 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:36041
2025-09-05 09:11:44,975 - distributed.worker - INFO -          dashboard at:          10.6.101.60:41519
2025-09-05 09:11:44,975 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,975 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,975 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,975 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,975 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-dt1fdf9a
2025-09-05 09:11:44,975 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,976 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,976 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,978 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:44,988 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:42249
2025-09-05 09:11:44,988 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:42249
2025-09-05 09:11:44,988 - distributed.worker - INFO -          dashboard at:          10.6.101.60:34475
2025-09-05 09:11:44,988 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:44,988 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:44,988 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:44,988 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:44,988 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-2elqp9fx
2025-09-05 09:11:44,988 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,004 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,005 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,005 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,006 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,007 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:39173
2025-09-05 09:11:45,007 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:39173
2025-09-05 09:11:45,007 - distributed.worker - INFO -          dashboard at:          10.6.101.60:46099
2025-09-05 09:11:45,007 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,007 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,007 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,008 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,008 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-_497eo5h
2025-09-05 09:11:45,008 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,009 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,009 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,009 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,009 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:44679
2025-09-05 09:11:45,009 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:44679
2025-09-05 09:11:45,009 - distributed.worker - INFO -          dashboard at:          10.6.101.60:46307
2025-09-05 09:11:45,009 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,009 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,009 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,009 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,009 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-5s7y082t
2025-09-05 09:11:45,009 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,010 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,010 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:43183
2025-09-05 09:11:45,010 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:43183
2025-09-05 09:11:45,010 - distributed.worker - INFO -          dashboard at:          10.6.101.60:42479
2025-09-05 09:11:45,010 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,010 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:33713
2025-09-05 09:11:45,010 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,010 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,010 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:33713
2025-09-05 09:11:45,010 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,010 - distributed.worker - INFO -          dashboard at:          10.6.101.60:40035
2025-09-05 09:11:45,010 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-0l4px_5p
2025-09-05 09:11:45,010 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,010 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,010 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,010 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,010 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,010 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ktd7cy5c
2025-09-05 09:11:45,011 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,017 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:37607
2025-09-05 09:11:45,017 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:37607
2025-09-05 09:11:45,017 - distributed.worker - INFO -          dashboard at:          10.6.101.60:40101
2025-09-05 09:11:45,017 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,017 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,017 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,017 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-uew_6vc9
2025-09-05 09:11:45,017 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,022 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,022 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,022 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,023 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,028 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,028 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,028 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,029 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,032 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,032 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,033 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,033 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,036 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,037 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,038 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,039 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,050 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,051 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,051 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,052 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,091 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:42161
2025-09-05 09:11:45,091 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:42161
2025-09-05 09:11:45,091 - distributed.worker - INFO -          dashboard at:          10.6.101.60:34991
2025-09-05 09:11:45,091 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,091 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,091 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,091 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,091 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ie68htm5
2025-09-05 09:11:45,091 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,107 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,107 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,107 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,108 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,121 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:38381
2025-09-05 09:11:45,121 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:38381
2025-09-05 09:11:45,121 - distributed.worker - INFO -          dashboard at:          10.6.101.60:36329
2025-09-05 09:11:45,121 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,121 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,121 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,121 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-u2kg8r93
2025-09-05 09:11:45,121 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,129 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:39013
2025-09-05 09:11:45,129 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:39013
2025-09-05 09:11:45,129 - distributed.worker - INFO -          dashboard at:          10.6.101.60:34895
2025-09-05 09:11:45,129 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,129 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,129 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,129 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,129 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-l8vzd49c
2025-09-05 09:11:45,130 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,133 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:34589
2025-09-05 09:11:45,133 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:34589
2025-09-05 09:11:45,133 - distributed.worker - INFO -          dashboard at:          10.6.101.60:40153
2025-09-05 09:11:45,133 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,133 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,133 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,133 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,133 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-8dmoq192
2025-09-05 09:11:45,133 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,147 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,147 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,147 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,149 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,152 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:36011
2025-09-05 09:11:45,152 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:36011
2025-09-05 09:11:45,152 - distributed.worker - INFO -          dashboard at:          10.6.101.60:39819
2025-09-05 09:11:45,152 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,152 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,152 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,152 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,152 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-rg3x3555
2025-09-05 09:11:45,152 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,153 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,153 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:44337
2025-09-05 09:11:45,153 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:44337
2025-09-05 09:11:45,153 - distributed.worker - INFO -          dashboard at:          10.6.101.60:44787
2025-09-05 09:11:45,153 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,153 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,153 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,153 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,153 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,153 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,153 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-vus31bpz
2025-09-05 09:11:45,153 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,154 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,154 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:41785
2025-09-05 09:11:45,154 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:41785
2025-09-05 09:11:45,154 - distributed.worker - INFO -          dashboard at:          10.6.101.60:46557
2025-09-05 09:11:45,154 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,154 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,154 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,154 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-vbs703a8
2025-09-05 09:11:45,154 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,155 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:42031
2025-09-05 09:11:45,155 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:42031
2025-09-05 09:11:45,155 - distributed.worker - INFO -          dashboard at:          10.6.101.60:38677
2025-09-05 09:11:45,155 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,155 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,155 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,155 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-hwun7l6u
2025-09-05 09:11:45,155 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,155 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:39257
2025-09-05 09:11:45,155 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:34531
2025-09-05 09:11:45,155 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:39257
2025-09-05 09:11:45,155 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:34531
2025-09-05 09:11:45,155 - distributed.worker - INFO -          dashboard at:          10.6.101.60:42963
2025-09-05 09:11:45,156 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,156 - distributed.worker - INFO -          dashboard at:          10.6.101.60:39355
2025-09-05 09:11:45,156 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,156 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,156 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,156 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,156 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,156 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,156 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-6h47md9a
2025-09-05 09:11:45,156 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,156 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,156 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-50gx00fv
2025-09-05 09:11:45,156 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,159 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,159 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:36717
2025-09-05 09:11:45,159 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:36717
2025-09-05 09:11:45,159 - distributed.worker - INFO -          dashboard at:          10.6.101.60:36495
2025-09-05 09:11:45,159 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,159 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,159 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,159 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,159 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-kindo9vt
2025-09-05 09:11:45,159 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,160 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,160 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,161 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:38603
2025-09-05 09:11:45,162 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:38603
2025-09-05 09:11:45,162 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,162 - distributed.worker - INFO -          dashboard at:          10.6.101.60:44021
2025-09-05 09:11:45,162 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,162 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,162 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,162 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,162 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-yc8o3goi
2025-09-05 09:11:45,162 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,166 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:46189
2025-09-05 09:11:45,166 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:46189
2025-09-05 09:11:45,166 - distributed.worker - INFO -          dashboard at:          10.6.101.60:43701
2025-09-05 09:11:45,166 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,166 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,166 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,166 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,166 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-b3iuny2k
2025-09-05 09:11:45,167 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,167 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:46227
2025-09-05 09:11:45,167 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:46227
2025-09-05 09:11:45,167 - distributed.worker - INFO -          dashboard at:          10.6.101.60:43613
2025-09-05 09:11:45,167 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,167 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,168 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,168 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,168 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-52d2insj
2025-09-05 09:11:45,168 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,174 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:38687
2025-09-05 09:11:45,174 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:38687
2025-09-05 09:11:45,174 - distributed.worker - INFO -          dashboard at:          10.6.101.60:44917
2025-09-05 09:11:45,174 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,174 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,174 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,174 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,174 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-gth344q4
2025-09-05 09:11:45,174 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,175 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:44555
2025-09-05 09:11:45,175 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:44555
2025-09-05 09:11:45,175 - distributed.worker - INFO -          dashboard at:          10.6.101.60:41093
2025-09-05 09:11:45,175 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,175 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:41057
2025-09-05 09:11:45,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,175 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,175 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:41057
2025-09-05 09:11:45,175 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,175 - distributed.worker - INFO -          dashboard at:          10.6.101.60:44871
2025-09-05 09:11:45,175 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-udozv_gv
2025-09-05 09:11:45,175 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,175 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,175 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,175 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-iadhb0pn
2025-09-05 09:11:45,175 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,178 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:36015
2025-09-05 09:11:45,178 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:36015
2025-09-05 09:11:45,178 - distributed.worker - INFO -          dashboard at:          10.6.101.60:44867
2025-09-05 09:11:45,178 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,178 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,178 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,178 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,178 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-0mp3nj9n
2025-09-05 09:11:45,179 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,179 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:45329
2025-09-05 09:11:45,179 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:45329
2025-09-05 09:11:45,179 - distributed.worker - INFO -          dashboard at:          10.6.101.60:42047
2025-09-05 09:11:45,179 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,179 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,179 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,179 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,179 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-ixulazt1
2025-09-05 09:11:45,179 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,179 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:42945
2025-09-05 09:11:45,180 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:42945
2025-09-05 09:11:45,180 - distributed.worker - INFO -          dashboard at:          10.6.101.60:38537
2025-09-05 09:11:45,180 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,180 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,180 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,180 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,180 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-_dw4uj2f
2025-09-05 09:11:45,180 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,181 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:33323
2025-09-05 09:11:45,181 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:33323
2025-09-05 09:11:45,181 - distributed.worker - INFO -          dashboard at:          10.6.101.60:41601
2025-09-05 09:11:45,181 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,181 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,181 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,181 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,181 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-m1qyb1tq
2025-09-05 09:11:45,182 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,182 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:34049
2025-09-05 09:11:45,182 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:34049
2025-09-05 09:11:45,182 - distributed.worker - INFO -          dashboard at:          10.6.101.60:39679
2025-09-05 09:11:45,182 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,182 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,182 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,182 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,182 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-59x_fzcb
2025-09-05 09:11:45,183 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,182 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,183 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,184 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,185 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,189 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,189 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:42947
2025-09-05 09:11:45,189 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:42947
2025-09-05 09:11:45,189 - distributed.worker - INFO -          dashboard at:          10.6.101.60:46033
2025-09-05 09:11:45,189 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,190 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,190 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,190 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,190 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-lediq8om
2025-09-05 09:11:45,190 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,190 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,190 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,191 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,193 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,194 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,194 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,196 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,197 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,198 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,198 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,199 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,200 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,201 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,201 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,203 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,203 - distributed.worker - INFO -       Start worker at:    tcp://10.6.101.60:38735
2025-09-05 09:11:45,203 - distributed.worker - INFO -          Listening to:    tcp://10.6.101.60:38735
2025-09-05 09:11:45,203 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,203 - distributed.worker - INFO -          dashboard at:          10.6.101.60:33547
2025-09-05 09:11:45,203 - distributed.worker - INFO - Waiting to connect to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,203 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,203 - distributed.worker - INFO -               Threads:                          2
2025-09-05 09:11:45,203 - distributed.worker - INFO -                Memory:                   9.62 GiB
2025-09-05 09:11:45,203 - distributed.worker - INFO -       Local Directory: /jobfs/148852475.gadi-pbs/dask-scratch-space/worker-oc2axe2p
2025-09-05 09:11:45,204 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,204 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,204 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,205 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,206 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,207 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,207 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,208 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,208 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,209 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,209 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,211 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,211 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,212 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,212 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,214 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,215 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,216 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,216 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,217 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,218 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,218 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,218 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,219 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,220 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,220 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,220 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,221 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,222 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,222 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,222 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,224 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,227 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,228 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,228 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,230 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,230 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,230 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,231 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,231 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,232 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,232 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,232 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,233 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,234 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,234 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,234 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,235 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,236 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,236 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,236 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,237 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,237 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,238 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,238 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,239 - distributed.worker - INFO - Starting Worker plugin shuffle
2025-09-05 09:11:45,240 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:11:45,240 - distributed.worker - INFO -         Registered to:     tcp://10.6.101.37:8753
2025-09-05 09:11:45,240 - distributed.worker - INFO - -------------------------------------------------
2025-09-05 09:11:45,242 - distributed.core - INFO - Starting established connection to tcp://10.6.101.37:8753
2025-09-05 09:12:06,687 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,687 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,687 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,687 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,687 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,687 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,688 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,688 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,688 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,688 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,689 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,689 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,689 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,689 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,689 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,689 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,690 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,690 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,690 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,690 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,690 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,690 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,690 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,690 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,690 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,690 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,690 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,691 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,691 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,691 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,691 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,690 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,691 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,694 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,694 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,694 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,694 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,694 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,692 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,694 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,695 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,693 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,693 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,696 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,694 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,694 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,694 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,694 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,695 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,695 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,695 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,696 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,696 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,695 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,696 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,696 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,697 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,700 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,702 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,703 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,703 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,704 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,704 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,704 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,705 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,705 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,705 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,706 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,706 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,706 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,706 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,706 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,707 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,707 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,707 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,707 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:06,703 - distributed.worker - INFO - Starting Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:12:06,715 - distributed.utils - INFO - Reload module qme_utils from .py file
2025-09-05 09:12:09,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,489 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,490 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,491 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,494 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,494 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,494 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,494 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,494 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,492 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,494 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,493 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,495 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,494 - distributed.worker - INFO - Starting Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:12:09,496 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,497 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,498 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,499 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,499 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,499 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,499 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,499 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,500 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,504 - distributed.utils - INFO - Reload module qme_vars from .py file
2025-09-05 09:12:09,873 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,873 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,873 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,874 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,874 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,874 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,874 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,874 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,874 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,874 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,874 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,875 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,875 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,875 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,875 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,875 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,875 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,875 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,875 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,875 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,876 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,876 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,876 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,876 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,876 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,876 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,876 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,876 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,876 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,877 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,877 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,877 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,877 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,877 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,877 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,877 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,877 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,878 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,878 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,878 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,878 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,878 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,878 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,878 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,878 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,878 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,878 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,878 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,878 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,878 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,879 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,879 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,879 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,879 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,879 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,879 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,879 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,879 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,879 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,879 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,879 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,879 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,879 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,879 - distributed.worker - INFO - Starting Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:12:09,880 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,880 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,880 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,880 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,880 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,880 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,880 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,880 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,881 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,881 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,881 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,881 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,881 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,881 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,882 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,882 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,882 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,882 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,882 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,882 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,882 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,882 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,883 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,884 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,884 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,884 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:09,885 - distributed.utils - INFO - Reload module qme_train from .py file
2025-09-05 09:12:10,331 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,331 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,331 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,331 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,331 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,331 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,332 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,332 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,332 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,332 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,332 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,332 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,332 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,332 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,333 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,333 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,334 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,334 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,334 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,334 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,334 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,334 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,334 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,334 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,334 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,335 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,335 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,335 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,335 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,335 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,335 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,336 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,336 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,336 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,336 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,336 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,336 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,336 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,336 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,337 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,337 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,337 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,337 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,337 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,337 - distributed.worker - INFO - Starting Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:12:10,337 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,337 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,337 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,337 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,338 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,338 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,338 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,339 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,340 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,340 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,340 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,340 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,340 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:12:10,340 - distributed.utils - INFO - Reload module qme_apply from .py file
2025-09-05 09:16:18,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.94s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,055 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,056 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,057 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,058 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,061 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,063 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.96s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,082 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,083 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:18,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:48,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:49,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,035 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:50,925 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:52,288 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:52,290 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,649 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:53,953 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,028 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,072 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,291 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,979 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:54,987 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,522 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:55,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:56,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:56,601 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:58,815 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.63s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:59,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:59,754 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:59,755 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:16:59,759 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,626 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,744 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,745 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:01,963 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,408 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:02,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,081 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,264 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:03,272 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:08,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:09,326 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:10,351 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,287 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,293 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:11,882 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,691 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,694 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,703 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,885 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:12,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,170 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,935 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:13,938 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,190 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:14,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:15,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.39s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,396 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,488 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,492 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,830 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:16,902 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,388 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,533 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,544 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:17,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,307 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,310 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,311 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,368 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:18,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:19,852 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:22,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:22,285 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:22,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:22,875 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:22,877 - distributed.core - INFO - Event loop was unresponsive in Worker for 17.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:22,880 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,640 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,643 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,676 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:30,677 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,347 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,517 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,934 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,941 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:31,942 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:32,228 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:32,233 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:33,598 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:33,602 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,098 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:34,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,034 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,037 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:35,656 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,113 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,657 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:36,734 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,222 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,227 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,227 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,387 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:38,562 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,036 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:39,040 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:40,121 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:40,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:40,969 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:41,461 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:45,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:46,757 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,534 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,538 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,542 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:50,874 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:51,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:52,315 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,349 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,472 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,473 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,683 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:53,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,008 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,187 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,192 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,205 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,581 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,771 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:54,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.77s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:57,555 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,131 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,146 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,146 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:58,147 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:17:59,013 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.88s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,277 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:00,278 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:03,591 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:09,378 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:09,383 - distributed.core - INFO - Event loop was unresponsive in Worker for 18.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:10,209 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:12,736 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:13,031 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:14,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:14,779 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,543 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,612 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:15,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,168 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,360 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,363 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:16,551 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,021 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,232 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,457 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,525 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.44s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,577 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,752 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,806 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:17,851 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.76s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.38s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,204 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.79s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:33,951 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,855 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,859 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:34,861 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.02s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,099 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,572 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.41s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,680 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,681 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,770 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,813 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:35,957 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.04s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,172 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,429 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,653 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:36,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:37,163 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,094 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.16s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,096 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,136 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,137 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:38,658 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:40,929 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.87s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:40,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:40,930 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:40,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,027 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.80s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:44,494 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,296 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,433 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.23s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,434 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,760 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:45,765 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,004 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,051 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,455 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.74s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,489 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,787 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:46,808 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,399 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,552 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,553 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:47,557 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,140 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,560 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:48,906 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.18s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:49,023 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.30s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,220 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,221 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,225 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,325 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.25s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:50,920 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:51,832 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.61s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:51,918 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:52,065 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:52,067 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.84s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:52,084 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.86s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:52,772 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:53,884 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:18:53,893 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,138 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,554 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:07,831 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.56s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,295 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,386 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.37s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:08,393 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,322 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.05s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,536 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:09,889 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.62s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:10,417 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.15s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,162 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:11,165 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,054 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.03s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,505 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,559 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,826 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:12,827 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,294 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,297 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,306 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:13,644 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.36s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,365 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,919 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.90s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:14,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:15,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:15,782 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:17,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:17,561 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:17,566 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:17,679 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:18,194 - distributed.core - INFO - Event loop was unresponsive in Worker for 14.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:19,712 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.43s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:20,928 - distributed.core - INFO - Event loop was unresponsive in Worker for 16.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:22,271 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:22,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.01s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:22,274 - distributed.core - INFO - Event loop was unresponsive in Worker for 19.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:27,404 - distributed.core - INFO - Event loop was unresponsive in Worker for 23.40s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:30,690 - distributed.core - INFO - Event loop was unresponsive in Worker for 26.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:33,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:33,937 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,872 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:34,873 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,201 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.08s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:35,202 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,348 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:36,558 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:37,266 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,713 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:38,819 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.67s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,573 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:39,586 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,083 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,083 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.93s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,085 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.98s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,088 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.00s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,114 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,380 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,486 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.34s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,490 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,496 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.35s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,692 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,931 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:40,932 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,047 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.95s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,421 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.29s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,704 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,705 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,814 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.66s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,817 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,821 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:41,823 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:42,324 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,097 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.97s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:43,689 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.59s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,606 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.50s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,609 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,610 - distributed.core - INFO - Event loop was unresponsive in Worker for 13.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:44,615 - distributed.core - INFO - Event loop was unresponsive in Worker for 15.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:46,280 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.19s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,403 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.32s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,405 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.31s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,789 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,912 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.82s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,917 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:47,980 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,922 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.64s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,965 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.68s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,972 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:48,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.71s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,778 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,779 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.69s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,781 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:49,785 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:50,377 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,701 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.42s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,707 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,791 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,797 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.81s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,798 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.52s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:51,926 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,175 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,177 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,180 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,181 - distributed.core - INFO - Event loop was unresponsive in Worker for 10.10s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,981 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,982 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,986 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:53,993 - distributed.core - INFO - Event loop was unresponsive in Worker for 8.72s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:19:57,743 - distributed.core - INFO - Event loop was unresponsive in Worker for 12.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:10,919 - distributed.worker - ERROR - Worker stream died during communication: tcp://10.6.101.37:42075
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1113, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2073, in gather_dep
    response = await get_data_from_worker(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 2876, in get_data_from_worker
    comm = await rpc.connect(worker)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
                ^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.60:37776 remote=tcp://10.6.101.37:42075>: ConnectionResetError: [Errno 104] Connection reset by peer
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:37087. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:45361. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:35643. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:36011. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:35125. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:42023. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,273 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:34085. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:37429. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:37259. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:34875. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:38831. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:39399. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:34323. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:33545. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,277 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:35065. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:42945. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:34049. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:44555. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:41785. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:39013. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:42031. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:36015. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,274 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:42947. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,277 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,278 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:38603. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:45329. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:41057. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:36963. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:39257. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:42161. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,276 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:36041. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,279 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:39173. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:38381. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,275 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:33145. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:43183. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:43795. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:42249. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:34265. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,280 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:46227. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:46189. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:37607. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:33713. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:38735. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,281 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:44679. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,282 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:38687. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,295 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:33875'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,297 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:44943'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,297 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:40705'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,297 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:34047'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,297 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:35139'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,298 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:46755'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,298 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:35687'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6915, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:40171'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:36597, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:42489'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3222, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:40015'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2108, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:36879, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3106, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.54:36701, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,298 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3047, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4711, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3134, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 804, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1510, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5502, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2513, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2954, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.37:38377, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1034, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3673, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1692, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2960, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.49:43829, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.37:45535, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,299 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1656, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1319, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,300 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1681, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,300 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,301 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,302 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,306 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:33383'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:37395'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:37851'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:36867'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:39923'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:41235'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:44135'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:34191'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,307 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:38863'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:42483'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1638, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:41389'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:45019'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1618, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:45515'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:38053'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 571, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 4710, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:42791'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1916, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2094, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 552, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3191, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,308 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:43341'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,308 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3212, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3752, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3218, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:41579'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1693, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1697, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:38651'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:37283'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5707, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3206, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:37877, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1210, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:40207'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5639, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:33509'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5186, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2093, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1040, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,309 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.44:44347, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6916, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1694, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:42499'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5519, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:46089'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2492, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.39:40125, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:34453, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3594, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1661, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2964, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.60:34589, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.54:44295, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2181, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,310 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,310 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:40959'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,310 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1683, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2508, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.66:40799, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1212, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3611, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 580, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2551, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1645, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.64:38589, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1328, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:39741'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,311 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2522, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 791, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,311 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2426, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3011, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 792, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2125, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2957, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:37719'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 6244, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1690, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2859, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,312 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:34453, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:32917'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5640, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.63:39903, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,313 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.60:34531, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,313 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:43157'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,313 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:42581'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 621, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:33253'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,314 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1350, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,314 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5332, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:35217'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3839, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3953, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.58:46017, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,315 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:38227'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,316 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3966, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,316 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 601, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2176, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:40217'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3159, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,317 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.66:40711, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,317 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:45877'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:11,317 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1216, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,318 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5602, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,318 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 5334, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 1189, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.41:43297, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.37:39553, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,319 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name='gather_dep(tcp://10.6.101.55:39811, {...})' coro=<Worker.gather_dep() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 3559, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 2505, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,320 - distributed.worker.state_machine - WARNING - Async instruction for <Task cancelled name="execute(('mean_chunk-4bd2b8670bc0f309eefca402291e2c5c', 7206, 0, 0))" coro=<Worker.execute() done, defined at /g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker_state_machine.py:3607>> ended with CancelledError
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,321 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,322 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,323 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,324 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:11,325 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:11,326 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:11,326 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:11,341 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:12,230 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,057 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,058 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,344 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:13,379 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:13,382 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:36717. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,394 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.24s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:13,399 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.60:44874 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:13,406 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:42693'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,407 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:13,407 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:13,407 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:13,407 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:13,407 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:13,414 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,715 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:13,718 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:34531. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,718 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:13,720 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:33323. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.57s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:13,728 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.58s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:13,734 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.60:44990 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:13,734 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.60:44866 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:13,738 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:41517'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,739 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:13,739 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:13,739 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:41875'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,739 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:13,740 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:13,740 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:13,740 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:13,740 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:13,740 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:13,740 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:13,740 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:13,746 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,746 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,748 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:13,750 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:38385. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,758 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.60:38385 -> tcp://10.6.101.53:35537
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.60:38385 remote=tcp://10.6.101.53:33530>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-05 09:20:13,762 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,763 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,763 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,763 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.60s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:13,768 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.60:44662 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:13,780 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:44259'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,781 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:13,781 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:13,781 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:13,781 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:13,781 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:13,789 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,802 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:13,804 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:40627. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,804 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,812 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.65s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:13,817 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.60:44708 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:13,820 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:34929'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:13,821 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:13,821 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:13,821 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:13,821 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:13,821 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:13,829 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,865 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:13,873 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:39741'. Reason: nanny-close-gracefully
2025-09-05 09:20:13,876 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:39741' closed.
2025-09-05 09:20:14,088 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:14,223 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:14,235 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:14,651 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:40959'. Reason: nanny-close-gracefully
2025-09-05 09:20:14,652 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:40959' closed.
2025-09-05 09:20:14,759 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:15,061 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,063 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,418 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,457 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:45019'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,459 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:45019' closed.
2025-09-05 09:20:15,473 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:15,506 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:43157'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,507 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:43157' closed.
2025-09-05 09:20:15,749 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,749 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,766 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,768 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,792 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,809 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,813 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:42693'. Reason: nanny-close-gracefully
2025-09-05 09:20:15,814 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:42693' closed.
2025-09-05 09:20:15,831 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:15,869 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,001 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,001 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,002 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,063 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,093 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,115 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,172 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:44259'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,173 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:44259' closed.
2025-09-05 09:20:16,213 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:41517'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,224 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:41517' closed.
2025-09-05 09:20:16,227 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,244 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:41875'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,245 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:34929'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,245 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:37395'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,246 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:41875' closed.
2025-09-05 09:20:16,247 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:34929' closed.
2025-09-05 09:20:16,247 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:37395' closed.
2025-09-05 09:20:16,249 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:45877'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,249 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:45877' closed.
2025-09-05 09:20:16,281 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:38227'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,282 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:38227' closed.
2025-09-05 09:20:16,352 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:33383'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,354 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:33383' closed.
2025-09-05 09:20:16,381 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:36867'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,383 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:36867' closed.
2025-09-05 09:20:16,397 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:16,399 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:34589. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,409 - distributed.worker - ERROR - failed during get data with tcp://10.6.101.60:34589 -> tcp://10.6.101.63:43443
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 962, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/iostream.py", line 1121, in write_to_fd
    return self.socket.send(data)  # type: ignore
           ^^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1795, in get_data
    response = await comm.read(deserializers=serializers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://10.6.101.60:34589 remote=tcp://10.6.101.63:44562>: BrokenPipeError: [Errno 32] Broken pipe
2025-09-05 09:20:16,414 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:16,419 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.60:44830 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:16,423 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:36715'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:16,423 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:16,424 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:16,424 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:16,424 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:16,424 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:16,426 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x14f702d9ae50>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:16,436 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,520 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:46755'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,522 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:46755' closed.
2025-09-05 09:20:16,597 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,599 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:37851'. Reason: nanny-close-gracefully
2025-09-05 09:20:16,600 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:37851' closed.
2025-09-05 09:20:16,763 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:16,791 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,925 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:16,936 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,019 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,151 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:41579'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,152 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:41579' closed.
2025-09-05 09:20:17,274 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,274 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,353 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,354 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,357 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,477 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:17,720 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,873 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:38053'. Reason: nanny-close-gracefully
2025-09-05 09:20:17,875 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:38053' closed.
2025-09-05 09:20:17,939 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,988 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,988 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:17,991 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,005 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,005 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,007 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,067 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,119 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,337 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:18,339 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:44337. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:18,350 - distributed.core - INFO - Event loop was unresponsive in Worker for 9.20s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:18,357 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.60:44848 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:18,361 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:33431'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:18,361 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:18,362 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:18,362 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:18,362 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:18,362 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:18,364 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x1527d66e6910>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:18,370 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,398 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:37283'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,399 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:37283' closed.
2025-09-05 09:20:18,406 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:33509'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,407 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:33509' closed.
2025-09-05 09:20:18,440 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,450 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:35687'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,450 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:40015'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,451 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:35687' closed.
2025-09-05 09:20:18,452 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:40015' closed.
2025-09-05 09:20:18,508 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,602 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,614 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:41389'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,616 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:41389' closed.
2025-09-05 09:20:18,795 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,855 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:36715'. Reason: nanny-close-gracefully
2025-09-05 09:20:18,857 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:36715' closed.
2025-09-05 09:20:18,930 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,935 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:18,939 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:18,976 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,006 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:33875'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,007 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:33875' closed.
2025-09-05 09:20:19,023 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,108 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,174 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:34191'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,175 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:34191' closed.
2025-09-05 09:20:19,278 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,278 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,358 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,359 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,372 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,416 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:46089'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,418 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:35217'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,419 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:46089' closed.
2025-09-05 09:20:19,420 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:35217' closed.
2025-09-05 09:20:19,424 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:40207'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,425 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:40207' closed.
2025-09-05 09:20:19,624 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,627 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:38863'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,694 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:38863' closed.
2025-09-05 09:20:19,702 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,704 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,705 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:19,724 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,732 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:39923'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,734 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:39923' closed.
2025-09-05 09:20:19,783 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:40217'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,785 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:40217' closed.
2025-09-05 09:20:19,810 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:38651'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,811 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:38651' closed.
2025-09-05 09:20:19,815 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:35139'. Reason: nanny-close-gracefully
2025-09-05 09:20:19,816 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:35139' closed.
2025-09-05 09:20:19,943 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,992 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,995 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:19,998 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,105 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:40171'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,106 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:40171' closed.
2025-09-05 09:20:20,166 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,233 - distributed.core - INFO - Connection to tcp://10.6.101.37:8753 has been closed.
2025-09-05 09:20:20,235 - distributed.worker - INFO - Stopping worker at tcp://10.6.101.60:33293. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:20,245 - distributed.core - INFO - Event loop was unresponsive in Worker for 11.09s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2025-09-05 09:20:20,252 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Worker->Scheduler local=tcp://10.6.101.60:44724 remote=tcp://10.6.101.37:8753>
Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
             ^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/tornado/gen.py", line 769, in run
    value = future.result()
            ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2025-09-05 09:20:20,256 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.6.101.60:42749'. Reason: worker-handle-scheduler-connection-broken
2025-09-05 09:20:20,257 - distributed.worker - INFO - Removing Worker plugin shuffle
2025-09-05 09:20:20,257 - distributed.worker - INFO - Removing Worker plugin qme_utils.py58b91349-375a-4f80-bc64-63a3345a5cc3
2025-09-05 09:20:20,257 - distributed.worker - INFO - Removing Worker plugin qme_vars.py3d9d9dae-18a4-4d2b-8fe5-6399b8b58b13
2025-09-05 09:20:20,257 - distributed.worker - INFO - Removing Worker plugin qme_train.pya33d068a-7082-4018-b81a-ff9e770713f8
2025-09-05 09:20:20,257 - distributed.worker - INFO - Removing Worker plugin qme_apply.py255bb687-8c19-490c-a9b0-654072a80cf5
2025-09-05 09:20:20,258 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
ConnectionRefusedError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 342, in connect
    comm = await wait_for(
           ^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils.py", line 1923, in wait_for
    return await fut
           ^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 560, in connect
    convert_stream_closed_error(self, e)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/tcp.py", line 143, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x15123129e8d0>: ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/comm/core.py", line 366, in connect
    await asyncio.sleep(backoff)
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/tasks.py", line 649, in sleep
    return await future
           ^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/worker.py", line 1267, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 416, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/utils_comm.py", line 395, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.06/lib/python3.11/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2025-09-05 09:20:20,264 - distributed.nanny - INFO - Worker closed
2025-09-05 09:20:20,373 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,378 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:40705'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,379 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:40705' closed.
2025-09-05 09:20:20,385 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:44943'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,386 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:44943' closed.
2025-09-05 09:20:20,395 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:42791'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,396 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:42791' closed.
2025-09-05 09:20:20,466 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:42483'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,467 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:42483' closed.
2025-09-05 09:20:20,512 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,787 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:33431'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,788 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:33431' closed.
2025-09-05 09:20:20,939 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:20,959 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:42489'. Reason: nanny-close-gracefully
2025-09-05 09:20:20,960 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:42489' closed.
2025-09-05 09:20:20,980 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,112 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,376 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,413 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:34047'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,414 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:34047' closed.
2025-09-05 09:20:21,421 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:42499'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,421 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:42499' closed.
2025-09-05 09:20:21,501 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:37719'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,502 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:37719' closed.
2025-09-05 09:20:21,629 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,706 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,708 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:21,768 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:41235'. Reason: nanny-close-gracefully
2025-09-05 09:20:21,769 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:41235' closed.
2025-09-05 09:20:22,107 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:42581'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,108 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:42581' closed.
2025-09-05 09:20:22,114 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:32917'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,116 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:45515'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,117 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:32917' closed.
2025-09-05 09:20:22,117 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:45515' closed.
2025-09-05 09:20:22,126 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:43341'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,127 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:43341' closed.
2025-09-05 09:20:22,170 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,204 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:44135'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,204 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:44135' closed.
2025-09-05 09:20:22,268 - distributed.nanny - ERROR - Worker process died unexpectedly
2025-09-05 09:20:22,587 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:33253'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,588 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:33253' closed.
2025-09-05 09:20:22,662 - distributed.nanny - INFO - Closing Nanny at 'tcp://10.6.101.60:42749'. Reason: nanny-close-gracefully
2025-09-05 09:20:22,663 - distributed.nanny - INFO - Nanny at 'tcp://10.6.101.60:42749' closed.
2025-09-05 09:20:22,666 - distributed.dask_worker - INFO - End worker
